{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) física(s), 1 GPU(s) lógica(s)\n",
      "Funciona\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"GPU(s) física(s),\", len(logical_gpus), \"GPU(s) lógica(s)\")\n",
    "        print(\"Funciona\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd #cargar los dataset\n",
    "#from bs4 import BeautifulSoup\n",
    "import random #mezclar datos\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub # para obtener el modelo pre-entrenado de BERT\n",
    "from tensorflow.keras import layers\n",
    "import bert\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "import random\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Datasets : ISEAR, MELD y IEMOCAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  CITY  COUN  SUBJ  SEX  AGE  RELI  PRAC  FOCC  MOCC  ...  SELF  RELA  \\\n",
      "0  11001     1     1     1    1   33     1     2     6     1  ...     3     3   \n",
      "1  11001     1     1     1    1   33     1     2     6     1  ...     2     2   \n",
      "2  11001     1     1     1    1   33     1     2     6     1  ...     2     1   \n",
      "3  11001     1     1     1    1   33     1     2     6     1  ...     1     1   \n",
      "4  11001     1     1     1    1   33     1     2     6     1  ...     0     2   \n",
      "\n",
      "   VERBAL  NEUTRO   Field1  Field3  Field2   MYKEY  \\\n",
      "0       2       0      joy       4       3  110011   \n",
      "1       0       0     fear       3       2  110012   \n",
      "2       0       0    anger       1       3  110013   \n",
      "3       0       2  sadness       4       4  110014   \n",
      "4       0       0  disgust       4       4  110015   \n",
      "\n",
      "                                                 SIT  STATE  \n",
      "0  During the period of falling in love, each tim...      1  \n",
      "1         When I was involved in a traffic accident.      1  \n",
      "2  When I was driving home after  several days of...      1  \n",
      "3  When I lost the person who meant the most to me.       1  \n",
      "4  The time I knocked a deer down - the sight of ...      1  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "isear = pd.read_excel('E:\\des\\DATASET TEXT\\ISEAR.xlsx')\n",
    "\n",
    "\n",
    "print(isear.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>guilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto    label\n",
       "0     During the period of falling in love, each tim...      joy\n",
       "1            When I was involved in a traffic accident.     fear\n",
       "2     When I was driving home after  several days of...    anger\n",
       "3     When I lost the person who meant the most to me.   sadness\n",
       "4     The time I knocked a deer down - the sight of ...  disgust\n",
       "...                                                 ...      ...\n",
       "7661  Two years back someone invited me to be the tu...    anger\n",
       "7662  I had taken the responsibility to do something...  sadness\n",
       "7663  I was at home and I heard a loud sound of spit...  disgust\n",
       "7664  I did not do the homework that the teacher had...    shame\n",
       "7665  I had shouted at my younger brother and he was...    guilt\n",
       "\n",
       "[7666 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isearDataset = isear.iloc[:, [40,36]]\n",
    "isearDataset = isearDataset.rename(columns={'Field1': 'label', 'SIT': 'texto'})\n",
    "isearDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarAcentos(texto):\n",
    "    texto = texto.replace('á', '')\n",
    "    texto = texto.replace('\\n', '')\n",
    "    return texto\n",
    "isearDataset['texto'] = isearDataset['texto'].apply(eliminarAcentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>I received a letter from a distant friend.</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>My parents were out and I was the eldest at ho...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5475</th>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto    label\n",
       "0     During the period of falling in love, each tim...    happy\n",
       "1            When I was involved in a traffic accident.     fear\n",
       "2     When I was driving home after  several days of...    angry\n",
       "3     When I lost the person who meant the most to me.       sad\n",
       "4     The time I knocked a deer down - the sight of ...  disgust\n",
       "...                                                 ...      ...\n",
       "5472         I received a letter from a distant friend.    happy\n",
       "5473  My parents were out and I was the eldest at ho...     fear\n",
       "5474  Two years back someone invited me to be the tu...    angry\n",
       "5475  I had taken the responsibility to do something...      sad\n",
       "5476  I was at home and I heard a loud sound of spit...  disgust\n",
       "\n",
       "[5477 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isearDataset = isearDataset.replace(to_replace=['joy', 'anger', 'sadness'], value=['happy', 'angry', 'sad']) #Reemplazar nombres de datos\n",
    "isearDataset = isearDataset.drop(isearDataset[isearDataset['label']== 'shame'].index) #Eliminar nombres de datos de emociones que no se ocupan\n",
    "isearDataset = isearDataset.drop(isearDataset[isearDataset['label']== 'guilt'].index)\n",
    "isearDataset = isearDataset.drop(isearDataset[isearDataset['label']== 'guit'].index)\n",
    "isearDataset = isearDataset.reset_index(drop=True)\n",
    "isearDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMeld=pd.read_csv('meld_train.csv')\n",
    "\n",
    "label = dfMeld['Emotion']\n",
    "text = dfMeld['Utterance']\n",
    "\n",
    "data = {\n",
    "    'texto' : text.tolist(),\n",
    "    'label' : label.tolist()\n",
    "}\n",
    "\n",
    "dfMeld= pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>You or me?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>You guys are messing with me, right?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>That was a good one. For a second there, I was...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto     label\n",
       "0     also I was the point person on my companys tr...   neutral\n",
       "1                      You mustve had your hands full.   neutral\n",
       "2                               That I did. That I did.   neutral\n",
       "3         So lets talk a little bit about your duties.   neutral\n",
       "4                                My duties?  All right.  surprise\n",
       "...                                                 ...       ...\n",
       "9984                                         You or me?   neutral\n",
       "9985  I got it. Uh, Joey, women don't have Adam's ap...   neutral\n",
       "9986               You guys are messing with me, right?  surprise\n",
       "9987                                              Yeah.   neutral\n",
       "9988  That was a good one. For a second there, I was...     happy\n",
       "\n",
       "[9989 rows x 2 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMeld = dfMeld.replace(to_replace=['joy', 'sadness', 'anger'], value=['happy', 'sad', 'angry'])\n",
    "dfMeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>You or me?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>You guys are messing with me, right?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>That was a good one. For a second there, I was...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto     label\n",
       "0     also I was the point person on my company's tr...   neutral\n",
       "1                      You must've had your hands full.   neutral\n",
       "2                               That I did. That I did.   neutral\n",
       "3         So let's talk a little bit about your duties.   neutral\n",
       "4                                My duties?  All right.  surprise\n",
       "...                                                 ...       ...\n",
       "9984                                         You or me?   neutral\n",
       "9985  I got it. Uh, Joey, women don't have Adam's ap...   neutral\n",
       "9986               You guys are messing with me, right?  surprise\n",
       "9987                                              Yeah.   neutral\n",
       "9988  That was a good one. For a second there, I was...     happy\n",
       "\n",
       "[9989 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eliminarAcentos(texto):\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "    return texto\n",
    "dfMeld['texto'] = dfMeld['texto'].apply(eliminarAcentos)\n",
    "dfMeld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Emoción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well what's the problem? Let me change it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>oh! Marry you again? I wouldn't marry you agai...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>Beast</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>You're a wicked little vampire. And I pray to ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>Brute</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>pig</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4637 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Texto  Emoción\n",
       "0                                            Excuse me.  neutral\n",
       "1                                                 Yeah.  neutral\n",
       "2                                   Is there a problem?  neutral\n",
       "3            Well what's the problem? Let me change it.  neutral\n",
       "4                                That's out of control.    angry\n",
       "...                                                 ...      ...\n",
       "4632  oh! Marry you again? I wouldn't marry you agai...    angry\n",
       "4633                                              Beast    angry\n",
       "4634  You're a wicked little vampire. And I pray to ...    angry\n",
       "4635                                              Brute    angry\n",
       "4636                                                pig    angry\n",
       "\n",
       "[4637 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocapDataset = pd.read_csv('df_filters.csv')\n",
    "iemocapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'angry', 'sad', 'happy', 'surprise', 'fear', 'disgust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocapDataset['Emoción'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well what's the problem? Let me change it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>oh! Marry you again? I wouldn't marry you agai...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>Beast</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>You're a wicked little vampire. And I pray to ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>Brute</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>pig</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4637 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto    label\n",
       "0                                            Excuse me.  neutral\n",
       "1                                                 Yeah.  neutral\n",
       "2                                   Is there a problem?  neutral\n",
       "3            Well what's the problem? Let me change it.  neutral\n",
       "4                                That's out of control.    angry\n",
       "...                                                 ...      ...\n",
       "4632  oh! Marry you again? I wouldn't marry you agai...    angry\n",
       "4633                                              Beast    angry\n",
       "4634  You're a wicked little vampire. And I pray to ...    angry\n",
       "4635                                              Brute    angry\n",
       "4636                                                pig    angry\n",
       "\n",
       "[4637 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocapDataset = iemocapDataset.rename(columns={'Emoción': 'label', 'Texto':'texto'})\n",
    "iemocapDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20098</th>\n",
       "      <td>oh! Marry you again? I wouldn't marry you agai...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20099</th>\n",
       "      <td>Beast</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20100</th>\n",
       "      <td>You're a wicked little vampire. And I pray to ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20101</th>\n",
       "      <td>Brute</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20102</th>\n",
       "      <td>pig</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto     label\n",
       "0      also I was the point person on my company's tr...   neutral\n",
       "1                       You must've had your hands full.   neutral\n",
       "2                                That I did. That I did.   neutral\n",
       "3          So let's talk a little bit about your duties.   neutral\n",
       "4                                 My duties?  All right.  surprise\n",
       "...                                                  ...       ...\n",
       "20098  oh! Marry you again? I wouldn't marry you agai...     angry\n",
       "20099                                              Beast     angry\n",
       "20100  You're a wicked little vampire. And I pray to ...     angry\n",
       "20101                                              Brute     angry\n",
       "20102                                                pig     angry\n",
       "\n",
       "[20103 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftodo = pd.concat([dfMeld, isearDataset,iemocapDataset])\n",
    "dftodo = dftodo.reset_index(drop=True)\n",
    "dftodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     6417\n",
       "happy       3432\n",
       "angry       3308\n",
       "sad         2862\n",
       "fear        1403\n",
       "disgust     1369\n",
       "surprise    1312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftodo['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='Count'>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=dftodo['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yeah, sure!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hey, Mon.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey-hey-hey. You wanna hear something that sucks.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do I ever.</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chris says they're closing down the bar.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No way!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yeah, apparently they're turning it into some ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Just coffee! Where are we gonna hang out now?</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Got me.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Can I get a beer.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hey, did you pick a roommate?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You betcha!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Is it the Italian guy?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Um-mm, yeah right!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oh my God, oh my God! Poor Monica!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texto     label\n",
       "20                                        Yeah, sure!   neutral\n",
       "21                                          Hey, Mon.   neutral\n",
       "22  Hey-hey-hey. You wanna hear something that sucks.   neutral\n",
       "23                                         Do I ever.     happy\n",
       "24           Chris says they're closing down the bar.       sad\n",
       "25                                            No way!  surprise\n",
       "26  Yeah, apparently they're turning it into some ...   neutral\n",
       "27      Just coffee! Where are we gonna hang out now?   disgust\n",
       "28                                            Got me.       sad\n",
       "29                                  Can I get a beer.   neutral\n",
       "30                      Hey, did you pick a roommate?   neutral\n",
       "31                                        You betcha!     happy\n",
       "32                             Is it the Italian guy?   neutral\n",
       "33                                 Um-mm, yeah right!     happy\n",
       "34                 Oh my God, oh my God! Poor Monica!  surprise"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftodo[20:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44914</th>\n",
       "      <td>Oh my God, I remember now! We were playing chess!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44915</th>\n",
       "      <td>What?! What else did he say?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44916</th>\n",
       "      <td>What?  Why?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44917</th>\n",
       "      <td>How do you lose a suitcase? A huge suitcase?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44918</th>\n",
       "      <td>Okay, what is in here? Rocks?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto     label\n",
       "0      also I was the point person on my company's tr...   neutral\n",
       "1                       You must've had your hands full.   neutral\n",
       "2                                That I did. That I did.   neutral\n",
       "3          So let's talk a little bit about your duties.   neutral\n",
       "4                                 My duties?  All right.  surprise\n",
       "...                                                  ...       ...\n",
       "44914  Oh my God, I remember now! We were playing chess!  surprise\n",
       "44915                       What?! What else did he say?  surprise\n",
       "44916                                        What?  Why?  surprise\n",
       "44917       How do you lose a suitcase? A huge suitcase?  surprise\n",
       "44918                      Okay, what is in here? Rocks?  surprise\n",
       "\n",
       "[44919 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = random.fit_resample(dftodo[['texto']], dftodo['label'])\n",
    "\n",
    "# Crear un nuevo dataframe con los datos sobremuestreados\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=['texto'])\n",
    "df_resampled['label'] = y_resampled\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     6417\n",
       "surprise    6417\n",
       "fear        6417\n",
       "sad         6417\n",
       "happy       6417\n",
       "disgust     6417\n",
       "angry       6417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='Count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=df_resampled['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryan\\anaconda3\\envs\\GPU_IEMOCAP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\bryan\\AppData\\Local\\Temp\\ipykernel_1336\\3238353294.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clase['original'] = df_clase['texto']\n",
      "100%|██████████| 7/7 [00:53<00:00,  7.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.word as naw\n",
    "from tqdm import tqdm\n",
    "\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "conteo_clases = dftodo['label'].value_counts()\n",
    "\n",
    "clase_mayoritaria = conteo_clases.idxmax()\n",
    "conteo_mayoritario = conteo_clases.max()\n",
    "\n",
    "df_balanceado = pd.DataFrame(columns=['texto', 'label', 'original'])\n",
    "\n",
    "\n",
    "for clase in tqdm(dftodo['label'].unique()):\n",
    "    df_clase = dftodo[dftodo['label'] == clase]\n",
    "    \n",
    "    if clase == clase_mayoritaria:\n",
    "        df_clase['original'] = df_clase['texto']  \n",
    "        df_balanceado = pd.concat([df_balanceado, df_clase])\n",
    "    else:\n",
    "        datos_faltantes = conteo_mayoritario - len(df_clase)\n",
    "        \n",
    "\n",
    "        datos_sinteticos = df_clase.sample(datos_faltantes, replace=True)\n",
    "        datos_sinteticos['original'] = datos_sinteticos['texto']  \n",
    "        datos_sinteticos['texto'] = datos_sinteticos['texto'].apply(aug.augment) \n",
    "        \n",
    "        df_balanceado = pd.concat([df_balanceado, df_clase, datos_sinteticos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     6417\n",
       "surprise    6417\n",
       "fear        6417\n",
       "sad         6417\n",
       "happy       6417\n",
       "disgust     6417\n",
       "angry       6417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanceado['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>You must've had your hands full.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44914</th>\n",
       "      <td>[One had too much prep and examinations and Si...</td>\n",
       "      <td>angry</td>\n",
       "      <td>I had too much homework and examinations and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44915</th>\n",
       "      <td>[Sob!]</td>\n",
       "      <td>angry</td>\n",
       "      <td>Bastard!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44916</th>\n",
       "      <td>[This is ridiculous. I - I seriously, I don ' ...</td>\n",
       "      <td>angry</td>\n",
       "      <td>This is ridiculous. I- I seriously, I don't un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44917</th>\n",
       "      <td>[What do you need to coif, contend with him?]</td>\n",
       "      <td>angry</td>\n",
       "      <td>What do you want to do, argue with him?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44918</th>\n",
       "      <td>[Made fault in examination.]</td>\n",
       "      <td>angry</td>\n",
       "      <td>Made mistakes in exam.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto    label  \\\n",
       "0      also I was the point person on my company's tr...  neutral   \n",
       "1                       You must've had your hands full.  neutral   \n",
       "2                                That I did. That I did.  neutral   \n",
       "3          So let's talk a little bit about your duties.  neutral   \n",
       "4      Now you'll be heading a whole division, so you...  neutral   \n",
       "...                                                  ...      ...   \n",
       "44914  [One had too much prep and examinations and Si...    angry   \n",
       "44915                                             [Sob!]    angry   \n",
       "44916  [This is ridiculous. I - I seriously, I don ' ...    angry   \n",
       "44917      [What do you need to coif, contend with him?]    angry   \n",
       "44918                       [Made fault in examination.]    angry   \n",
       "\n",
       "                                                original  \n",
       "0      also I was the point person on my company's tr...  \n",
       "1                       You must've had your hands full.  \n",
       "2                                That I did. That I did.  \n",
       "3          So let's talk a little bit about your duties.  \n",
       "4      Now you'll be heading a whole division, so you...  \n",
       "...                                                  ...  \n",
       "44914  I had too much homework and examinations and I...  \n",
       "44915                                           Bastard!  \n",
       "44916  This is ridiculous. I- I seriously, I don't un...  \n",
       "44917            What do you want to do, argue with him?  \n",
       "44918                             Made mistakes in exam.  \n",
       "\n",
       "[44919 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanceado = df_balanceado.reset_index(drop=True)\n",
    "df_balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Oh, yeah, Bob said there might be flood damage.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Oh, yeah, Bob said there might be flood damage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Yeah, either that, or he has a really big cat.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Yeah, either that, or he has a really big cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>If you said, \"Big lima bean, bubbling up.\" Wou...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you said, \"Big lima bean, bubbling up.\" Wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Rach? What are you doing?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Rach? What are you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>It's a diaper commercial.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>It's a diaper commercial.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Hey, you wanna get something to eat or uh, do ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hey, you wanna get something to eat or uh, do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Uhh, the ball thing.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Uhh, the ball thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Yeah?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Yeah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Uhh,</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Uhh,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>What?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Hey.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hey.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hey!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>How did it go with Erin?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>How did it go with Erin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Y'know?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Y'know?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>That was so awkward, we were really nervous.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>That was so awkward, we were really nervous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Didn't you sleep together?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Didn't you sleep together?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yeah, that really calms me down.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Yeah, that really calms me down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Okay.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I cannot sleep in a public place.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I cannot sleep in a public place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It's okay, y'know, you just nodded off again.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>It's okay, y'know, you just nodded off again.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texto    label  \\\n",
       "80    Oh, yeah, Bob said there might be flood damage.  neutral   \n",
       "81     Yeah, either that, or he has a really big cat.  neutral   \n",
       "82  If you said, \"Big lima bean, bubbling up.\" Wou...  neutral   \n",
       "83                          Rach? What are you doing?  neutral   \n",
       "84                          It's a diaper commercial.  neutral   \n",
       "85  Hey, you wanna get something to eat or uh, do ...  neutral   \n",
       "86                               Uhh, the ball thing.  neutral   \n",
       "87                                              Yeah?  neutral   \n",
       "88                                               Uhh,  neutral   \n",
       "89                                              What?  neutral   \n",
       "90                                               Hey.  neutral   \n",
       "91                                               Hey!  neutral   \n",
       "92                           How did it go with Erin?  neutral   \n",
       "93                                            Y'know?  neutral   \n",
       "94       That was so awkward, we were really nervous.  neutral   \n",
       "95                         Didn't you sleep together?  neutral   \n",
       "96                   Yeah, that really calms me down.  neutral   \n",
       "97                                              Okay.  neutral   \n",
       "98                  I cannot sleep in a public place.  neutral   \n",
       "99      It's okay, y'know, you just nodded off again.  neutral   \n",
       "\n",
       "                                             original  \n",
       "80    Oh, yeah, Bob said there might be flood damage.  \n",
       "81     Yeah, either that, or he has a really big cat.  \n",
       "82  If you said, \"Big lima bean, bubbling up.\" Wou...  \n",
       "83                          Rach? What are you doing?  \n",
       "84                          It's a diaper commercial.  \n",
       "85  Hey, you wanna get something to eat or uh, do ...  \n",
       "86                               Uhh, the ball thing.  \n",
       "87                                              Yeah?  \n",
       "88                                               Uhh,  \n",
       "89                                              What?  \n",
       "90                                               Hey.  \n",
       "91                                               Hey!  \n",
       "92                           How did it go with Erin?  \n",
       "93                                            Y'know?  \n",
       "94       That was so awkward, we were really nervous.  \n",
       "95                         Didn't you sleep together?  \n",
       "96                   Yeah, that really calms me down.  \n",
       "97                                              Okay.  \n",
       "98                  I cannot sleep in a public place.  \n",
       "99      It's okay, y'know, you just nodded off again.  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanceado[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44914</th>\n",
       "      <td>[One had too much prep and examinations and Si...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44915</th>\n",
       "      <td>[Sob!]</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44916</th>\n",
       "      <td>[This is ridiculous. I - I seriously, I don ' ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44917</th>\n",
       "      <td>[What do you need to coif, contend with him?]</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44918</th>\n",
       "      <td>[Made fault in examination.]</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto    label\n",
       "0      also I was the point person on my company's tr...  neutral\n",
       "1                       You must've had your hands full.  neutral\n",
       "2                                That I did. That I did.  neutral\n",
       "3          So let's talk a little bit about your duties.  neutral\n",
       "4      Now you'll be heading a whole division, so you...  neutral\n",
       "...                                                  ...      ...\n",
       "44914  [One had too much prep and examinations and Si...    angry\n",
       "44915                                             [Sob!]    angry\n",
       "44916  [This is ridiculous. I - I seriously, I don ' ...    angry\n",
       "44917      [What do you need to coif, contend with him?]    angry\n",
       "44918                       [Made fault in examination.]    angry\n",
       "\n",
       "[44919 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled = pd.DataFrame({'texto': df_balanceado['texto'], 'label': df_balanceado['label']})\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yeah, sure!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hey, Mon.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey-hey-hey. You wanna hear something that sucks.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do I ever.</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chris says they're closing down the bar.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No way!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yeah, apparently they're turning it into some ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Just coffee! Where are we gonna hang out now?</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Got me.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Can I get a beer.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hey, did you pick a roommate?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You betcha!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Is it the Italian guy?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Um-mm, yeah right!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oh my God, oh my God! Poor Monica!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texto     label\n",
       "20                                        Yeah, sure!   neutral\n",
       "21                                          Hey, Mon.   neutral\n",
       "22  Hey-hey-hey. You wanna hear something that sucks.   neutral\n",
       "23                                         Do I ever.     happy\n",
       "24           Chris says they're closing down the bar.       sad\n",
       "25                                            No way!  surprise\n",
       "26  Yeah, apparently they're turning it into some ...   neutral\n",
       "27      Just coffee! Where are we gonna hang out now?   disgust\n",
       "28                                            Got me.       sad\n",
       "29                                  Can I get a beer.   neutral\n",
       "30                      Hey, did you pick a roommate?   neutral\n",
       "31                                        You betcha!     happy\n",
       "32                             Is it the Italian guy?   neutral\n",
       "33                                 Um-mm, yeah right!     happy\n",
       "34                 Oh my God, oh my God! Poor Monica!  surprise"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftodo[20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>He was with her when he wrote this poem.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Look,  'My vessel so empty with nothing inside.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Now that I've touched you, you seem emptier st...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Done.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ah y'know, this building is on my paper route ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oh.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How'd did it go?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I know.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ameri-can.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ameri-ccan.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ameri-can. Y'know it's a</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texto    label\n",
       "20           He was with her when he wrote this poem.  neutral\n",
       "21    Look,  'My vessel so empty with nothing inside.  neutral\n",
       "22  Now that I've touched you, you seem emptier st...  neutral\n",
       "23                                              Done.  neutral\n",
       "24  Ah y'know, this building is on my paper route ...  neutral\n",
       "25                                                Oh.  neutral\n",
       "26                                                Hi.  neutral\n",
       "27                                                Hi.  neutral\n",
       "28                                   How'd did it go?  neutral\n",
       "29                                            I know.  neutral\n",
       "30                                              Yeah.  neutral\n",
       "31                                              Yeah.  neutral\n",
       "32                                         Ameri-can.  neutral\n",
       "33                                        Ameri-ccan.  neutral\n",
       "34                           Ameri-can. Y'know it's a  neutral"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled[20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        also I was the point person on my company's tr...\n",
       "1                         You must've had your hands full.\n",
       "2                                  That I did. That I did.\n",
       "3            So let's talk a little bit about your duties.\n",
       "4        Now you'll be heading a whole division, so you...\n",
       "                               ...                        \n",
       "44914    [One had too much prep and examinations and Si...\n",
       "44915                                               [Sob!]\n",
       "44916    [This is ridiculous. I - I seriously, I don ' ...\n",
       "44917        [What do you need to coif, contend with him?]\n",
       "44918                         [Made fault in examination.]\n",
       "Name: texto, Length: 44919, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44919, 1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44919,)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar el paquete 'averaged_perceptron_tagger' para la lematización pre-entrenada\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44919/44919 [01:47<00:00, 418.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Definir la función para asignar etiquetas POS de WordNet a etiquetas POS de NLTK\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_emotion_text(texto):\n",
    "    if isinstance(texto, list): #En caso de ser lista toma el primer valor\n",
    "        texto = texto[0] \n",
    "\n",
    "    if texto.startswith('[') and texto.endswith(']'): #Si empieza y termina con [ ] los elimina\n",
    "        texto = texto[1:-1]\n",
    "\n",
    "    texto = texto.lower()\n",
    "\n",
    "    texto = texto.replace('á', '')\n",
    "    texto = texto.replace('\\n', '')\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "\n",
    "    texto = re.sub(r\"@[A-Za-z0-9]+\", ' ', texto)\n",
    "    texto = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', texto)\n",
    "    texto = re.sub(r\"[^a-zA-Z.'!?]\", ' ', texto)\n",
    "    texto = re.sub(r\"#\", ' ', texto)\n",
    "    texto = re.sub(r\"\\s(?=\\')\", \"\", texto) #Eliminar los espacios que une los apóstrofes\n",
    "    texto = texto.replace(\"' \", \"'\")\n",
    "    texto = re.sub(r\" +\", ' ', texto)\n",
    "\n",
    "    # Tokenizar el texto y obtener las etiquetas POS\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(texto))\n",
    "    \n",
    "    # Mapear las etiquetas POS de NLTK a etiquetas POS de WordNet\n",
    "    wordnet_tagged = [(word, pos_tagger(tag)) for word, tag in pos_tagged]\n",
    "    \n",
    "    # Lematizar cada palabra con su etiqueta POS correspondiente\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, tag) if tag else word for word, tag in wordnet_tagged]\n",
    "    \n",
    "    # Unir las palabras lematizadas para formar el texto lematizado\n",
    "    lemmatized_text = \" \".join(lemmatized_words)\n",
    "\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\')\", \"\", lemmatized_text) #Eliminar los espacios que une los apóstrofes\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\.)\", \"\", lemmatized_text) #Eliminar los espacios que une los .\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\!)\", \"\", lemmatized_text) #Eliminar los espacios que une los !\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\?)\", \"\", lemmatized_text) #Eliminar los espacios que une los ?\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "# Llamado a la función de limpieza\n",
    "texto_clean = [clean_emotion_text(text) for text in tqdm(df_resampled['texto'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    also I was the point person on my company's tr...\n",
       "1                     You must've had your hands full.\n",
       "2                              That I did. That I did.\n",
       "3        So let's talk a little bit about your duties.\n",
       "4    Now you'll be heading a whole division, so you...\n",
       "5                                               I see.\n",
       "6    But there'll be perhaps 30 people under you so...\n",
       "7                                        Good to know.\n",
       "8                                We can go into detail\n",
       "9    All right then, we'll have a definite answer f...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['texto'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"also I was the point person on my company's transition from the KL-5 to GR-6 system.\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['texto'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"also i be the point person on my company's transition from the kl to gr system.\",\n",
       " \"you must've have your hand full.\",\n",
       " 'that i do. that i do.',\n",
       " \"so let's talk a little bit about your duty.\",\n",
       " \"now you'll be head a whole division so you'll have a lot of duty.\",\n",
       " 'i see.',\n",
       " \"but there'll be perhaps people under you so you can dump a certain amount on them.\",\n",
       " 'good to know.',\n",
       " 'we can go into detail',\n",
       " \"all right then we'll have a definite answer for you on monday but i think i can say with some confidence you'll fit in well here.\"]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_clean[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"also i be the point person on my company's transition from the kl to gr system.\",\n",
       " \"you must've have your hand full.\",\n",
       " 'that i do. that i do.',\n",
       " \"so let's talk a little bit about your duty.\",\n",
       " \"now you'll be head a whole division so you'll have a lot of duty.\",\n",
       " 'i see.',\n",
       " \"but there'll be perhaps people under you so you can dump a certain amount on them.\",\n",
       " 'good to know.',\n",
       " 'we can go into detail',\n",
       " \"all right then we'll have a definite answer for you on monday but i think i can say with some confidence you'll fit in well here.\",\n",
       " 'absolutely. you can relax',\n",
       " 'ok!',\n",
       " 'all right well...',\n",
       " 'yeah sure!',\n",
       " 'hey mon.',\n",
       " 'hey hey hey. you wan na hear something that suck.',\n",
       " \"yeah apparently they're turn it into some kinda coffee place.\",\n",
       " 'can i get a beer.',\n",
       " 'hey do you pick a roommate?',\n",
       " 'be it the italian guy?',\n",
       " 'he be with her when he write this poem.',\n",
       " \"look'my vessel so empty with nothing inside.\",\n",
       " \"now that i've touch you you seem empty still.'\",\n",
       " 'do.',\n",
       " \"ah y'know this building be on my paper route so i...\",\n",
       " 'oh.',\n",
       " 'hi.',\n",
       " 'hi.',\n",
       " \"how'd do it go?\",\n",
       " 'i know.',\n",
       " 'yeah.',\n",
       " 'yeah.',\n",
       " 'ameri can.',\n",
       " 'ameri ccan.',\n",
       " \"ameri can. y'know it's a\",\n",
       " 'which part exactly?',\n",
       " 'the whole thing! can we go?',\n",
       " 'hey what about the scene with the kangaroo? do do you like that part?',\n",
       " \"that's for come buddy.\",\n",
       " \"i'll see you later.\",\n",
       " 'okay look i think we have to tell rachel she mess up her dessert.',\n",
       " 'yes and it be my die wish to have that ring.',\n",
       " \"see if i'm not bury with that ring then my spirit be go to wander the nether world for all eternity\",\n",
       " \"okay that's enough honey!\",\n",
       " \"i do n't know. let me see the ring.\",\n",
       " 'all right.',\n",
       " \"what've you be up to?\",\n",
       " 'oh you know the usual teaching aerobics party way too much.',\n",
       " 'oh and in case you be wonder those be my leg on the new james bond poster.',\n",
       " 'i know.',\n",
       " \"i'm back.\",\n",
       " 'so be we gon na get together or what?',\n",
       " \"um absolutely. uh how'bout tomorrow afternoon? do you know uh central perk in the village say five ish?\",\n",
       " \"great i'll see you then.\",\n",
       " \"even though you do do a good bob impression i'm thinkin'when she see you tomorow she's probably gon na realize hey you're not bob.\",\n",
       " \"i'm hop that when bob do n't show up she will seek comfort in the open arm of the wry stranger at the next table.\",\n",
       " 'no.',\n",
       " 'this be my wedding.',\n",
       " \"fine. you'll you'll watch it on video when we get back.\",\n",
       " 'thank you.',\n",
       " 'thank you.',\n",
       " 'hey!',\n",
       " 'nothing!',\n",
       " \"but um i do n't think it's anything serious.\",\n",
       " \"uh that's an eighteenth century indian artifact from calcutta.\",\n",
       " 'so much more.',\n",
       " \"well well to sum up we're have fun you look young.\",\n",
       " 'okay',\n",
       " \"but that's not enough. so so here's a key to my apartment.\",\n",
       " 'really.',\n",
       " \"you do n't think this be too fast.\",\n",
       " 'ross can i talk to you for a minute?',\n",
       " \"yes please! so what's go on?\",\n",
       " 'hey you ok?',\n",
       " 'there be hum... there be another reason that i think it be time to end it with joey.',\n",
       " 'i start to realize that i be have feeling for someone else.',\n",
       " 'ok geller. last day of the conference you know what happen to the keynote speaker.',\n",
       " \"oh professor clerk we're kind of in the middle of a conversation here.\",\n",
       " 'yeah can you guy just throw him in the pool later?',\n",
       " \"i mean we're scientist right?\",\n",
       " 'oh yeah bob say there might be flood damage.',\n",
       " 'yeah either that or he have a really big cat.',\n",
       " 'if you say big lima bean bubble up. would she understand the difference?',\n",
       " 'rach? what be you do?',\n",
       " \"it's a diaper commercial.\",\n",
       " 'hey you wan na get something to eat or uh do you wan na see how long we can throw this ball back and forth? huh?',\n",
       " 'uhh the ball thing.',\n",
       " 'yeah?',\n",
       " 'uhh',\n",
       " 'what?',\n",
       " 'hey.',\n",
       " 'hey!',\n",
       " 'how do it go with erin?',\n",
       " \"y'know?\",\n",
       " 'that be so awkward we be really nervous.',\n",
       " \"do n't you sleep together?\",\n",
       " 'yeah that really calm me down.',\n",
       " 'okay.',\n",
       " 'i can not sleep in a public place.',\n",
       " \"it's okay y'know you just nod off again.\",\n",
       " 'why?',\n",
       " 'oh and deaf.',\n",
       " \"so they're constantly like have to reassure each other that they're have a good time.\",\n",
       " 'well if you want you can stay with rachel and me tonight.',\n",
       " \"it's just her water breaking. calm down will you?\",\n",
       " 'breathe breathe breathe.',\n",
       " 'i mean be it gina?',\n",
       " 'which one be gina?',\n",
       " 'dark big hair with the airplane earring.',\n",
       " \"no no no that's dina.\",\n",
       " \"i do n't know you think see you saturday'was funny.\",\n",
       " 'look honey mark be in fashion okay i like have a friend that i can share this stuff with.',\n",
       " 'you guy would never want to go to a lecture with me.',\n",
       " 'yeah hey i i have clothes i even pick them out.',\n",
       " 'i mean for for all you know i could be a fashion..... monger.',\n",
       " 'yeah.',\n",
       " 'unless you wan na practice the foxtrot again? or or the tango?',\n",
       " \"ahh thanks but no. you see i i think i'm ready to dance with girl.\",\n",
       " 'okay.',\n",
       " 'yeah.',\n",
       " 'go get em treeger.',\n",
       " 'right. hey ahh you wan na come? marge have a girlfriend.',\n",
       " \"yeah you could dance real good with her she's the same size as me.\",\n",
       " \"no i'm good.\",\n",
       " \"well unfortunately i do n't get many callback so\",\n",
       " 'who know?',\n",
       " 'okay uh we have narrow it down to raymond ben kyle and joey. the rest of you thank you very much.',\n",
       " \"actually that ca n't happen.\",\n",
       " \"yeah because you all have such different look we're put you with raymond and kyle with ben.\",\n",
       " \"so it'll be either you two or you two.\",\n",
       " 'yeah it be.',\n",
       " \"no we we're gon na be like best friend that's why it's gon na be weird.\",\n",
       " \"ok i'm sense that this be some kind of word play because you be pink with barely control glee.\",\n",
       " 'i',\n",
       " \"oh that's not what you want...\",\n",
       " 'this be my father paul stevens. dad this be ross geller.',\n",
       " \"i usually prefer elizabeth's boyfriend to address me as mr. stevens.\",\n",
       " 'of course of course mr. stevens.',\n",
       " 'i',\n",
       " 'okay.',\n",
       " 'i can i can see that.',\n",
       " 'okay.',\n",
       " 'what?',\n",
       " \"oh well it's not on tv yet.\",\n",
       " \"well then it's not on the wall yet.\",\n",
       " 'okay fine i will bring you a tape huh?',\n",
       " \"so umm now do you have any of matt lauer's clothes here? maybe? just one that have n't be clean yet?\",\n",
       " \"oh yeah i'm sure. and all of a sudden his hand be n't the problem anymore.\",\n",
       " 'oh boy scout could have camp under there.',\n",
       " 'uma thurman.',\n",
       " 'thanks rach.',\n",
       " 'oh yeah you have to tell her.',\n",
       " \"feminist issue. that's where i go!\",\n",
       " 'yeah well...',\n",
       " 'yeah yeah you have the ring?',\n",
       " 'yeah right here in my pocket. pheebs?',\n",
       " \"okay now will you guy get out of here? i want this be to be a surprise and she's gon na know.\",\n",
       " 'yeah yeah you guy. get out of here!',\n",
       " 'hi guy.',\n",
       " \"we're just really very excited about this charity event that we have to go to.\",\n",
       " 'okay umm ross?',\n",
       " \"i'm i'm really warm so i'm go to be take off my sweater.\",\n",
       " \"now i'm just let you know that this be\",\n",
       " \"i'm sorry. i'm do. i'm do.\",\n",
       " \"y'know last night be embarrass for you too.\",\n",
       " \"no not really. i mean you've see me naked hundred of time.\",\n",
       " 'uh huh. but it be a first for the rest of my building.',\n",
       " \"okay. all right that's true! but y'know i just do n't embarrass that easily.\",\n",
       " \"no i do n't! ross i think i'm just a more secure person than you be.\",\n",
       " 'be that so?',\n",
       " 'yeah.',\n",
       " 'hey both you guy should be up there with me.',\n",
       " \"i mean you two be be my i mean i'm lucky to have just one good\",\n",
       " 'thanks man.',\n",
       " 'i get ta go check something over here.',\n",
       " 'okay we have a lot of option here a number of prototype for you to try on.',\n",
       " 'call it even?!',\n",
       " \"well i'm gon na go get these in some water.\",\n",
       " 'no no i take them from the hotel lobby.',\n",
       " 'i have a question about this scene.',\n",
       " 'yes?',\n",
       " \"peel the onion. first of all he's good look.\",\n",
       " 'yeah.',\n",
       " \"i think my character's gon na need a little bit more of reason than that.\",\n",
       " 'oh hey how about this one.',\n",
       " \"y'know who have a great video camera?\",\n",
       " 'greg and jenny?',\n",
       " 'do you still wan na call em? i wan na call em.',\n",
       " \"let's call em.\",\n",
       " 'hello? eighth street deli?',\n",
       " 'here you go.',\n",
       " \"her name's ronni. she's a pet mortician.\",\n",
       " 'sure. so how long you be...',\n",
       " 'remember when you be a little kid i use to take you to the navy yard and show you the big ship?',\n",
       " \"no it's only be six year.\",\n",
       " \"i just want to put a nice memory in your head so you'd know that i be n't always such a terrible guy.\",\n",
       " '... joe.',\n",
       " \"y'ever be in love?\",\n",
       " \"... i d'know.\",\n",
       " \"then y'have n't. you're burn your tomato.\",\n",
       " \"joe your dad's in love big time. and the bad part of it be it's with two different woman.\",\n",
       " \"everything's gon na be all right. okay dick?\",\n",
       " 'hey rach how be work?',\n",
       " \"oh great. although i do sit down where there be n't a chair.\",\n",
       " 'by the way ross drop by a box of your stuff.',\n",
       " 'oh well i guess i have that one come.',\n",
       " \"i'm just gon na throw it out it's probably just a bunch of shampoo and...\",\n",
       " 'something wrong?',\n",
       " 'no. nothing.',\n",
       " 'and then and then you say that thing about about bring the mesozoic era in the st century.',\n",
       " 'yeah.',\n",
       " \"it's not that bad.\",\n",
       " \"so you're just bing?\",\n",
       " \"all right cut let's pick again pick again.\",\n",
       " 'okay.',\n",
       " 'why?!',\n",
       " \"you know i do n't think we bring enough stuff. do you forget to pack the baby's anvil?\",\n",
       " \"it's gon na be worth it.\",\n",
       " \"it's a known fact that woman love baby all right?\",\n",
       " 'woman love guy who love baby.',\n",
       " \"it's that whole sensitive thing.\",\n",
       " \"quick aim him at that pack o'babes over there.\",\n",
       " 'maybe one of them will break away.',\n",
       " 'all right gim me the baby.',\n",
       " 'no i get him.',\n",
       " 'hello.',\n",
       " 'you wan na smell him?',\n",
       " 'well we be great guy.',\n",
       " 'bye.',\n",
       " 'well not really.',\n",
       " \"i mean technically it's it's not against the rule or anything but it be frown upon.\",\n",
       " 'well ross it seem pretty clear.',\n",
       " \"i mean what's more important?\",\n",
       " 'what people think or how you feel huh?',\n",
       " 'ross you get ta follow your heart.',\n",
       " 'hey.',\n",
       " 'hey hey hey! so how do it go with dana? any reason i should leave a block of time open say thursday?',\n",
       " \"hey relax i just need more time. we're go to dinner tonight.\",\n",
       " 'go out with who?',\n",
       " 'uh dana keystone from college.',\n",
       " 'no that be dana caplin.',\n",
       " 'all right.',\n",
       " 'umm all right wayne level with me.',\n",
       " 'here you go!',\n",
       " 'okay?',\n",
       " \"hey how you doin'?\",\n",
       " 'hey.',\n",
       " 'no hey well i i completely understand. you be you be stress.',\n",
       " 'i know.',\n",
       " 'what?',\n",
       " \"but i ca n't tell you.\",\n",
       " \"okay but would n't it be easy if you have to tell me something that you could tell me.\",\n",
       " \"well sure in a perfect world. but no i promise i would n't tell and i swear to like all my god.\",\n",
       " 'okay. do it have to do with ross and rachel?',\n",
       " 'no.',\n",
       " 'do it have to do with joey?',\n",
       " 'no.',\n",
       " 'do it have to do with with chandler and that sock that he keep by his bed?',\n",
       " \"no but let's come back to that later!\",\n",
       " \"actually i'm not here to complement the chef.\",\n",
       " \"ohh oh that's okay i hate when people come back to complement the chef.\",\n",
       " 'like i have nothing well to do!',\n",
       " \"so what's up?\",\n",
       " 'oh good to see you too. do you come down here to tell me that?',\n",
       " \"and bobby's gon na be here the whole time.\",\n",
       " \"i mean you're my favorite guy in the whole world.\",\n",
       " \"i'm not even scar to tell mom and dad.\",\n",
       " \"okay bobby why do n't we just come over here and let them have a little moment.\",\n",
       " \"i'd love to ask you in but uh my sister's visiting and i think she's asleep on the couch.\",\n",
       " \"oh hey great you're up. rachel this be my sister krista. krista this be rachel.\",\n",
       " 'like it would help.',\n",
       " 'uh it be very nice meeting you.',\n",
       " \"hi mom it's jill.\",\n",
       " \"yeah i'm fine. i'm just stick at the bank in an atm vestibule.\",\n",
       " \"jill say vestibule... i'm go with vestibule.\",\n",
       " \"i'm fine. no i'm not alone... i do n't know some guy.\",\n",
       " 'be you see anybody right now?',\n",
       " 'personal shopping? what be that? like where you walk around with snooty rich people and tell them what to buy?',\n",
       " 'uh huh.',\n",
       " 'hey!',\n",
       " 'if you have the big apartment you have to deal with people come over all the time.',\n",
       " \"that fridge have get to be stock okay that's your department now.\",\n",
       " 'what be you do?',\n",
       " 'i think i leave a donut up here.',\n",
       " \"so in conclusion the line all go up so i'm happy.\",\n",
       " 'tomorrow at.',\n",
       " \"oh excuse me. i forget my briefcase y'know by accident.\",\n",
       " 'well what about you?',\n",
       " \"you're not feel leave out or anything be ya?\",\n",
       " 'hey bob.',\n",
       " \"if i see him i'll ask.\",\n",
       " 'oh then you know each other.',\n",
       " \"we're on a semi first name basis.\",\n",
       " 'what do you think of add him to our team?',\n",
       " \"but this be eleven. it's almost twice as hard up here.\",\n",
       " 'a freakish thin date with a hanger for her head?',\n",
       " 'so?',\n",
       " 'well then we still have a problem.',\n",
       " 'yeah!',\n",
       " 'with what?',\n",
       " \"well we're try to find someone to perform our wedding and they're all either boring or annoy or y'know ca n't stop star at the lady.\",\n",
       " \"phoebe we're get\",\n",
       " 'guy thank you very much but neither of you be marry us.',\n",
       " 'we be go to have a legitimate member of the clergy! and when i say legitimate i mean gay and in control of his saliva!',\n",
       " 'i do.',\n",
       " 'that be suppose to be a good thing i forget why.',\n",
       " \"just listen monica i do you know okay do you know i could n't sleep for like a month because i get like a dot of ink on one of the sofa cushion.\",\n",
       " 'well you you coulda just turn the cushion over.',\n",
       " \"yeah i would've except i have a big spaghetti stain on the other side.\",\n",
       " \"okay this be what i'm talk about this. i i need to live in a land where people can spill.\",\n",
       " 'you can spill. in the sink.',\n",
       " \"no you're not you're wonder which cushion it be.\",\n",
       " 'uh huh.',\n",
       " \"well i'm i'm just glad i could y'know help you out.\",\n",
       " \"hero i uh i do n't know well all right.\",\n",
       " 'no.',\n",
       " \"no i wo n't.\",\n",
       " 'but i should tell you this this exact same thing happen to my roommate denise.',\n",
       " 'lose the robe.',\n",
       " \"well i'm gon na get another espresso. can i get you another latte?\",\n",
       " \"no no i'm still work on mine.\",\n",
       " 'oh yeah that hug look pretty brutal.',\n",
       " 'pretty nice?',\n",
       " \"you'll have to pardon my roommate he want to marry this.\",\n",
       " \"we do n't have buck but would you be willing to trade for it? we've get a canoe.\",\n",
       " \"y'know i i really do n't think we need a canoe.\",\n",
       " 'all right just just take the entertainment center and then when you get home throw the canoe away!',\n",
       " 'pheebs?',\n",
       " 'yeah?',\n",
       " \"okay. then i guess it's just wait here then. hi. i need one fake ticket to yemen.\",\n",
       " 'oh no no no no. no no no i just i just need a pretend ticket.',\n",
       " 'what would you give to a kid if he want a ticket to play with?',\n",
       " 'be you travel with a child?',\n",
       " 'no.',\n",
       " \"all right y'know what she's gon na think that i'm hand you a credit card but what i'm really gon na do be hand you a library card.\",\n",
       " 'okay but this be the last time.',\n",
       " 'hey.',\n",
       " 'hey.',\n",
       " \"how's she do?\",\n",
       " \"well yeah do n't do n't you think it's a she?\",\n",
       " \"i do n't know. i ca n't tell what ever it be go back in too quickly.\",\n",
       " \"well anyway i get to go change i'm ah meeting some of the cast for drink.\",\n",
       " 'what?',\n",
       " \"yeah but jason's really sensitive.\",\n",
       " 'well sensitive be important pick him.',\n",
       " 'yeah.',\n",
       " 'hi.',\n",
       " 'so uh apparently people be familiar with the europe story?',\n",
       " 'yeah.',\n",
       " \"listen about that the whole uh who come on to who thing really do n't matter.\",\n",
       " \"i mean i think it would've happen either way.\",\n",
       " \"i mean if you have n't initiate it i i i know i would've.\",\n",
       " 'do we have a name yet?',\n",
       " 'no not yet.',\n",
       " \"that's fine for now we'll just call her baby girl green.\",\n",
       " 'oh no baby girl geller green.',\n",
       " 'why be ross do that?',\n",
       " \"no that's all right. do n't worry about it.\",\n",
       " 'yeah! look!',\n",
       " 'i know.',\n",
       " \"all right do n't waste it i mean its still food.\",\n",
       " 'hey joey be this the bed where olivia lose her virginity?',\n",
       " 'also so',\n",
       " \"oh in my head he's do some pretty not gay stuff!\",\n",
       " 'well at the christmas party him and santa do some definitely gay stuff!',\n",
       " \"ok you've get to promise that you'll never ever tell ross that i tell you.\",\n",
       " 'about what?',\n",
       " \"he's plan your birthday party.\",\n",
       " 'about what?',\n",
       " \"well he do n't tell me.\",\n",
       " \"hey do n't look at me. this be ross's thing.\",\n",
       " 'no you be not. we tell you stuff.',\n",
       " \"chandler we still have n't get an rsvp from your dad.\",\n",
       " \"oh! right. umm maybe that's because i do n't send him an invitation.\",\n",
       " \"it's not like we run in the same circle.\",\n",
       " 'ooh i think i wan na trade circle.',\n",
       " \"so what! as long as he's not wear a white dress and a veil i do n't care.\",\n",
       " 'okay i think i need to do some shopping.',\n",
       " \"hello! who's in there?\",\n",
       " \"how ya doin'?\",\n",
       " \"i guess you would n't believe me if i say i be kurt douglas huh?\",\n",
       " 'okay you guy just relax. i doooo.',\n",
       " 'i get ta go.',\n",
       " \"sorry i'm late but i leave late.\",\n",
       " 'okay.',\n",
       " 'so pheebs what be the book about?',\n",
       " 'i think you say you read it in high school.',\n",
       " 'well yeah but then i remember i start it and there be this pep rally and i be i be on top of the pyramid but anyway umm what be this book about?',\n",
       " 'excuse me can i can i bum one of those?',\n",
       " \"y'know what actually okay okay okay what's so funny over here?\",\n",
       " \"oh i think you guy meant marijuana cigarette y'know?\",\n",
       " \"y'know what i mean like dubbies?\",\n",
       " 'but no i actually smoke the regular one all all the time.',\n",
       " 'we get high.',\n",
       " 'oh me too.',\n",
       " \"i'm kid.\",\n",
       " 'yeah.',\n",
       " 'hi.',\n",
       " \"hey how'd it go?\",\n",
       " 'you know what? you be right. i',\n",
       " 'ok.',\n",
       " \"okay if you guy have microphone in there too i do n't mean\",\n",
       " \"it's.\",\n",
       " \"yeah rach i think you're handle that really well.\",\n",
       " 'handle it?',\n",
       " \"now maybe i would have a problem with this if it be n't for me and joshua.\",\n",
       " \"and somewhere along the way one of them be gon na realise what they've do and they're call the whole thing off.\",\n",
       " \"all right what's my next present?\",\n",
       " \"all right there's a nuclear holocaust i'm the last man on earth. would you go out with me?\",\n",
       " 'enhh',\n",
       " \"i've get canned good.\",\n",
       " 'excellent hole joe.',\n",
       " 'my drinking?',\n",
       " \"oh i must've say that after you leave.\",\n",
       " 'that you enjoy the occasional drink ing binge.',\n",
       " 'what if i create a position for you?',\n",
       " \"i'll make you an assistant buyer in this department.\",\n",
       " \"i'd need an expense account.\",\n",
       " 'and an assistant.',\n",
       " \"they're male nurse.\",\n",
       " 'not in my head.',\n",
       " \"i'm move on and you're move on with me.\",\n",
       " \"come on give me one good reason why you do n't wan na go.\",\n",
       " \"umm why do n't you give\",\n",
       " \"hard than it sound. be n't it?\",\n",
       " \"okay you're come with me and i also tell them that if we're still here when they get off that we'll go down to the cafeteria and have some\",\n",
       " \"yep! there's always room for\",\n",
       " 'joey how do you make',\n",
       " \"oh it's easy. yeah i i can do it with anything. watch uh grandma's chicken salad\",\n",
       " 'hello this be monica...',\n",
       " 'yeah???',\n",
       " 'oh...',\n",
       " \"okay yes we'll be right we'll be right down.\",\n",
       " 'thank you.',\n",
       " \"okay. let's bring it in.\",\n",
       " 'wait no honey honey throw it to me throw it to me.',\n",
       " 'here you go.',\n",
       " 'well if the magician can open my beer with his but cheek then all right.',\n",
       " \"y'know i be think if we have a a big fight and uh we break up for a few hour\",\n",
       " 'technically we could have sex again. what do you think bossy and domineer?!',\n",
       " \"okay. but wait we ca n't. my cousin cassie be in the guest room we're suppose to have lunch.\",\n",
       " 'well get rid of her obsessive and shrill.',\n",
       " 'i think i heard voice. you must be chandler.',\n",
       " 'nice to meet you too.',\n",
       " 'so be you ready to go?',\n",
       " 'yeah.',\n",
       " \"i'll be right with you.\",\n",
       " \"th th that's all it be a third nipple.\",\n",
       " 'just your run of the mill third nipple.',\n",
       " 'you can take it off.',\n",
       " \"take your shirt off and let's see what we're deal with here. what be you do?\",\n",
       " 'just show you my run of the mill slice it right off third nipple.',\n",
       " \"well that's not a third nipple.\",\n",
       " \"first of all it's on your as.\",\n",
       " 'wait a minute hold it. johnson! will you come in here a moment?',\n",
       " \"i'm with hamilton!\",\n",
       " \"he's good with rear thing bring him in too.\",\n",
       " \"it's from france in europe western europe. y'know umm a few year ago i actually be backpack across western europe.\",\n",
       " 'i study for a year in barcelona.',\n",
       " 'anyway umm so i be um i be hike',\n",
       " \"um uh we're we're just have this baby together but uh uh that's all.\",\n",
       " \"uh well umm we're just not in that place y'know? but we're very excited about this.\",\n",
       " 'oh. well then shut me up.',\n",
       " 'just tell me how.',\n",
       " 'let it go ross.',\n",
       " \"yeah well you do n't know chi chi.\",\n",
       " 'do you all promise?',\n",
       " 'chandler? do you promise to be good?',\n",
       " 'hey pheebs.',\n",
       " 'dear ms. buffay.',\n",
       " 'thank you for call attention to our error.',\n",
       " 'we have credit your account with five hundred dollar.',\n",
       " \"we're sorry for the inconvenience and hope you'll accept this\",\n",
       " 'oh my god honey we be so meant to be together. we both have copy of the',\n",
       " 'honey both yours.',\n",
       " 'yeah? the work problem?',\n",
       " 'what problem do you tell him you have?',\n",
       " \"oh that's not important. the point be i really i think everything's gon na be okay.\",\n",
       " \"okay i've get some one you wan na put them in her panty?\",\n",
       " 'when you get a sec another round of daiquiri.',\n",
       " 'remember a virgin for me please.',\n",
       " \"oh! and do n't let me leave without get the name of that carpet guy.\",\n",
       " \"ahh come on! y'know what y'know what i think i'm just gon na go home and call kathy.\",\n",
       " 'well if you think it will help.',\n",
       " 'all right i definitely taste nutmeg.',\n",
       " 'hey.',\n",
       " \"uh you've have a lot of sex right?\",\n",
       " \"do n't worry about that man that happen.\",\n",
       " 'yeah! once.',\n",
       " 'i do it anyway.',\n",
       " 'sup? sup dude?',\n",
       " \"so you're play a little\",\n",
       " \"okay look he's not gon na hurt them right?\",\n",
       " \"i do n't wan na leave him alone.\",\n",
       " 'alright?',\n",
       " 'we we have our first fight this morning.',\n",
       " 'i think it have to do with my work late.',\n",
       " \"i say some thing that i do n't mean and he he throw some faeces...\",\n",
       " \"y'know if you're gon na work late i could look in on him for you.\",\n",
       " \"okay but if you do make sure it seem like you're there to see him okay and you're not like do it as a favour to me.\",\n",
       " \"okay but if he ask i'm not go to lie.\",\n",
       " 'check this out.',\n",
       " \"it's almost as good as be there.\",\n",
       " 'uh may i help you?',\n",
       " \"yeah i talk to you on the phone i'm the lady that get stick with the racecar bed.\",\n",
       " \"look it's like i tell you there's nothing i can do. you sign for it monica velula geller.\",\n",
       " 'all right jester man look we wan na see the king.',\n",
       " \"oh ho kay i'm talk to the king.\",\n",
       " 'so this must be kinda neat for ya huh?',\n",
       " \"i mean your dad tell me that you get a couple of day off school and you you ah do n't have to sell those cooky anymore.\",\n",
       " 'yeah.',\n",
       " \"my dad say if i spend as much time help him clean apartment as i do daydream about out space he'd be able to afford a trip to the taj mahal.\",\n",
       " 'i think you would have to clean a whole lot of apartment to go all the way to india.',\n",
       " \"oh. look just friend i wo n't grope you. i promise.\",\n",
       " \"no it's not too soon i have lunch at a eleven.\",\n",
       " 'i invent the game of cup as a way to give joey money.',\n",
       " 'exactly.',\n",
       " \"i do n't know.\",\n",
       " 'but i can see through your sheet.',\n",
       " \"yeah yeah that's her.\",\n",
       " \"but y'know what?\",\n",
       " 'why?',\n",
       " 'no. no. no. she live on the',\n",
       " \"no those first two window that's the lobby.\",\n",
       " \"and y'know the other one over there that's the stairway.\",\n",
       " \"you've be count wrong.\",\n",
       " 'no! steady as a rock! now be you with me.',\n",
       " \"all right gentleman you're up first.\",\n",
       " 'okay.',\n",
       " 'okay.',\n",
       " \"you have second. and the lightning round begin stop it now. what be monica's nickname when she be a field hockey goalie?\",\n",
       " 'big fat goalie.',\n",
       " 'correct. rachel claim',\n",
       " 'dangerous liaison',\n",
       " 'correct. her actual favorite movie be...',\n",
       " \"weekend at bernie's\",\n",
       " \"well look why do n't you just why do n't you do your phase two strip club thing with us.\",\n",
       " 'okay.',\n",
       " \"well that should n't be a problem. i mean i work in fashion and all i meet be eligible straight men.\",\n",
       " 'pete can i get you something else?',\n",
       " \"yeah a slice of cheesecake and and a date if you're give' em out.\",\n",
       " \"have n't you and i cover that topic?\",\n",
       " 'hmm come on you just say to her that you.',\n",
       " \"come on you think she should go out with me do n't you?\",\n",
       " 'well i mean be you sure you want to go out with her?',\n",
       " 'i mean really think about it.',\n",
       " 'ho ho i will.',\n",
       " 'i respectfully disagree.',\n",
       " 'who care? nobody read those thing',\n",
       " \"i do n't have a page.\",\n",
       " 'no no this be my collection of fossil sample.',\n",
       " 'you',\n",
       " 'why?',\n",
       " 'hey if mommy can have a wife daddy can have a bra.',\n",
       " \"ohh it's time to go.\",\n",
       " \"oh no no no see that that clock's a little fast uh we have minute.\",\n",
       " 'huh what can we do in minute?',\n",
       " 'twice?',\n",
       " \"well that's ambitious.\",\n",
       " 'hey uh you can ignore that.',\n",
       " 'i',\n",
       " 'hey i have all the space i need. just do what i do.',\n",
       " \"y'know what? i be\",\n",
       " 'okay.',\n",
       " 'see this be a',\n",
       " 'all right buddy time to roll over.',\n",
       " 'be you under the sheet?',\n",
       " 'yes.',\n",
       " \"that's right you just enjoy.\",\n",
       " 'okay.',\n",
       " 'hey tell ya what.',\n",
       " 'let me walk you home.',\n",
       " 'no. you?',\n",
       " 'no. why?',\n",
       " \"uhh well i've get an audition down the street and i spill sauce all over the front of my shirt. you get an extra one?\",\n",
       " 'yeah sure. umm here.',\n",
       " \"yeah i do n't think so joe.\",\n",
       " 'all right i guess this will be fine.',\n",
       " 'hey listen umm what what be you do tonight?',\n",
       " 'nothing why?',\n",
       " \"how would you feel about take out my assistant tag? i'll pay.\",\n",
       " \"i'm not ask you to go on a\",\n",
       " \"joey just just he he's new in town and i know he do n't have any guy friend.\",\n",
       " 'just take him to like a ball game or something.',\n",
       " \"i'll really appreciate it.\",\n",
       " 'yeah okay.',\n",
       " \"problem odour in the litter box? do n't change your kitty change your kitty litter.\",\n",
       " 'yeah. you okay?',\n",
       " \"hi. well look i be just gon na leave a message be n't tonight your your big anniversary dinner?\",\n",
       " 'you wan na talk i mean i can come over?',\n",
       " \"all right all right i'm come over and i'm bring chinese food.\",\n",
       " \"it's for me.\",\n",
       " 'oh. okay bye.',\n",
       " 'hello?',\n",
       " 'transit authority?',\n",
       " 'yes hello.',\n",
       " \"i'm do research for a book and i be wonder what someone might do if they leave a baby on a city bus.\",\n",
       " \"hi here's the deal.\",\n",
       " 'we lose a carseat on a bus today.',\n",
       " \"it's white plastic with a handle and it fit onto a stroller.\",\n",
       " 'oh and there be a baby in it.',\n",
       " 'he want to talk to you again.',\n",
       " 'hello.',\n",
       " \"i'm sorry i'm a little late.\",\n",
       " 'let me start by uh by introduce myself i be professor geller.',\n",
       " \"so to sum up i'm professor geller.\",\n",
       " 'good evening sir.',\n",
       " 'my name be ross geller.',\n",
       " \"i'm one of the people who apply for the apartment.\",\n",
       " \"and i i realize that the competition be fierce but i'm sorry.\",\n",
       " 'man i wish i be naked.',\n",
       " 'that be how god intend it.',\n",
       " \"i overhear you guy on the phone the other day and you say i'll just tell rachel that i'm do laundry for a couple of hour.\",\n",
       " 'and he say laundry?',\n",
       " 'be',\n",
       " 'well if you have keep listen you you would have hear me call him mr. big ot.',\n",
       " 'mr. bigot. he tell the most',\n",
       " \"i really think you make a good point. i mean y'know until you get cut off.\",\n",
       " \"yeah what's up with that girl monica?\",\n",
       " \"okay i've get one for you if you have too which one would you rather eat a see eye dog or a talk gorilla?\",\n",
       " \"i'd have to say the talk gorilla because at least i can explain to him that you're make me eat him.\",\n",
       " 'okay i hear you loud and clear. bob will stay put.',\n",
       " \"i think it's best sir.\",\n",
       " 'but we really do need to find someone up here.',\n",
       " 'the work be start to pile up.',\n",
       " \"i've get a stack of document on my desk this high.\",\n",
       " \"y'know what you should do just toss em in the shedder and claim you never get em.\",\n",
       " \"that's a good one.\",\n",
       " 'what do a guy have to',\n",
       " \"yeah yeah everybody's here. hey everybody say hi to julie in new mexico.\",\n",
       " \"be n't there a national football league.\",\n",
       " 'yes. yes there be they play on sunday and monday night.',\n",
       " \"when they're hungry enough they'll come in.\",\n",
       " 'hey joey you want to talk to me?',\n",
       " \"i do n't know. you uh you get something for me?\",\n",
       " 'oh yeah this be from rachel.',\n",
       " \"ten. okay. now tag there's such a thing as too many woman.\",\n",
       " \"that's\",\n",
       " 'what be with the dish?',\n",
       " 'yeah toast oatmeal... nothing that spatter.',\n",
       " \"y'know they say a watched pot never beep.\",\n",
       " \"phoebe why do n't you just call her? you obviously want to.\",\n",
       " \"well do n't cha wan na?\",\n",
       " 'yeah.',\n",
       " 'okay well i do know you.',\n",
       " \"that's what i say.\",\n",
       " 'well so?',\n",
       " \"ok bye. well monica's not come it's just gon na be me and rachel.\",\n",
       " \"oh. well hold on camper be you sure you've think this thing through?\",\n",
       " \"it's laundry. the thinking through be minimal.\",\n",
       " 'no.',\n",
       " 'oh and uh the fabric softener?',\n",
       " \"that's the rule.\",\n",
       " 'ok ok how about if we split it?',\n",
       " 'what do you mean like buy it together?',\n",
       " 'yeah',\n",
       " \"you think we're ready for something like that?\",\n",
       " 'why not?',\n",
       " \"well it's a pretty big commitment i mean what if one of us want to move out?\",\n",
       " \"i'm not move out.\",\n",
       " \"yeah yeah it's just that with my last roommate kip...\",\n",
       " \"oh no stay here we'll keep do this. i'll pay you.\",\n",
       " \"no i get in trouble for that before. i'll see you later.\",\n",
       " \"aw forget it it's from\",\n",
       " 'okay look how be this gon na affect you?',\n",
       " \"it's\",\n",
       " \"you're right.\",\n",
       " \"y'know what?\",\n",
       " \"i'm ask you to do me a favor.\",\n",
       " 'and as my wife i think you should grant me this favor.',\n",
       " \"my brother's go through that right now he's such a mess. how do you get through it?\",\n",
       " 'well you might try accidentally break something valuable of hers say her',\n",
       " 'leg?',\n",
       " \"that's one way! me i i go for the watch.\",\n",
       " \"no real honey really it's fine just g go with susan.\",\n",
       " 'okay okay bye',\n",
       " 'so what be they do?',\n",
       " \"hey you're early.\",\n",
       " \"i'm just take it to be re wire.\",\n",
       " 'no no mr. heckle no one be make any noise up here.',\n",
       " 'hi rach.',\n",
       " 'ross?',\n",
       " 'yeah?',\n",
       " \"i'm good except umm you still owe me a dance.\",\n",
       " 'i think i might need one more cup of coffee.',\n",
       " 'sure! uh let me get it for ya.',\n",
       " 'okay.',\n",
       " 'i believe this belong to the father of your baby.',\n",
       " 'uh huh. now you can turn around or you can go in there and rip the band aid off. what to you want to do?',\n",
       " 'okay sorry. yeah.',\n",
       " 'hey rach.',\n",
       " 'it can t be me i m stand right here.',\n",
       " 'wan na peek?',\n",
       " 'hello sir you know monica.',\n",
       " \"do n't spoil it.\",\n",
       " 'hi.',\n",
       " 'hello.',\n",
       " 'hi ross.',\n",
       " 'yeah huh.',\n",
       " 'i can get a quick bite to eat but then i have to come back up here.',\n",
       " 'nooo he? s leave for a good job.',\n",
       " 'okay then.',\n",
       " 'okay.',\n",
       " 'so see ya on saturday.',\n",
       " 'yeah you bet.',\n",
       " 'whazzup??',\n",
       " 'listen can you do me a favor?',\n",
       " \"i'm gon na be out today.\",\n",
       " 'can you just keep an eye on joey make sure nothing happen between him and molly?',\n",
       " 'i think the check in be that way.',\n",
       " 'ahh.',\n",
       " 'monica face it chandler be against marriage. and and always will be!',\n",
       " \"that's right.\",\n",
       " 'chandler',\n",
       " 'you get',\n",
       " 'i know.',\n",
       " 'i do.',\n",
       " 'sometime?',\n",
       " 'maybe?',\n",
       " \"well i just think it'd make me feel good to do something nice for my friend.\",\n",
       " 'oh no no no.',\n",
       " \"well y'know i'm. i mean who need a saving account.\",\n",
       " 'you mean with casey.',\n",
       " \"no no no i think i'm gon na see how thing go with kathy. she's pretty cool.\",\n",
       " 'or casey.',\n",
       " 'no no kathy.',\n",
       " 'could be casey.',\n",
       " 'no. no kathy.',\n",
       " 'consider casey.',\n",
       " 'hey anybody get a length of rope about six foot long with a little nouse at the end?',\n",
       " \"honey what's the matter?\",\n",
       " 'i just saw janice.',\n",
       " 'i like her.',\n",
       " 'why? because she can sing and play guitar and do both at the same time?',\n",
       " \"well that's pretty much all i'm look for from these people.\",\n",
       " \"yeah pheebs come on you two have completely different style. y'know she's more.. y'know and you're more\",\n",
       " \"okay my next song's call phoebe buffay what can i say.\",\n",
       " \"i really love when we be sing partner and i should n't have leave you that way.\",\n",
       " \"oh no one of those look for the hidden meaning'songs.\",\n",
       " 'yes hello.',\n",
       " 'i have a question.',\n",
       " \"umm i use your pen to draw on my friend's face.\",\n",
       " 'a beard and a moustache.',\n",
       " 'thank you.',\n",
       " 'no',\n",
       " 'umm he say he think i be funny.',\n",
       " \"so okay look look umm let's just go downstairs we'll have some fun and you will forget all about it.\",\n",
       " \"oh come on! rach it's it's not that bad.\",\n",
       " \"look just because some idiot draw on your face do n't mean you should n't have any fun!\",\n",
       " 'and besides hey hey hey no one be even gon na',\n",
       " 'okay there be',\n",
       " \"no it's okay. some some kid ask me to pick it up for him but i do n't\",\n",
       " 'you say you wan na come in for some lemonade?',\n",
       " 'oh right right.',\n",
       " 'well not just lemonade iced tea sometimes juice.',\n",
       " 'well sorry i just i think you like me.',\n",
       " \"it's okay. i suppose it could happen to anyone not anyone i know but... by the way i can still see it.\",\n",
       " \"ok i have a question. well actually it's not so much a question as.. more of a general wondering... ment.\",\n",
       " 'ok.',\n",
       " \"ok. here go. for a while now i've be want to um....\",\n",
       " \"yes yes that's right...\",\n",
       " 'well i be probably go to do it at some point.',\n",
       " \"i do n't mean\",\n",
       " \"well we probably wo n't invite you to the wedding...\",\n",
       " 'thank you chandler.',\n",
       " 'sincerely.',\n",
       " \"david i'm pretend to\",\n",
       " 'all right. all right.',\n",
       " 'actually i do have one small complaint.',\n",
       " 'oh.. please! i i welcome criticism.',\n",
       " 'we do?',\n",
       " \"chandler here you go get your traditional thanksgiving feast you get your tomato soup your grilled cheese fixin's and your family size bag of funyuns.\",\n",
       " \"all right i'm nine year old.\",\n",
       " 'we just finish this magnificent thanksgiving dinner.',\n",
       " 'that little naked guy would be me.',\n",
       " \"oh that's nana right there in the middle.'me and the gang at java joe's'.\",\n",
       " \"let's see... yeah?\",\n",
       " 'look like a fun gang.',\n",
       " 'rachel have something that she want to tell you and umm i believe that this be your red sweater.',\n",
       " 'no. this be my red sweater.',\n",
       " 'okay.',\n",
       " 'in the category of favorite return male character the nominee be john wheeler from',\n",
       " 'yeah.',\n",
       " \"you're an aquarius huh?\",\n",
       " \"i bet you're a gemini.\",\n",
       " 'nope.',\n",
       " 'taurus?',\n",
       " 'nope.',\n",
       " 'virgo?',\n",
       " 'nope.',\n",
       " 'sagittarius?',\n",
       " 'yep.',\n",
       " \"you're not gon na speed anymore right?\",\n",
       " \"i wo n't speed.\",\n",
       " \"and you promise you'll get this take care of right away?\",\n",
       " 'i promise.',\n",
       " 'and in the meantime you good let him drive. do he have a license?',\n",
       " 'yeah!',\n",
       " 'can he handle the stick?',\n",
       " 'oh well',\n",
       " 'oh this should be easy. i have a very wide pelvis. you remember chandler.',\n",
       " \"it's you. this be yours.\",\n",
       " \"y'know y'know i'm lookin'and i do n't think anyone's home here.\",\n",
       " \"i say we just break the window crawl through and and y'know explain later.\",\n",
       " \"i do n't think so. hello? when you get in there\",\n",
       " \"hey what's up?\",\n",
       " 'so what so what you saw him with a girl?',\n",
       " \"now look you're go to go out on a date with danny and you're go to be so charm he's gon na forget all about that stupid subway girl.\",\n",
       " 'she be kinda stupid.',\n",
       " \"you're right.\",\n",
       " \"all right i'm just gon na go on the date.\",\n",
       " \"i'm gon na go on the date.\",\n",
       " 'that be the new plan.',\n",
       " 'hi.',\n",
       " 'hey.',\n",
       " 'hi.',\n",
       " 'do i? thank you so do you.',\n",
       " 'thanks.',\n",
       " 'sparkly.',\n",
       " 'mr. major capades guy.',\n",
       " \"i i remember when you be just like king friday in mr. roger's ice be nice.\",\n",
       " \"yeah well ya know i'm kind of spooky that way. wooo.\",\n",
       " \"i miss you. i'm gon na get change.\",\n",
       " 'ok.',\n",
       " 'um now. phoebs.',\n",
       " 'oh right ok. ole.',\n",
       " 'what?',\n",
       " 'listen i forget your address can you give me a call?',\n",
       " 'thanks bye.',\n",
       " \"oh i'd love to but i get ta get up so early the next day and so you know me work come first\",\n",
       " 'oh yeah yeah yeah...',\n",
       " \"kinda have a... a thing for the day of our life's people.\",\n",
       " 'i do it every year.',\n",
       " 'yeah...',\n",
       " 'yeah...',\n",
       " \"oh that's ross's.\",\n",
       " 'remember what?',\n",
       " 'come on ross? remember back in college when he fell in love with carol and buy her that ridiculously expensive crystal duck?',\n",
       " 'wait just a second.',\n",
       " 'i can show you an id if you want?',\n",
       " 'oh yeah well i just start wear bra again.',\n",
       " 'oh that must be it.',\n",
       " 'well i hope you have fun tonight.',\n",
       " 'i believe it.',\n",
       " 'yes i do.',\n",
       " 'jurassic park',\n",
       " 'maybe we should check the trash chute.',\n",
       " \"ross could n't fit down the trash chute.\",\n",
       " \"that's right he almost could. which be exactly how i get stuck there.\",\n",
       " 'hey!',\n",
       " \"just y'know out.\",\n",
       " 'what be you do?',\n",
       " 'i uh go to a bar. and then i just uh just walk around for a while.',\n",
       " 'ross you leave you scarf in hey you guy.',\n",
       " 'oh yeah that look good.',\n",
       " 'you guy make a',\n",
       " 'okay.',\n",
       " \"y'know we do n't have to imagine.\",\n",
       " \"we'll just see.\",\n",
       " 'hi joey.',\n",
       " \"hey! how you doin'?\",\n",
       " \"i'd love to show ya but i just tuck her in.\",\n",
       " \"she's sleep.\",\n",
       " 'hey uh would you two girl like to go for a drink?',\n",
       " 'and how do i know?',\n",
       " 'her die wish be for one last kiss.',\n",
       " \"smelly cat smelly cat what be they feed you? smelly cat smelly cat it's not your fault.\",\n",
       " \"y'know you could totally sell this. it'd be perfect for like umm a kitty litter campaign.\",\n",
       " 'i... a jingle? no no no no no.',\n",
       " \"okay well if i be in this for the money i'd be a millionaire by now y'know.\",\n",
       " 'you just get to get out of that jingle head sweetie.',\n",
       " \"aw you're right you're right. i'm sorry.\",\n",
       " 'okay sir um mm let see if i get this right.',\n",
       " 'ah so this be a half caf double tall easy hazel nut non fat no foam with whip extra hot latte right?',\n",
       " 'um coffee to go please.',\n",
       " 'isabella rosselini.',\n",
       " \"why? cause otherwise you'd go for it?\",\n",
       " 'yeah maybe.',\n",
       " \"what you do n't think i'd go up to her?\",\n",
       " 'ross it take you ten year to finally admit you like me.',\n",
       " \"you know what honey you go ahead we'll call her an alternate.\",\n",
       " 'okay hold my crawler.',\n",
       " 'okay.',\n",
       " \"okay that's that's enough.\",\n",
       " \"wo n't you dance around with me.\",\n",
       " 'oh ho yeah. yeah the hand guy.',\n",
       " \"okay that's fair.\",\n",
       " 'all right.',\n",
       " 'good!',\n",
       " 'pick one.',\n",
       " \"you're welcome.\",\n",
       " 'joey! we should just switch.',\n",
       " 'so what be it for anyway?',\n",
       " 'i wan na say a disease.',\n",
       " 'i just get this really weird message from ross. he say turn on',\n",
       " 'oh oh professor geller.',\n",
       " 'ahh to be again.',\n",
       " 'hey! so uh be he excite about the ticket?',\n",
       " 'doorknob?',\n",
       " 'yeah it kinda grows on you. actually i want to finish talk to you about uh spring vacation.',\n",
       " 'how do you feel?',\n",
       " \"well let's just say that krog will be fully equip to destroy the universe again in twelve to fourteen hour.\",\n",
       " 'okay so i',\n",
       " 'and protect them from a tornado?',\n",
       " 'i know the baby be asleep.',\n",
       " 'be not as important as the fact that phoebe take care of the baby all by herself.',\n",
       " \"you're right you're right i should n't freak out.\",\n",
       " 'cause this be what will happen when you and i have baby!',\n",
       " 'when will that be?',\n",
       " 'a dreamless sleep.',\n",
       " 'well the big news be still you dump barry at the altar!',\n",
       " \"alright. let's talk reality for a second.\",\n",
       " 'okay.',\n",
       " 'when be you come home?',\n",
       " \"c'mon this be us.\",\n",
       " \"i'm not! this be what i'm do now. i've get this job\",\n",
       " \"okay i'm not just waitress.\",\n",
       " \"i'm..\",\n",
       " 'i um...',\n",
       " 'i write the special on the special board and uh... and i uh...',\n",
       " \"we get off around midnight why do n't we pick you up then?\",\n",
       " 'so um will you bring the truck?',\n",
       " \"i'll even let you ring the bell.\",\n",
       " \"they're nice guy.\",\n",
       " 'your son.',\n",
       " \"well jamie be the name of susan's first girlfriend so we go back to jordie.\",\n",
       " 'i get it.',\n",
       " 'i get it.',\n",
       " \"no you do n't.\",\n",
       " 'yeah listen...',\n",
       " 'well you just ask if i want to go to bed with you tonight.',\n",
       " 'knock knock knock knock hi.',\n",
       " 'um could you please tell sergei that um i be fascinate by what boutros boutros gali say in the new york time.',\n",
       " \"you do n't say boutros boutros gali.\",\n",
       " 'boutros boutros gali.',\n",
       " 'he say he be too.',\n",
       " 'interesting.',\n",
       " 'so i be wonder....',\n",
       " \"so you're a chef?\",\n",
       " 'monica can i talk to you behind my menu please. what be you do?',\n",
       " 'well i be have a conversation.',\n",
       " 'that would be great. thank you.',\n",
       " \"oh y'know the same thing happen to me one time.\",\n",
       " \"do n't you remember when we be jog in the park and we saw that really pretty bird and want to take a picture i do n't have my camera!\",\n",
       " \"here i'll get it.\",\n",
       " \"we'd better take these pant off upstairs or that stain's gon na set.\",\n",
       " 'action!',\n",
       " \"here's your call sheet for tomorrow.\",\n",
       " 'i know.',\n",
       " 'oh yeah i should probably call them.',\n",
       " \"oh i do n't think i ever hear that story.\",\n",
       " 'what a sweet story.',\n",
       " 'we have it. only now we call it the beach house.',\n",
       " 'after apply the waxine and linen strip to leg number one',\n",
       " \"grasp one of the linen strip by its easy grab tab'and pull it off in one quick pain free motion.\",\n",
       " \"huh well the girl in the satin nightie on the commercial do n't seem to think it's that bad.\",\n",
       " \"but hey y'know if you do n't believe me please by my guest.\",\n",
       " \"now umm remember i'm still learn.\",\n",
       " 'one two three four!',\n",
       " 'so?',\n",
       " 'david who?',\n",
       " \"oh you say someone's name enough they turn around.\",\n",
       " \"yeah i'm just i'm just in town for a conference. umm\",\n",
       " 'yeah. well i i get like thirty of them.',\n",
       " 'yeah.',\n",
       " \"it's no big deal. hey y'know you do what you get ta do. right?\",\n",
       " \"but hey it's not just me i mean the scientist and the tour guide\",\n",
       " 'whatever.',\n",
       " 'okay mon back me up here.',\n",
       " 'where you work the uh waiter eat with the waiter right?',\n",
       " 'and the chef eat with the other chef right?',\n",
       " \"look ross really it's it's no big deal.\",\n",
       " \"y'know hey i understand.\",\n",
       " \"y'know?\",\n",
       " \"hey when i'm in a play and you're in the audience i do n't talk to you right?\",\n",
       " \"so it's y'know it's uh it's cool.\",\n",
       " \"i'll see you tomorrow.\",\n",
       " \"yeah when we're in the audience he do n't talk to us but he do wave.\",\n",
       " \"hey i be n't the only one who look like an idiot.\",\n",
       " 'all right?',\n",
       " \"yeah that's the same.\",\n",
       " \"oh wait! that ca n't be the one rachel's talk about. she do n't even know that happen. so which one be it?\",\n",
       " 'oh come on monica relive past pain and get depress be what thanksgiving be all about.',\n",
       " 'hi guy.',\n",
       " 'hi phoebe.',\n",
       " 'no we',\n",
       " 'hormone.',\n",
       " 'hormone yeah.',\n",
       " \"your parent'?\",\n",
       " \"yeah they're out of town.\",\n",
       " \"yeah yeah it's this\",\n",
       " 'yeah that work.',\n",
       " 'honey you remember my bos doug right?',\n",
       " 'yes hi.',\n",
       " 'no leg chew for us sir.',\n",
       " 'oh well give it time.',\n",
       " 'how about we all go out to dinner tomorrow night?',\n",
       " \"just so you know we're not see him tomorrow.\",\n",
       " 'no.',\n",
       " \"now maybe you just like wan na but the whole duck in there! who care y'know? now i get the leg\",\n",
       " ...]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make fault in examination.'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_clean[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_resampled['label']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "labelEncoder = le.fit_transform(labels)\n",
    "\n",
    "data_labels = labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: angry, Valor: 0\n",
      "Clase: disgust, Valor: 1\n",
      "Clase: fear, Valor: 2\n",
      "Clase: happy, Valor: 3\n",
      "Clase: neutral, Valor: 4\n",
      "Clase: sad, Valor: 5\n",
      "Clase: surprise, Valor: 6\n"
     ]
    }
   ],
   "source": [
    "# Obtener los nombres de las clases\n",
    "class_names = le.classes_\n",
    "\n",
    "# Obtener los valores numéricos asignados a cada clase\n",
    "class_values = le.transform(class_names)\n",
    "\n",
    "# Imprimir los nombres de las clases y sus valores numéricos\n",
    "for name, value in zip(class_names, class_values):\n",
    "    print(f'Clase: {name}, Valor: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_final = pd.DataFrame({'texto': texto_clean, 'label': data_labels})\n",
    "\n",
    "\n",
    "df_final.to_csv('datos_procesados_Balanceados.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullTokenizer = bert.bert_tokenization.FullTokenizer #llamada a la instancia de bert libreria para obtener la tokenización.\n",
    "\n",
    "\n",
    "\n",
    "#Llamado al modelo pre-entrenado de Bert L-12\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\", trainable=False)\n",
    "\n",
    "\n",
    "#obtener el vocabulario del Hub de bert\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "\n",
    "#transformación a minusculas\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "#aplicación al tokenizador mediante el vocabulario y transformando las palabras a minusculas\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para aplicar el token en cada sentencia\n",
    "def encode_sentence(sent):\n",
    "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n",
    "  #Se aplica CLS para el inicio de clasificación y SEP para la separación en cada secuencia. Esto lo pide Bert.\n",
    "\n",
    "#Transforma los tokens en lista de ids para obtener la forma numerica de los datos\n",
    "def get_ids(tokens):\n",
    "  return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "#Se aplica la mascara para eliminar los tokens de PAD que son los padding para igualar los valores, igualando el token PAD en 0\n",
    "def get_mask(tokens):\n",
    "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "#Indica si el token es de la primera frase o segunda fase, agrando 0 o 1 dependiendo de la separación\n",
    "def get_segments(tokens):\n",
    "  seg_ids = [] #es una lista que se rellena con el token\n",
    "  current_seg_ids = 0\n",
    "\n",
    "  for tok in tokens: #recorre todos los tokens\n",
    "    seg_ids.append(current_seg_ids)\n",
    "    if tok == \"[SEP]\": #si el token es de separación\n",
    "      current_seg_ids = 1-current_seg_ids #convierte los 1 en 0 y viceversa\n",
    "\n",
    "  return seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamada a la función que convierte en tokens\n",
    "data_inputs = [encode_sentence(sentence) for sentence in texto_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Se crea una lista mediante la secuencia, su respectivo label y el largo de la frase.\n",
    "data_with_len = [[sent, data_labels[i], len(sent)]\n",
    "                 for i, sent in enumerate(data_inputs)]\n",
    "\n",
    "\n",
    "random.shuffle(data_with_len) #Se mezcla los datos de forma aleatoria\n",
    "\n",
    "valor_maximo=-np.inf\n",
    "\n",
    "for sent_lab in data_with_len:\n",
    "    if sent_lab[2]>valor_maximo:\n",
    "        valor_maximo=sent_lab[2]\n",
    "\n",
    "#Se genera una tupla, se entrega la secuencia para obtener las ids, mask y segments, Además se agrega el label de la secuencia.\n",
    "sorted_all = [([get_ids(sent_lab[0]),\n",
    "                get_mask(sent_lab[0]),\n",
    "                get_segments(sent_lab[0])],\n",
    "               sent_lab[1])\n",
    "               for sent_lab in data_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor_maximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[101,\n",
       "    1517,\n",
       "    1165,\n",
       "    178,\n",
       "    1129,\n",
       "    2647,\n",
       "    2041,\n",
       "    1120,\n",
       "    2286,\n",
       "    1843,\n",
       "    178,\n",
       "    3333,\n",
       "    1106,\n",
       "    14131,\n",
       "    1139,\n",
       "    2555,\n",
       "    1113,\n",
       "    170,\n",
       "    13670,\n",
       "    1112,\n",
       "    1869,\n",
       "    2815,\n",
       "    1464,\n",
       "    5307,\n",
       "    178,\n",
       "    1341,\n",
       "    1115,\n",
       "    1122,\n",
       "    1129,\n",
       "    170,\n",
       "    177,\n",
       "    19429,\n",
       "    1611,\n",
       "    1105,\n",
       "    178,\n",
       "    22591,\n",
       "    1566,\n",
       "    3737,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]],\n",
       "  2),\n",
       " ([[101,\n",
       "    1165,\n",
       "    12861,\n",
       "    1295,\n",
       "    16712,\n",
       "    1103,\n",
       "    1413,\n",
       "    1104,\n",
       "    1103,\n",
       "    1505,\n",
       "    1219,\n",
       "    1126,\n",
       "    10592,\n",
       "    5246,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  2),\n",
       " ([[101, 1105, 1304, 1277, 27466, 14367, 1197, 119, 102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  3),\n",
       " ([[101,\n",
       "    1165,\n",
       "    178,\n",
       "    1129,\n",
       "    12791,\n",
       "    11811,\n",
       "    1204,\n",
       "    1118,\n",
       "    1139,\n",
       "    2585,\n",
       "    1534,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  0),\n",
       " ([[101, 1122, 112, 188, 1136, 8964, 2598, 119, 102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  0),\n",
       " ([[101,\n",
       "    1177,\n",
       "    1184,\n",
       "    1129,\n",
       "    1128,\n",
       "    2564,\n",
       "    1107,\n",
       "    1103,\n",
       "    2319,\n",
       "    1111,\n",
       "    136,\n",
       "    1195,\n",
       "    112,\n",
       "    1396,\n",
       "    1243,\n",
       "    14863,\n",
       "    21413,\n",
       "    189,\n",
       "    15818,\n",
       "    1643,\n",
       "    2112,\n",
       "    3621,\n",
       "    119,\n",
       "    119,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1]),\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]],\n",
       "  4),\n",
       " ([[101,\n",
       "    1165,\n",
       "    178,\n",
       "    2484,\n",
       "    1148,\n",
       "    1107,\n",
       "    1103,\n",
       "    171,\n",
       "    119,\n",
       "    170,\n",
       "    12211,\n",
       "    119,\n",
       "    1346,\n",
       "    178,\n",
       "    1138,\n",
       "    2100,\n",
       "    1104,\n",
       "    1292,\n",
       "    2298,\n",
       "    1105,\n",
       "    1873,\n",
       "    1150,\n",
       "    1129,\n",
       "    1499,\n",
       "    3365,\n",
       "    1133,\n",
       "    1165,\n",
       "    178,\n",
       "    1148,\n",
       "    1767,\n",
       "    1104,\n",
       "    1143,\n",
       "    1138,\n",
       "    1499,\n",
       "    178,\n",
       "    1180,\n",
       "    1136,\n",
       "    2059,\n",
       "    1122,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]],\n",
       "  3),\n",
       " ([[101,\n",
       "    1184,\n",
       "    136,\n",
       "    106,\n",
       "    1131,\n",
       "    23609,\n",
       "    13002,\n",
       "    1103,\n",
       "    1338,\n",
       "    6473,\n",
       "    1161,\n",
       "    11850,\n",
       "    11085,\n",
       "    106,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  6),\n",
       " ([[101, 11019, 183, 112, 189, 5594, 1251, 13155, 2820, 119, 102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "  1),\n",
       " ([[101,\n",
       "    178,\n",
       "    1464,\n",
       "    1304,\n",
       "    6782,\n",
       "    1165,\n",
       "    178,\n",
       "    1138,\n",
       "    1106,\n",
       "    1660,\n",
       "    1146,\n",
       "    1380,\n",
       "    1115,\n",
       "    1118,\n",
       "    1268,\n",
       "    1129,\n",
       "    2317,\n",
       "    1105,\n",
       "    1780,\n",
       "    178,\n",
       "    1202,\n",
       "    183,\n",
       "    112,\n",
       "    189,\n",
       "    1243,\n",
       "    1122,\n",
       "    170,\n",
       "    1912,\n",
       "    1104,\n",
       "    28117,\n",
       "    7912,\n",
       "    3161,\n",
       "    1115,\n",
       "    1234,\n",
       "    1202,\n",
       "    183,\n",
       "    112,\n",
       "    189,\n",
       "    1660,\n",
       "    1128,\n",
       "    1103,\n",
       "    1268,\n",
       "    1106,\n",
       "    1138,\n",
       "    119,\n",
       "    102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]),\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]],\n",
       "  5)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_all[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[101, 1177, 1128, 112, 1231, 1817, 4911, 119, 102],\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " 5)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_all[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44919"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del generador, mediante la entrega de la tupla de los datos.\n",
    "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                             output_types=(tf.int32, tf.int32)) #La salida es entera de tuplas de los datos transformados int(texto), int(etiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of padding and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEQUENCE_LENGTH=300\n",
    "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
    "                                       padded_shapes=((3, SEQUENCE_LENGTH), ()),\n",
    "                                       padding_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1517,  1165, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1105,  1304, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 14863,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1152,  5080, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  8264, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 3, 0, 0, 4, 3, 6, 1, 5, 1, 6, 4, 2, 3, 6, 3, 4, 1, 6, 3, 2,\n",
      "       1, 3, 5, 2, 1, 2, 5, 2, 1, 4, 5, 5, 3, 5, 6, 0, 4, 1, 6, 2, 4, 6,\n",
      "       1, 5, 3, 3, 2, 3, 3, 5, 3, 0, 5, 6, 0, 4, 6, 5, 3, 4, 3, 2])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2112,  5674, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1631, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   185, 10061, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1139,  5372, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  5968,  3457, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 6, 1, 6, 1, 2, 2, 5, 6, 3, 2, 6, 4, 3, 6, 4, 6, 6, 6, 0, 3, 4,\n",
      "       5, 6, 2, 2, 3, 5, 5, 5, 4, 2, 3, 2, 3, 5, 2, 2, 1, 1, 2, 3, 3, 1,\n",
      "       6, 0, 1, 4, 4, 6, 3, 1, 0, 2, 2, 5, 0, 6, 1, 4, 3, 0, 5, 2])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1229, 2824, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 3008, 1150, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1184,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 6798, 1643, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 4, 6, 3, 2, 2, 5, 0, 4, 5, 4, 1, 5, 2, 6, 5, 6, 5, 2, 1, 0,\n",
      "       5, 0, 3, 0, 1, 2, 2, 1, 6, 4, 4, 6, 0, 6, 4, 3, 2, 4, 1, 3, 2, 2,\n",
      "       1, 2, 5, 2, 6, 2, 4, 3, 3, 4, 2, 5, 0, 2, 4, 5, 5, 6, 1, 4])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1256,  1126, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  7059,  7692, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  1768, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 4, 6, 3, 0, 6, 6, 0, 6, 3, 0, 4, 0, 5, 0, 4, 6, 4, 3, 0, 6, 6,\n",
      "       5, 1, 5, 4, 4, 4, 2, 4, 0, 3, 5, 0, 5, 3, 4, 1, 2, 6, 4, 3, 4, 3,\n",
      "       3, 6, 4, 3, 2, 5, 1, 5, 0, 5, 4, 4, 3, 1, 5, 4, 5, 5, 6, 1])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1103, 16319, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1341, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 12861,  1295, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1119,  5042, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 13159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1519, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 0, 1, 3, 3, 5, 1, 2, 2, 5, 2, 3, 5, 2, 3, 5, 6, 5, 4, 2, 3, 2,\n",
      "       0, 6, 1, 5, 4, 4, 0, 3, 2, 1, 2, 2, 3, 3, 1, 4, 3, 3, 6, 0, 5, 0,\n",
      "       1, 3, 6, 2, 1, 6, 3, 0, 3, 0, 2, 4, 0, 2, 0, 5, 6, 6, 0, 4])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1107,  7678, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2283,  1114, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1126,  1162, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  2660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 18257,  1324, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 19863,  4578, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 3, 1, 6, 3, 0, 4, 6, 2, 1, 6, 5, 4, 4, 2, 6, 6, 4, 1, 5, 3, 3,\n",
      "       6, 0, 2, 1, 4, 4, 1, 3, 2, 2, 3, 4, 2, 1, 0, 6, 2, 1, 0, 4, 6, 4,\n",
      "       3, 3, 1, 5, 0, 3, 6, 6, 6, 2, 3, 2, 4, 6, 2, 2, 5, 6, 6, 2])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  170, 3101, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1525, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1185, 1272, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1631, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1423, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 4, 5, 6, 4, 3, 5, 1, 0, 0, 0, 2, 6, 6, 3, 2, 0, 5, 0, 6,\n",
      "       1, 6, 3, 0, 4, 2, 2, 4, 5, 0, 6, 1, 2, 0, 1, 3, 6, 6, 4, 0, 6, 3,\n",
      "       4, 2, 4, 3, 1, 3, 3, 4, 3, 0, 3, 6, 4, 5, 0, 3, 1, 5, 2, 3])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178, 21276, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1431, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1103,  1285, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 5, 2, 4, 5, 0, 3, 5, 6, 2, 3, 1, 5, 1, 5, 5, 1, 4, 2, 1, 3, 3,\n",
      "       1, 0, 1, 6, 2, 0, 2, 1, 1, 0, 0, 2, 0, 5, 5, 2, 5, 4, 6, 4, 4, 0,\n",
      "       1, 0, 0, 0, 0, 1, 1, 4, 5, 3, 6, 3, 6, 4, 6, 2, 4, 5, 1, 1])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 12861,  1295, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   184,  2246, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1128,  1243, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1160, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1119,  1486, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 6, 6, 5, 2, 3, 3, 5, 5, 0, 0, 3, 4, 3, 1, 2, 0, 6, 6, 2, 0,\n",
      "       5, 2, 5, 5, 4, 3, 4, 2, 0, 4, 3, 6, 6, 4, 6, 1, 2, 3, 5, 4, 2, 5,\n",
      "       6, 3, 5, 6, 5, 6, 6, 0, 6, 3, 3, 2, 2, 6, 5, 3, 6, 0, 2, 4])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  3186, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,  1156, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1817,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863,  4208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 3, 0, 0, 1, 3, 5, 0, 1, 6, 6, 5, 5, 6, 5, 3, 4, 3, 6, 0, 4, 3,\n",
      "       3, 5, 4, 0, 4, 1, 6, 4, 4, 6, 5, 1, 5, 1, 2, 3, 6, 6, 1, 5, 4, 0,\n",
      "       5, 2, 6, 4, 0, 0, 0, 4, 2, 1, 3, 5, 0, 4, 1, 3, 3, 5, 2, 3])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1177, 1202, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 4056, 1440, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1105, 1119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  170, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1268,  106, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 1, 0, 3, 0, 3, 3, 4, 2, 6, 1, 2, 3, 4, 0, 4, 2, 2, 4, 0, 4, 2,\n",
      "       3, 4, 6, 6, 2, 3, 4, 2, 3, 3, 1, 1, 2, 0, 4, 2, 6, 6, 1, 3, 2, 1,\n",
      "       6, 0, 3, 1, 3, 3, 5, 3, 3, 4, 5, 2, 6, 6, 5, 5, 6, 5, 1, 3])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1128,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1129,   185, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1196,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,  1107, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   194,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 2, 2, 1, 0, 0, 4, 5, 1, 5, 2, 4, 2, 3, 5, 2, 0, 0, 5, 2, 3,\n",
      "       2, 1, 4, 1, 6, 6, 0, 3, 2, 0, 4, 3, 3, 2, 2, 4, 5, 2, 4, 5, 5, 0,\n",
      "       6, 0, 2, 5, 6, 1, 2, 4, 3, 1, 2, 3, 1, 6, 2, 6, 3, 1, 1, 4])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165,  1825, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1268,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 15276,  1306, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 4, 2, 2, 3, 1, 5, 0, 2, 0, 6, 1, 6, 4, 1, 6, 4, 6, 6, 3, 3, 2,\n",
      "       5, 1, 6, 4, 3, 1, 0, 3, 6, 5, 3, 5, 4, 6, 4, 2, 2, 1, 1, 6, 3, 6,\n",
      "       4, 0, 0, 6, 1, 4, 0, 1, 2, 6, 1, 6, 0, 6, 4, 4, 5, 2, 2, 3])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 19563,   192, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 18780,  1111, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863, 11159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1115,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1435, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 1, 6, 1, 2, 5, 2, 2, 6, 5, 1, 4, 4, 2, 2, 2, 6, 1, 4, 0, 6, 6,\n",
      "       2, 2, 6, 0, 4, 6, 6, 1, 0, 5, 2, 2, 1, 3, 3, 4, 4, 1, 0, 2, 5, 4,\n",
      "       6, 0, 4, 1, 3, 5, 5, 4, 0, 4, 6, 6, 0, 6, 1, 3, 3, 1, 0, 3])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1464, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1115,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1184,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1150,  1161, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 3, 3, 4, 5, 1, 5, 2, 4, 0, 5, 5, 2, 0, 0, 5, 2, 3, 4, 2, 0, 3,\n",
      "       2, 3, 3, 2, 2, 1, 0, 6, 3, 3, 0, 2, 5, 5, 5, 5, 1, 1, 4, 6, 4, 3,\n",
      "       4, 1, 0, 6, 5, 4, 6, 1, 2, 1, 5, 5, 0, 0, 2, 0, 6, 6, 0, 6])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  2022,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1141, 21820, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  1148, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1103,  1992, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  2660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1268,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 6, 1, 1, 2, 6, 5, 1, 5, 0, 5, 1, 1, 3, 3, 2, 0, 3, 3, 1, 0, 1,\n",
      "       6, 5, 3, 0, 3, 6, 0, 4, 2, 3, 0, 3, 3, 5, 6, 5, 2, 5, 3, 0, 5, 5,\n",
      "       1, 3, 6, 2, 0, 3, 5, 6, 2, 3, 5, 4, 0, 5, 4, 5, 0, 1, 3, 4])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   170,  1705, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 13159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  3039, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 19082,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 11721,  1567, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 6, 2, 5, 4, 5, 1, 2, 2, 0, 5, 4, 3, 4, 5, 3, 5, 5, 4, 6, 5, 1,\n",
      "       1, 0, 4, 6, 4, 3, 0, 1, 0, 4, 2, 2, 2, 4, 0, 5, 1, 5, 3, 4, 0, 6,\n",
      "       6, 2, 6, 5, 6, 1, 4, 1, 3, 4, 1, 1, 1, 1, 4, 0, 3, 6, 3, 5])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  5804,  1131, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1195, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  5804, 11609, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1120,  2989, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 6, 4, 3, 5, 0, 5, 1, 1, 2, 1, 5, 4, 6, 1, 1, 1, 2, 1, 4, 6, 3,\n",
      "       5, 1, 3, 0, 6, 5, 4, 6, 6, 2, 3, 3, 2, 6, 3, 2, 3, 2, 4, 0, 3, 4,\n",
      "       1, 5, 3, 0, 2, 5, 0, 6, 0, 3, 5, 1, 6, 0, 4, 2, 0, 5, 1, 1])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 19563,   194, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1156, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  8147,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1362,  2332, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1141,  1104, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 5, 4, 1, 5, 2, 1, 3, 4, 3, 1, 4, 5, 3, 3, 4, 1, 2, 1, 6, 6, 3,\n",
      "       6, 3, 2, 1, 1, 3, 1, 1, 0, 2, 5, 5, 4, 5, 5, 2, 3, 3, 3, 6, 3, 4,\n",
      "       6, 0, 2, 3, 2, 2, 2, 4, 4, 0, 6, 1, 1, 4, 6, 0, 1, 6, 5, 2])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   185, 10061, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1464, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1105,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1195,  1444, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  5412, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 3, 0, 3, 0, 6, 0, 6, 6, 5, 4, 0, 5, 3, 6, 6, 1, 2, 6, 0, 4, 4,\n",
      "       3, 4, 6, 1, 3, 0, 0, 2, 0, 0, 2, 2, 2, 2, 6, 0, 6, 1, 0, 3, 6, 2,\n",
      "       1, 6, 1, 5, 0, 1, 2, 6, 2, 0, 5, 3, 5, 2, 5, 3, 2, 4, 5, 2])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1185,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 8582, 1107, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1129, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1105, 1191, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 3, 4, 5, 5, 2, 1, 0, 5, 0, 1, 0, 5, 1, 6, 3, 0, 6, 0, 1, 3, 5,\n",
      "       3, 6, 4, 4, 4, 0, 6, 0, 1, 1, 3, 3, 6, 1, 2, 1, 4, 6, 6, 6, 5, 5,\n",
      "       3, 6, 5, 3, 6, 1, 6, 4, 0, 5, 3, 1, 2, 6, 0, 6, 6, 0, 4, 5])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294, 14863, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  1304, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103, 12239, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 20839, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 4, 1, 3, 4, 3, 5, 2, 0, 2, 6, 3, 6, 0, 6, 1, 1, 2, 0, 0, 0, 3,\n",
      "       6, 5, 3, 3, 0, 5, 2, 6, 5, 1, 5, 1, 4, 2, 4, 2, 5, 5, 0, 4, 1, 0,\n",
      "       1, 1, 2, 4, 0, 1, 6, 0, 2, 4, 1, 1, 5, 3, 3, 0, 1, 0, 0, 2])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1126,  1162, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1134,  1508, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  2206,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   174, 13430, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  4103,  1195, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 4, 4, 2, 3, 0, 0, 5, 0, 4, 3, 4, 6, 2, 3, 2, 5, 0, 5, 1, 1, 4,\n",
      "       1, 4, 6, 4, 1, 4, 0, 4, 6, 3, 4, 6, 1, 6, 5, 4, 4, 3, 6, 6, 1, 0,\n",
      "       4, 5, 2, 3, 1, 3, 5, 1, 4, 0, 1, 6, 3, 2, 2, 5, 5, 2, 1, 3])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 3074, 1111, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 8147, 1115, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1885, 1122, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 9294, 1185, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  184,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 1, 0, 3, 2, 4, 5, 1, 4, 4, 4, 4, 6, 1, 4, 0, 5, 2, 4, 6, 3, 0,\n",
      "       1, 5, 4, 4, 6, 5, 0, 5, 5, 2, 5, 0, 3, 4, 1, 2, 5, 3, 4, 6, 3, 1,\n",
      "       2, 5, 6, 2, 1, 6, 6, 4, 4, 4, 3, 3, 5, 6, 1, 6, 1, 6, 1, 1])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 15276,  1306, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1170,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1122,  1321, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  5540,  1105, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1111,  1164, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 3, 5, 0, 2, 1, 5, 0, 6, 5, 2, 3, 2, 5, 5, 6, 6, 1, 4, 3, 5, 0,\n",
      "       2, 2, 3, 6, 5, 4, 6, 6, 4, 4, 1, 6, 2, 1, 0, 3, 0, 3, 0, 5, 6, 4,\n",
      "       5, 1, 6, 5, 3, 3, 3, 2, 6, 4, 0, 4, 5, 6, 1, 5, 5, 5, 1, 3])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  1185, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  6699, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1800, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165, 20839, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2676,  1293, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 0, 2, 0, 4, 3, 3, 5, 4, 2, 0, 3, 4, 0, 2, 4, 3, 2, 5, 1, 4, 6,\n",
      "       2, 5, 3, 2, 6, 6, 4, 2, 4, 0, 2, 0, 5, 5, 4, 6, 0, 5, 3, 1, 1, 3,\n",
      "       4, 3, 0, 6, 2, 0, 6, 3, 3, 5, 1, 0, 0, 2, 5, 4, 3, 0, 6, 4])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1396,  2511, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,  9994, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  7236,  1106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14807,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1191, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 5, 4, 6, 6, 1, 2, 5, 2, 5, 4, 3, 3, 2, 1, 2, 4, 4, 0, 5, 6, 3,\n",
      "       6, 4, 2, 1, 4, 4, 4, 4, 1, 5, 2, 3, 4, 6, 0, 6, 4, 2, 1, 4, 0, 2,\n",
      "       4, 1, 2, 5, 5, 4, 0, 0, 2, 1, 0, 2, 2, 6, 3, 0, 6, 0, 0, 4])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1173,  1494, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1272,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1219,   170, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1136,  1511, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 12804, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 1, 0, 4, 0, 2, 5, 4, 5, 6, 1, 2, 5, 6, 2, 5, 4, 4, 6, 6, 2, 5,\n",
      "       0, 6, 6, 5, 0, 3, 6, 5, 3, 5, 4, 4, 4, 5, 3, 6, 5, 1, 1, 0, 4, 2,\n",
      "       4, 2, 0, 4, 5, 4, 2, 4, 4, 0, 6, 4, 6, 0, 0, 1, 2, 2, 4, 4])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  1324, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 11721, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1195, 16722, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1138, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   179, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 5, 0, 4, 2, 0, 2, 0, 0, 4, 4, 3, 0, 6, 4, 3, 2, 3, 1, 3, 3, 3,\n",
      "       5, 6, 6, 1, 6, 3, 4, 2, 2, 1, 4, 6, 6, 2, 1, 0, 5, 3, 2, 5, 3, 6,\n",
      "       3, 1, 3, 3, 3, 2, 5, 5, 3, 5, 2, 5, 4, 1, 3, 5, 6, 0, 4, 3])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1122,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  3485, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1170,  2824, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   175, 21091, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1139,  1910, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1423,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 3, 2, 5, 5, 3, 1, 3, 0, 2, 2, 2, 4, 2, 0, 4, 1, 0, 0, 0, 4, 1,\n",
      "       0, 2, 0, 1, 0, 2, 6, 5, 5, 2, 4, 4, 1, 3, 5, 5, 0, 2, 2, 4, 6, 1,\n",
      "       0, 6, 3, 2, 3, 0, 5, 5, 2, 0, 0, 6, 1, 3, 3, 4, 3, 3, 5, 1])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(all_batched.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1517  1165   178  1129  2647  2041  1120  2286  1843   178  3333\n",
      "   1106 14131  1139  2555  1113   170 13670  1112  1869  2815  1464  5307\n",
      "    178  1341  1115  1122  1129   170   177 19429  1611  1105   178 22591\n",
      "   1566  3737   119   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0]], shape=(3, 300), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(all_batched.take(1)))\n",
    "\n",
    "primer_valor_primer_batch = first_batch[0][0]  # Acceder al primer elemento del primer lote\n",
    "print(primer_valor_primer_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of train, validation and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_BATCHES totales:  702\n",
      "NB_BATCHES validacion:  140\n",
      "NB_BATCHES testeo:  70\n",
      "NB_BATCHES entrenamiento 492\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Calcular el número total de lotes\n",
    "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
    "print(\"NB_BATCHES totales: \",NB_BATCHES)\n",
    "\n",
    "# Calcular el número de lotes para validación y prueba\n",
    "NB_BATCHES_VAL = (NB_BATCHES * 20) // 100\n",
    "NB_BATCHES_TEST = (NB_BATCHES * 10) // 100\n",
    "print(\"NB_BATCHES validacion: \",NB_BATCHES_VAL)\n",
    "print(\"NB_BATCHES testeo: \",NB_BATCHES_TEST)\n",
    "print(\"NB_BATCHES entrenamiento\", NB_BATCHES - (NB_BATCHES_TEST + NB_BATCHES_VAL))\n",
    "\n",
    "# Se crea los conjuntos de datos para entrenamiento, validación y prueba\n",
    "val_dataset = all_batched.take(NB_BATCHES_VAL)\n",
    "test_dataset = all_batched.skip(NB_BATCHES_VAL).take(NB_BATCHES_TEST)\n",
    "train_dataset = all_batched.skip(NB_BATCHES_VAL + NB_BATCHES_TEST) \n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  492\n",
      "Validation size:  140\n",
      "Test size:  70\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \", len(list(train_dataset)))\n",
    "print(\"Validation size: \", len(list(val_dataset)))\n",
    "print(\"Test size: \", len(list(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 23998,  1362, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  6124, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   177,  1306, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1120,   170, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 1, 0, 2, 3, 2, 2, 4, 4, 4, 3, 4, 2, 3, 5, 2, 2, 0, 3, 1, 1, 4,\n",
      "       6, 3, 3, 1, 1, 3, 4, 1, 5, 5, 3, 4, 6, 0, 5, 6, 0, 0, 3, 4, 6, 2,\n",
      "       6, 5, 1, 3, 0, 4, 3, 0, 1, 5, 0, 6, 3, 5, 6, 0, 3, 4, 1, 0])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  3008,  1152, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170, 19487, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1112,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1185,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1118,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3465,  1107, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 2, 2, 0, 5, 5, 1, 2, 4, 0, 6, 4, 3, 0, 3, 4, 5, 2, 1, 0, 0,\n",
      "       5, 5, 0, 0, 3, 2, 6, 6, 5, 3, 2, 6, 3, 4, 1, 4, 5, 4, 3, 6, 1, 5,\n",
      "       3, 0, 0, 6, 3, 6, 2, 4, 1, 0, 0, 3, 2, 0, 4, 6, 5, 5, 5, 5])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1293,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1211,  5683, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 11019, 16869, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  5113,  3210, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,   136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1601, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 4, 5, 3, 4, 2, 2, 4, 3, 2, 2, 1, 1, 3, 0, 1, 2, 5, 3, 6, 6,\n",
      "       6, 2, 1, 2, 2, 5, 4, 6, 0, 1, 0, 2, 3, 0, 0, 3, 3, 0, 2, 0, 0, 0,\n",
      "       6, 6, 1, 4, 3, 1, 5, 3, 5, 4, 0, 5, 1, 0, 4, 6, 5, 0, 6, 0])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1126, 1162, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1198, 1240, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 9294,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1195, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 4, 1, 6, 6, 0, 6, 0, 3, 6, 4, 4, 6, 5, 1, 4, 3, 3, 4, 6, 6, 1,\n",
      "       0, 1, 3, 3, 2, 2, 3, 2, 5, 6, 6, 6, 5, 3, 6, 1, 5, 2, 4, 0, 3, 6,\n",
      "       4, 0, 5, 4, 6, 0, 1, 0, 6, 4, 1, 3, 2, 2, 3, 2, 5, 6, 1, 1])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 12804, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  2633,  3676, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2945,  1104, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 5, 3, 3, 1, 6, 3, 4, 4, 2, 1, 1, 0, 5, 2, 4, 6, 4, 6, 2, 4,\n",
      "       0, 0, 1, 2, 5, 5, 6, 0, 0, 3, 5, 5, 5, 5, 5, 1, 5, 5, 2, 4, 1, 1,\n",
      "       1, 1, 4, 5, 4, 1, 5, 4, 5, 3, 4, 5, 5, 4, 2, 0, 2, 4, 3, 2])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  8531, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1114,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   170,  1825, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23382,  1138, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 0, 0, 2, 5, 2, 6, 1, 0, 4, 3, 5, 0, 1, 0, 5, 6, 2, 2, 1, 6, 4,\n",
      "       4, 2, 5, 3, 4, 5, 1, 2, 1, 0, 1, 1, 6, 3, 4, 1, 6, 1, 2, 3, 4, 0,\n",
      "       6, 0, 2, 6, 2, 4, 0, 3, 6, 0, 4, 0, 4, 1, 4, 1, 0, 1, 5, 2])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  2946, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1150,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  1159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 0, 6, 4, 4, 5, 5, 2, 0, 6, 1, 6, 6, 0, 0, 1, 2, 2, 2, 4, 4, 5,\n",
      "       3, 4, 1, 3, 3, 3, 2, 6, 5, 2, 4, 1, 0, 3, 1, 4, 5, 3, 1, 4, 2, 4,\n",
      "       6, 0, 5, 1, 0, 1, 6, 3, 1, 6, 1, 5, 6, 4, 6, 5, 4, 0, 3, 1])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1300,  2998, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3008,  1152, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1304,  1218, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1103,  1473, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1250,  1111, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   184, 19515, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 2, 0, 6, 5, 4, 1, 5, 0, 5, 0, 2, 0, 6, 1, 0, 3, 4, 0, 4, 5, 1,\n",
      "       1, 3, 1, 6, 2, 2, 3, 5, 0, 0, 5, 6, 5, 1, 6, 0, 6, 2, 4, 6, 0, 2,\n",
      "       3, 6, 2, 1, 5, 0, 5, 0, 2, 6, 1, 4, 0, 6, 5, 5, 1, 5, 5, 0])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   112,  1940, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3076,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1139,  6907, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1105,  1191, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,  2564, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 0, 5, 4, 5, 5, 0, 5, 2, 6, 4, 6, 5, 3, 5, 3, 4, 2, 3, 1, 1, 6,\n",
      "       5, 5, 6, 2, 6, 3, 2, 2, 2, 2, 0, 6, 1, 3, 1, 3, 5, 5, 3, 2, 1, 0,\n",
      "       5, 4, 3, 1, 3, 2, 0, 6, 0, 2, 4, 1, 5, 5, 0, 2, 2, 4, 6, 3])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3008, 22572, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1321,  1107, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1177, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  7936,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 4, 4, 6, 1, 5, 2, 0, 6, 0, 3, 1, 2, 1, 3, 5, 4, 2, 1, 3, 2, 3,\n",
      "       2, 4, 5, 0, 2, 5, 0, 5, 1, 2, 1, 1, 6, 6, 5, 5, 2, 3, 1, 1, 6, 0,\n",
      "       2, 6, 0, 2, 3, 2, 6, 1, 4, 5, 4, 0, 1, 6, 5, 6, 5, 5, 4, 0])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,   102, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,   136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  1873, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2914,  5540, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178, 18884, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 6, 0, 0, 1, 6, 1, 3, 4, 4, 2, 5, 4, 4, 0, 4, 5, 4, 1, 4, 0, 3,\n",
      "       2, 6, 6, 6, 0, 4, 5, 1, 1, 4, 3, 4, 0, 5, 2, 1, 6, 5, 1, 1, 5, 1,\n",
      "       1, 4, 4, 2, 1, 3, 1, 4, 4, 5, 4, 5, 6, 2, 2, 2, 4, 1, 2, 1])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 2654, 1243, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1435, 1113, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1198, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 5412, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 4, 0, 2, 0, 6, 5, 2, 6, 6, 3, 4, 3, 4, 0, 6, 1, 6, 1, 3, 0, 6,\n",
      "       3, 1, 3, 2, 2, 3, 5, 3, 0, 6, 6, 1, 2, 5, 1, 2, 4, 3, 5, 2, 2, 3,\n",
      "       1, 1, 0, 2, 3, 2, 1, 1, 0, 6, 5, 6, 5, 5, 3, 3, 0, 0, 5, 5])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1196,  1660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1152,  1474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  5412, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20839,  3440, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 6, 6, 0, 1, 1, 4, 6, 2, 3, 3, 0, 6, 5, 2, 0, 5, 5, 0, 3, 0,\n",
      "       2, 4, 1, 0, 5, 3, 4, 5, 4, 3, 5, 1, 1, 1, 6, 4, 0, 3, 2, 1, 4, 0,\n",
      "       1, 2, 0, 2, 6, 0, 3, 0, 4, 5, 5, 6, 3, 4, 4, 6, 5, 4, 5, 2])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1184,   136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  2820, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863,  9294, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1293,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1126, 15462, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,  1474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 0, 2, 2, 2, 3, 5, 5, 2, 5, 1, 6, 6, 3, 4, 0, 0, 6, 3, 0, 2, 3,\n",
      "       2, 0, 5, 1, 4, 5, 2, 1, 3, 0, 4, 5, 0, 5, 6, 1, 2, 6, 3, 2, 3, 6,\n",
      "       4, 6, 2, 6, 4, 1, 1, 0, 0, 5, 2, 3, 6, 2, 0, 3, 6, 3, 0, 0])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1128, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1170, 4417, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1103, 2945, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 6798, 1161, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 9294, 1324, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 1, 2, 0, 2, 3, 4, 0, 3, 5, 1, 4, 1, 6, 2, 4, 0, 0, 2, 3, 2, 5,\n",
      "       1, 2, 3, 2, 0, 6, 2, 4, 1, 1, 5, 1, 4, 1, 5, 1, 2, 6, 6, 6, 4, 0,\n",
      "       6, 1, 1, 6, 1, 1, 2, 2, 2, 0, 1, 2, 2, 6, 0, 4, 5, 2, 1, 3])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1148,  1159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1464, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,   172, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1129,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1175,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 1, 1, 2, 6, 2, 0, 0, 5, 2, 2, 4, 2, 2, 5, 1, 3, 6, 1, 4, 3, 2,\n",
      "       6, 5, 1, 2, 2, 6, 0, 3, 2, 1, 6, 4, 3, 6, 1, 5, 1, 1, 5, 0, 1, 0,\n",
      "       1, 2, 0, 6, 1, 0, 5, 2, 1, 3, 6, 5, 0, 5, 1, 3, 0, 6, 5, 4])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  176, 2386, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1177, 1686, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 9294,  171, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 2283, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 6059,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 5, 6, 5, 0, 4, 3, 6, 2, 4, 4, 6, 2, 0, 5, 5, 3, 5, 4, 0, 1, 0,\n",
      "       5, 0, 1, 3, 2, 6, 4, 4, 0, 2, 0, 2, 0, 6, 1, 6, 1, 4, 4, 5, 0, 5,\n",
      "       0, 2, 4, 0, 6, 1, 2, 6, 6, 1, 4, 5, 0, 6, 5, 1, 3, 3, 3, 0])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  2590, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 14863,  1293, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 1, 3, 2, 2, 0, 0, 6, 5, 3, 2, 4, 4, 1, 3, 3, 6, 5, 4, 3, 3, 3,\n",
      "       2, 6, 6, 4, 2, 6, 6, 2, 5, 4, 0, 4, 4, 6, 3, 4, 0, 5, 3, 1, 2, 0,\n",
      "       0, 6, 4, 3, 3, 2, 0, 2, 0, 1, 3, 3, 1, 0, 1, 1, 2, 6, 1, 1])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 5547, 8876, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1139, 9122, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 8147, 1612, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 9994, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 5, 5, 0, 5, 4, 5, 3, 2, 6, 6, 5, 1, 0, 5, 0, 6, 2, 1, 2, 6, 5,\n",
      "       0, 0, 0, 0, 4, 2, 2, 2, 6, 2, 4, 6, 4, 4, 5, 0, 5, 6, 3, 3, 1, 5,\n",
      "       6, 5, 4, 0, 4, 4, 0, 3, 0, 6, 5, 1, 6, 0, 4, 3, 6, 4, 0, 4])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1126,  1162, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1129,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   179,  7745, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 23998,  1435, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1129, 13155, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 4, 4, 1, 4, 2, 0, 0, 0, 1, 3, 4, 4, 0, 6, 0, 6, 1, 5, 0, 1, 4,\n",
      "       5, 0, 2, 1, 3, 4, 2, 3, 3, 4, 1, 3, 0, 1, 3, 6, 2, 2, 5, 3, 0, 4,\n",
      "       0, 4, 4, 2, 4, 4, 1, 5, 4, 5, 1, 5, 3, 1, 3, 0, 4, 0, 5, 1])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1115,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  1197, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1143, 13002, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1177,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1195,  1138, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1921,  1105, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 6, 0, 6, 1, 0, 6, 6, 2, 6, 3, 0, 3, 0, 3, 4, 2, 0, 1, 6, 1, 6,\n",
      "       3, 6, 3, 2, 0, 1, 0, 0, 3, 1, 4, 3, 1, 2, 4, 2, 2, 4, 0, 6, 4, 5,\n",
      "       1, 0, 0, 0, 1, 2, 1, 3, 5, 0, 4, 5, 5, 0, 2, 1, 0, 4, 5, 0])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1185,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1129, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1229, 1106, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1202, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 2, 1, 5, 4, 6, 3, 0, 2, 5, 1, 0, 4, 6, 3, 6, 0, 4, 6, 5, 0,\n",
      "       5, 6, 3, 0, 2, 0, 0, 6, 4, 2, 2, 2, 6, 2, 3, 6, 4, 1, 1, 1, 0, 0,\n",
      "       6, 4, 3, 3, 3, 0, 1, 0, 0, 1, 3, 6, 2, 2, 0, 4, 6, 2, 0, 4])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   112,   182, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1725, 10194, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,   170, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   194,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 1, 0, 5, 0, 0, 0, 6, 1, 2, 2, 1, 4, 0, 3, 4, 1, 6, 2, 6, 2, 4,\n",
      "       4, 2, 2, 0, 5, 2, 6, 4, 6, 4, 6, 3, 6, 1, 4, 1, 0, 0, 6, 2, 5, 6,\n",
      "       5, 6, 2, 0, 1, 1, 5, 0, 6, 6, 6, 4, 3, 1, 4, 0, 3, 2, 5, 4])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  7413, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1117,   192, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 17869,  1184, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1120,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 5, 2, 0, 3, 6, 1, 1, 5, 6, 5, 0, 4, 2, 5, 3, 0, 3, 1, 0, 5, 6,\n",
      "       2, 3, 3, 2, 5, 3, 2, 6, 3, 4, 3, 6, 0, 5, 5, 6, 1, 0, 5, 0, 1, 1,\n",
      "       6, 4, 6, 0, 2, 1, 0, 6, 5, 0, 4, 1, 5, 6, 4, 5, 1, 2, 1, 1])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1198,  2100, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1293,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1105,  1106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20542,  1631, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 0, 0, 1, 6, 3, 2, 4, 6, 6, 4, 3, 1, 4, 6, 6, 5, 4, 4, 5, 3, 0,\n",
      "       4, 2, 3, 6, 3, 5, 4, 4, 2, 6, 1, 5, 2, 4, 4, 4, 4, 6, 6, 4, 5, 6,\n",
      "       6, 4, 1, 1, 6, 0, 3, 5, 6, 1, 2, 0, 3, 5, 0, 2, 0, 5, 4, 3])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1202,  183, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1185, 3943, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1541,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1165,  170, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 2824, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  194,  112, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 6, 0, 3, 1, 3, 1, 3, 1, 5, 0, 5, 1, 0, 3, 2, 1, 2, 0, 2, 2,\n",
      "       0, 4, 4, 0, 0, 0, 6, 4, 6, 1, 6, 6, 2, 5, 3, 0, 3, 6, 5, 5, 3, 5,\n",
      "       6, 4, 3, 0, 2, 4, 4, 3, 0, 5, 1, 1, 0, 4, 6, 4, 4, 3, 1, 0])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1112,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  179, 7745, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1541,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1165, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1301, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 2373, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 6, 0, 5, 2, 0, 3, 1, 1, 4, 1, 1, 0, 0, 5, 2, 6, 4, 4, 3, 1,\n",
      "       1, 2, 3, 6, 0, 5, 0, 4, 1, 2, 0, 3, 5, 5, 2, 0, 4, 6, 5, 1, 6, 2,\n",
      "       3, 3, 2, 2, 3, 3, 3, 3, 0, 4, 2, 6, 0, 1, 3, 3, 5, 2, 2, 1])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1103,  2945, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  2945, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1184,  1164, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1105,  1177, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 1, 2, 0, 2, 0, 4, 2, 1, 4, 6, 3, 0, 0, 1, 1, 2, 1, 6, 4, 1, 3,\n",
      "       2, 4, 5, 3, 1, 6, 0, 4, 3, 2, 1, 4, 4, 1, 6, 6, 1, 3, 5, 1, 1, 4,\n",
      "       1, 3, 4, 2, 4, 2, 5, 5, 3, 1, 6, 5, 3, 6, 2, 1, 2, 0, 6, 3])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  177, 6262, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1122,  112, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1293, 1169, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1266, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 5, 4, 0, 6, 3, 2, 1, 0, 2, 1, 3, 2, 6, 3, 0, 3, 5, 1, 6, 3, 6,\n",
      "       5, 3, 4, 1, 2, 5, 4, 3, 4, 3, 3, 4, 0, 0, 4, 4, 5, 1, 1, 2, 1, 0,\n",
      "       6, 4, 5, 0, 2, 6, 0, 4, 4, 0, 6, 2, 1, 3, 3, 1, 5, 5, 2, 5])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   170,  2246, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1185, 16976, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2218,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 6, 6, 6, 2, 1, 4, 6, 6, 0, 4, 3, 5, 6, 1, 3, 1, 1, 1, 2, 4, 1,\n",
      "       1, 5, 4, 1, 5, 5, 1, 1, 0, 0, 3, 3, 4, 4, 3, 4, 3, 6, 0, 3, 2, 1,\n",
      "       2, 5, 6, 5, 3, 6, 4, 5, 6, 3, 2, 5, 1, 6, 5, 0, 0, 0, 3, 6])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(train_dataset.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1517,  1165, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1105,  1304, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 14863,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1152,  5080, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  8264, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 3, 0, 0, 4, 3, 6, 1, 5, 1, 6, 4, 2, 3, 6, 3, 4, 1, 6, 3, 2,\n",
      "       1, 3, 5, 2, 1, 2, 5, 2, 1, 4, 5, 5, 3, 5, 6, 0, 4, 1, 6, 2, 4, 6,\n",
      "       1, 5, 3, 3, 2, 3, 3, 5, 3, 0, 5, 6, 0, 4, 6, 5, 3, 4, 3, 2])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2112,  5674, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1631, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   185, 10061, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1139,  5372, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  5968,  3457, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 6, 1, 6, 1, 2, 2, 5, 6, 3, 2, 6, 4, 3, 6, 4, 6, 6, 6, 0, 3, 4,\n",
      "       5, 6, 2, 2, 3, 5, 5, 5, 4, 2, 3, 2, 3, 5, 2, 2, 1, 1, 2, 3, 3, 1,\n",
      "       6, 0, 1, 4, 4, 6, 3, 1, 0, 2, 2, 5, 0, 6, 1, 4, 3, 0, 5, 2])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1229, 2824, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 3008, 1150, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1184,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 6798, 1643, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 4, 6, 3, 2, 2, 5, 0, 4, 5, 4, 1, 5, 2, 6, 5, 6, 5, 2, 1, 0,\n",
      "       5, 0, 3, 0, 1, 2, 2, 1, 6, 4, 4, 6, 0, 6, 4, 3, 2, 4, 1, 3, 2, 2,\n",
      "       1, 2, 5, 2, 6, 2, 4, 3, 3, 4, 2, 5, 0, 2, 4, 5, 5, 6, 1, 4])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1256,  1126, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  7059,  7692, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  1768, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 4, 6, 3, 0, 6, 6, 0, 6, 3, 0, 4, 0, 5, 0, 4, 6, 4, 3, 0, 6, 6,\n",
      "       5, 1, 5, 4, 4, 4, 2, 4, 0, 3, 5, 0, 5, 3, 4, 1, 2, 6, 4, 3, 4, 3,\n",
      "       3, 6, 4, 3, 2, 5, 1, 5, 0, 5, 4, 4, 3, 1, 5, 4, 5, 5, 6, 1])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1103, 16319, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1341, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 12861,  1295, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1119,  5042, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 13159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1519, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 0, 1, 3, 3, 5, 1, 2, 2, 5, 2, 3, 5, 2, 3, 5, 6, 5, 4, 2, 3, 2,\n",
      "       0, 6, 1, 5, 4, 4, 0, 3, 2, 1, 2, 2, 3, 3, 1, 4, 3, 3, 6, 0, 5, 0,\n",
      "       1, 3, 6, 2, 1, 6, 3, 0, 3, 0, 2, 4, 0, 2, 0, 5, 6, 6, 0, 4])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1107,  7678, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2283,  1114, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1126,  1162, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  2660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 18257,  1324, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 19863,  4578, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 3, 1, 6, 3, 0, 4, 6, 2, 1, 6, 5, 4, 4, 2, 6, 6, 4, 1, 5, 3, 3,\n",
      "       6, 0, 2, 1, 4, 4, 1, 3, 2, 2, 3, 4, 2, 1, 0, 6, 2, 1, 0, 4, 6, 4,\n",
      "       3, 3, 1, 5, 0, 3, 6, 6, 6, 2, 3, 2, 4, 6, 2, 2, 5, 6, 6, 2])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  170, 3101, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1525, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1185, 1272, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1631, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1423, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 4, 5, 6, 4, 3, 5, 1, 0, 0, 0, 2, 6, 6, 3, 2, 0, 5, 0, 6,\n",
      "       1, 6, 3, 0, 4, 2, 2, 4, 5, 0, 6, 1, 2, 0, 1, 3, 6, 6, 4, 0, 6, 3,\n",
      "       4, 2, 4, 3, 1, 3, 3, 4, 3, 0, 3, 6, 4, 5, 0, 3, 1, 5, 2, 3])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178, 21276, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1431, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1103,  1285, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 5, 2, 4, 5, 0, 3, 5, 6, 2, 3, 1, 5, 1, 5, 5, 1, 4, 2, 1, 3, 3,\n",
      "       1, 0, 1, 6, 2, 0, 2, 1, 1, 0, 0, 2, 0, 5, 5, 2, 5, 4, 6, 4, 4, 0,\n",
      "       1, 0, 0, 0, 0, 1, 1, 4, 5, 3, 6, 3, 6, 4, 6, 2, 4, 5, 1, 1])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 12861,  1295, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   184,  2246, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1128,  1243, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1160, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1119,  1486, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 6, 6, 5, 2, 3, 3, 5, 5, 0, 0, 3, 4, 3, 1, 2, 0, 6, 6, 2, 0,\n",
      "       5, 2, 5, 5, 4, 3, 4, 2, 0, 4, 3, 6, 6, 4, 6, 1, 2, 3, 5, 4, 2, 5,\n",
      "       6, 3, 5, 6, 5, 6, 6, 0, 6, 3, 3, 2, 2, 6, 5, 3, 6, 0, 2, 4])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  3186, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,  1156, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1817,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863,  4208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 3, 0, 0, 1, 3, 5, 0, 1, 6, 6, 5, 5, 6, 5, 3, 4, 3, 6, 0, 4, 3,\n",
      "       3, 5, 4, 0, 4, 1, 6, 4, 4, 6, 5, 1, 5, 1, 2, 3, 6, 6, 1, 5, 4, 0,\n",
      "       5, 2, 6, 4, 0, 0, 0, 4, 2, 1, 3, 5, 0, 4, 1, 3, 3, 5, 2, 3])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1177, 1202, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 4056, 1440, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1105, 1119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  170, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1268,  106, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 1, 0, 3, 0, 3, 3, 4, 2, 6, 1, 2, 3, 4, 0, 4, 2, 2, 4, 0, 4, 2,\n",
      "       3, 4, 6, 6, 2, 3, 4, 2, 3, 3, 1, 1, 2, 0, 4, 2, 6, 6, 1, 3, 2, 1,\n",
      "       6, 0, 3, 1, 3, 3, 5, 3, 3, 4, 5, 2, 6, 6, 5, 5, 6, 5, 1, 3])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1128,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1129,   185, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1196,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,  1107, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   194,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 2, 2, 1, 0, 0, 4, 5, 1, 5, 2, 4, 2, 3, 5, 2, 0, 0, 5, 2, 3,\n",
      "       2, 1, 4, 1, 6, 6, 0, 3, 2, 0, 4, 3, 3, 2, 2, 4, 5, 2, 4, 5, 5, 0,\n",
      "       6, 0, 2, 5, 6, 1, 2, 4, 3, 1, 2, 3, 1, 6, 2, 6, 3, 1, 1, 4])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165,  1825, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1268,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 15276,  1306, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 4, 2, 2, 3, 1, 5, 0, 2, 0, 6, 1, 6, 4, 1, 6, 4, 6, 6, 3, 3, 2,\n",
      "       5, 1, 6, 4, 3, 1, 0, 3, 6, 5, 3, 5, 4, 6, 4, 2, 2, 1, 1, 6, 3, 6,\n",
      "       4, 0, 0, 6, 1, 4, 0, 1, 2, 6, 1, 6, 0, 6, 4, 4, 5, 2, 2, 3])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 19563,   192, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 18780,  1111, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863, 11159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1115,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1435, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 1, 6, 1, 2, 5, 2, 2, 6, 5, 1, 4, 4, 2, 2, 2, 6, 1, 4, 0, 6, 6,\n",
      "       2, 2, 6, 0, 4, 6, 6, 1, 0, 5, 2, 2, 1, 3, 3, 4, 4, 1, 0, 2, 5, 4,\n",
      "       6, 0, 4, 1, 3, 5, 5, 4, 0, 4, 6, 6, 0, 6, 1, 3, 3, 1, 0, 3])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1464, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1115,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1184,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1150,  1161, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 3, 3, 4, 5, 1, 5, 2, 4, 0, 5, 5, 2, 0, 0, 5, 2, 3, 4, 2, 0, 3,\n",
      "       2, 3, 3, 2, 2, 1, 0, 6, 3, 3, 0, 2, 5, 5, 5, 5, 1, 1, 4, 6, 4, 3,\n",
      "       4, 1, 0, 6, 5, 4, 6, 1, 2, 1, 5, 5, 0, 0, 2, 0, 6, 6, 0, 6])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  2022,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1141, 21820, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  1148, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1103,  1992, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  2660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1268,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 6, 1, 1, 2, 6, 5, 1, 5, 0, 5, 1, 1, 3, 3, 2, 0, 3, 3, 1, 0, 1,\n",
      "       6, 5, 3, 0, 3, 6, 0, 4, 2, 3, 0, 3, 3, 5, 6, 5, 2, 5, 3, 0, 5, 5,\n",
      "       1, 3, 6, 2, 0, 3, 5, 6, 2, 3, 5, 4, 0, 5, 4, 5, 0, 1, 3, 4])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   170,  1705, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 13159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  3039, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 19082,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 11721,  1567, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 6, 2, 5, 4, 5, 1, 2, 2, 0, 5, 4, 3, 4, 5, 3, 5, 5, 4, 6, 5, 1,\n",
      "       1, 0, 4, 6, 4, 3, 0, 1, 0, 4, 2, 2, 2, 4, 0, 5, 1, 5, 3, 4, 0, 6,\n",
      "       6, 2, 6, 5, 6, 1, 4, 1, 3, 4, 1, 1, 1, 1, 4, 0, 3, 6, 3, 5])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  5804,  1131, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1195, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  5804, 11609, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1120,  2989, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 6, 4, 3, 5, 0, 5, 1, 1, 2, 1, 5, 4, 6, 1, 1, 1, 2, 1, 4, 6, 3,\n",
      "       5, 1, 3, 0, 6, 5, 4, 6, 6, 2, 3, 3, 2, 6, 3, 2, 3, 2, 4, 0, 3, 4,\n",
      "       1, 5, 3, 0, 2, 5, 0, 6, 0, 3, 5, 1, 6, 0, 4, 2, 0, 5, 1, 1])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 19563,   194, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1156, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  8147,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1362,  2332, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1141,  1104, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 5, 4, 1, 5, 2, 1, 3, 4, 3, 1, 4, 5, 3, 3, 4, 1, 2, 1, 6, 6, 3,\n",
      "       6, 3, 2, 1, 1, 3, 1, 1, 0, 2, 5, 5, 4, 5, 5, 2, 3, 3, 3, 6, 3, 4,\n",
      "       6, 0, 2, 3, 2, 2, 2, 4, 4, 0, 6, 1, 1, 4, 6, 0, 1, 6, 5, 2])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   185, 10061, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1464, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1105,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1195,  1444, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  5412, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 3, 0, 3, 0, 6, 0, 6, 6, 5, 4, 0, 5, 3, 6, 6, 1, 2, 6, 0, 4, 4,\n",
      "       3, 4, 6, 1, 3, 0, 0, 2, 0, 0, 2, 2, 2, 2, 6, 0, 6, 1, 0, 3, 6, 2,\n",
      "       1, 6, 1, 5, 0, 1, 2, 6, 2, 0, 5, 3, 5, 2, 5, 3, 2, 4, 5, 2])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1185,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 8582, 1107, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1129, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1105, 1191, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 3, 4, 5, 5, 2, 1, 0, 5, 0, 1, 0, 5, 1, 6, 3, 0, 6, 0, 1, 3, 5,\n",
      "       3, 6, 4, 4, 4, 0, 6, 0, 1, 1, 3, 3, 6, 1, 2, 1, 4, 6, 6, 6, 5, 5,\n",
      "       3, 6, 5, 3, 6, 1, 6, 4, 0, 5, 3, 1, 2, 6, 0, 6, 6, 0, 4, 5])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294, 14863, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9294,  1304, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103, 12239, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 20839, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 4, 1, 3, 4, 3, 5, 2, 0, 2, 6, 3, 6, 0, 6, 1, 1, 2, 0, 0, 0, 3,\n",
      "       6, 5, 3, 3, 0, 5, 2, 6, 5, 1, 5, 1, 4, 2, 4, 2, 5, 5, 0, 4, 1, 0,\n",
      "       1, 1, 2, 4, 0, 1, 6, 0, 2, 4, 1, 1, 5, 3, 3, 0, 1, 0, 0, 2])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1126,  1162, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1134,  1508, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  2206,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   174, 13430, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  4103,  1195, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 4, 4, 2, 3, 0, 0, 5, 0, 4, 3, 4, 6, 2, 3, 2, 5, 0, 5, 1, 1, 4,\n",
      "       1, 4, 6, 4, 1, 4, 0, 4, 6, 3, 4, 6, 1, 6, 5, 4, 4, 3, 6, 6, 1, 0,\n",
      "       4, 5, 2, 3, 1, 3, 5, 1, 4, 0, 1, 6, 3, 2, 2, 5, 5, 2, 1, 3])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 3074, 1111, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 8147, 1115, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1885, 1122, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 9294, 1185, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  184,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 1, 0, 3, 2, 4, 5, 1, 4, 4, 4, 4, 6, 1, 4, 0, 5, 2, 4, 6, 3, 0,\n",
      "       1, 5, 4, 4, 6, 5, 0, 5, 5, 2, 5, 0, 3, 4, 1, 2, 5, 3, 4, 6, 3, 1,\n",
      "       2, 5, 6, 2, 1, 6, 6, 4, 4, 4, 3, 3, 5, 6, 1, 6, 1, 6, 1, 1])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 15276,  1306, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1170,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1122,  1321, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  5540,  1105, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1111,  1164, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 3, 5, 0, 2, 1, 5, 0, 6, 5, 2, 3, 2, 5, 5, 6, 6, 1, 4, 3, 5, 0,\n",
      "       2, 2, 3, 6, 5, 4, 6, 6, 4, 4, 1, 6, 2, 1, 0, 3, 0, 3, 0, 5, 6, 4,\n",
      "       5, 1, 6, 5, 3, 3, 3, 2, 6, 4, 0, 4, 5, 6, 1, 5, 5, 5, 1, 3])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  1185, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  6699, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1800, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1165, 20839, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2676,  1293, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 0, 2, 0, 4, 3, 3, 5, 4, 2, 0, 3, 4, 0, 2, 4, 3, 2, 5, 1, 4, 6,\n",
      "       2, 5, 3, 2, 6, 6, 4, 2, 4, 0, 2, 0, 5, 5, 4, 6, 0, 5, 3, 1, 1, 3,\n",
      "       4, 3, 0, 6, 2, 0, 6, 3, 3, 5, 1, 0, 0, 2, 5, 4, 3, 0, 6, 4])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1396,  2511, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,  9994, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  7236,  1106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14807,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1191, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 5, 4, 6, 6, 1, 2, 5, 2, 5, 4, 3, 3, 2, 1, 2, 4, 4, 0, 5, 6, 3,\n",
      "       6, 4, 2, 1, 4, 4, 4, 4, 1, 5, 2, 3, 4, 6, 0, 6, 4, 2, 1, 4, 0, 2,\n",
      "       4, 1, 2, 5, 5, 4, 0, 0, 2, 1, 0, 2, 2, 6, 3, 0, 6, 0, 0, 4])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1173,  1494, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1272,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1219,   170, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1136,  1511, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   187, 12804, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 1, 0, 4, 0, 2, 5, 4, 5, 6, 1, 2, 5, 6, 2, 5, 4, 4, 6, 6, 2, 5,\n",
      "       0, 6, 6, 5, 0, 3, 6, 5, 3, 5, 4, 4, 4, 5, 3, 6, 5, 1, 1, 0, 4, 2,\n",
      "       4, 2, 0, 4, 5, 4, 2, 4, 4, 0, 6, 4, 6, 0, 0, 1, 2, 2, 4, 4])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  1324, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165, 11721, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1195, 16722, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1138, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   179, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 5, 0, 4, 2, 0, 2, 0, 0, 4, 4, 3, 0, 6, 4, 3, 2, 3, 1, 3, 3, 3,\n",
      "       5, 6, 6, 1, 6, 3, 4, 2, 2, 1, 4, 6, 6, 2, 1, 0, 5, 3, 2, 5, 3, 6,\n",
      "       3, 1, 3, 3, 3, 2, 5, 5, 3, 5, 2, 5, 4, 1, 3, 5, 6, 0, 4, 3])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1122,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  3485, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1170,  2824, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   175, 21091, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1139,  1910, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1423,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 3, 2, 5, 5, 3, 1, 3, 0, 2, 2, 2, 4, 2, 0, 4, 1, 0, 0, 0, 4, 1,\n",
      "       0, 2, 0, 1, 0, 2, 6, 5, 5, 2, 4, 4, 1, 3, 5, 5, 0, 2, 2, 4, 6, 1,\n",
      "       0, 6, 3, 2, 3, 0, 5, 5, 2, 0, 0, 6, 1, 3, 3, 4, 3, 3, 5, 1])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(val_dataset.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165, 20839, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   177,  6262, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1175, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1885,  1869, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1517,   170, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2100,  1234, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 3, 2, 1, 6, 5, 1, 4, 6, 6, 6, 4, 5, 1, 5, 0, 5, 6, 3, 5, 4, 5,\n",
      "       1, 0, 1, 0, 2, 1, 2, 1, 6, 3, 5, 4, 2, 6, 0, 0, 5, 3, 3, 6, 1, 5,\n",
      "       6, 3, 3, 0, 0, 5, 4, 1, 0, 5, 1, 5, 6, 2, 2, 5, 0, 0, 0, 1])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1105,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  5212,  1121, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1397,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1138, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178, 20055, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 5, 5, 1, 0, 2, 1, 6, 5, 1, 4, 4, 1, 4, 6, 6, 6, 2, 1, 2, 2, 4,\n",
      "       5, 4, 4, 6, 0, 2, 0, 6, 4, 1, 1, 1, 5, 0, 3, 4, 6, 1, 4, 4, 6, 3,\n",
      "       3, 3, 2, 4, 0, 6, 1, 4, 0, 4, 0, 4, 0, 1, 0, 2, 6, 0, 2, 2])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101,  179, 7745, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1184,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1293, 1242, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1115, 1115, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1103, 2581, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 0, 6, 6, 5, 4, 0, 4, 4, 0, 4, 1, 2, 4, 3, 4, 6, 0, 2, 4, 2, 5,\n",
      "       1, 0, 1, 3, 1, 5, 0, 5, 4, 1, 4, 5, 3, 4, 0, 5, 1, 1, 1, 4, 0, 3,\n",
      "       6, 6, 1, 6, 0, 5, 1, 6, 5, 6, 4, 1, 0, 6, 5, 2, 3, 5, 1, 1])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 22572,  5709, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3008,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1209, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1105,  1120, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  9964, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  2486, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 4, 3, 4, 3, 2, 0, 4, 4, 0, 5, 1, 3, 6, 0, 0, 1, 1, 6, 3, 0, 2,\n",
      "       6, 4, 1, 2, 0, 6, 0, 0, 3, 0, 4, 4, 1, 2, 6, 6, 2, 6, 0, 6, 4, 2,\n",
      "       0, 2, 4, 5, 6, 1, 2, 0, 4, 2, 3, 4, 3, 0, 6, 1, 4, 6, 0, 5])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1631, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2626,  1141, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  2566,  1178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1519, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 1, 5, 6, 5, 5, 0, 3, 4, 1, 5, 4, 1, 4, 0, 2, 2, 0, 0, 5, 1, 2,\n",
      "       0, 3, 5, 1, 5, 5, 5, 6, 0, 1, 0, 1, 0, 2, 6, 4, 2, 5, 5, 2, 6, 2,\n",
      "       5, 1, 5, 1, 3, 2, 6, 1, 0, 1, 3, 3, 6, 5, 4, 5, 5, 2, 4, 0])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1184,   136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  9468,  1324, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  9294,  1107, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1838, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 1, 0, 3, 0, 5, 3, 2, 6, 4, 4, 0, 6, 6, 0, 1, 2, 2, 4, 5, 4, 5,\n",
      "       2, 1, 4, 0, 1, 5, 3, 3, 4, 4, 3, 2, 4, 0, 5, 6, 6, 0, 0, 1, 1, 0,\n",
      "       5, 2, 6, 1, 6, 3, 3, 1, 0, 3, 1, 2, 2, 0, 2, 4, 1, 1, 3, 4])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 15276,   177, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1202,  1136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1152,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218, 12861, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1202, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 2, 5, 3, 3, 2, 5, 0, 3, 3, 2, 6, 1, 6, 1, 4, 5, 5, 5, 5, 6, 6,\n",
      "       0, 4, 4, 4, 2, 5, 4, 2, 4, 4, 0, 3, 2, 1, 1, 5, 5, 3, 3, 5, 4, 3,\n",
      "       4, 4, 2, 5, 6, 3, 2, 3, 1, 4, 3, 0, 1, 0, 4, 3, 4, 6, 2, 4])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1184,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1129, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1928, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1141, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 6, 4, 6, 2, 1, 4, 5, 1, 5, 6, 2, 1, 5, 6, 2, 1, 5, 5, 2, 4, 6,\n",
      "       4, 1, 4, 0, 3, 4, 0, 0, 4, 0, 0, 1, 6, 4, 1, 1, 3, 2, 1, 4, 4, 4,\n",
      "       6, 1, 3, 1, 4, 1, 5, 2, 6, 2, 6, 6, 5, 5, 0, 0, 3, 2, 3, 5])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  6798,  1161, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2147,  1115, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 12645,  1115, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1107,  1115, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 5, 2, 4, 1, 4, 2, 0, 6, 1, 4, 5, 6, 2, 6, 2, 4, 2, 4, 5, 4, 1,\n",
      "       6, 3, 0, 4, 2, 3, 3, 6, 5, 6, 1, 0, 4, 2, 6, 6, 3, 3, 0, 6, 4, 3,\n",
      "       1, 4, 6, 4, 2, 3, 1, 6, 3, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 4])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  2660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1473,  1104, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1119, 14635, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  7413,  4046, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863, 14863, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 5, 6, 3, 3, 5, 3, 0, 1, 0, 6, 1, 5, 5, 2, 2, 5, 2, 1, 6, 0, 6,\n",
      "       2, 1, 4, 3, 5, 6, 1, 0, 5, 2, 0, 1, 5, 6, 5, 3, 3, 0, 4, 3, 2, 4,\n",
      "       5, 6, 6, 0, 6, 6, 6, 1, 6, 4, 1, 3, 4, 4, 5, 0, 1, 6, 5, 4])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1128,  2564, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2100,   175, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863, 11159, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  4208,  4208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  3960,  2037, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1177, 15276, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 3, 6, 2, 6, 2, 4, 0, 5, 2, 1, 6, 5, 6, 2, 1, 2, 1, 2, 5, 6, 6,\n",
      "       2, 5, 2, 0, 0, 2, 1, 3, 5, 6, 2, 5, 2, 6, 2, 3, 3, 0, 6, 6, 2, 0,\n",
      "       1, 0, 6, 4, 1, 6, 3, 2, 2, 3, 2, 1, 4, 1, 5, 0, 6, 0, 1, 6])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1301, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1103,  7471, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1525, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1474,  8456, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20542,   136, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1141,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([4, 2, 1, 6, 3, 0, 5, 0, 6, 5, 4, 1, 1, 3, 3, 6, 6, 4, 0, 0, 3, 3,\n",
      "       3, 0, 2, 1, 3, 1, 1, 4, 6, 0, 0, 3, 3, 4, 4, 3, 5, 1, 0, 6, 5, 0,\n",
      "       5, 1, 0, 6, 3, 0, 2, 3, 5, 6, 5, 3, 1, 6, 2, 6, 5, 6, 6, 2])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  2112,  5674, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1800,  2819, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1301,  1243, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101, 22572,  5709, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 0, 4, 2, 2, 0, 3, 2, 0, 2, 6, 6, 5, 3, 0, 6, 6, 5, 3, 3, 1, 2,\n",
      "       3, 3, 6, 6, 4, 0, 0, 3, 4, 6, 5, 4, 3, 4, 0, 1, 4, 1, 2, 0, 6, 2,\n",
      "       4, 3, 0, 6, 0, 3, 5, 6, 0, 1, 5, 6, 1, 5, 6, 6, 1, 0, 2, 3])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 1928, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 9294, 1141, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1219,  170, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 0, 5, 2, 4, 1, 5, 3, 2, 0, 1, 3, 4, 2, 2, 6, 5, 0, 3, 4, 0, 1,\n",
      "       0, 2, 2, 6, 1, 1, 6, 3, 2, 6, 4, 2, 5, 1, 5, 5, 6, 0, 1, 3, 2, 2,\n",
      "       5, 2, 3, 1, 3, 5, 3, 1, 5, 6, 3, 5, 4, 2, 1, 1, 0, 6, 3, 1])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1139, 1534, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 4835, 1128, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 8991, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1170, 1940, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 5, 1, 5, 6, 5, 0, 3, 5, 2, 3, 6, 4, 0, 2, 0, 5, 2, 1, 0, 3, 6,\n",
      "       5, 5, 3, 0, 2, 2, 2, 1, 0, 1, 4, 6, 6, 5, 4, 5, 1, 1, 6, 0, 6, 3,\n",
      "       5, 1, 2, 3, 2, 1, 1, 0, 4, 3, 6, 2, 0, 6, 1, 6, 2, 0, 0, 2])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9627,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1362,  2332, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1142,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1122,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 11721,  1525, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  2246, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 6, 5, 6, 4, 3, 1, 0, 0, 5, 0, 2, 1, 5, 1, 2, 1, 1, 0, 5, 3, 6,\n",
      "       5, 3, 0, 1, 6, 0, 3, 2, 4, 4, 2, 3, 0, 5, 2, 6, 5, 2, 5, 3, 6, 1,\n",
      "       4, 4, 4, 0, 0, 6, 4, 3, 0, 0, 4, 4, 3, 4, 1, 0, 4, 5, 1, 3])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   170,  1372, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1185,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1156, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 23998,   187, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 4, 1, 3, 0, 4, 1, 6, 0, 4, 3, 3, 6, 1, 2, 2, 2, 3, 5, 0, 1, 4,\n",
      "       1, 0, 6, 2, 3, 0, 3, 0, 2, 0, 6, 5, 4, 0, 3, 2, 0, 3, 1, 2, 0, 6,\n",
      "       5, 2, 6, 1, 2, 0, 2, 3, 1, 5, 3, 0, 3, 3, 0, 0, 1, 1, 3, 3])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101, 21146,  1883, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1133,  1122, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 15354,  1208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1218,  1187, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   184,  1183, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   171,  8474, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 6, 4, 5, 1, 4, 4, 2, 5, 5, 4, 2, 1, 3, 2, 4, 1, 0, 3, 0, 5, 6,\n",
      "       6, 2, 6, 0, 1, 4, 3, 0, 6, 4, 6, 0, 5, 6, 0, 4, 0, 6, 4, 3, 1, 0,\n",
      "       0, 0, 0, 3, 2, 5, 1, 5, 0, 5, 0, 5, 0, 4, 1, 6, 2, 6, 3, 6])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1517,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   178,  1660, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1218,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1129, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 14863,  1115, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 2, 2, 2, 5, 3, 3, 1, 2, 6, 6, 0, 3, 5, 3, 4, 0, 1, 0, 1, 6, 6,\n",
      "       0, 3, 3, 0, 4, 4, 6, 5, 1, 1, 2, 1, 6, 0, 0, 3, 2, 6, 3, 0, 0, 3,\n",
      "       2, 0, 3, 4, 4, 1, 0, 4, 6, 4, 6, 5, 3, 3, 3, 0, 1, 3, 2, 4])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 3084, 3822, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1131, 2549, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 1321, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1184,  136, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 4208,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 0, 6, 3, 5, 4, 0, 5, 1, 0, 1, 4, 6, 2, 6, 5, 1, 5, 5, 5, 2, 5,\n",
      "       1, 4, 3, 1, 6, 1, 0, 3, 0, 5, 3, 3, 4, 4, 2, 3, 1, 0, 0, 4, 1, 4,\n",
      "       3, 5, 3, 2, 3, 3, 1, 2, 2, 0, 3, 6, 2, 4, 6, 3, 3, 0, 2, 0])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 9294, 1324, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218, 1208, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101,  178, 5412, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 8147,  102, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1122,  112, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1126, 1162, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 4, 2, 4, 3, 6, 5, 5, 2, 4, 5, 3, 1, 0, 4, 0, 3, 6, 2, 1, 3, 6,\n",
      "       3, 4, 1, 5, 1, 1, 6, 0, 2, 1, 6, 5, 2, 3, 4, 2, 3, 4, 0, 1, 4, 5,\n",
      "       4, 0, 5, 3, 0, 1, 0, 6, 5, 4, 1, 5, 3, 4, 2, 6, 4, 5, 4, 1])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  9294,  5540, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  1103, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,   170,  3218, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   170,  1910, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1229, 10458, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  4208,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 6, 5, 1, 3, 6, 6, 2, 4, 4, 2, 4, 4, 5, 1, 1, 2, 0, 6, 1,\n",
      "       1, 6, 1, 4, 5, 5, 1, 5, 6, 3, 0, 0, 6, 2, 3, 3, 2, 3, 5, 2, 5, 4,\n",
      "       1, 5, 3, 3, 6, 6, 4, 2, 6, 0, 0, 4, 0, 5, 4, 3, 2, 0, 2, 0])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1165, 1139, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 5804, 1112, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165, 1103, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101,  178, 1138, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1293, 1202, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1185,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 5, 3, 2, 6, 0, 1, 5, 5, 3, 4, 4, 1, 0, 5, 1, 3, 5, 1, 3, 4, 5,\n",
      "       1, 5, 0, 6, 2, 5, 5, 1, 2, 5, 1, 2, 2, 5, 3, 2, 0, 5, 6, 4, 1, 4,\n",
      "       2, 6, 4, 0, 6, 2, 3, 3, 1, 0, 2, 6, 6, 2, 1, 3, 4, 2, 4, 0])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   170,  1197, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1218,  1290, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  4035,  2528, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1272,  1191, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1128,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 21534,   119, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([6, 5, 1, 5, 2, 5, 5, 0, 1, 5, 1, 2, 4, 0, 2, 6, 4, 5, 4, 4, 2, 5,\n",
      "       3, 2, 6, 1, 3, 1, 0, 1, 2, 4, 6, 4, 5, 6, 1, 3, 4, 6, 5, 6, 4, 0,\n",
      "       3, 3, 6, 5, 3, 4, 5, 6, 6, 5, 5, 6, 1, 1, 4, 0, 6, 0, 3, 4])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1185,  3943, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 12493,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 15354,  4208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1177,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 20844,   106, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,   112, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 4, 5, 0, 5, 5, 4, 1, 6, 6, 1, 2, 0, 1, 6, 1, 2, 4, 2, 1, 2,\n",
      "       5, 0, 0, 5, 2, 2, 4, 4, 2, 3, 0, 1, 1, 0, 3, 1, 1, 1, 6, 5, 4, 5,\n",
      "       5, 0, 1, 4, 4, 5, 3, 6, 3, 0, 6, 6, 5, 0, 0, 0, 0, 5, 3, 1])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,   178,  2812, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1294,  1128, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1136,  1208, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,   178,  1341, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,  1139, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101, 25338,  3329, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([2, 5, 3, 2, 2, 4, 6, 1, 4, 5, 4, 4, 5, 4, 0, 1, 1, 4, 1, 6, 6, 3,\n",
      "       0, 5, 3, 3, 1, 0, 5, 6, 0, 4, 1, 2, 2, 6, 6, 0, 3, 6, 6, 2, 6, 0,\n",
      "       2, 2, 6, 3, 3, 2, 4, 1, 4, 1, 2, 1, 1, 2, 6, 4, 1, 0, 0, 1])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[  101,  1314,  3397, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1184,  4933, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1165,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  101,  1133, 23998, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  1105,  1234, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]],\n",
      "\n",
      "       [[  101,  2612,   178, ...,     0,     0,     0],\n",
      "        [    1,     1,     1, ...,     0,     0,     0],\n",
      "        [    0,     0,     0, ...,     0,     0,     0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 6, 1, 3, 6, 2, 0, 1, 1, 0, 5, 2, 6, 0, 3, 5, 6, 6, 3, 1, 4, 4,\n",
      "       2, 1, 2, 6, 2, 3, 6, 2, 4, 4, 3, 0, 5, 5, 1, 4, 6, 0, 6, 2, 3, 5,\n",
      "       1, 1, 5, 6, 6, 1, 0, 0, 0, 2, 6, 2, 2, 4, 4, 1, 5, 4, 6, 0])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1185, 7163, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1139,  180, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1917, 1129, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1199, 2880, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218, 1105, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 9294, 1324, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([5, 5, 3, 1, 4, 6, 4, 1, 3, 2, 0, 5, 5, 5, 0, 1, 6, 3, 3, 1, 0, 2,\n",
      "       1, 1, 5, 6, 0, 2, 0, 2, 6, 6, 5, 1, 0, 6, 3, 5, 5, 3, 2, 4, 5, 5,\n",
      "       4, 0, 3, 2, 6, 0, 6, 1, 5, 0, 2, 1, 5, 1, 5, 0, 3, 1, 6, 6])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1208, 1175, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1170, 1989, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1165,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 8147,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 8147,  119, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 9294,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([3, 3, 5, 4, 1, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 1, 4, 6, 3, 3, 1, 3,\n",
      "       4, 0, 2, 6, 5, 5, 0, 0, 3, 0, 6, 6, 0, 4, 2, 3, 4, 6, 5, 3, 4, 2,\n",
      "       5, 6, 3, 4, 3, 1, 6, 5, 2, 4, 0, 6, 3, 4, 5, 6, 2, 5, 4, 4])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(64, 3, 300), dtype=int32, numpy=\n",
      "array([[[ 101, 1103, 1671, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 3335, 1177, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1128, 1234, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 101, 1139, 3547, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1435, 1855, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]],\n",
      "\n",
      "       [[ 101, 1218,  178, ...,    0,    0,    0],\n",
      "        [   1,    1,    1, ...,    0,    0,    0],\n",
      "        [   0,    0,    0, ...,    0,    0,    0]]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 2, 0, 1, 5, 3, 5, 4, 3, 2, 3, 3, 5, 6, 1, 3, 6, 5, 6, 1, 6, 0,\n",
      "       5, 0, 2, 5, 5, 1, 5, 6, 5, 4, 1, 2, 3, 3, 2, 4, 6, 5, 2, 5, 2, 3,\n",
      "       3, 6, 5, 3, 5, 0, 2, 6, 2, 4, 3, 2, 2, 4, 6, 4, 4, 0, 6, 5])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(test_dataset.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de datos de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do all youre coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh. Thats so Monica can keep track. That way ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y'know what?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Push!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>Yeah, I mean, come on Ross, no one will even n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>They’re not listening too me?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>Of course they’re listening to you! Everybody ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>Monica you really think I should try this phas...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>I think you look fine.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto   Emotion\n",
       "0     Why do all youre coffee mugs have numbers on ...  surprise\n",
       "1     Oh. Thats so Monica can keep track. That way ...     angry\n",
       "2                                          Y'know what?   neutral\n",
       "3                        Come on, Lydia, you can do it.   neutral\n",
       "4                                                 Push!     happy\n",
       "...                                                 ...       ...\n",
       "2605  Yeah, I mean, come on Ross, no one will even n...   neutral\n",
       "2606                      They’re not listening too me?  surprise\n",
       "2607  Of course they’re listening to you! Everybody ...   neutral\n",
       "2608  Monica you really think I should try this phas...   neutral\n",
       "2609                             I think you look fine.   neutral\n",
       "\n",
       "[2610 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meld_text = pd.read_csv('test_sent_emo.csv')\n",
    "meld_text = meld_text.iloc[:,[1,3]]\n",
    "meld_text = meld_text.rename(columns={'Utterance':'texto'})\n",
    "meld_text['Emotion'] = meld_text['Emotion'].replace(['anger', 'joy', 'sadness'], ['angry', 'happy', 'sad'])\n",
    "meld_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y'know what?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Push!</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>Yeah, I mean, come on Ross, no one will even n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>They’re not listening too me?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>Of course they’re listening to you! Everybody ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>Monica you really think I should try this phas...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>I think you look fine.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto   Emotion\n",
       "0     Why do all you're coffee mugs have numbers on ...  surprise\n",
       "1     Oh. That's so Monica can keep track. That way ...     angry\n",
       "2                                          Y'know what?   neutral\n",
       "3                        Come on, Lydia, you can do it.   neutral\n",
       "4                                                 Push!     happy\n",
       "...                                                 ...       ...\n",
       "2605  Yeah, I mean, come on Ross, no one will even n...   neutral\n",
       "2606                      They’re not listening too me?  surprise\n",
       "2607  Of course they’re listening to you! Everybody ...   neutral\n",
       "2608  Monica you really think I should try this phas...   neutral\n",
       "2609                             I think you look fine.   neutral\n",
       "\n",
       "[2610 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eliminarAcentos(texto):\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "    return texto\n",
    "meld_text['texto'] = meld_text['texto'].apply(eliminarAcentos)\n",
    "meld_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Descargar el paquete 'averaged_perceptron_tagger' para la lematización pre-entrenada\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [00:05<00:00, 514.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Definir la función para asignar etiquetas POS de WordNet a etiquetas POS de NLTK\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_emotion_text(texto):\n",
    "    if isinstance(texto, list): #En caso de ser lista toma el primer valor\n",
    "        texto = texto[0] \n",
    "\n",
    "    if texto.startswith('[') and texto.endswith(']'): #Si empieza y termina con [ ] los elimina\n",
    "        texto = texto[1:-1]\n",
    "\n",
    "    texto = texto.lower()\n",
    "\n",
    "    texto = texto.replace('á', '')\n",
    "    texto = texto.replace('\\n', '')\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "\n",
    "    texto = re.sub(r\"@[A-Za-z0-9]+\", ' ', texto)\n",
    "    texto = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', texto)\n",
    "    texto = re.sub(r\"[^a-zA-Z.'!?]\", ' ', texto)\n",
    "    texto = re.sub(r\"#\", ' ', texto)\n",
    "    texto = re.sub(r\"\\s(?=\\')\", \"\", texto) #Eliminar los espacios que une los apóstrofes\n",
    "    texto = texto.replace(\"' \", \"'\")\n",
    "    texto = re.sub(r\" +\", ' ', texto)\n",
    "\n",
    "    # Tokenizar el texto y obtener las etiquetas POS\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(texto))\n",
    "    \n",
    "    # Mapear las etiquetas POS de NLTK a etiquetas POS de WordNet\n",
    "    wordnet_tagged = [(word, pos_tagger(tag)) for word, tag in pos_tagged]\n",
    "    \n",
    "    # Lematizar cada palabra con su etiqueta POS correspondiente\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, tag) if tag else word for word, tag in wordnet_tagged]\n",
    "    \n",
    "    # Unir las palabras lematizadas para formar el texto lematizado\n",
    "    lemmatized_text = \" \".join(lemmatized_words)\n",
    "\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\')\", \"\", lemmatized_text) #Eliminar los espacios que une los apóstrofes\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\.)\", \"\", lemmatized_text) #Eliminar los espacios que une los .\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\!)\", \"\", lemmatized_text) #Eliminar los espacios que une los !\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\?)\", \"\", lemmatized_text) #Eliminar los espacios que une los ?\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "# Llamado a la función de limpieza\n",
    "texto_clean_text = [clean_emotion_text(text) for text in tqdm(meld_text['texto'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 4, ..., 4, 4, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le_text2 = LabelEncoder()\n",
    "\n",
    "data_labels_text = le_text2.fit_transform(meld_text['Emotion'])\n",
    "data_labels_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le_text2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para aplicar el token en cada sentencia\n",
    "def encode_sentence(sent):\n",
    "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n",
    "  #Se aplica CLS para el inicio de clasificación y SEP para la separación en cada secuencia. Esto lo pide Bert.\n",
    "\n",
    "#Transforma los tokens en lista de ids para obtener la forma numerica de los datos\n",
    "def get_ids(tokens):\n",
    "  return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "#Se aplica la mascara para eliminar los tokens de PAD que son los padding para igualar los valores, igualando el token PAD en 0\n",
    "def get_mask(tokens):\n",
    "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "#Indica si el token es de la primera frase o segunda fase, agrando 0 o 1 dependiendo de la separación\n",
    "def get_segments(tokens):\n",
    "  seg_ids = [] #es una lista que se rellena con el token\n",
    "  current_seg_ids = 0\n",
    "\n",
    "  for tok in tokens: #recorre todos los tokens\n",
    "    seg_ids.append(current_seg_ids)\n",
    "    if tok == \"[SEP]\": #si el token es de separación\n",
    "      current_seg_ids = 1-current_seg_ids #convierte los 1 en 0 y viceversa\n",
    "\n",
    "  return seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputs_text = [encode_sentence(sent) for sent in texto_clean_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_label = [[sent_text, data_labels_text[i]] \n",
    "              for i, sent_text in enumerate(data_inputs_text)]\n",
    "\n",
    "sorted_all_text = [([get_ids(sent_lab_text[0]),\n",
    "                    get_mask(sent_lab_text[0]),\n",
    "                    get_segments(sent_lab_text[0])],\n",
    "                    sent_lab_text[1]) for sent_lab_text in sent_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text = tf.data.Dataset.from_generator(lambda: sorted_all_text, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_batch = dataset_text.padded_batch(BATCH_SIZE,\n",
    "                                               padded_shapes=((3,SEQUENCE_LENGTH), ()),\n",
    "                                               padding_values=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Emoción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well what's the problem? Let me change it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>oh! Marry you again? I wouldn't marry you agai...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>Beast</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>You're a wicked little vampire. And I pray to ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>Brute</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>pig</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4637 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Texto  Emoción\n",
       "0                                            Excuse me.  neutral\n",
       "1                                                 Yeah.  neutral\n",
       "2                                   Is there a problem?  neutral\n",
       "3            Well what's the problem? Let me change it.  neutral\n",
       "4                                That's out of control.    angry\n",
       "...                                                 ...      ...\n",
       "4632  oh! Marry you again? I wouldn't marry you agai...    angry\n",
       "4633                                              Beast    angry\n",
       "4634  You're a wicked little vampire. And I pray to ...    angry\n",
       "4635                                              Brute    angry\n",
       "4636                                                pig    angry\n",
       "\n",
       "[4637 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iemocap_text = pd.read_csv('df_filters.csv')\n",
    "iemocap_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Emoción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well what's the problem? Let me change it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>oh! Marry you again? I wouldn't marry you agai...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>Beast</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>You're a wicked little vampire. And I pray to ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>Brute</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>pig</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4637 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Texto  Emoción\n",
       "0                                            Excuse me.  neutral\n",
       "1                                                 Yeah.  neutral\n",
       "2                                   Is there a problem?  neutral\n",
       "3            Well what's the problem? Let me change it.  neutral\n",
       "4                                That's out of control.    angry\n",
       "...                                                 ...      ...\n",
       "4632  oh! Marry you again? I wouldn't marry you agai...    angry\n",
       "4633                                              Beast    angry\n",
       "4634  You're a wicked little vampire. And I pray to ...    angry\n",
       "4635                                              Brute    angry\n",
       "4636                                                pig    angry\n",
       "\n",
       "[4637 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eliminarAcentos(texto):\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "    return texto\n",
    "iemocap_text['Texto'] = iemocap_text['Texto'].apply(eliminarAcentos)\n",
    "iemocap_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Emoción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>How do you know he's even thinking about it?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>It's got that about it.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>What is going on here, Joe?</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>She is not his girl. She knows she's not.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Then why is she still single? New York is full...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>How do you know why she waited?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Because she knows what I know, that's why. She...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Nobody in this house dares take away her faith...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>I want you to-- I want you to act like he is c...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>I won't stand for any nonsense.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Because if he's not coming back, I'll kill mys...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Just believe with me, Joe. Only last week a ma...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>What have I got to hide? What the hell is the ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>You're the only one who still loves his parents.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>I know. It kind of went out of style, didn't it?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>It's not so bad; it's a good thing.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>[BREATHING] You know, it's lovely here. The ai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>You're not sorry you came.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>I'm not sorry, no. But I'm...I can't stay.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>For one thing, your mother much as told me to go.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Well.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>And then, you. You've been kind of...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>What?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Sort of embarrassed ever since I got here.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Well I was kind of planning of sneaking up on ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>I knew they would.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Well sure, from your mother's point of view. W...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>I, umm. I guess, I guess that's kind of why I ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>[BREATHING]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>I love you. Annie, I love you.</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[LAUGHTER]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>I don't really have any imagination, that's al...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>[LAUGHTER]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Am I embarrassing you? Are you - See, I didn't...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>No. No</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Chris, I've been ready a long, long, time.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>I almost got married two years ago.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>You started to write me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>You felt something that far back?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Every day since.</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Texto   Emoción\n",
       "250       How do you know he's even thinking about it?   neutral\n",
       "251                            It's got that about it.     angry\n",
       "252                        What is going on here, Joe?     angry\n",
       "253          She is not his girl. She knows she's not.     angry\n",
       "254  Then why is she still single? New York is full...     angry\n",
       "255                    How do you know why she waited?   neutral\n",
       "256  Because she knows what I know, that's why. She...     angry\n",
       "257  Nobody in this house dares take away her faith...     angry\n",
       "258  I want you to-- I want you to act like he is c...     angry\n",
       "259                    I won't stand for any nonsense.     angry\n",
       "260  Because if he's not coming back, I'll kill mys...     angry\n",
       "261  Just believe with me, Joe. Only last week a ma...     angry\n",
       "262  What have I got to hide? What the hell is the ...     angry\n",
       "263   You're the only one who still loves his parents.   neutral\n",
       "264   I know. It kind of went out of style, didn't it?   neutral\n",
       "265                It's not so bad; it's a good thing.   neutral\n",
       "266  [BREATHING] You know, it's lovely here. The ai...   neutral\n",
       "267                         You're not sorry you came.   neutral\n",
       "268         I'm not sorry, no. But I'm...I can't stay.   neutral\n",
       "269  For one thing, your mother much as told me to go.   neutral\n",
       "270                                              Well.   neutral\n",
       "271              And then, you. You've been kind of...   neutral\n",
       "272                                              What?   neutral\n",
       "273         Sort of embarrassed ever since I got here.   neutral\n",
       "274  Well I was kind of planning of sneaking up on ...   neutral\n",
       "275                                 I knew they would.   neutral\n",
       "276  Well sure, from your mother's point of view. W...   neutral\n",
       "277  I, umm. I guess, I guess that's kind of why I ...   neutral\n",
       "278                                        [BREATHING]     happy\n",
       "279                     I love you. Annie, I love you.     happy\n",
       "280                                         [LAUGHTER]     happy\n",
       "281  I don't really have any imagination, that's al...     happy\n",
       "282                                         [LAUGHTER]     happy\n",
       "283  Am I embarrassing you? Are you - See, I didn't...     happy\n",
       "284                                             No. No     happy\n",
       "285         Chris, I've been ready a long, long, time.   neutral\n",
       "286                I almost got married two years ago.   neutral\n",
       "287                           You started to write me.   neutral\n",
       "288                  You felt something that far back?  surprise\n",
       "289                                   Every day since.     happy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iemocap_text[250:290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Emoción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well what's the problem? Let me change it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I don't understand why this is so complicated ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clearly. You know, do you have like a supervis...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yeah. Do you want to see my supervisor? Huh? Y...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Did you get the mail? So you saw my letter?</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yeah. I know.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Texto  Emoción\n",
       "0                                         Excuse me.  neutral\n",
       "1                                              Yeah.  neutral\n",
       "2                                Is there a problem?  neutral\n",
       "3         Well what's the problem? Let me change it.  neutral\n",
       "4                             That's out of control.    angry\n",
       "5  I don't understand why this is so complicated ...    angry\n",
       "6  Clearly. You know, do you have like a supervis...  neutral\n",
       "7  Yeah. Do you want to see my supervisor? Huh? Y...    angry\n",
       "8        Did you get the mail? So you saw my letter?      sad\n",
       "9                                      Yeah. I know.      sad"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iemocap_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Descargar el paquete 'averaged_perceptron_tagger' para la lematización pre-entrenada\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4637 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4637/4637 [00:09<00:00, 464.34it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Definir la función para asignar etiquetas POS de WordNet a etiquetas POS de NLTK\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_emotion_text(texto):\n",
    "    if isinstance(texto, list): #En caso de ser lista toma el primer valor\n",
    "        texto = texto[0] \n",
    "\n",
    "    if texto.startswith('[') and texto.endswith(']'): #Si empieza y termina con [ ] los elimina\n",
    "        texto = texto[1:-1]\n",
    "\n",
    "    texto = texto.lower()\n",
    "\n",
    "    texto = texto.replace('á', '')\n",
    "    texto = texto.replace('\\n', '')\n",
    "    texto = texto.replace('[]', \"'\")\n",
    "    texto = texto.replace('', \"'\")\n",
    "\n",
    "    texto = re.sub(r\"@[A-Za-z0-9]+\", ' ', texto)\n",
    "    texto = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', texto)\n",
    "    texto = re.sub(r\"[^a-zA-Z.'!?]\", ' ', texto)\n",
    "    texto = re.sub(r\"#\", ' ', texto)\n",
    "    texto = re.sub(r\"\\s(?=\\')\", \"\", texto) #Eliminar los espacios que une los apóstrofes\n",
    "    texto = texto.replace(\"' \", \"'\")\n",
    "    texto = re.sub(r\" +\", ' ', texto)\n",
    "\n",
    "    # Tokenizar el texto y obtener las etiquetas POS\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(texto))\n",
    "    \n",
    "    # Mapear las etiquetas POS de NLTK a etiquetas POS de WordNet\n",
    "    wordnet_tagged = [(word, pos_tagger(tag)) for word, tag in pos_tagged]\n",
    "    \n",
    "    # Lematizar cada palabra con su etiqueta POS correspondiente\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, tag) if tag else word for word, tag in wordnet_tagged]\n",
    "    \n",
    "    # Unir las palabras lematizadas para formar el texto lematizado\n",
    "    lemmatized_text = \" \".join(lemmatized_words)\n",
    "\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\')\", \"\", lemmatized_text) #Eliminar los espacios que une los apóstrofes\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\.)\", \"\", lemmatized_text) #Eliminar los espacios que une los .\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\!)\", \"\", lemmatized_text) #Eliminar los espacios que une los !\n",
    "    lemmatized_text = re.sub(r\"\\s(?=\\?)\", \"\", lemmatized_text) #Eliminar los espacios que une los ?\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "# Llamado a la función de limpieza\n",
    "texto_clean_text_iemocap = [clean_emotion_text(text) for text in tqdm(iemocap_text['Texto'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excuse me.',\n",
       " 'yeah.',\n",
       " 'be there a problem?',\n",
       " \"well what's the problem? let me change it.\",\n",
       " \"that's out of control.\",\n",
       " \"i do n't understand why this be so complicate for people when they get here. it's just a simple form. i just need an id.\",\n",
       " 'clearly. you know do you have like a supervisor or something?',\n",
       " \"yeah. do you want to see my supervisor? huh? yeah. do you want to see my supervisor? fine. i'll be right back.\",\n",
       " 'do you get the mail? so you saw my letter?',\n",
       " 'yeah. i know.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texto_clean_text_iemocap[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le_text3 = LabelEncoder()\n",
    "\n",
    "data_labels_text_iemocap = le_text3.fit_transform(iemocap_text['Emoción'])\n",
    "data_labels_text_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le_text3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para aplicar el token en cada sentencia\n",
    "def encode_sentence(sent):\n",
    "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n",
    "  #Se aplica CLS para el inicio de clasificación y SEP para la separación en cada secuencia. Esto lo pide Bert.\n",
    "\n",
    "#Transforma los tokens en lista de ids para obtener la forma numerica de los datos\n",
    "def get_ids(tokens):\n",
    "  return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "#Se aplica la mascara para eliminar los tokens de PAD que son los padding para igualar los valores, igualando el token PAD en 0\n",
    "def get_mask(tokens):\n",
    "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "#Indica si el token es de la primera frase o segunda fase, agrando 0 o 1 dependiendo de la separación\n",
    "def get_segments(tokens):\n",
    "  seg_ids = [] #es una lista que se rellena con el token\n",
    "  current_seg_ids = 0\n",
    "\n",
    "  for tok in tokens: #recorre todos los tokens\n",
    "    seg_ids.append(current_seg_ids)\n",
    "    if tok == \"[SEP]\": #si el token es de separación\n",
    "      current_seg_ids = 1-current_seg_ids #convierte los 1 en 0 y viceversa\n",
    "\n",
    "  return seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputs_text_iemocap = [encode_sentence(sent) for sent in texto_clean_text_iemocap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]', 'excuse', 'me', '.', '[SEP]'],\n",
       " ['[CLS]', 'yeah', '.', '[SEP]'],\n",
       " ['[CLS]', 'be', 'there', 'a', 'problem', '?', '[SEP]']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_inputs_text_iemocap[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_label_iemocap = [[sent_text, data_labels_text_iemocap[i]] \n",
    "              for i, sent_text in enumerate(data_inputs_text_iemocap)]\n",
    "\n",
    "sorted_all_text_iemocap = [([get_ids(sent_lab_text[0]),\n",
    "                    get_mask(sent_lab_text[0]),\n",
    "                    get_segments(sent_lab_text[0])],\n",
    "                    sent_lab_text[1]) for sent_lab_text in sent_label_iemocap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[101, 9107, 1143, 119, 102], array([1, 1, 1, 1, 1]), [0, 0, 0, 0, 0]], 4),\n",
       " ([[101, 8147, 119, 102], array([1, 1, 1, 1]), [0, 0, 0, 0]], 4),\n",
       " ([[101, 1129, 1175, 170, 2463, 136, 102],\n",
       "   array([1, 1, 1, 1, 1, 1, 1]),\n",
       "   [0, 0, 0, 0, 0, 0, 0]],\n",
       "  4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_all_text_iemocap[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_iemocap = tf.data.Dataset.from_generator(lambda: sorted_all_text_iemocap, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_batch_iemocap = dataset_text_iemocap.padded_batch(BATCH_SIZE,\n",
    "                                               padded_shapes=((3,SEQUENCE_LENGTH), ()),\n",
    "                                               padding_values=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bert + NGram-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 3, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda_24 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_25 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_26 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " keras_layer_9 (KerasLayer)     [(None, 768),        108310273   ['lambda_24[0][0]',              \n",
      "                                 (None, 300, 768)]                'lambda_25[0][0]',              \n",
      "                                                                  'lambda_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 300, 50)      76850       ['keras_layer_9[0][1]']          \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 300, 50)      115250      ['keras_layer_9[0][1]']          \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 300, 50)      153650      ['keras_layer_9[0][1]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d_21 (Globa  (None, 50)          0           ['conv1d_21[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_22 (Globa  (None, 50)          0           ['conv1d_22[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_23 (Globa  (None, 50)          0           ['conv1d_23[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (None, 150)          0           ['global_max_pooling1d_21[0][0]',\n",
      "                                                                  'global_max_pooling1d_22[0][0]',\n",
      "                                                                  'global_max_pooling1d_23[0][0]']\n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 150)          0           ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 256)          38656       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 256)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 7)            1799        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,696,478\n",
      "Trainable params: 386,205\n",
      "Non-trainable params: 108,310,273\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "x_1 = layers.Conv1D(filters=50, kernel_size=2, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "x_1 = layers.GlobalMaxPooling1D()(x_1)\n",
    "x_2 = layers.Conv1D(filters=50, kernel_size=3, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "x_2 = layers.GlobalMaxPooling1D()(x_2)\n",
    "x_3 = layers.Conv1D(filters=50, kernel_size=4, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "x_3 = layers.GlobalMaxPooling1D()(x_3)\n",
    "#x_4 = layers.Conv1D(filters=50, kernel_size=5, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "#x_4 = layers.GlobalMaxPooling1D()(x_4)\n",
    "\n",
    "#merged = tf.concat([x_1, x_2, x_3, x_4], axis=-1)\n",
    "merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "dropout = layers.Dropout(0.2)(merged)\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(dropout)\n",
    "dropout = layers.Dropout(0.5)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(dropout)\n",
    "\n",
    "modelBertCnn = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertCnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertCnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#--------------------Checkpoint--------------------\n",
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('model/BERT/CNN/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_path = 'model/BERT/CNN/64batch/BERT_CNN_model_best_{epoch:02d}_val_{val_sparse_categorical_accuracy:.4f}'\n",
    "\n",
    "# Callback de ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_format='tf',\n",
    "    save_weights_only=False,\n",
    ")\n",
    "\n",
    "\n",
    "#----------------Tensorboard-------------------\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "os.makedirs('logs/BERT/CNN/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"logs/BERT/CNN/64batch\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "    492/Unknown - 577s 898ms/step - loss: 1.4235 - sparse_categorical_accuracy: 0.4664\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.58739, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_01_val_0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_01_val_0.5874\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_01_val_0.5874\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 848s 1s/step - loss: 1.4235 - sparse_categorical_accuracy: 0.4664 - val_loss: 1.1503 - val_sparse_categorical_accuracy: 0.5874\n",
      "Epoch 2/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 1.1585 - sparse_categorical_accuracy: 0.5809\n",
      "Epoch 2: val_sparse_categorical_accuracy improved from 0.58739 to 0.61373, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_02_val_0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_02_val_0.6137\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_02_val_0.6137\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 708s 1s/step - loss: 1.1585 - sparse_categorical_accuracy: 0.5809 - val_loss: 1.0742 - val_sparse_categorical_accuracy: 0.6137\n",
      "Epoch 3/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 1.0329 - sparse_categorical_accuracy: 0.6313\n",
      "Epoch 3: val_sparse_categorical_accuracy improved from 0.61373 to 0.64654, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_03_val_0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_03_val_0.6465\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_03_val_0.6465\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 755s 1s/step - loss: 1.0329 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.0020 - val_sparse_categorical_accuracy: 0.6465\n",
      "Epoch 4/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.9295 - sparse_categorical_accuracy: 0.6724\n",
      "Epoch 4: val_sparse_categorical_accuracy improved from 0.64654 to 0.66384, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_04_val_0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_04_val_0.6638\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_04_val_0.6638\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 709s 1s/step - loss: 0.9295 - sparse_categorical_accuracy: 0.6724 - val_loss: 0.9507 - val_sparse_categorical_accuracy: 0.6638\n",
      "Epoch 5/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.8356 - sparse_categorical_accuracy: 0.7028\n",
      "Epoch 5: val_sparse_categorical_accuracy improved from 0.66384 to 0.67288, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_05_val_0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_05_val_0.6729\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_05_val_0.6729\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 708s 1s/step - loss: 0.8356 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.9310 - val_sparse_categorical_accuracy: 0.6729\n",
      "Epoch 6/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.7510 - sparse_categorical_accuracy: 0.7368\n",
      "Epoch 6: val_sparse_categorical_accuracy improved from 0.67288 to 0.68203, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_06_val_0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_06_val_0.6820\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_06_val_0.6820\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 750s 1s/step - loss: 0.7510 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.9137 - val_sparse_categorical_accuracy: 0.6820\n",
      "Epoch 7/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.6781 - sparse_categorical_accuracy: 0.7614\n",
      "Epoch 7: val_sparse_categorical_accuracy improved from 0.68203 to 0.69375, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_07_val_0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_07_val_0.6938\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_07_val_0.6938\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 709s 1s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.9209 - val_sparse_categorical_accuracy: 0.6938\n",
      "Epoch 8/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.6173 - sparse_categorical_accuracy: 0.7837\n",
      "Epoch 8: val_sparse_categorical_accuracy improved from 0.69375 to 0.69855, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_08_val_0.6985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_08_val_0.6985\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_08_val_0.6985\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 708s 1s/step - loss: 0.6173 - sparse_categorical_accuracy: 0.7837 - val_loss: 0.8929 - val_sparse_categorical_accuracy: 0.6985\n",
      "Epoch 9/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.5711 - sparse_categorical_accuracy: 0.7997\n",
      "Epoch 9: val_sparse_categorical_accuracy improved from 0.69855 to 0.70167, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_09_val_0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_09_val_0.7017\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_09_val_0.7017\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 710s 1s/step - loss: 0.5711 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.9144 - val_sparse_categorical_accuracy: 0.7017\n",
      "Epoch 10/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.5226 - sparse_categorical_accuracy: 0.8157\n",
      "Epoch 10: val_sparse_categorical_accuracy improved from 0.70167 to 0.70670, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_10_val_0.7067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_10_val_0.7067\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_10_val_0.7067\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 765s 1s/step - loss: 0.5226 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.8998 - val_sparse_categorical_accuracy: 0.7067\n",
      "Epoch 11/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.4767 - sparse_categorical_accuracy: 0.8323\n",
      "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.70670\n",
      "492/492 [==============================] - 619s 1s/step - loss: 0.4767 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.9640 - val_sparse_categorical_accuracy: 0.6939\n",
      "Epoch 12/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.4548 - sparse_categorical_accuracy: 0.8430\n",
      "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.70670\n",
      "492/492 [==============================] - 619s 1s/step - loss: 0.4548 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.9550 - val_sparse_categorical_accuracy: 0.7021\n",
      "Epoch 13/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.4238 - sparse_categorical_accuracy: 0.8520\n",
      "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.70670\n",
      "492/492 [==============================] - 619s 1s/step - loss: 0.4238 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.9615 - val_sparse_categorical_accuracy: 0.7066\n",
      "Epoch 14/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.4025 - sparse_categorical_accuracy: 0.8593\n",
      "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.70670\n",
      "492/492 [==============================] - 619s 1s/step - loss: 0.4025 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.9737 - val_sparse_categorical_accuracy: 0.7064\n",
      "Epoch 15/15\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.3735 - sparse_categorical_accuracy: 0.8692\n",
      "Epoch 15: val_sparse_categorical_accuracy improved from 0.70670 to 0.70871, saving model to model/BERT/CNN/64batch\\BERT_CNN_model_best_15_val_0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, restored_function_body, restored_function_body while saving (showing 5 of 329). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_15_val_0.7087\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/BERT/CNN/64batch\\BERT_CNN_model_best_15_val_0.7087\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 706s 1s/step - loss: 0.3735 - sparse_categorical_accuracy: 0.8692 - val_loss: 1.0021 - val_sparse_categorical_accuracy: 0.7087\n"
     ]
    }
   ],
   "source": [
    "historymodelBertCnn =  modelBertCnn.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    validation_data = val_dataset,\n",
    "    callbacks = [model_checkpoint,tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAGMCAYAAACmm+O/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC2cElEQVR4nOzdd1xV9RvA8c9lywaZIoh7TxRy5cLcpZU7V65MTTMrrVxlmg1/apqWZWpproampuW23Li34gAREES2rHvP74+jV6+gAgKX8bxfr/PCe+4Zz71y+J7nfJdGURQFIYQQQgghhBBCGJ2JsQMQQgghhBBCCCGESpJ0IYQQQgghhBCikJAkXQghhBBCCCGEKCQkSRdCCCGEEEIIIQoJSdKFEEIIIYQQQohCQpJ0IYQQQgghhBCikJAkXQghhBBCCCGEKCQkSRdCCCGEEEIIIQoJSdKFEIVaSEgIU6dO5dSpU8YORQghhBAlyI4dO5g+fTpJSUnGDkWUMJKkCyEyWbp0KRqNhmvXrhk1jvT0dHr06MHJkyepWbPmMx9Po9EwdepU/eucfE5fX18GDhz4zDEIIYQQBamwlOn5KTdl9NSpU9FoNI99Pzg4mG7duuHm5oaNjc0zRihEzkiSLkQOBAcHM3z4cCpUqICVlRX29vY0bdqUuXPncvfuXWOHV+y89957mJqasmLFCkxM5M+VEEKIvCNlunic1NRUunfvzqhRoxg2bJixwxElkJmxAxCiqNi0aRPdu3fH0tKS/v37U6tWLdLS0vj333959913OXPmDN99952xwyw2YmNjcXJyYsOGDZQqVSpfztGvXz969eqFpaVlvhxfCCFE4SRlevFy4cKFHD/M/+ijj5gwYUKW7506dYpBgwYxevTovAhPiByTJF2IbLh69Sq9evWiXLly7NixA09PT/17I0eO5PLly2zatClPzpWUlCTNqgBHR0cmT56co31y+t2Zmppiamqa09CEEEIUYVKmG4+iKKSkpOT5w/fcPGw3MzPDzCzrVKhhw4Y0bNjwWcMSItek/agQ2fD555+TmJjIDz/8YFCY31epUiXGjBkDwLVr19BoNCxdujTTdo/2ib7fH+rs2bP06dMHJycnmjVrxpdffolGo+H69euZjjFx4kQsLCy4c+cOAHv37qV79+74+PhgaWmJt7c3b7/9drab6p05c4bWrVtTqlQpypYty/Tp09HpdFlu+9dff9G8eXNsbGyws7OjU6dOnDlz5qnnuN8fbs+ePQwfPpzSpUtjb29P//799Z8jp+cZOHAgtra2BAcH07FjR+zs7Ojbty+gNlN7++23cXV1xc7OjhdffJEbN248Nq6H++kpisL06dMpW7Ys1tbWtGrVKsvPGBMTw/jx46lduza2trbY29vToUMHTpw48dTvQwghhPFIma4qiDLd19eXzp07s3XrVho2bEipUqX49ttvAbXF3NixY/H29sbS0pJKlSoxa9asTPHqdDrmzp1L7dq1sbKywtXVlfbt23PkyBGD8zzcJz09PZ1p06ZRuXJlrKysKF26NM2aNeOff/7Rb5NVn/SMjAw++eQTKlasiKWlJb6+vnzwwQekpqZm+bn+/fdf/P39sbKyokKFCixfvvyp358Q2SE16UJkw59//kmFChVo0qRJvhy/e/fuVK5cmRkzZqAoCp07d+a9995jzZo1vPvuuwbbrlmzhhdeeAEnJycA1q5dS3JyMiNGjKB06dIcOnSIr7/+mhs3brB27donnjciIoJWrVqRkZHBhAkTsLGx4bvvvsvyCfdPP/3EgAEDaNeuHbNmzSI5OZmFCxfSrFkzjh07hq+v71M/56hRo3B0dGTq1KlcuHCBhQsXcv36dXbt2qUvKHNynoyMDNq1a6e/CbK2tgZgyJAh/Pzzz/Tp04cmTZqwY8cOOnXq9NT4ACZPnsz06dPp2LEjHTt25OjRo7zwwgukpaUZbHflyhX++OMPunfvTvny5YmMjOTbb7+lRYsWnD17ljJlymTrfEIIIQqWlOkFV6aD2hS9d+/eDB8+nKFDh1K1alWSk5Np0aIFYWFhDB8+HB8fH/bt28fEiRMJDw9nzpw5+v0HDx7M0qVL6dChA0OGDCEjI4O9e/dy4MCBx9Z2T506lZkzZzJkyBD8/f2Jj4/nyJEjHD16lLZt2z72Mw0ZMoRly5bx6quv8s4773Dw4EFmzpzJuXPn+P333w22vXz5Mq+++iqDBw9mwIABLFmyhIEDB+Ln55cng92KEk4RQjxRXFycAigvvfRStra/evWqAig//vhjpvcAZcqUKfrXU6ZMUQCld+/embZt3Lix4ufnZ7Du0KFDCqAsX75cvy45OTnTvjNnzlQ0Go1y/fr1J8Y6duxYBVAOHjyoX3fr1i3FwcFBAZSrV68qiqIoCQkJiqOjozJ06FCD/SMiIhQHB4dM6x/1448/KoDi5+enpKWl6dd//vnnCqCsX78+x+cZMGCAAigTJkww2Pb48eMKoLz55psG6/v06ZPp+78f1/3PeevWLcXCwkLp1KmTotPp9Nt98MEHCqAMGDBAvy4lJUXRarUG57h69apiaWmpfPzxx0/8PoQQQhiHlOkFV6YriqKUK1dOAZQtW7YYHOOTTz5RbGxslIsXLxqsnzBhgmJqaqqEhIQoiqIoO3bsUADlrbfeyhTHw+V0uXLlDMrounXrKp06dXri57j//3Xf/fuHIUOGGGw3fvx4BVB27NiR6XPt2bNHv+7WrVuKpaWl8s477zzxvEJkhzR3F+Ip4uPjAbCzs8u3c7zxxhuZ1vXs2ZOgoCCCg4P161avXo2lpSUvvfSSft3DT8iTkpKIjo6mSZMmKIrCsWPHnnjezZs389xzz+Hv769f5+rqqm82ft8///xDbGwsvXv3Jjo6Wr+YmpoSEBDAzp07s/U5hw0bhrm5uf71iBEjMDMzY/Pmzbk+z4gRIzJ9JoC33nrLYP3YsWOfGt+2bdtIS0tj9OjRBrUAWe1raWmpH6RGq9Vy+/ZtbG1tqVq1KkePHn3quYQQQhQ8KdMLrky/r3z58rRr185g3dq1a2nevDlOTk4GMQQGBqLVatmzZw8Av/76KxqNhilTpmQ6/5OmT3N0dOTMmTNcunQpW58FHtw/jBs3zmD9O++8A5BpnIIaNWrQvHlz/WtXV1eqVq3KlStXsn1OIR5HknQhnsLe3h6AhISEfDtH+fLlM63r3r07JiYmrF69GlD7Sq9du5YOHTroYwIICQlh4MCBODs7Y2tri6urKy1atAAgLi7uiee9fv06lStXzrS+atWqBq/vF3KtW7fG1dXVYPn777+5detWtj7no+eytbXF09NT3yc8p+cxMzOjbNmymT6TiYkJFStWfOJnysr9/oKPxunq6qpvinifTqfjf//7H5UrV8bS0hIXFxdcXV05efLkU793IYQQxiFlesGV6fdl9X1cunSJLVu2ZDp/YGAggD6G4OBgypQpg7Ozc7Ziuu/jjz8mNjaWKlWqULt2bd59911Onjz5xH3u3z9UqlTJYL2HhweOjo6ZxhTw8fHJdAwnJ6csx9oRIqekT7oQT2Fvb0+ZMmU4ffp0trZ/3JNdrVb72H2y6i9WpkwZmjdvzpo1a/jggw84cOAAISEhzJo1y+CYbdu2JSYmhvfff59q1aphY2NDWFgYAwcOfOxgMTl1/zg//fQTHh4emd5/3Oio+X2eh2uzC9qMGTOYNGkSr7/+Op988gnOzs6YmJgwduzYPPvehRBC5C0p0wuuTL8vq+9Dp9PRtm1b3nvvvSz3qVKlyjOd8/nnnyc4OJj169fz999/8/333/O///2PRYsWMWTIkCfu+6Qa+oc9bnYYRVFyHK8Qj5IkXYhs6Ny5M9999x379++ncePGT9z2fo1rbGyswfqsRnV9mp49e/Lmm29y4cIFVq9ejbW1NV26dNG/f+rUKS5evMiyZcvo37+/fv3Do5c+Sbly5bJsCnbhwgWD1/drpd3c3PRPuXPj0qVLtGrVSv86MTGR8PBwOnbsmGfnKVeuHDqdjuDgYIPag0c/0+P2vR9nhQoV9OujoqIyPRlft24drVq14ocffjBYHxsbi4uLS65iF0IIkf+kTC+YMv1JKlasSGJi4lPPX7FiRbZu3UpMTEyOa9OdnZ0ZNGgQgwYNIjExkeeff56pU6c+Nkm/f/9w6dIlqlevrl8fGRlJbGys/h5BiIIgzd2FyIb33nsPGxsbhgwZQmRkZKb3g4ODmTt3LqA+pXdxcdH3p7rvm2++yfF5X3nlFUxNTfnll19Yu3YtnTt3Nphv9f5T3Ief2iqKoo/laTp27MiBAwc4dOiQfl1UVBQrVqww2K5du3bY29szY8YM0tPTMx0nKioqW+f77rvvDPZfuHAhGRkZdOjQIc/Oc/9Y8+bNM1j/8EixjxMYGIi5uTlff/21wXea1b6mpqaZnpavXbuWsLCwp55HCCGE8UiZXjBl+pP06NGD/fv3s3Xr1kzvxcbGkpGRAajfmaIoTJs2LdN2T6qxvn37tsFrW1tbKlWqlGkqtYfdf7jwaJk/e/ZsgGzPEiNEXpCadCGyoWLFiqxcuZKePXtSvXp1+vfvT61atUhLS2Pfvn2sXbvWYH7OIUOG8NlnnzFkyBAaNmzInj17uHjxYo7P6+bmRqtWrZg9ezYJCQn07NnT4P1q1apRsWJFxo8fT1hYGPb29vz666/Z7g/13nvv8dNPP9G+fXvGjBmjn66lXLlyBn237O3tWbhwIf369aNBgwb06tULV1dXQkJC2LRpE02bNmX+/PlPPV9aWhpt2rShR48eXLhwgW+++YZmzZrx4osv5tl56tWrR+/evfnmm2+Ii4ujSZMmbN++ncuXLz81PldXV8aPH8/MmTPp3LkzHTt25NixY/z111+Zasc7d+7Mxx9/zKBBg2jSpAmnTp1ixYoVBjXwQgghCh8p0wumTH+Sd999lw0bNtC5c2f9tGVJSUmcOnWKdevWce3aNVxcXGjVqhX9+vVj3rx5XLp0ifbt26PT6di7dy+tWrVi1KhRWR6/Ro0atGzZEj8/P5ydnTly5Ajr1q177PYAdevWZcCAAXz33XfExsbSokULDh06xLJly+jatatBqwEh8p1RxpQXooi6ePGiMnToUMXX11exsLBQ7OzslKZNmypff/21kpKSot8uOTlZGTx4sOLg4KDY2dkpPXr0UG7duvXY6VqioqIee87FixcrgGJnZ6fcvXs30/tnz55VAgMDFVtbW8XFxUUZOnSocuLEicdOGfOokydPKi1atFCsrKwULy8v5ZNPPlF++OEHg+la7tu5c6fSrl07xcHBQbGyslIqVqyoDBw4UDly5MgTz3F/upbdu3crw4YNU5ycnBRbW1ulb9++yu3btzNtn53zDBgwQLGxscnyfHfv3lXeeustpXTp0oqNjY3SpUsXJTQ09KlTsCmKomi1WmXatGmKp6enUqpUKaVly5bK6dOnM03vkpKSorzzzjv67Zo2bars379fadGihdKiRYsnfh9CCCGMT8r0/C/Ty5Ur99ip0BISEpSJEycqlSpVUiwsLBQXFxelSZMmypdffmkwtVtGRobyxRdfKNWqVVMsLCwUV1dXpUOHDkpQUJDBeR4uo6dPn674+/srjo6OSqlSpZRq1aopn376qcFxH52CTVEUJT09XZk2bZpSvnx5xdzcXPH29lYmTpxo8PvwpM8l9wAir2gURUY3EELkr6VLlzJo0CAOHz5Mw4YNjR2OEEIIIXJJynQh8p/0SRdCCCGEEEIIIQoJSdKFEEIIIYQQQohCQpJ0IYQQQgghhBCikJA+6UIIIYQQQgghRCEhNelCCCGEEEIIIUQhIUm6EEIIIYQQQghRSEiSLoQQQgghhBBCFBJmxg6goOl0Om7evImdnR0ajcbY4QghhBAoikJCQgJlypTBxESen+cFKe+FEEIUJjkp60tckn7z5k28vb2NHYYQQgiRSWhoKGXLljV2GMWClPdCCCEKo+yU9SUuSbezswPUL8fe3t7I0QghhBAQHx+Pt7e3vowSz07KeyGEEIVJTsr6Epek32/yZm9vL4W2EEKIQkWaZecdKe+FEEIURtkp66XjmxBCCCGEEEIIUUhIki6EEEIIIYQQQhQSkqQLIYQQQgghhBCFRInrky6EEE+iKAoZGRlotVpjhyKKEVNTU8zMzKTPeSEi17rIL+bm5piamho7DCFEESZJuhBC3JOWlkZ4eDjJycnGDkUUQ9bW1nh6emJhYWHsUEo8udZFftJoNJQtWxZbW1tjhyKEKKIkSRdCCECn03H16lVMTU0pU6YMFhYWUusp8oSiKKSlpREVFcXVq1epXLkyJibS28xY5FoX+UlRFKKiorhx4waVK1eWGnUhRK5Iki6EEKg1azqdDm9vb6ytrY0djihmSpUqhbm5OdevXyctLQ0rKytjh1RiybUu8purqyvXrl0jPT1dknQhRK7Io3whhHiI1HCK/CK/W4WL/H+I/CItM4QQz0pKKCGEEEIIIYQQopCQJP0ZJKSks+LgdUJjZOAZIYQoDHx9fZkzZ46xwxBC5DO51oUQ+S1dq+NYyB1WHgwp8HNLkv4M3l59gg9/P80vhwr+P04IIe4bOHAgGo0m09K+ffts7b9r1y40Gg2xsbH5G2gBOHz4MMOGDcvTY7Zs2ZKxY8fm6TGFyA251h+Qa10Ikdcy7iXlC3cFM2DJIepN+5tu3+zjg99PEZ2YWqCxyMBxz+CVBl5sOxfJuqAbjGtbBTNTeeYhhDCO9u3b8+OPPxqss7S0zNNzpKWlFfrpw1xdXY0dghD5Sq51lVzrQohnlaHVcSosjgNXYjhw5TZHrsWQlKY12MahlDn+5Z1JSMnAxTZv/9Y+iWSVz6BNdXdK21hwKyGVXReijB2OEKIEs7S0xMPDw2BxcnIC1EGMvv/+e7p164a1tTWVK1dmw4YNAFy7do1WrVoB4OTkhEajYeDAgYBaqzRq1CjGjh2Li4sL7dq1A+D06dN06NABW1tb3N3d6devH9HR0fpYWrZsyVtvvcV7772Hs7MzHh4eTJ061SDe2bNnU7t2bWxsbPD29ubNN98kMTFR//7SpUtxdHRk48aNVK1aFWtra1599VWSk5NZtmwZvr6+ODk58dZbb6HVPihQH20CGxsby5AhQ3B1dcXe3p7WrVtz4sQJ/ftTp06lXr16/PTTT/j6+uLg4ECvXr1ISEgA1JrL3bt3M3fuXH2t5bVr1wDYvXs3/v7+WFpa4unpyYQJE8jIyHiG/0Uhnk6udZVc60KInMrQ6jgeGsui3cEM/PEQde/VlM/acp7dF6NIStNib2VG2xruTOpcg01vNePYpLYs7t+Q8i42BRqrUZP0PXv20KVLF8qUKYNGo+GPP/7I9r7//fcfZmZm1KtXL9/iexoLMxO61fcCYPWRUKPFIYTIH4qikJyWUeCLoih5/lmmTZtGjx49OHnyJB07dqRv377ExMTg7e3Nr7/+CsCFCxcIDw9n7ty5+v2WLVuGhYUF//33H4sWLSI2NpbWrVtTv359jhw5wpYtW4iMjKRHjx4G51u2bBk2NjYcPHiQzz//nI8//ph//vlH/76JiQnz5s3jzJkzLFu2jB07dvDee+8ZHCM5OZl58+axatUqtmzZwq5du+jWrRubN29m8+bN/PTTT3z77besW7fusZ+7e/fu3Lp1i7/++ougoCAaNGhAmzZtiImJ0W8THBzMH3/8wcaNG9m4cSO7d+/ms88+A2Du3Lk0btyYoUOHEh4eTnh4ON7e3oSFhdGxY0caNWrEiRMnWLhwIT/88APTp0/P/X+SMBpjXev5cb3LtS7XuhBClVVS3nXBf3z213l2XXhMUj75BRb3b8jgZuWpWcYBExPjzNZg1ObuSUlJ1K1bl9dff52XX3452/vFxsbSv39/2rRpQ2RkZD5G+HQ9G3nz/b9X2XH+FrcSUnCzk7lvhSgu7qZrqTF5a4Gf9+zH7bC2yNmf540bN2Jra2uw7oMPPuCDDz4A1Fqi3r17AzBjxgzmzZvHoUOHaN++Pc7OzgC4ubnh6OhocIzKlSvz+eef619Pnz6d+vXrM2PGDP26JUuW4O3tzcWLF6lSpQoAderUYcqUKfpjzJ8/n+3bt9O2bVsAg36fvr6+TJ8+nTfeeINvvvlGvz49PZ2FCxdSsWJFAF599VV++uknIiMjsbW1pUaNGrRq1YqdO3fSs2fPTN/Jv//+y6FDh7h165a+OfCXX37JH3/8wbp16/T9WXU6HUuXLsXOzg6Afv36sX37dj799FMcHBywsLDA2toaDw8P/bG/+eYbvL29mT9/PhqNhmrVqnHz5k3ef/99Jk+eLNN7FTHGutYh59e7XOtyrQshspah1XH6ZjwHrtzmwJXbHL6aufm6vZUZARVK81yF0jxXwZlqHvaYGikRfxKjJukdOnSgQ4cOOd7vjTfeoE+fPpiamuao9j0/VHa3o4GPI0dDYvk1KIwRLSsaNR4hRMnUqlUrFi5caLDu/g05qDfS99nY2GBvb8+tW7eeelw/Pz+D1ydOnGDnzp2ZkgRQa6kevnF/mKenp8H5tm3bxsyZMzl//jzx8fFkZGSQkpJCcnIy1tbWAFhbW+tv2gHc3d3x9fU1OLe7u/tjP8eJEydITEykdOnSBuvv3r1LcHCw/rWvr6/+pj2rWLNy7tw5GjdubDAfctOmTUlMTOTGjRv4+Pg8cX8hckuu9czkWheiZCpOSfmjitzAcT/++CNXrlzh559/zlZTo9TUVFJTH4zGFx8fn+cx9Wrkw9GQWNYcCeWNFhUM/pALIYquUuamnP24nVHOm1M2NjZUqlTpse+bm5sbvNZoNOh0umwd92GJiYl06dKFWbNmZdrW09MzW+e7du0anTt3ZsSIEXz66ac4Ozvz77//MnjwYNLS0vQ37lkdIyefIzExEU9PT3bt2pXpvYdrEXP73Yjiw1jX+v1z54Rc65nJtS5EyRCdmMq58HhOh8Vz8Optjly7Q2Kq4fgQRTUpf1SRStIvXbrEhAkT2Lt3L2Zm2Qt95syZTJs2LV/j6lTHk2l/nuFqdBKHrsYQUKH003cSQhR6Go0mx83Oi6L7ozg/PCjT4zRo0IBff/0VX1/fbP8dflRQUBA6nY6vvvpK31R0zZo1uTrWkzRo0ICIiAjMzMzw9fXN9XEsLCwyfTfVq1fn119/RVEU/YPZ//77Dzs7O8qWLfssYQsjkGs9M7nWVXKtC1HwMrQ6rkQncS48nrPh8ZwLT+BceDxRCZmnQSsuSfmjikxHGq1WS58+fZg2bZq+iVV2TJw4kbi4OP0SGpr3A7zZWJrRpW4ZQAaQE0IYR2pqKhEREQbLw6MwP0m5cuXQaDRs3LiRqKgog5GXHzVy5EhiYmLo3bs3hw8fJjg4mK1btzJo0KBs3fgDVKpUifT0dL7++muuXLnCTz/9xKJFi7K1b04EBgbSuHFjunbtyt9//821a9fYt28fH374IUeOHMn2cXx9fTl48CDXrl0jOjoanU7Hm2++SWhoKKNHj+b8+fOsX7+eKVOmMG7cOOmjKvKVXOuZybUuRNEVm5zG/uDbLPn3Ku+uPUHnr/dSY8pWXvjfHsasOs63u6+w52IUUQmpaDRQ3sWGDrU8+KhTdTaOzjzQW3FI0KEI1aQnJCRw5MgRjh07xqhRowB1ABBFUTAzM+Pvv/+mdevWmfaztLTM8/lDs9KjkTerDoey+VQ4U1+sib2V+dN3EkKIPLJlyxaDJqgAVatW5fz580/d18vLi2nTpjFhwgQGDRpE//79Wbp0aZbblilThv/++4/333+fF154gdTUVMqVK0f79u2zfcNat25dZs+ezaxZs5g4cSLPP/88M2fOpH///tnaP7s0Gg2bN2/mww8/ZNCgQURFReHh4cHzzz+Pu7t7to8zfvx4BgwYQI0aNbh79y5Xr17F19eXzZs38+6771K3bl2cnZ0ZPHgwH330UZ5+BiEeJdd6ZnKtC1H4aXUK126rtePnHqodD49LyXJ7GwtTqnnaU93Tjuqe9lT3tKequx02lkUmfX0mGiU/5vrJBY1Gw++//07Xrl2zfF+n03H27FmDdd988w07duxg3bp1lC9fPlN/qqzEx8fj4OBAXFwc9vb2eRE6oE7f8sL/9nDpViLTu9bitefK5dmxhRD5LyUlhatXr1K+fHmsrGSWBpH3nvQ7ll9lU0FZsGABX3zxBREREdStW5evv/4af3//x24/Z84cFi5cSEhICC4uLrz66qvMnDlT/71MnTo1U1e17Cai9z3uO5VrXeQ3+R0TJV1CSjrnIxL0CfnZ8AQuRiRwNz3rVjhlnUrpE/Ea95Jybydro01/ll9yUtYb9VFEYmIily9f1r++evUqx48fx9nZGR8fHyZOnEhYWBjLly/HxMSEWrVqGezv5uaGlZVVpvXGoNFo6NnIm+mbzrHmSKgk6UIIIUqE1atXM27cOBYtWkRAQABz5syhXbt2XLhwATc3t0zbr1y5kgkTJrBkyRKaNGnCxYsXGThwIBqNhtmzZ+u3q1mzJtu2bdO/zm2/aCGEEPknNjmNoyF3OBEapyblEfGExtzNclsrcxOquj+oGa/uaU81TztpgZwFo5Z4R44coVWrVvrX48aNA2DAgAEsXbqU8PBwQkJCjBVejr3coCyztpzn5I04zt6Mp0aZolcbIoQQQuTE7NmzGTp0KIMGDQJg0aJFbNq0iSVLljBhwoRM2+/bt4+mTZvSp08fQO0H3Lt3bw4ePGiwnZmZmcF81UIIIYxLURSuRCcRdP0OQdfuEBRyh8u3sh7bwtPB6l4i/iAp9y1tU2z6jOc3oybpLVu25Emt7R/XT+q+qVOnMnXq1LwN6hk421jwQg0PNp0KZ82RUKa+WNPYIQkhhBD5Ji0tjaCgICZOnKhfZ2JiQmBgIPv3789ynyZNmvDzzz9z6NAh/P39uXLlCps3b6Zfv34G2126dIkyZcpgZWVF48aNmTlz5hPnpC6IKVeFEKIkSUnXcvJGnJqUX48h6Pod7iSnZ9qugqsN9b2dqFHmXlLuYY+TjYURIi4+pO1YHuvRyJtNp8L5/VgYEzpUwyoX8x0LIYQQRUF0dDRarTbT4Fzu7u6P7T/ep08foqOjadasGYqikJGRwRtvvMEHH3yg3yYgIIClS5dStWpVwsPDmTZtGs2bN+f06dPY2dlledyCmHJVCCGKs1vxKQRdv8OR63cIun6HMzfjSNcaVqhamplQt6wjfr5O+Pk40aCcE86SkOc5SdLzWLNKLng5liIs9i5bz0TwUj0vY4ckhBBCFBq7du1ixowZfPPNNwQEBHD58mXGjBnDJ598wqRJkwDo0KGDfvs6deoQEBBAuXLlWLNmDYMHD87yuBMnTtR3mwO1Jt3b2zt/P4wQQhRRWp3CxcgEjly/w9HrdzhyPSbLvuSudpY0LOeE372lZhkHLMxk+sH8Jkl6HjM10fCqX1nmbr/E6sOhkqQLIYQotlxcXDA1NSUyMtJgfWRk5GP7k0+aNIl+/foxZMgQAGrXrk1SUhLDhg3jww8/zHJ6L0dHR6pUqWIw2OyjCmrKVSGEKIoSUzM4FnLnXtP1OxwPiSUhNcNgGxMNVPWwx6+cIw3LOeNXzomyTqXQaKQfeUGTJD0fdG9Ylnk7LrEv+DYht5PxKW1t7JCEEEKIPGdhYYGfnx/bt2/XT6Gq0+nYvn07o0aNynKf5OTkTIm4qanaNexx49QkJiYSHBycqd+6EEKIrN24k8yRa3f0zdcvRMSje+RPrK2lGfV9HGng40RDXyfqeTtiJyOtFwqSpOeDsk7WNKvkwt5L0awNCuWdF6oaOyQhhBAiX4wbN44BAwbQsGFD/P39mTNnDklJSfrR3vv374+XlxczZ84EoEuXLsyePZv69evrm7tPmjSJLl266JP18ePH06VLF8qVK8fNmzeZMmUKpqam9O7d22ifUwghCrO4u+nsD77Nv5ej2Hspmuu3kzNt4+1cCj8fJ/x8nfHzcaKqh52Mtl5ISZKeT3o28laT9CM3GBtYRS4AIYTIpcuXL7NmzRrefvttSpUqZexwxCN69uxJVFQUkydPJiIignr16rFlyxb9YHIhISEGNecfffQRGo2Gjz76iLCwMFxdXenSpQuffvqpfpsbN27Qu3dvbt++jaurK82aNePAgQO4uroW+OcTBUeudSGyL12r43hoLHsvRrH3cjQnQmMNasrNTDTU8nLAr5wTDcupA7y521sZL2CRI5Kk55O2NdxxsjYnIj6FPRejaFXNzdghCSFEllq2bEm9evWYM2cOoM5bPXbsWMaOHfvYfTQaDb///ru+ifOzetw5U1JSePXVVxk7dqzctBdio0aNemzz9l27dhm8NjMzY8qUKUyZMuWxx1u1alVehifukWtdiKJLURSCo5L491IU/16O5sCVGBIf6VNewdWG5yu70qySC89VLI2tpaR6RZX8z+UTSzNTutUvy5L/rrLqcIgk6UKIfNGlSxfS09PZsmVLpvf27t3L888/z4kTJ6hTp062j3n48GFsbGzyMsxcn3P06NF07dqVgQMHFmg8QhQ2cq0LUfLcTkzlv+DbamJ+KZqbcSkG7zvbWNC0kgvNK7nQrLILZRzlAVdxIUl6PurZyJsl/11l+7lbRCWk4mono84KIfLW4MGDeeWVV7hx4wZly5Y1eO/HH3+kYcOGObppB4zSpPhx51y8eHEBRyJE4STXuhDFX0q6lqDrd9h7KZq9l6I4czPe4H0LMxMa+TrRrJIrzSu7UMPTHhPpUlssySR3+aiqhx31vB3J0Cn8dvSGscMRQhRDnTt3xtXVlaVLlxqsT0xMZO3atXTt2pXevXvj5eWFtbU1tWvX5pdffnniMX19ffXNYQEuXbrE888/j5WVFTVq1OCff/7JtM/7779PlSpVsLa2pkKFCkyaNIn09HSDbf78808aNWqElZUVLi4udOvW7bHnDAkJ4aWXXsLW1hZ7e3t69OhhMM3X1KlTqVevHj/99BO+vr44ODjQq1cvEhISsvGtCVH0yLUu17oofhRF4Vx4PN/tCabfDwep9/Hf9P3+IIt2B+sT9GoedgxtXp7lr/tzYvILrBjyHCNaVqSWl4Mk6MWY1KTns16NvDkeGsvqI6EMe76CzDMoRFGiKJCeeXTUfGduDdn8W2FmZkb//v1ZunQpH374of5vzNq1a9Fqtbz22musXbuW999/H3t7ezZt2kS/fv2oWLEi/v7+Tz2+Tqfj5Zdfxt3dnYMHDxIXF5dl/1U7OzuWLl1KmTJlOHXqFEOHDsXOzo733nsPgE2bNtGtWzc+/PBDli9fTlpaGps3b37sOe/ftO/evZuMjAxGjhxJz549Dfo3BwcH88cff7Bx40bu3LlDjx49+OyzzwwGIBMiW4x1rUO2r3e51uVaF8VDZHwKey9F3+tbfpvoxFSD993sLGlW2YXnK7vStJKLtMQtoSRJz2ed65bh441nuRKVRND1OzT0dTZ2SEKI7EpPhhllCv68H9wEi+z3E3399df54osv2L17Ny1btgTU5q+vvPIK5cqVY/z48fptR48ezdatW1mzZk22bty3bdvG+fPn2bp1K2XKqN/FjBkz6NChg8F2H330kf7fvr6+jB8/nlWrVulv3D/99FN69erFtGnT9NvVrVs3y3Nu376dU6dOcfXqVby9vQFYvnw5NWvW5PDhwzRq1AhQb/CXLl2KnZ0dAP369WP79u1y4y5yzljXOuToepdrXa51UTTdSkjhl4OhbDp1k4uRiQbvlTI3JaCCM80rq03YK7vZSqWekCQ9v9lamtGptidrg26w6nCoJOlCiDxXrVo1mjRpwpIlS2jZsiWXL19m7969fPzxx2i1WmbMmMGaNWsICwsjLS2N1NRUrK2ts3Xsc+fO4e3trb9pB2jcuHGm7VavXs28efMIDg4mMTGRjIwM7O3t9e8fP36coUOH5uic92/aAWrUqIGjoyPnzp3T37j7+vrqb9oBPD09uXXrVrbOIURRJNe6Sq51URQoisLRkDss23edv06Hk65V50fTaKCOlwPNKrvQrJIrDco5YmlmauRoRWEjSXoB6OXvzdqgG2w6Gc6ULjWwszI3dkhCiOwwt1ZruYxx3hwaPHgwo0ePZsGCBfz4449UrFiRFi1aMGvWLObOncucOXOoXbs2NjY2jB07lrS0tDwLd//+/fTt25dp06bRrl07HBwcWLVqFV999ZV+m/yYUsnc3PBvqUajQafT5fl5RAlgrGv9/rlzQK51udZF4ZaSrmXD8Zss23/NYOC3huWc6PucDy2ruOFkY2HECEVRIEl6AWjg40RFVxuCo5L480Q4fQJ8jB2SECI7NJocNTs3ph49ejBmzBhWrlzJ8uXLGTFiBBqNhv/++4+XXnqJ1157DVCbjV68eJEaNWpk67jVq1cnNDSU8PBwPD09AThw4IDBNvv27aNcuXJ8+OGH+nXXr1832KZOnTps376dQYMGZfucoaGh+hq2s2fPEhsbm+24hcgRudblWhfiGYXcTubng9dZcySU2GR1MEVLMxO61vOiX+Ny1PJyMHKEoiiRJL0AaDQaejXy4dPN51h9JFSSdCFEnrO1taVnz55MnDiR+Ph4/VzDlStXZt26dezbtw8nJydmz55NZGRktm+AAwMDqVKlCgMGDOCLL74gPj7e4Ab9/jlCQkJYtWoVjRo1YtOmTfz+++8G20yZMoU2bdpQsWJFevXqRUZGBps3b+b999/P8py1a9emb9++zJkzh4yMDN58801atGhBw4YNc/cFCVFMyLUuROGh0ynsvRzN8n3X2HHhForaoh1v51L0e64cPRp642gtteYi52QKtgLSrYEXZiYaToTGcj4i/uk7CCFEDg0ePJg7d+7Qrl07fb/Sjz76iAYNGtCuXTtatmyJh4cHXbt2zfYxTUxM+P3337l79y7+/v4MGTIk02BNL774Im+//TajRo2iXr167Nu3j0mTJhls07JlS9auXcuGDRuoV68erVu35tChQ1meU6PRsH79epycnHj++ecJDAykQoUKrF69OmdfiBDFlFzrQhhXfEo6S/69SpvZuxmw5BDbz6sJ+vNVXPlhQEN2jW/FsOcrSoIuck2jKPef+ZQM8fHxODg4EBcXZzDQSUEY8XMQf52OYFBTX6Z0qVmg5xZCPFlKSgpXr16lfPnyWFlZGTscUQw96XfMmGVTcfW471SudZHf5Hes+LoQkcDy/df4/VgYyWlaAOwszeje0JvXnvOhgqutkSMUhVlOynpp7l6AejTy5q/TEfx+LIwJHarJSI5CCCGEEEIUYulaHf+cjWTZvmscvBqjX1/V3Y7+TcrRtZ4XNpaSUom8Jb9RBej5yq54OlgRHpfC32ci6VLXSHOyCiGEEEIIIR4rKiGVVYdCWHEwhIj4FABMTTS0q+lO/8a+BJR3lvnMRb6RJL0AmZpo6O5Xlnk7LrPmSKgk6UIIIYQQQhQSiqJwLDSW5fuusenUg7nNXWwt6O3vQ58AHzwd8n6aQSEeJUl6Aeve0Jt5Oy6z91I0oTHJeDvnfD5kIYQQQgghRN5ISdfy54mbLN9/nVNhcfr19X0cGdDYlw61PaSbqihQkqQXMG9na5pVcuHfy9GsDbrBuLZVjB2SEEIIIYQQJU5oTDIrDoaw+nAId+7NbW5hZsKLdcvQv3E56pR1NG6AosSSJN0IejTyVpP0I6GMaVMZUxPpzyJEYVHCJrwQBUh+twoX+f8Q+UV+twq3DK2OnReiWHnwOrsuRunnNvdyLEW/xurc5s42MnWaMC5J0o3ghRruOFqbEx6Xwt5LUbSs6mbskIQo8czNzQFITk6mVCnpbybyXnJyMvDgd00Yh1zrIr+lpaUBYGoqzaMLk/C4u6w+HMrqw6GEx6Xo1zer5MKAJr60ruYmFWei0JAk3QiszE3pWs+LpfuuseZIqCTpQhQCpqamODo6cuvWLQCsra1l1FaRJxRFITk5mVu3buHo6Cg37kYm17rITzqdjqioKKytrTEzk9tsY9PqFPZcimLlwRC2n4tEd6/W3MnanB4Nvenl70N5FxvjBilEFuSvh5H0bOTN0n3X+OdsJLcTUylta2nskIQo8Tw8PAD0N+9C5CVHR0f975gwLrnWRX4yMTHBx8dHHv4Y0a2EFNYeucHKgyGExd7Vr/cv70zfAB/a15KB4EThJkm6kVT3tKduWQdO3Ijj92NhDGlewdghCVHiaTQaPD09cXNzIz093djhiGLE3NxcatALEbnWRX6ysLDAxMTE2GGUODqdwr7g26w4eJ1/zkaSca/a3N7KjFf8ytI3wIdKbnZGjlKI7JEk3Yh6NPLmxI04Vh0OZXCz8vLEVYhCwtTUVBIqIUoAudaFKPpuJ6ayNugGvxwK4frtZP36Bj6O9A0oR6c6nliZy3UuihZJ0o3oxbplmL7xHJdvJXI0JBa/ck7GDkkIIYQQQohCTVEUDl6NYcXBELaejiBNqwPAztKMbg286BPgQzUPeyNHKUTuSVscI7KzMqdjbU8AVh8OMXI0QgghRO4sWLAAX19frKysCAgI4NChQ0/cfs6cOVStWpVSpUrh7e3N22+/TUpKisE2OT2mEKL4i01O4/u9VwicvZte3x3gzxM3SdPqqFPWgVmv1Obgh234+KVakqCLIk9q0o2sl783vx69wcaT4UzuUhNbS/kvEUIIUXSsXr2acePGsWjRIgICApgzZw7t2rXjwoULuLllnr1k5cqVTJgwgSVLltCkSRMuXrzIwIED0Wg0zJ49O1fHFEIUX4qiEHT9DisPhrDxVDhpGWqtubWFKS/V86JvgA+1vByMHKUQeUujKIpi7CAKUnx8PA4ODsTFxWFvb/ynbIqi0Gb2bq5EJTHrldr0bORj7JCEEEIUsMJWNuVEQEAAjRo1Yv78+YA6BZW3tzejR49mwoQJmbYfNWoU586dY/v27fp177zzDgcPHuTff//N1TGzUpS/UyEExKek8/vRMFYeDOFCZIJ+fXVPe/oG+PBSvTLYWZkbMUIhciYn5ZI0dzcyjUZDz4beAKw6HGrkaIQQQojsS0tLIygoiMDAQP06ExMTAgMD2b9/f5b7NGnShKCgIH3z9StXrrB582Y6duyY62MKIYoHRVE4HhrLe+tOEPDpdqZsOMOFyASszE141a8sv7/ZhM1vNeO158pJgi6KNWlbXQi83KAsX2y9wLGQWC5GJlDFXaaHEEIIUfhFR0ej1Wpxd3c3WO/u7s758+ez3KdPnz5ER0fTrFkzFEUhIyODN954gw8++CDXxwRITU0lNTVV/zo+Pj63H0sIUcCSUjNYf/wmKw5e58zNB9duZTdb+gb40K1BWRxKSVIuSg5J0gsBVztLWldz4++zkaw+HMqkzjWMHZIQQgiRL3bt2sWMGTP45ptvCAgI4PLly4wZM4ZPPvmESZMm5fq4M2fOZNq0aXkYqRAiv529Gc/KQ9f549hNElMzALAwNaFjbQ/6PleOhuWcZIpiUSJJkl5I9PL35u+zkfx+LIz32lfF0kzmcxRCCFG4ubi4YGpqSmRkpMH6yMhIPDw8stxn0qRJ9OvXjyFDhgBQu3ZtkpKSGDZsGB9++GGujgkwceJExo0bp38dHx+Pt7d3bj+aECKfpKRr2XgynBUHr3MsJFa/vryLDX38fXjFryzONhbGC1CIQkCS9ELi+cquuNtbEhmfyrazt+hUx9PYIQkhhBBPZGFhgZ+fH9u3b6dr166AOsjb9u3bGTVqVJb7JCcnY2JiOCSOqan6YFpRlFwdE8DS0hJLS8tn/1BCiHxx+VYiKw+G8OvRG8TdTQfAzERDu5oe9A3woXHF0lJrLsQ9kqQXEmamJnT382b+zsusPhIqSboQQogiYdy4cQwYMICGDRvi7+/PnDlzSEpKYtCgQQD0798fLy8vZs6cCUCXLl2YPXs29evX1zd3nzRpEl26dNEn6087phCiaEjN0LL1TCQrD17nwJUY/Xovx1L0CfChe8OyuNlZGTFCIQonSdILkR4N1SR976UowmLv4uVYytghCSGEEE/Us2dPoqKimDx5MhEREdSrV48tW7boB34LCQkxqDn/6KOP0Gg0fPTRR4SFheHq6kqXLl349NNPs31MIUThFnI7mZWHQlh7JJTbSWkAmGigdTV3+j7nw/OVXTE1kVpzIR5H5kkvZPosPsC+4NuMDazM2MAqxg5HCCFEASjsZVNRJN+pEAUrQ6tj+/lbrDgYwp6LUfr17vaW9GzkQ69G3pSRCihRguWkXJKa9EKmZyNv9gXfZu2RG4xuXVmeMgohhBBCiELrZuxdVh0OZfXhECLjH0yD+HwVV/oG+NCmmhtmpiZPOIIQ4lFGvWL27NlDly5dKFOmDBqNhj/++OOJ2//222+0bdsWV1dX7O3tady4MVu3bi2YYAtIu5oe2FuZERZ7l/8uRxs7HCGEEEIIIQxodQo7L9xiyLIjNJu1g3nbLxEZn0ppGwveaFGR3e+2ZPnr/rSr6SEJuhC5YNSa9KSkJOrWrcvrr7/Oyy+//NTt9+zZQ9u2bZkxYwaOjo78+OOPdOnShYMHD1K/fv0CiDj/WZmb0q2+F8v2X2f1kVCer+Jq7JCEEEIIIYTgVkIKa4/c4JdDIdy4c1e//rkKzvQNKMcLNd1lGmEh8oBRk/QOHTrQoUOHbG8/Z84cg9czZsxg/fr1/Pnnn8UmSQfo0cibZfuv8/eZCGKS0mSuSCGEEEIIYRSKorA/+DYrDoaw9UwEGTp1OCt7KzNe9fOmT4APldxsjRylEMVLke6TrtPpSEhIwNnZ+bHbpKamkpr6oH9MfHx8QYT2TGqWcaC2lwOnwuL4/VgYg5uVN3ZIQgghhBCiBFEUtUn7zM3nuXQrUb++gY8jfQPK0amOJ1bmUmsuRH4o0kn6l19+SWJiIj169HjsNjNnzmTatGkFGFXe6NHIm1Nhcaw5HMrrTX3RaGQAOSGEEEIIkf/OR8QzfeM5/r03PpKtpRld65ehj385apSR2RKEyG9FNklfuXIl06ZNY/369bi5uT12u4kTJzJu3Dj96/j4eLy9vQsixGfyYt0yfLrpLBciEzgeGkt9HydjhySEEEIIIYqxqIRUZv9zkdWHQ9ApYGFqwqBmvoxsVQl7K3NjhydEiVEkk/RVq1YxZMgQ1q5dS2Bg4BO3tbS0xNLSsoAiyzsOpczpWMuT346FseZIqCTpQgghhBAiX6Ska1ny31W+2RlMYmoGAB1rezChfXV8SlsbOTohSp4il6T/8ssvvP7666xatYpOnToZO5x81bORN78dC2PD8Zt81KkGNpZF7r9LCCGEEEIUUoqisOlUOJ/9dV4/Wnudsg5M6lyDRr6PH/NJCJG/jJr1JSYmcvnyZf3rq1evcvz4cZydnfHx8WHixImEhYWxfPlyQG3iPmDAAObOnUtAQAAREREAlCpVCgcHB6N8hvzkX96Z8i42XI1OYtOpcHo0LPzN9IUQQgghROF3PDSWTzaeJej6HQA87K14r31VutbzwsRExkISwphMjHnyI0eOUL9+ff30aePGjaN+/fpMnjwZgPDwcEJCQvTbf/fdd2RkZDBy5Eg8PT31y5gxY4wSf37TaDR0b1gWgNWHQ40cjRBCCCGEKOpuxt5l7KpjdF3wH0HX71DK3JSxgZXZMb4FLzcoKwm6EIWAUWvSW7ZsiaIoj31/6dKlBq937dqVvwEVQq82KMtXf18k6PodLt9KoJKbnbFDEkIIIYQQRUxSagbf7g7mu71XSEnXAfBKg7K8264qHg5WRo5OCPEw6eRcyLnZW9GqqhvbzkWy5sgNPuhY3dghCSGEEEKIIkKnU1h39AZfbr3ArYRUAPx9nZnUuQa1yxa/7qJCFAeSpBcBvRp5s+1cJL8G3WD8C1WxMDNqLwUhhBBCCFEEHLhym082nuXMzXgAfJytmdihGu1reaDRSLN2IQorSdKLgJZVXXGzs+RWQio7zkfSvpansUMSQgghhBCF1LXoJGb+dY6tZyIBsLM0Y3SbSgxo4oulmamRoxNCPI0k6UWAmakJr/qV5ZtdwfxyKFSSdCGEEEIIkUnc3XTm77jE0n3XSNcqmGigT4APbwdWobStpbHDE0JkkyTpRUSPht4s3B3M7otRrD0SSneZjk0IIYQQQgAZWh0rD4Xwv38ucic5HYDnq7jyUafqVHGXQYeFKGqkc/OziA+HX4dCUnS+n8rXxYa3WlcG4MPfT+vntBRCCCGEECXXzgu3aD93L5PXn+FOcjqV3WxZOqgRy1/3lwRdiCJKatKfxZ9vwaW/4dpeeHkxlG+er6cb06YyFyIS2HImguE/BfHn6KZ4OpTK13MKIYQQQojC50JEAp9uPseei1EAONtY8HZgZXr7+2BmKvVwQhRlcgU/i8Cp4FIVEsJh+Yuw6zPQafPtdCYmGr7qUZdqHnZEJ6YybHkQKen5dz4hhBBCCFG4xCSl8eHvp+gwdw97LkZhbqph2PMV2Dm+Jf0a+0qCLkQxIFfxs3CvCcN2Qv3XQNHBrpmw/CW1GXw+sbE0Y3H/hjjbWHAqLI731p1EUZR8O58QQgghhDA+RVFYeySUNl/tYsXBEHQKtK/pwbZxLfigY3UcSpkbO0QhRB6RJP1ZWdjASwvU5u4WtmrT90VN4dK2fDult7M13/RtgJmJhg0nbrJwd3C+nUsIIYQQQhjX5VuJ9PruAO+uO8md5HSqedixathzLOrnR7nSNsYOTwiRxyRJzyt1esCw3eBRG5Jvw4pX4O9JoE3Pl9M9V6E0016qCcAXWy+w7WxkvpxHCCGEEEIYR0q6ltn/XKTD3D0cvBqDlbkJEztU48/RzXiuQmljhyeEyCeSpOcll0oweBv4D1Nf75sHP3aAO9fz5XR9A8rR77lyKAqMWXWMi5EJ+XIeIYQQQghRsP67HE2HuXuZt/0S6VqFVlVd+eftFgxvURFz6XcuRLEmV3heM7eCjl9Aj5/AygFuHIZvm8PZDflyusldavBcBWeS0rQMWXaEO0lp+XIeIYQQ4nEWLFiAr68vVlZWBAQEcOjQocdu27JlSzQaTaalU6dO+m0GDhyY6f327dsXxEcRwuhuJ6YybvVx+n5/kKvRSbjZWfJN3wYsGdgIb2drY4cnhCgAkqTnlxovwvC94NUQUuJgTT/Y/C6kp+TpacxNTfimrx9lnUoREpPMqF+OkqHV5ek5hBBCiMdZvXo148aNY8qUKRw9epS6devSrl07bt26leX2v/32G+Hh4frl9OnTmJqa0r17d4Pt2rdvb7DdL7/8UhAfRwij0ekUVh8OofVXu/ntWBgaDQxoXI5t77SgY21PNBqNsUMUQhQQSdLzk1M5eH0LNB2jvj70HfwQCNGX8/Q0zjYWfD+gIdYWpvx3+TbTN53L0+MLIYQQjzN79myGDh3KoEGDqFGjBosWLcLa2polS5Zkub2zszMeHh765Z9//sHa2jpTkm5paWmwnZOTU0F8HCGM4lJkAr2+O8D7v54i7m46NTzt+f3Npkx7qRb2VjJquxAljSTp+c3UHNp+DH3XgXVpiDgF37WAk2vy9DTVPOz5X896ACzdd41Vh0Ly9PhCCCHEo9LS0ggKCiIwMFC/zsTEhMDAQPbv35+tY/zwww/06tULGxvDEap37dqFm5sbVatWZcSIEdy+fTtPYxeiMEhJ1/Ll1gt0nLeXQ9diKGVuykedqrNhVFPqeTsaOzwhhJFIkl5QKreFN/4D3+aQlgi/DYU/RkJaUp6dol1ND8a1rQLApPWnOXwtJs+OLYQQQjwqOjoarVaLu7u7wXp3d3ciIiKeuv+hQ4c4ffo0Q4YMMVjfvn17li9fzvbt25k1axa7d++mQ4cOaLXaxx4rNTWV+Ph4g0WIwmzvpSjazdnD/J2XSdcqBFZ3Y9s7LRjSvAJmMjCcECWa/AUoSPae0H89tJwIGhM4/jN81woiz+bZKUa3rkSn2p6kaxXe+CmIsNi7eXZsIYQQIi/98MMP1K5dG39/f4P1vXr14sUXX6R27dp07dqVjRs3cvjwYXbt2vXYY82cORMHBwf94u3tnc/RC5E7UQmpjFl1jH4/HOL67WQ87K1Y9Jofi/s3xMuxlLHDE0IUApKkFzQTU2g5AfpvAFsPiL4Ai1tB0FJQlGc+vEaj4Yvudajhac/tpDSGLjtCclrGs8cthBBCPMLFxQVTU1MiIyMN1kdGRuLh4fHEfZOSkli1ahWDBw9+6nkqVKiAi4sLly8/fkyXiRMnEhcXp19CQ0Oz9yGEKCA6ncLKgyG0+WoX64/fxEQDg5r6su2dFrSv5SEDwwkh9CRJN5byzWHEf1CpLWSkwJ9jYN3rkPLszfOsLcxYPKAhpW0sOBsez7trT6LkwQMAIYQQ4mEWFhb4+fmxfft2/TqdTsf27dtp3LjxE/ddu3YtqampvPbaa089z40bN7h9+zaenp6P3cbS0hJ7e3uDRYjC4kJEAt2/3c8Hv58iPiWDWl72rB/ZjCldamJraWbs8IQQhYwk6cZk4wJ91qgDy5mYwZnf1DnVw44+86G9HEuxqJ8f5qYaNp0KZ/6OvB1RXgghhAAYN24cixcvZtmyZZw7d44RI0aQlJTEoEGDAOjfvz8TJ07MtN8PP/xA165dKV26tMH6xMRE3n33XQ4cOMC1a9fYvn07L730EpUqVaJdu3YF8pmEyCt307TM2nKeTvP2EnT9DjYWpkzuXIM/3mxK7bIOxg5PCFFIyaM7YzMxUado82mi1qTfuQY/vKAm7s+NgGdo+tTI15lPXqrFhN9O8dU/F6nsbkf7Wk9ufiiEEELkRM+ePYmKimLy5MlERERQr149tmzZoh9MLiQkBBMTwzqBCxcu8O+///L3339nOp6pqSknT55k2bJlxMbGUqZMGV544QU++eQTLC0tC+QzCZEXdl24xaT1pwmNUccHalfTnakv1sTTQfqdCyGeTKOUsHbQ8fHxODg4EBcXV/iawt29A+tHwfmN6uuqHeGlBWDt/EyHnbrhDEv3XcPawpTf3mxCNY9C9rmFEKKEK9RlUxEl36kwllvxKXy88SwbT4YDUMbBimkv1aJtDfen7CmEKM5yUi5Jc/fCpJQT9PwZOn4JphZwYTMsagbXszfX7ON81Kk6TSuVJjlNy5BlR4hJSsujgIUQQgghBKgDw/104DptvtrNxpPhmJpoGNKsPP+MayEJuhAiRyRJL2w0GvAfCkO2gXNFiA+DpZ1gz5eg0+XqkGamJszv3YBypa25cecub64IIl2bu2MJIYQQQghD5yPieWXRPib9cZqE1AzqlnVg/cimfNS5BjYyMJwQIockSS+sPOvC8N1QuwcoWtjxCfzcDRIin75vFpxsLFjcvyG2lmYcuBLDx3/m3dzsQgghhBAl1caTN3lx/n8cC4nF1tKMaS/W5Lc3m1LLSwaGE0LkjiTphZmlHbz8ndov3dwaruyCRU3hwpZcHa6Kux1zetZDo4GfDlzn5wPX8zZeIYQQQogSQlEUvtl1mVErj5GWoaNVVVe2v9OCAU18MTWROc+FELknSXphp9FA/ddg6E5wqwFJUfBLT/hzLKQl5fhwgTXcGf9CVUAdUO7Aldt5HLAQQgghRPGWrtUx4ddTfL7lAgCDm5Xn+wGNcLe3MnJkQojiQJL0osKtmpqoPzdSfR30IyxqDmFBOT7Umy0r0qVuGTJ0CiN+DiI0JjmPgxVCCCGEKJ7i7qYz8MdDrD4SiokGPn6pJpM615DacyFEnpEkvSgxt4L2M6D/erArAzHB8H1b2P05aDOyfRiNRsPnr9ShtpcDd5LTGbr8CEmp2d9fCCGEEKIkCo1J5tWF+/jv8m1sLEz5YUAj+jf2NXZYQohiRpL0oqhCSxjxH9Tspg4qt/NT+LEDxFzJ9iFKWZjyXX8/XGwtOR+RwLg1x9HplPyLWQghhBCiCDseGku3b/7j0q1EPOytWPNGY1pVczN2WEKIYkiS9KLK2hle/RG6fQeW9nDjkNr8/ehPoGQv2fZ0KMW3/fywMDVh65lI5m6/lM9BCyGEEEIUPX+dCqfnt/uJTkyjhqc9v49sQs0yMnq7ECJ/SJJelGk0ULenWqterimkJcKGUbD6NUjK3oBwfuWcmN6tFgBzt19i86nw/IxYCCGEEKLIUBSFb3cH8+bKo6Rm6GhdzY01bzTG06GUsUMTQhRjkqQXB44+MOBPCJwGJuZwfiMsbAyX/snW7j0aejO4WXkA3llzgjM34/IzWiGEEEKIQi9dq+OD308z86/zKAoMaFyO7/r5YWtpZuzQhBDFnCTpxYWJKTQbC0O3g2s1SIyEFa/Cpncg7emjt0/sUI3mlV24m65l2PIgohNT8z9mIYQQQohCKD4lndeXHuaXQyFoNDClSw2mvVQLM1O5dRZC5D/5S1PceNaFYbsg4A319eHv4dvn4eaxJ+5mZmrC/N4NKO9iQ1jsXUb8HERahi7/4xVCCCGEKETCYu/SfeF+9l6KppS5Kd/1a8igpuWNHZYQogSRJL04Mi8FHWbBa7+BrQfcvgTfB8KeL0GnfexuDtbmLO7vh52lGYev3WHKhtMo2RyETgghhBCiqDt5I5auC/7jQmQCbnaWrBnemLY13I0dlhCihJEkvTir1Abe3A81XgJdBuz4BH7sCHeuPX4XNzvm9a6PRgO/HAplwc7LBRevEEIIIYSRbD0TQY9v9xOVkEo1Dzv+GNmU2mVlBHchRMGTJL24s3aG7sug6yKwsIPQA7CwGRxf+dip2lpVc+PDjtUB+PLvi5KoCyGEEKLYUhSF7/de4Y2fg0hJ19Giiitr32hMGUcZwV0IYRySpJcEGg3U6w0j/gXv5yAtAf4YAWv6Q3JMlrsMaV6B8S9UAeCLrRdYuCu4ICMWQgghhMh3GVodk9efYfqmcygK9A3w4YcBDbGzMjd2aEKIEkyS9JLEyRcGbYY2k8HEDM5tgG8aw+XtWW4+qnVl3mmrJuqztpxn0W5J1IUQQghRPCSmZjBk+RF+OnAdjQY+6lSd6V1lBHchhPHJX6GSxsQUmr8DQ7aBSxVIjICfX4a/3of0u5k2H92mMuPuJeqf/XWebyVRF0IIIUQRFx53l1cX7mPXhSiszE1Y2NePIc0roNFojB2aEEIYN0nfs2cPXbp0oUyZMmg0Gv7444+n7rNr1y4aNGiApaUllSpVYunSpfkeZ7FUpj4M2w2NhqqvDy6C71pC+IlMm77VpjJvB6qJ+sy/zvPdHknUhRBCCFE0nQ6Lo+uC/zgfkYCLrSWrhzWmfS0PY4clhBB6Rk3Sk5KSqFu3LgsWLMjW9levXqVTp060atWK48ePM3bsWIYMGcLWrVvzOdJiysIaOn0JfdeBrTtEnYfFbeDf/2Waqm1MYGXGBlYGYMbm8yzec8UYEQshhBBC5Nq2s5H0+HY/kfGpVHG35Y+RTajr7WjssIQQwoBGKSQTYWs0Gn7//Xe6du362G3ef/99Nm3axOnTp/XrevXqRWxsLFu2bMnWeeLj43FwcCAuLg57e/tnDbv4SLoNf74F5zeqr8s1hW6LwNHHYLPZ/1xk3vZLgNp3a0jzCgUdqRBCFA6KAilxUMrxmQ8lZVPek+9UPOrH/67yycaz6BRoXtmFBX0bYC8DxAlRciiK2r03JQ5S4yElHlLj7v2MV9fr//3Qz5Q4GLQJrJ5tSsaclEtmz3SmArZ//34CAwMN1rVr146xY8caJ6DixKY09PwZjq9Q+6df/w8WNoWmY8B/GFipv0hvB1YGRWHejstM33QOQBJ1IUTJkRQNwTsheIe6eNaFvmuMHZUQ4gm0OoVPNp5l6b5rAPRq5M0nXWthLgPElUw6HSRGQmwIxIWCYznw8gMT+X3IsYw0SLgJcWGQEgtoQGOiziylMbn3mof+/eh7Wb0mG9sCqYnZSLDjHknI40GXkbvPmhL3zEl6ThSpJD0iIgJ3d3eDde7u7sTHx3P37l1Klco8n2Vqaiqpqan61/Hx8fkeZ5Gl0UD919Ra9N+HQ+hB2PEJ7PsamowC/+ForOx5u20VFODre4m6RqNhcLPyxo5eCCHyXkYa3DikzoIRvOPeuB0PNUALy1C7B5mYGi1EIcTjJaVm8NYvx9h+/hYAEzpUY/jzMkBcsaYokHwb7lyH2PtLyEOvQ0GbariPXRmo3gVqvAg+jeVvOoA2Qx1gOi4M4m/c+xkGcTfUn/E3IfEWBmViUaExAUt7tRLS0kFNvq3sH1p376eVw4N/W7sUaIhFKknPjZkzZzJt2jRjh1G0OJeHQX/B6d9g9yy4fQl2TId986HxKDQBwxjXtgqKAvN3XuaTjWfRAK9Loi6EKA5uB6sJ+eXtcG0vpCUavu9eGyq1hoqti/TNnFarZenSpWzfvp1bt26h0+kM3t+xY0e2j7VgwQK++OILIiIiqFu3Ll9//TX+/v5ZbtuyZUt2796daX3Hjh3ZtGkTAIqiMGXKFBYvXkxsbCxNmzZl4cKFVK5cOQefUJR0EXEpDF52mDM347E0M+F/PevRsbanscMSeeHunYcS7xA1+db/OwTSk568v8YUHLzU5DzyjFobfOhbdbFxhWqd1YTdtzmYFsMuETodJN16kHg/nHzfX5cQDoru6ccytQT7MmDtrL5WFEBR91WUzK8N3tNl8Z7yyHuP2c7C9l4C/bQE2yHzOgsbtXKyECtSSbqHhweRkZEG6yIjI7G3t8+yFh1g4sSJjBs3Tv86Pj4eb2/vfI2zWDAxhTrdodbLarK+53OIvgg7p8P+r9E0HsU7zw9DQWHBzmA+3ngWjQYGNZVEXQhRxKTEw9U9EHyvtvzONcP3rV3UhLxSG6jQCuzcszxMUTNmzBiWLl1Kp06dqFWrVq5rFlevXs24ceNYtGgRAQEBzJkzh3bt2nHhwgXc3Nwybf/bb7+Rlpamf3379m3q1q1L9+7d9es+//xz5s2bx7JlyyhfvjyTJk2iXbt2nD17Fisrq1zFKUqWUzfiGLr8CBHxKZS2sWDxgIY08HEydlgiu1ITs6gBfygpT417ygE0YOcJTuXU8ZUc7/10Kqf+294LTO+lQekpcGUnnN0AFzZBUhQE/agupZygaic1Ya/QEsws8/uT5w1tBkRfUL+vTAn4DYgPB136049jYqY+yHDwUr8zBy+wL/vgtb0X2LgU+oS3KCpyA8dt3ryZU6dO6df16dOHmJgYGTguv+m0cOZ32P25etEDWDmgPPcm8xLb8L9/1WZkU7vUYKAk6kKIwkynhfDjcHmHmpiHHgLloRktTMzB57kHibl77Xzvq2iMssnFxYXly5fTsWPHZzpOQEAAjRo1Yv78+QDodDq8vb0ZPXo0EyZMeOr+c+bMYfLkyYSHh2NjY4OiKJQpU4Z33nmH8ePHAxAXF4e7uztLly6lV69e2YpLyvuSSVEUfjkUytQNZ0jT6qjoasPSQf54O1sbO7SSLS1ZbYKe1ZIUfe/fMerPxEi4G/P0Y9q4PZR430vE7yfhDmVzl1Br09WHtmfXw/lNkBz94D1Le6jSDqq/CJUC1VmSCgNFgZgrcPMYhAWpS/hJyLj7lB01YOeRdfLtUFb9aetWZFuLFUZFZuC4xMRELl++rH999epVjh8/jrOzMz4+PkycOJGwsDCWL18OwBtvvMH8+fN57733eP3119mxYwdr1qzRN48T+cjEFGq/CjW7GSTrml0zectyAX6VevLmZX+m/nkWExMN/Rv7GjtiIYR4IP7mgybsV3ZlvgEsXUlNyiu2Ad9mYGlrlDALkoWFBZUqVXqmY6SlpREUFMTEiRP160xMTAgMDGT//v3ZOsYPP/xAr169sLGxAdR7gYiICIOBYh0cHAgICGD//v2PTdJlDBpxN03Lh3+c4rejYQAEVnfnqx51cShVDJsrG5M2Q/0bminRfnjdI4l3enLOz1PKKXMN+P1E3ME7f5JkU3P14WylNtD5f3B9H5zbAOf+VJt/n1qrLubWULmtmrBXaQeWdnkfy+MkRKqJ+M2j95Lyo/cGbXuEpT04V3iQcD+agNt5FM+m/MWEUZP0I0eO0KpVK/3r+83SBwwYwNKlSwkPDyckJET/fvny5dm0aRNvv/02c+fOpWzZsnz//fe0a9euwGMvsR5O1s/+Abs/RxN1nmY3FnPI5hcWpb7Al+uT0AD9JFEXQhhL+l315up+Yh51zvB9S3so/7x6I1axNTj5GiVMY3rnnXeYO3cu8+fPz3VT9+joaLRabZaDup4/f/6p+x86dIjTp0/zww8/6NdFREToj/HoMe+/lxUZg6ZkuxqdxIifgzgfkYCJBt5tpw4QZ2IizXCzTVEe9PWOC1UHWIsLVV8n3nqQgGeVEGaHqYXafci6tNp/2bq02lTauvRD61zUdQ7e+pmFjMbEFMo3V5f2s+DGYTVhP7sB4kLU2vaz69U+2ZXaqAl71fbqw4W8khKv1pA/nJDHh2XeztQCPOqAVwN1pHovP3CuKCPWF2G5TtLXrVvHmjVrCAkJMehbBnD06NFsHaNly5Y8qbX90qVLs9zn2LFjOYpV5AMTU6j1CtR4kKxbRZ1jrNlvvG76Fz9u6sDqjHH0bF7b2JEKIYq7tOR7fe1CIfKs2oT9+j7ISHloI41603K/CbtXwwf9EUuof//9l507d/LXX39Rs2ZNzM0Na1R+++23fI/hhx9+oHbt2o8dZC4nZAyakmvL6XDGrz1JYmoGLraWfN27Po0rljZ2WIXP/anH7ife93/qk/HQpw+4pqdRk9Gskmz969LqFL/3/21hW3T7LpuYgE+AurwwXe0ydXa9mrDHBMOFzepiYqb2Xa/+IlTrpH4/2ZWRChGnDWvJoy+RefR0DbhWu5eM11d/utUEM4u8+7zC6HJ1hzJv3jw+/PBDBg4cyPr16xk0aBDBwcEcPnyYkSNH5nWMojAzMVEHl6vRFc6tR9n9Ofa3zjLG7Dfit/3FyWv9qfPKhAcjPgohRE7cn0onNkQd+CYu9MHP2Hv/frjP4MPsve41YW+t3jTJ3yEDjo6OdOvW7ZmO4eLigqmpaZaDunp4eDxx36SkJFatWsXHH39ssP7+fpGRkXh6PhiJOzIyknr16j32eJaWllhaFpFBnUSeSNfq+HzLeRbvvQqAv68zX/epj7t9CR1cUJv+yN/H+z/vJeLxYaBNe/px7vf1dvRWa7QdfcDW/V5Cfi8JL+VYcvsqazRQpr66tJkCt86qyfq5Deq/L29Tl41j1WmNa7ykjhZv/9DMAjqtmoA/nJBHnM56MDdHHyhzv4a8AXjWLdjm9cIocjVwXLVq1ZgyZQq9e/fGzs6OEydOUKFCBSZPnkxMTIx+8JjCSAaSyWc6Hcq5Ddza+DHud4MBSDe1wbzpm/Dcm3KTLIQwlJH2oBY87oa6PJqQG9SIP4aFrXoz6eSrNmOv2BpcqxaZWpuiXDYFBATg7+/P119/DagDx/n4+DBq1KgnDhy3dOlS3njjDcLCwihd+kGt5/2B48aPH88777wDqN+Pm5ubDBwn9CLjUxi18iiHr90BYNjzFXi3XVXMTUtA897oy3D9X3Xk7ocT8uxMmaUxVafLcvS5l4B7P/TTR+2vbF5CH3LkhehLag37uQ0QfuKhNzTgHaAm9pGn1Sbsj07vCeoDEC+/B0l5mfpg61pg4Yv8lZNyKVdJurW1NefOnaNcuXK4ubnxzz//ULduXS5dusRzzz3H7du3cx18fpNCu2AoOi2/rlhEzUuLqG5yb1wBCzsIGA6NR0qyLsR9CZGwaybcuarOzfroYvvQv82znmqy0NKmQ0qceuMYd+PBjeT95Ds2VG16makpXxZsPe7dRJa9t9y7mby/zsqxyCTkWTFm2RQVFcWFC+qsHVWrVsXVNWc3hKtXr2bAgAF8++23+Pv7M2fOHNasWcP58+dxd3enf//+eHl5MXPmTIP9mjdvjpeXF6tWrcp0zFmzZvHZZ58ZTMF28uTJHE3BJuV98bU/+DajfzlKdGIadpZmfNG9Du1rFeP5zzPSIGQ/XNwKF7eozasfx9Ty3t9GnweJ98OJuF2ZEt/Vp8Dcufaghv3G4czvm9tAmXpqIn6/ltyxXJEuy8ST5fvo7h4eHsTExFCuXDl8fHw4cOAAdevW5erVq0/sYy5KDo2JKa+89ibTN7bgxv61jDX7jeppIbD3Szi46F6yPkqSdVFy6XTqHKzbpmVjvtd7LOzU5oY2ruq0KPf/beP2yHpXNWl91gFjtBmQGq8OEnQ3Vk24s7Xc2za7o/maWT2UfN+7mXw4Abf3Kjpz0xYhSUlJjB49muXLl6PTqbVvpqam9O/fn6+//hpr6+yNnNyzZ0+ioqKYPHkyERER1KtXjy1btugHfgsJCcHkkd/FCxcu8O+///L3339necz33nuPpKQkhg0bRmxsLM2aNWPLli0yR3oJp9MpLNoTzJdbL6BToJqHHQtf86O8i42xQ8t7SdFw6R81KQ/eof4tvu/+NJGu1QybpDt4q3//ZbCwwsHJF5q+pS5xYXB+I8RcBfeaalLuWrXkdhkQT5WrmvQhQ4bg7e3NlClTWLBgAe+++y5NmzblyJEjvPzyywajtBY28mS9YCmKwicbz/Hjf8G8YBLEZ6U345Rwb551C1vwH6Ym6zYywIsoQSLPwJ9jHjxZ96wHjYaoyW1SlHpzlnjrwb+TbmWvH+HDNKb3EvdHE3gXNYFPSzJMqLNasmqKlxvWpQ0TcH2N+L3XNi4lvuagIMqmOXPmULt2bdq0aQPA8OHD2bZtG/Pnz6dp06aAOpjcW2+9Rdu2bVm4cGG+xFFQpLwvXuKS03ln7XG2nbsFwCsNyjK9ay1KWRSTJEdR1LLh4ha1xvzGYQxaGVm7qFN9VWkHFVoZf+RzIUSO5Xtzd51Oh06nw8xMrYhftWoV+/bto3LlygwfPhwLi8I7uqAU2gVPURQ+3niWH/+7hgYdPzWNplnYDxBxSt3A3AYChkGDAepTxxJ+sy6KsbQk2D0L9s0HRavWjLeZpCboT3qarihqLYpB8v7o8tB7uZ0e53EsbMHKIZuLo+FrS3tpWpkNBVE2BQUF0b17d6ZNm0a/fv1wcXFh3bp1tGzZ0mC7nTt30qNHD6KiovIljoIi5X3xcTosjhErggiNuYuFmQnTXqxJr0beuZ46sNBIvwtX9z5IzONvGL7vURuqtFeXMg2khlyIIi7fk/SiTApt41AUhWl/nmXpvmtoNDCrW2162J+CXZ9BxMkHG1o5qPM8etQBz3s/XarITb4o+i7+DZvfUQdFA6jeRZ131cEr78+VkaaOeH4/gU98JKFPiTNMvEs5Pj7hliS7QBRU2RQVFUX//v3566+/sLa2JigoiOrVqxtsc+bMGfz9/UlKyu5UTIWTlPfFw+rDIUxaf4a0DB1lnUqx6DU/ank5GDus3Iu/ea9v+Va4sgsy7j54z8xKnYmiSjuo3C5/ygchhNHkS5J+8uTJp290T506dbK9bUGTQtt4MiXqr9Shh19ZuPAX7JsHN45kPfWEmRW41XiQtHvWVV9bZK+/pBBGFR8OWybA2T/U1w7e0PELqNrBqGGJwqUgyyZFUdBoNLRp04bSpUuzfPlyfV/vu3fvMmDAAGJiYti2bVu+xpHfpLwv2u6maZm8/jRrg9Ta5TbV3Jjdox4O1uZGjiyHdDp1JO+LW9Ql4pH7aXuve83Y24Nvc7m3EaIYy5eB4+rVq4dGo9EX7k+i1Wqze1hRgmg0GqZ0qYGiKCzbf533fz2JBujesCNU66jW/kWdVwuw8JPqz4hTar/Ym0fVRX8wE7WG/eEad4/aMhCdKDx0WjiyBLZ/rDZV15hC4zehxQSwtDV2dKIEu1+Gz507l3bt2lG2bFnq1q0LwIkTJ7CysmLr1q3GDFGUcNeikxix4ijnwuMx0cA7L1RlRIuKmJgUkebtqQkQvFOtLb/0tzquiJ4GyjZ8kJi715JufkKITLKdpF+9elX/72PHjjF+/HjeffddGjduDMD+/fv56quv+Pzzz/M+SlFsaDQapr5YEwVYvv867/16Eo1Gw6t+ZcHMQk24PetA/Xs76HTq1FQPJ+7hJ9UCL+q8upxa8+AEDj73kvbaDxJ4ey8pAEXBCj8JG8dCWJD62ssPOs9Rfx+FKCRq1arFpUuXWLFiBefPnwegd+/e9O3bl1Klith0f6LY2HomgvFrTpCQmoGLrQXzetWnSSUXY4f1ZIoCt4Ph8ja1tvzav4YtAy3soFJrNSmv1FbmvRZCPFWu+qT7+/szdepUOnbsaLB+8+bNTJo0iaCgoDwLMK9J87fCQVEUJq8/w08HrqPRwJev1uUVv7LZP0BCxL2k/cSD5P3Otay3tS79UNJeV/1ZuqJMeyHyXmqiOuf5gYXqwHCW9tBmMjR8XX7fxBNJ2ZT35DstWjK0Or7YeoFv91wBoGE5J+b3aYCHQyGcdi8jFcJPQMgBdQk9qI4D8jCn8mq3pirtwKeJWhEhhCjR8n2e9FOnTlG+fPlM68uXL8/Zs2dzc0hRwmg0Gj5+qSYKCj8fCGH8uhMA2U/U7TzUpcoLD9alxKnN4x+ucY86D8m31cFZrux6sK25tdpc3q26Os/o/Z8O3jJ6qsidC1tg83iIC1Vf1+gK7T8De0+jhiXEwzZs2ECHDh0wNzdnw4YNT9z2xRdfLKCoREl3Kz6FUb8c49DVGACGNCvP+x2qYW5aSMrj5BgIPQShByDkoNpKSptquI2pJXj7P2jGXrqStOITQuRarmrSGzRoQK1atfj+++/1062lpaUxZMgQTp8+zdGjR59yBOORJ+uFi06nMGn9aVYcVEe8nty5Bq83y/wAKNfSU+DWWTV5v5+4R56G9OSstze3AdeqWSTvZaWwFVmLvwl/vQ/n7iU8Dj7Q6SvDB0hCPEVBlU0mJiZERETg5uaGyRMeSGo0miI/voyU90XDgSu3GbXyGNGJqdhamvH5q3XoWNuIDzcVRe1mF3IQQvarteRR5zNvZ10avJ8DnwDwaay21DOzLPh4hRBFRr7XpC9atIguXbpQtmxZ/UjuJ0+qfYv//PPP3BxSlFAmJho+eakWFmYm/PjfNT7eeJboxFTebVc1b+Y/NbcCrwbqcp9OCzFXIeoc3Dr/4OftS5CelHmQOlCnq3KtCq7Vwa3ag5/G7u+uKOoDh7t3HiymFup8qtK0Ln/ptHD4e9j+CaQlqAPDNRkFLd4HCxtjRydElnQ6XZb/FqKgKYrCt3uu8MXWC2h1ClXd7Vj4WgMquBbwwJradPUBfugBNSkPOfjIQG/3lK6sJuTez4HPc1JTLoTIV7meJz0pKclgsJnq1avTp08fbGwK982pPFkvnBRF4ZtdwXyx9QIAPRt682m3WpgVZFM3bQbEXMkieb+c9dRwoPY5dq1qWOvuVh3sPHNWeOt06gjgDyfb+iVW/ZkSm/X72rTMxzO3Ad+mULG1urhUkZuJvBR+Av4co06rA+DVELrMBY9axo1LFFmFpWyKjY3F0dHRaOfPS4XlOxWZxd1NZ/zaE/xzNhKAl+t7Mb1bLawtclV3lDN3Y+HG4Qd9yW8cMZyrHMDEHMrUV5Nxn+fAOwBsCvngdUKIQi9f5kkvLqTQLtxWHQrhg99PoVOgbQ13vu5dHytzIw+4pU1Xk/db59Qmb/d/3r4Muoys97F0uFfjXk1N4jUmj0nA7yXhKbGgPEOtlok5lHJSl7sxkBRl+L69F1RoBRVbqT9tSuf+XAUtLUlNisOOqtPxOZVXB/5zrqB+3oJ8+JCaCDtnwMGF6v+XpQMETgG/QTKWgXgmxiibZs2aha+vLz179gSge/fu/Prrr3h6erJ582b9tGxFlZT3hdOZm3G8ueIo128nY2FqwpQXa9DH3ydvWs89SlEgNkRNxu/Xkt86Czxy61vKSU3Eve81XS9TX22JJ4QQeShfkvTiMtiMFNqF39YzEYz+5RhpGTr8fZ1ZPKAhDqXMjR1WZhlpEBOcRfIerI7snRvmNveSbcdHfj5msbr3voXNg2RVUSDyDATvUJeQ/ZCR8tBJNGrfuYqt1aTdO6Dw9KPTpqux3zyqDswTdkxt0fC4BxhWDuB8L2F3rvAgeXeuoPYXzMubvvObYPN7EH9DfV3zZWg/Ux3AUIhnZIyyqXz58qxYsYImTZrwzz//0KNHD1avXs2aNWsICQnh77//LpA48ouU94XPb0dvMPG3U6Rm6PByLMXC1xpQp6xj3p1Am66OPxN66EFNeUJ45u2cKzzoT+79nNraTB60CiHyWb4k6cVlsBkptIuGA1duM3TZERJSM6jmYcfy1/1xsy8iT7UzUtVa9vtJe/RFMDHLnFhnWhzzJ1lOv6sm6sE7IHinOnDew8ytwbdZwTeN1+nUhxxh9xLym0fVfoGPjpgLavcBLz/1e4q5qrZsSLj55ONbOoBz+czJu3NFtdlidj9j3A11YLjzG9XXjuWg02yoHJizzyvEExijbCpVqhQXL17E29ubMWPGkJKSwrfffsvFixcJCAjgzp07BRJHfpHyvnBZeySUd9edBKBVVVf+17MejtbPOHZKcozadD304INR1zM1XTdTH0z7NH5QW27n/mznFUKIXMiXgeNksBlRkJ6rUJrVwxvTf8khzkck8MqifSx/PYDyLoV7zANATbTda6pLYWBe6kECDpAQqU5Hd7+mPekWXPpbXQDsyjyoZa/QMu/64cXfvFc7fj8pPw6pcZm3s3JQB77zaqAm5mUaZD2NWVqyOgJvzJUHy+1gNYmPv6EeO/y4ujzKwk5N4B9N3p0rgK2bmsBrM+DQd7DzU7WZvYkZNHkLnn8XLKzz5jsRwoicnJwIDQ3F29ubLVu2MH36dEAdI6QwP2wXRc+GEzd5/1c1QR/YxJfJnWtgYpLDh8GKov6dDzmgDvIWeijrUdetHO8l4/7qTy8/+ZsthChypE+6KNRCbifTb8lBrt9OxsXWgqWD/Knl5WDssIqP+03jr+xUE/br+x5pGs9DTeNbZ79pfHKMOqjazaP3kvKjkBiReTszK/X4DyflzhWevSY//S7cufZI8n5FTeDjQsnUH/FhFrZqAp+RBtHqQIZ4B0DnOeBe49niEuIxjFE2jRo1io0bN1K5cmWOHTvGtWvXsLW1ZdWqVXz++eeFejrV7JDyvnDYeiaCN1ccRatT6O3vw4xutbLX/zw9RX3IGnIvIQ89CMnRmbcrXemh/uTPqaOwS9N1IUQhlC/N3efNm5ftAN56661sb1vQpNAueqISUhn44yHO3IzH1tKM7/r50aSSjLKaL/RN43feaxp/yvB9c2so99Co8a5V1X0iTho2W4+5kvnYGlN15HuvBveScj/1tWkBjzeQkfqYBP6KmsA/3P/dygECp0GDAXLTJ/KVMcqm9PR05s6dS2hoKAMHDqR+/foA/O9//8POzo4hQ4YUSBz5Rcp749t9MYqhy46QptXxcn0vvuxe9/E16IlRaiIeekBtuh5+PPPsJaaW90Zdv9eX3NtfRl0XQhQZ+ZKkly9f3uB1VFQUycnJ+qlaYmNjsba2xs3NjStXsrhBLySk0C6aElLSGbY8iP1XbmNhasKcXvXoWDuLJtAib91vGn+/pj0x0vB969Lq6PRZDZTnVF5NxO/XkHvUKfxNDjNS1ZGAY65AUjRUbqs2fxcin0nZlPfkOzWu/cG3GfjjIVIzdHSs7cG8XvUfTKuq06ktle4P7hZ6MOuHuzauD2rIvQPUlleFZaBTIYTIoXyfgm3lypV88803/PDDD1StWhWACxcuMHToUIYPH07fvn1zF3kBkEK76EpJ1zJ21XG2nIlAo4FPXqrFa8+VM3ZYJYeiqFPX3B+A7vp/D5rG27o/6D/uVV/9ae1s3HiFKEIKqmwqLjO1ZIeU98YTdP0O/X44SHKaltbV3Fj0mh8W2mQ48Qtc3Ao3DkHKo2OSaNTWVd7+D0ZedypfsNNsCiFEPsr3JL1ixYqsW7dO3zTuvqCgIF599VWuXr2a00MWGCm0izatTmHS+tOsPBgCwNuBVXirTaX8mV9VPFl6CkScAvsy6iL/B0LkWkGVTcVlppbskPLeOE6HxdF78QESUjJoVsmF77u6YxW0GI7+ZDhYqLkNlPW715/8OSjbUJ3lRAghiql8Gd39YeHh4WRkZGRar9VqiYyMzGIPIfKGqYmGT7vWwsXWknnbL/G/bRe5nZTKlC41Mc3pSLHi2ZhbgXcjY0chhMgBmalF5KcLEQn0++EgCSnpvFYmnKm2qzBbsPHBWB+lK4HfQHXaT/faYJqr21AhhCj2cvXXsU2bNgwfPpzvv/+eBg0aAGot+ogRIwgMlLmDRf7SaDSMa1uF0jYWTP3zDMv3X+d2Uhqze9TF0szU2OEJIYQQJc6VqEQGLP6X51P2MMr2HyrHXIKYe29WaAXPvQmVAmUQTiGEyIZcJelLlixhwIABNGzYEHNzdWTmjIwM2rVrx/fff5+nAQrxOAOa+OJsY8G4NcfZdDKc2OQ0vu3XEFtLeTIvhBBP89Zbb1GpUqVMM7LMnz+fy5cvM2fOHOMEJoqcsLBQ/l4yg/UZm3G3iIUM1JHY6/aEgBEyfaUQQuRQjvukK4pCaGgorq6u3Lhxg3PnzgFQrVo1qlSpki9B5iXpo1b87L0UxfCfgkhO01Lby4GlgxpR2lZGfxVCFB3GKJu8vLzYsGEDfn5+BuuPHj3Kiy++yI0bNwokjvwi5X0BuHWO5D3zMT29BkvU6dK0Nu6YBgwFv0EyPZoQQjwkX/ukK4pCpUqVOHPmDJUrV6Zy5cq5DlSIvNC8siu/DH2OQUsPcyosjlcX7Wf56/54Oxfy6b6EEMKIbt++jYODQ6b19vb2REdHGyEiUSTodHB5Gxz4Bq7s5H5Je96kIp7txuHg1wPMLIwaohBCFHU57hhkYmJC5cqVuX37dn7EI0Su1PV2ZO0bjfFyLMXV6CReWbiP8xHxxg5LCCEKrUqVKrFly5ZM6//66y8qVKiQo2MtWLAAX19frKysCAgI4NChQ0/cPjY2lpEjR+Lp6YmlpSVVqlRh8+bN+venTp2KRqMxWKpVq5ajmEQeS0uCQ4thQSNY2R2u7ESLCZu1/oyw+BTbUXtxCHhNEnQhhMgDueq8+9lnn/Huu++ycOFCatWqldcxCZErFV1t+XVEEwYsOcSFyAR6LNrPDwMb0chX5usWQohHjRs3jlGjRhEVFUXr1q0B2L59O1999VWO+qOvXr2acePGsWjRIgICApgzZw7t2rXjwoULuLm5Zdo+LS2Ntm3b4ubmxrp16/Dy8uL69es4OjoabFezZk22bdumf21mJuONGEVsKBxeDEFL9XObK5Z2/KEJ5Ku4lqTZlmXNsMaUdbYxaphCCFGc5GqedCcnJ5KTk8nIyMDCwoJSpUoZvB8TE/OYPY1P+qgVf3HJ6Qxedpgj1+9gaWbCgj4NCKzhbuywhBDisYxVNi1cuJBPP/2UmzdvAuDr68vUqVPp379/to8REBBAo0aNmD9/PqBO7ebt7c3o0aOZMGFCpu0XLVrEF198wfnz5/WDzz5q6tSp/PHHHxw/fjznH+oeKe+fgaLAjcNqk/azG0DRquudypPacBivH6/Cf6GpONtYsHrYc1R2tzNuvEIIUQTk+zzpMuKrKMwcrM35aXAAo1YeZfv5Wwz/OYiZL9emR0NvY4cmhBCFyogRIxgxYgRRUVGUKlUKW1vbHO2flpZGUFAQEydO1K8zMTEhMDCQ/fv3Z7nPhg0baNy4MSNHjmT9+vW4urrSp08f3n//fUxNH0yjeenSJcqUKYOVlRWNGzdm5syZ+Pj4PDaW1NRUUlNT9a/j46XLU45p0+HsejU5Dwt6sL788/Dcm6T4tmHQsqPsD72NvZUZPw32lwRdCCHyQa6S9AEDBuR1HELkqVIWpizq58eEX0/x69EbvLfuJDFJaQx/vgIajcbY4QkhRKGQkZHBrl27CA4Opk+fPgDcvHkTe3v7bCXs0dHRaLVa3N0NWyu5u7tz/vz5LPe5cuUKO3bsoG/fvmzevJnLly/z5ptvkp6ezpQpUwC1dn7p0qVUrVqV8PBwpk2bRvPmzTl9+jR2dlknhTNnzmTatGk5+fjivuQYtTn7ocWQoLaqwNQCaveA594Aj9qkZmgZvjyI/VduY2tpxvLBAdQsk3ngQSGEEM8u1x28goOD+fHHHwkODmbu3Lm4ubnx119/4ePjQ82aNfMyRiFyxdzUhC+718HF1oJv91zhs7/OczsxlYkdqmNiIom6EKJku379Ou3btyckJITU1FTatm2LnZ0ds2bNIjU1lUWLFuXLeXU6HW5ubnz33XeYmpri5+dHWFgYX3zxhT5J79Chg377OnXqEBAQQLly5VizZg2DBw/O8rgTJ05k3Lhx+tfx8fF4e0sLqie6ewe2fwzHf4GMu+o6GzdoNAQaDgJbdUyBdK2Ot345xu6LUViZm7BkYCPqeTsaL24hhCjmsjW6+4ULFwxe7969m9q1a3Pw4EF+++03EhMTAThx4oS+gBWiMNBoNEzsWJ0POqqjAi/ee5Xxa0+QrtUZOTIhhDCuMWPG0LBhQ+7cuWMwtky3bt3Yvn17to7h4uKCqakpkZGRBusjIyPx8PDIch9PT0+qVKli0LS9evXqREREkJaWluU+jo6OVKlShcuXLz82FktLS+zt7Q0W8QTRl+H7QDiyRE3QPWpD10Xw9mlo+b4+QdfqFN5Zc4KtZyKxMDPh+/6N8C8vA7IKIUR+ylaS/ttvv9G3b1+0WnXgkAkTJjB9+nT++ecfLCweTLXRunVrDhw4kD+RCvEMhj1fka+618XURMNvx8IYtvwISakZxg5LCCGMZu/evXz00UcG5Tiog8eFhYVl6xgWFhb4+fkZJPU6nY7t27fTuHHjLPdp2rQply9fRqd78LD04sWLeHp6ZorlvsTERIKDg/H09MxWXOIpgnfA963h9mWwLwv9N8DwvVCvN5hZ6jfT6RQm/HqSDSduYmaiYWHfBjSr7GLEwIUQomTIVpI+fvx4nJ2dadeuHQCnTp2iW7dumbZzc3MjOjo6byMUIo+84leWxf39sDI3YeeFKF5ZuI/QmGRjhyWEEEah0+n0D98fduPGjcf2+87KuHHjWLx4McuWLePcuXOMGDGCpKQkBg0aBED//v0NBpYbMWIEMTExjBkzhosXL7Jp0yZmzJjByJEj9duMHz+e3bt3c+3aNfbt20e3bt0wNTWld+/ez/CJBYoCB7+Dn19Vp1Mr6w/DdkKFFvDIeC2KojD1zzOsDbqBiQbm9a5Pm+oyU4oQQhSEbCXp5ubmfP311wwfPhxQm52Fh4dn2u7YsWN4eXnlbYRC5KHW1dxZMeQ5XGwtOR+RwEsL/uPQ1cI7ZaAQQuSXF154wWC2Fo1GQ2JiIlOmTKFjx47ZPk7Pnj358ssvmTx5MvXq1eP48eNs2bJFP5hcSEiIwT2Dt7c3W7du5fDhw9SpU4e33nqLMWPGGEzXduPGDXr37k3VqlXp0aMHpUuX5sCBA7i6uj77By+ptOmwaRz89a46pVrd3jBwo75Z+8MUReGzv86zfP91NBr4qkddOtaWVgxCCFFQcjVP+vjx4zl48CBr166lSpUqHD16lMjISPr370///v0Ldb90mTdVANyMvcvQ5Uc4czMec1MNH79Ui97+j5/aRwgh8pMxyqbQ0FDat2+PoihcunSJhg0bcunSJVxcXNizZw9ubpmTt6JEyvuHJMfAmv5wbS+ggcCp0HRMptrz++Zsu8icbZcAmNGtNn0CpHwUQohnlZNyKVdJelpaGqNGjWLp0qVkZGRgZmaGVqulT58+LF261GAwmMJGCm1x3900LePXnWDTSbWGZ0DjckzqXAMz02w1MBFCiDxjrLIpIyOD1atXc+LECRITE2nQoAF9+/Y1GEiuqJLy/p6oC7CyJ9y5Cha28Mr3ULXDYzdftDuYz/5Sp8+b3LkGrzcrX1CRCiFEsZZvSbpWq+XLL79kw4YNpKWlUadOHV555RUSExOpX78+lStXfubg85sU2uJhiqIwf8dlvvrnIgBNK5VmQZ8GOFpnPXiREELkh4Ium9LT06lWrRobN26kevXq+X4+Y5DyHri0DdYNgtR4cPSB3qvA/fHT5C7bd40pG84A8G67qoxsVamgIhVCiGIvJ+VSjqoMZ8yYwQcffICtrS1eXl6sXLmSdevW0aNHjyKRoAvxKI1Gw+g2lVn0mh/WFqb8d/k2XRf8x+VbCcYOTQgh8o25uTkpKSnGDkPkF0WBAwthZXc1QfdpAkN3PjFBX304RJ+gj25dSRJ0IYQwohwl6cuXL+ebb75h69at/PHHH/z555+sWLHCYBqVnFqwYAG+vr5YWVkREBDAoUOHnrj9nDlzqFq1KqVKlcLb25u3335bbjTEM2tfy4NfRzTBy7EU124n03XBPnacj3z6jkIIUUSNHDmSWbNmkZEh01EWKxlp8OdbsGUCKDqo/xr0Xw82j586bf3xMCb8dgqAIc3KM65tlYKKVgghRBbMcrJxSEiIwYivgYGBaDQabt68SdmyZXN88tWrVzNu3DgWLVpEQEAAc+bMoV27dly4cCHLAWtWrlzJhAkTWLJkCU2aNOHixYsMHDgQjUbD7Nmzc3x+IR5W3dOeDaOaMmLFUQ5djWHwsiO8374aw5+vgOYxg+sIIURRdfjwYbZv387ff/9N7dq1sbGxMXj/t99+M1JkIteSbsOafnD9P9CYQNtPoPHIxw4QB7DldDjj1pxAUaBvgA8fdqouZZ4QQhhZjpL0jIwMrKysDNaZm5uTnp6eq5PPnj2boUOH6udSXbRoEZs2bWLJkiUGU7Hct2/fPpo2bUqfPn0A8PX1pXfv3hw8eDBX5xfiUaVtLfl5cABTNpzhl0MhfPbXeS5GJDDj5dpYmRfeARGFECKnHB0deeWVV4wdhsgrt86pA8TFXgcLO3h1CVR54Ym77A++zehfjqHVKbzSoCyfvFRLEnQhhCgEcpSkK4rCwIEDsbS01K9LSUnhjTfeMHgCn52n72lpaQQFBTFx4kT9OhMTEwIDA9m/f3+W+zRp0oSff/6ZQ4cO4e/vz5UrV9i8eTP9+vV77HlSU1NJTU3Vv46Pj39qbKJkszAzYUa3WlT3tGPan2f57VgYwdFJfNfPD3d7q6cfQAghCjGdTscXX3zBxYsXSUtLo3Xr1kydOrVYjOheYl3cCusGQ1oCOPlC79XgVu2Ju4TH3WXUyqOkaxU61vbg81frYGIiCboQQhQGOUrSBwwYkGnda6+9lqsTR0dHo9VqcXd3N1jv7u7O+fPns9ynT58+REdH06xZMxRFISMjgzfeeIMPPvjgseeZOXMm06ZNy1WMouTSaDT0b+xLRVdb3lxxlBOhsbw4/1++69eQut6Oxg5PCCFy7dNPP2Xq1KkEBgZSqlQp5s2bR1RUFEuWLDF2aCKnFAX2fQ3/TAYUKNcMeiwHm9JP3C01Q8uIn49yOymN6p72fNW9HqaSoAshRKGRq3nS88LNmzfx8vJi3759NG7cWL/+vffeY/fu3Vk2Yd+1axe9evVi+vTpBAQEcPnyZcaMGcPQoUOZNGlSlufJqibd29u7ZE/JInLk+u0kBi87wuVbiViamfD5q3V4qZ6XscMSQhQjBTldWOXKlRk/fjzDhw8HYNu2bXTq1Im7d+9iYpKj8WQLtWI/BVtGKmwcB8d/Vl83GAAdvwSzp08h+tEfp/j5QAj2VmZsHN0cn9LW+RysEEKInJRLOapJz0suLi6YmpoSGWk4gnZkZCQeHh5Z7jNp0iT69evHkCFDAKhduzZJSUkMGzaMDz/8MMubC0tLS4Pm+ULkVLnSNvz+ZhPGrDrOjvO3GLPqOBciEhj/QlVpGiiEKHLyehBYYQSJUeoAcSH71QHi2s2EgOFPHCDuvnVBN/j5QAgAc3vVlwRdCCEKIaM9MrewsMDPz4/t27fr1+l0OrZv325Qs/6w5OTkTIm4qak6mJeRGgSIEsLOypzF/RvyRouKAHyzK5hhPx0hISV3gyYKIYSx5PUgsKKARZ6Bxa3VBN3SAfquhefeyFaCfjosjg9/V6daG9OmMq2qZZ5JRwghhPEZrSYdYNy4cQwYMICGDRvi7+/PnDlzSEpK0o/23r9/f7y8vJg5cyYAXbp0Yfbs2dSvX1/f3H3SpEl06dJFn6wLkV9MTTRM6FCNah52vPfrSbadu8UrC/fxff9GUhMhhCgy8nIQWFHAzm+G34ZCWiI4V1AHiHPN3pzmsclpjFgRRGqGjlZVXRnTpnI+ByuEECK3jJqk9+zZk6ioKCZPnkxERAT16tVjy5Yt+sHkQkJCDGrOP/roIzQaDR999BFhYWG4urrSpUsXPv30U2N9BFECda3vha+LDcOWH+FiZCIvLviXb/o2oElFF2OHJoQQT5WXg8CKAqIo8N8c2DYNUKD889B9GVg7Z2t3nU5h7OrjhMbcxdu5FP/rWU+6awkhRCFmtIHjjKXYDyQjCkxkfArDlh/hxI04TE00TO1Sg36NfY0dlhCiCJKyKe8Vm+80PQX+HAMnV6mvGw6GDrPA1Dzbh/jfPxeZu/0SlmYm/PZmE2qWccinYIUQQjxOTsql4jOMqxAFzN3eitXDG/NSvTJodQqT1p/hw99Pka7VGTs0IYQQxUFCJCzrrCboGlN19PbOs3OUoO84H8nc7ZcAmNGttiToQghRBEiSLsQzsDI3ZU7PerzfvhoaDaw4GMJr3x8kJinN2KEJIYQoysJPqgPE3TgMVg7w2q/gPzRHh7h+O4mxq44D8NpzPrziJ6P3CyFEUSBJuhDPSKPRMKJlRb7v3xBbSzMOXo3hxfn/cj4i3tihCSGEKIrOboAl7SD+BpSuBEN2QMVWOTrE3TQtb/x8lPiUDOr7ODK5c818ClYIIURekyRdiDzSpro7v73ZBB9na27cucsr3+zj7zMRxg5LCCFEUaFNhx2fqnOgpydDhVYwZBu4VMrRYRRF4cPfT3EuPB4XWwu+6dsACzO55RNCiKJC/mILkYequNuxfmRTGlcoTVKalmE/BTF/xyVK2PiMQgghciriFCxuBXs+V1/7D4e+66CUU44P9fOB6/x2LAxTEw1f926Ap0OpPA5WCCFEfpIkXYg85mRjwfLB/gxoXA6AL/++yIifj3JH+qkLIYR4lDYddn0G37VUE/VSTvDKD9DxczDN+Uy5Qdfv8PHGswC8374qjSuWzuOAhRBC5DejzpMuRHFlbmrCtJdqUdXDnsnrT7PlTATHQu8wu0c9mlaS+dSFEEKgJuV/jFB/AlTrDJ3/B7ZuuTpcVEIqb64IIl2r0LG2B0ObV8jDYIUQQhQUqUkXIh/1CfDh9zebUsHVhsj4VPp+f5BPN50lNUNr7NCEEEIYizYdds3KXHve8+dcJ+gZWh2jVh4lMj6Viq42fP5qXTQaTd7GLYQQokBIki5EPqtd1oGNo5vRN8AHgMV7r9J1wT4uRiYYOTIhhBAF7n7f810zQJeh1p6/eRBqvwrPkFR/vvUCB6/GYGNhyrf91NlGhBBCFE2SpAtRAKwtzPi0W22+79+Q0jYWnAuPp8vX/7L0v6syqJwQoshbsGABvr6+WFlZERAQwKFDh564fWxsLCNHjsTT0xNLS0uqVKnC5s2bn+mYhd6Tas/t3J/p0JtOhvPdnisAfNm9LpXcbPMgYCGEEMYiSboQBSiwhjt/jW1OiyqupGbomPrnWQb+eJhbCSnGDk0IIXJl9erVjBs3jilTpnD06FHq1q1Lu3btuHXrVpbbp6Wl0bZtW65du8a6deu4cOECixcvxsvLK9fHLPQiTsPi1nleew5w+VYC7647AcDw5yvQobZnXkQshBDCiDRKCavGi4+Px8HBgbi4OOzt7Y0djiihFEVh+f7rzNh8jtQMHc42Fsx6pQ5tazxbbYoQomgqymVTQEAAjRo1Yv78+QDodDq8vb0ZPXo0EyZMyLT9okWL+OKLLzh//jzm5uZ5csysFIrvVJsO//4Pdn8OunS19rzjl1DrlWdOzgESUtJ5acF/XIlKonGF0vw02B8zU6l/EUKIwign5ZL8JRfCCDQaDQOa+PLn6GZU97QnJimNocuP8MHvp0hOyzB2eEIIkS1paWkEBQURGBioX2diYkJgYCD79+/Pcp8NGzbQuHFjRo4cibu7O7Vq1WLGjBlotdpcH7NQul97vvNTNUHPw9pzUB/2vrfuJFeikvCwt+LrPvUlQRdCiGJC/poLYURV3O34Y2QThj2vTpOz8mAInef9y6kbcUaOTAghni46OhqtVou7u2ErIHd3dyIiIrLc58qVK6xbtw6tVsvmzZuZNGkSX331FdOnT8/1MQFSU1OJj483WIxCm67WnH/XEiJOqrXnL3+fJ33PH/bdniv8dToCc1MN37zWABdbyzw7thBCCOOSJF0II7M0M+WDjtVZOSQAD3srrkQn0e2b/1iw8zJaXYnqjSKEKAF0Oh1ubm589913+Pn50bNnTz788EMWLVr0TMedOXMmDg4O+sXb2zuPIs6BiNPwfZsHtedVO6m153W650nt+X37Lkcza8t5AKZ0qUkDH6c8O7YQQgjjkyRdiEKiSSUXtoxtTqfanmToFL7YeoHeiw9w406ysUMTQogsubi4YGpqSmRkpMH6yMhIPDw8stzH09OTKlWqYGpqql9XvXp1IiIiSEtLy9UxASZOnEhcXJx+CQ0NfYZPlkMP156Hn3hQe95rRZ7WngPcjL3L6F+OoVPglQZl9dN7CiGEKD4kSReiEHG0tmB+n/p82b0uNhamHLoaQ4e5e1l/PMzYoQkhRCYWFhb4+fmxfft2/TqdTsf27dtp3Lhxlvs0bdqUy5cvo9Pp9OsuXryIp6cnFhYWuTomgKWlJfb29gZLgYg8UyC15wCpGVreXHGU20lp1PC059NutdDk8TmEEEIYnyTpQhQyGo2GV/3KsnlMc+r7OJKQksGYVccZs+oY8Snpxg5PCCEMjBs3jsWLF7Ns2TLOnTvHiBEjSEpKYtCgQQD079+fiRMn6rcfMWIEMTExjBkzhosXL7Jp0yZmzJjByJEjs33MQkGbDru/gG9b5Hvt+X0f/3mW46GxOJQyZ9FrfliZmz59JyGEEEWOmbEDEEJkrVxpG9YOb8z8nZf5esdl1h+/yZFrd/hfz3r4l3c2dnhCCAFAz549iYqKYvLkyURERFCvXj22bNmiH/gtJCQEE5MHdQLe3t5s3bqVt99+mzp16uDl5cWYMWN4//33s31Mo4s8A3+MUJNzUGvPO/8v35JzgLVHQllxMASNBub0qodPaet8O5cQQgjjknnShSgCgq7f4e3VxwmJScZEAyNaVmRsYBXMZbodIYoFKZvyXr58p9p0+HcO7J6lNm23coSOX0DtvG/a/rDTYXG8snAfqRk6xgZWZmxglXw7lxBCiPwh86QLUcz4lXNi85jmdPcri06BBTuDeWXhPq5EJRo7NCGEKBn0fc+nP+h7PvIQ1OmRrwl6bHIaI1YEkZqho1VVV95qXTnfziWEEKJwkCRdiCLC1tKML7rX5Zu+DXAoZc7JG3F0mvcvKw+GUMIaxAghRMHRpsOeh/qeWznCy4vzte/5fTqdwphVxwmNuYuPszVzetbHxEQGihNCiOJOknQhipiOtT3ZMrY5TSqW5m66lg9+P8Wwn4K4nZhq7NCEEKL4ObgIdhRs7fl9c7dfYvfFKCzNTFj0mh8O1ub5fk4hhBDGJ0m6EEWQ5//bu/O4KOv1b+CfmQFmANlxhl0QFAEBDRIR16TQyvJXp7THo2RlTx4tjU4ulZotklkequMR9WTZ86u0TdMsS1EJVwxCUQERUUCZAWQZllicuZ8/0ClSDGXgnoHP+/W6Xzr33PdwfUHn4prv5mCN/30yCi/fGwQrmRS7T2sw4b00pJ4pFzs0IqKeJfJJwOvObus9v2ZvrgbvpeQDAFb8TyiCPbhWARFRb8EinchMSaUSzBrdH9vmxGCAsg/Ka5sQvzEdr24/hbqmK2KHR0TUM1jZAE/u7rbecwC4cLke8zdnAQCmD++HhyO8uuXrEhGRaWCRTmTmgj3ssePZkXh8hC8A4OND53HXO/ux7deLnKtORGQM3VScA8BvzTo887+Z0DZewVAfRyy5P7jbvjYREZkGFulEPYDCUoZXHwjBpieGoZ+LDcpqmzB/SxamrDuC05e0YodHREQd9PrO08gp1cK1jxXWTouAlQV/VSMi6m34zk/Ug4wZ2Bc/zh+NF+MCYW0pQ/r5Stz/QRqWbDuJ6oZmscMjIqKb0Da24KuMEgBA0pShcHNQiBwRERGJgUU6UQ+jsJRhzrgApLwwBveFuUMvAP/vyAWMe2c/PjtaBJ2eQ+CJiEzR7lMaNF/RI0DZBzEBLmKHQ0REImGRTtRDeThaY83/uQOfzYrCQFUfVDW04KWt2Zi85iAyLlSJHR4REf3J9uOXAACTwjwg6cZ58EREZFpYpBP1cCP8XbHzuVFYen8w7OQWyL5Yg4fXHsILXxxHWW2j2OERERGAyvpmHDhbAQC4P9xd5GiIiEhMLNKJegFLmRRPjPTD3n+OxSNXt/L5OrMEd72Tiv+mnUOLTi9yhEREvdsPJ0uh0wsI8bCHf98+YodDREQiYpFO1Iv0tZNj1SPh2PqPEQjzckBd0xW8sTMHE99Lw8GrPThERNT9dlwd6v5AuIfIkRARkdhYpBP1QkN9nLDtHzF466FQONta4WxZHab99yhm/28GSqoaxA6PiKhXUdc04mhhJQDgvjAOdSci6u1YpBP1UlKpBFOH+WDfC2Px+AhfSCXADyfViF2divdT8tHYohM7RCKiXmFndikEAYjo5wQvJxuxwyEiIpGxSCfq5RxsLPHqAyHY+dwoDPNzRmOLHqt3n8Hd/0rF7tMaCAK3bCMi6koc6k5ERH/EIp2IAABB7vbY8vRwvDd1CFT2chRX/oZZn/yCxz86hnPldWKHR0TUIxVXNiCruBpSCTAx1E3scIiIyASwSCciA4lEggeHeGLvC2Mxe6w/LGUSpJ4pR1zSz3jrh1zUN10RO0Qioh7l2t7o0f4uUNopRI6GiIhMAYt0IrqOrdwCCycMwo/zR2NsYF+06AQkpxbgrnf349usixwCT0RkJNeGuk8K41B3IiJqxSKdiNrVv28ffPT4nfjvjEj4ONtAo23CvM1ZmLL+CHJKtWKHR0Rk1vI1tchV18JSJsGEwRzqTkRErVikE9FNSSQSxAar8NPzo/HC3QOhsJQivbAS972fhqXfnkRlfbPYIRIRmaVrveijB/SFo42VyNEQEZGpYJFORB2isJTh2fEDkPLCWNwb6ga9AHxy+AKiE1Pw0tZsFHBxOSKiDhMEATtOlAIAJnFVdyIi+gPRi/Q1a9bA19cXCoUCUVFRSE9Pv+n11dXVmDNnDtzd3SGXyzFw4EB8//333RQtEXk6WuM/0yLw6VNRGOxpj6Yrenx2tAjj303FU5uO4ci5y5yzTkT0F05d0qKwoh5yCylig1Vih0NERCbEQswvvmXLFiQkJCA5ORlRUVFISkpCXFwc8vLyoFQqr7u+ubkZd999N5RKJb766it4enriwoULcHR07P7giXq5mABX7Jg7EkfOVeLDA+ewJ6fMcIR6OuCpUX64N9QdljLRPwskIjI514a6xwap0Ecu6q9jRERkYkT97Xn16tWYNWsWZs6cieDgYCQnJ8PGxgYbN2684fUbN25EZWUltm3bhpiYGPj6+mLMmDEIDw/v5siJCGidrx7t74L/xt+JlBfG4P9E+UBuIUX2xRrM25yFMW/vw/qfC6BtbBE7VCLqQrcyKu7jjz+GRCJpcygUbbcee/zxx6+7ZsKECV3djG6j1wu/r+oe7i5yNEREZGpEK9Kbm5uRkZGB2NjY34ORShEbG4vDhw/f8J7t27cjOjoac+bMgUqlwuDBg7FixQrodLp2v05TUxO0Wm2bg4iMz79vH6z4n1AcWnQXEu4eCNc+VrhU04gV3+diROJevP7daZRUNYgdJhEZ2bVRccuWLUNmZibCw8MRFxeHsrKydu+xt7dHaWmp4bhw4cJ110yYMKHNNZ9//nlXNqNbZRZV4VJNI/rILTA28PqRg0RE1LuJVqRXVFRAp9NBpWo7D0ulUkGtVt/wnnPnzuGrr76CTqfD999/jyVLluDdd9/FG2+80e7XSUxMhIODg+Hw9vY2ajuIqC2XPnI8N34ADiy8CysfDsUAZR/UNV3BhwcKMWbVfsz5LBNZxdVih0lERnKro+KA1lE4bm5uhuPPvwsAgFwub3ONk5NTVzajW13rRb8nRAWFpUzkaIiIyNSY1WRRvV4PpVKJ9evXIyIiAlOmTMHLL7+M5OTkdu9ZvHgxampqDEdxcXE3RkzUeyksZZhypw9+en40Ppp5J2ICXKDTC9h5ohST1xzEI8mH8OMpNXR6LjJHZK5uZ1QcANTV1aFfv37w9vbGgw8+iFOnTl13zf79+6FUKhEYGIjZs2fj8uXLXdKG7nZFp8fObK7qTkRE7RNtpRJXV1fIZDJoNJo25zUaDdzc3G54j7u7OywtLSGT/f6pc1BQENRqNZqbm2Fldf0eo3K5HHK53LjBE1GHSSQSjAtUYlygEqcu1eDDA4XYcfwSjp2vwrHzGfB1scETI/3wtwgv2Fhx8SQic3KzUXG5ubk3vCcwMBAbN25EWFgYampq8M4772DEiBE4deoUvLy8ALQOdX/ooYfg5+eHgoICvPTSS5g4cSIOHz7c5neAP2pqakJTU5PhsalObztyrhIVdc1wtLHEyABXscMhIiITJFpPupWVFSIiIpCSkmI4p9frkZKSgujo6BveExMTg7Nnz0Kv1xvOnTlzBu7u7jcs0InItIR4OGD1o0OQtuAuzB7rD3uFBc5fbsDSb09hxFt7serHXJRpG8UOk4i6UHR0NGbMmIEhQ4ZgzJgx+Oabb9C3b1+sW7fOcM3UqVPxwAMPIDQ0FJMnT8Z3332HY8eOYf/+/e2+rrlMb7s21H3iYO5+QURENyZqdkhISMCGDRuwadMm5OTkYPbs2aivr8fMmTMBADNmzMDixYsN18+ePRuVlZWYN28ezpw5g507d2LFihWYM2eOWE0gotvg5qDAwgmDcHjxeCx/IAQ+zjaobmjBmn0FiFm5Fy98cRw5pabZC0ZEv7udUXF/ZmlpiaFDh+Ls2bPtXtO/f3+4urre9BpzmN7WfEWPH062DnV/gEPdiYioHaKOLZ0yZQrKy8uxdOlSqNVqDBkyBLt27TIMmysqKoJU+vvnCN7e3vjxxx/x/PPPIywsDJ6enpg3bx4WLlwoVhOIqBNs5RaIH+GLvw/vh92n1diQVoiMC1X4OrMEX2eWYNQAVzw1qj9GD3CFRCIRO1wi+pM/joqbPHkygN9Hxc2dO7dDr6HT6ZCdnY1777233WtKSkpw+fJluLu3v12ZOUxvS8svh7bxCpR2cgzzcxY7HCIiMlESQRB61apNWq0WDg4OqKmpgb29vdjhENGfZBZV4cO0QvxwshTX1pQbqOqDp0b2x4NDPSC34ErI1POYc27asmUL4uPjsW7dOgwbNgxJSUn44osvkJubC5VKhRkzZsDT0xOJiYkAgNdeew3Dhw9HQEAAqqursWrVKmzbtg0ZGRkIDg5GXV0dli9fjocffhhubm4oKCjAggULUFtbi+zs7A4X4qb4PZ23+Vd8m3UJM2N8sWxSiNjhEBFRN7qVvMRVmojIpNzh44Q7pjmhuLIBGw8W4otjxTijqcOCr09g1U95eHKkH6ZF+cBOYSl2qESEWx8VV1VVhVmzZkGtVsPJyQkRERE4dOgQgoODAQAymQwnTpzApk2bUF1dDQ8PD9xzzz14/fXXTb6n/GZ+a9Zh9+nWaQFc1Z2IiG6GPelEZNJqfmvB5vQifHzoPEprWheVs1NYYEZ0P8yM8YNrH/P9pZ3oGuYm4zO17+nOE6WY81kmvJyskbZgHKfwEBH1MreSl7isKBGZNAdrS/zfMf5IfXEcVv0tDP59bVHbeAVr9hVg5Mq9WPbtSZRUNYgdJhHRTW0/fhFAay86C3QiIroZFulEZBasLKR4JNIbu58fg+S/RyDcywGNLXpsOnwBY1btR8KWLJzR1IodJhHRdbSNLdiXVw4AmBTGoe5ERHRznJNORGZFKpVgwmA3xIWocKjgMv6z/ywOnr2Mb369iG9+vYi7g1X4x1h/DPVxEjtUIiIAwO5TGjRf0SNA2QdB7nZih0NERCaORToRmSWJRIKYAFfEBLjieHE11u4vwI+n1dh9WoPdpzWI7u+C2WP9MYrbtxGRyHacuASgtRed70dERPRXWKQTkdkL93ZE8vQInC2rRXLqOWz79SIOn7uMw+cuI9TTAbPH+iMuxA0yKX85JqLuVVnfjAP5FQCA+8Pb3+ediIjoGs5JJ6IeI0Bph3ceCUfqgnGYGeMLhaUU2Rdr8I9PM3H36lRsOVaE5it6scMkol7kh5OluKIXEOJhD/++fcQOh4iIzACLdCLqcTwdrbFsUggOLRqP5+4KgL3CAucq6rHw62yMfnsf/pt2DvVNV8QOk4h6gR3HW4e6P8C90YmIqINYpBNRj+Vsa4WEewJxaPF4vHTvICjt5FBrG/HGzhzErNyLf+0+g6r6ZrHDJKIeSqNtxNHCSgDAfWEc6k5ERB3DIp2Ierw+cgs8PdofaQvHIfGhUPi62KC6oQXvpeQjZuVevP7daZTW/CZ2mETUw3x3ohSCAET0c4KXk43Y4RARkZlgkU5EvYbcQobHhvkg5YWx+OCxoQh2t0dDsw4fHijE6Lf3YeFXJ3CuvE7sMImoh7g21H0Se9GJiOgWcHV3Iup1ZFIJJoV74P4wd6SeKcd/9hcgvbASW34pxhcZxZg42A2zxwQg1MtB7FCJyEwVVzYgq7gaUglwL4t0IiK6BSzSiajXkkgkGBuoxNhAJTIuVOI/+wqQkluG77PV+D5bjRH+LnhqlB/GDlRCyu3biOgWXNsbPdrfBUo7hcjREBGROWGRTkQEIKKfMz583Bm5ai2S9xdgx4lSHCq4jEMFl+Hf1xZPjuyPh+7whMJSJnaoRGQGtmddG+rOVd2JiOjWcE46EdEfDHKzR9LUoUh9cSxmjfKDndwCBeX1eGlrNka8tRerf8pDWW2j2GESkQnL19QiV10LS5kEEwa7iR0OERGZGRbpREQ34OVkg5fvC8ahxXdhyf3B8HS0RmV9M97fexYj39qHF788jly1VuwwicgE7ThRCgAYPaAvHG2sRI6GiIjMDYe7ExHdhJ3CEk+O9EN8dD/8dFqDDWnn8GtRNb7MKMGXGSUYNcAVT470w5iBfSGRcN46UW8nCMLvq7qHc6g7ERHdOhbpREQdYCGT4t5Qd9wb6o6MC1XYeKAQP5wsRVp+BdLyKzBA2QdPjvTD5KGct07Um526pEVhRT3kFlLEBqvEDoeIiMwQi3QiolsU0c8JEf2cUFzZgI8OnseWY0XIL6vDom+yserHPEyP7oe/D+8H1z5ysUMlom52rRc9NkiFPnL+mkVERLeOc9KJiG6Tt7MNlk4KxuGXxuPle4Pg4aDA5fpmJO3Jx4i39mLR1yeQr6kVO0wi6iZ6vYDvrs5HnxTOvdGJiOj2sEgnIuoke4UlZo3uj58XjMMHjw1FuJcDmq/osflYMe7+18+I35iOtPxyCIIgdqhE1IUyi6pwsfo39JFbYGygUuxwiIjITHEcFhGRkVjIpJgU7oH7w1rnrf83rRA/nlYj9Uw5Us+UI1BlhydH+eHBIR6QW3DeOlFPc22o+z3BKq5NQUREt41FOhGRkUkkEkT6OiPS1xkXLtfjo4Pn8cUvxcjT1GLBVyfw9q48zIjuh2lRPnDhvHWiHuGKTo+d2VeHug/hqu5ERHT7ONydiKgL9XOxxasPhODwovFYNHEQ3OwVqKhrwurdZzDirb1Y/E02zpbViR0mEXXS0cJKVNQ1w9HGEiMDXMUOh4iIzBh70omIuoGDjSWeGeOPJ0f64fvsUmxIO4eTF7X4PL0In6cX4U5fJ9zRzwlDvBwxxMcR7g7WYodMRLdge1brUPeJg91hKWMfCBER3T5mESKibmQpk+LBIZ7YMXcktjw9HHcHqyCRAMfOV2Fd6jnM/jQT0Yl7EbViD57+5Bf8Z/9ZHDpbgdrGFrFDJ2rXmjVr4OvrC4VCgaioKKSnp7d77ccffwyJRNLmUCgUba4RBAFLly6Fu7s7rK2tERsbi/z8/K5uxm1rvqLHDye5qjsRERkHe9KJiEQgkUgQ1d8FUf1dUFzZgMMFl/FrcTWOF1cjT1MLjbYJP53W4KfTmqvXAwF9+2CItyPCvR0xxNsRgW527LEj0W3ZsgUJCQlITk5GVFQUkpKSEBcXh7y8PCiVN17h3N7eHnl5eYbHEomkzfNvv/023n//fWzatAl+fn5YsmQJ4uLicPr06esKelOQll8ObeMVKO3kiPJzETscIiIycyzSiYhE5u1sA29nGzx6pzcAoKH5Ck5d0iKrqBpZxa3HxerfkF9Wh/yyOnyZUQIAUFhKMdjDwVC0D/F2hJeT9XUFD1FXWr16NWbNmoWZM2cCAJKTk7Fz505s3LgRixYtuuE9EokEbm5uN3xOEAQkJSXhlVdewYMPPggA+OSTT6BSqbBt2zZMnTq1axrSCddWdb8vzB0yKf//ERFR57BIJyIyMTZWFrjT1xl3+jobzpXXNuH41YL9eEnrn7WNV/DLhSr8cqHKcJ2LrZWhaA/3dsQQL0c42FiK0QzqBZqbm5GRkYHFixcbzkmlUsTGxuLw4cPt3ldXV4d+/fpBr9fjjjvuwIoVKxASEgIAKCwshFqtRmxsrOF6BwcHREVF4fDhw+0W6U1NTWhqajI81mq1nW1eh/zWrDOMeJkUzlXdiYio81ikExGZgb52csQGqxAbrAIA6PUCCi/XI6vo96I9p1SLy/XN2Jtbhr25ZYZ7/VxtW4t2LwcM8XFCkLsd92kno6ioqIBOp4NKpWpzXqVSITc394b3BAYGYuPGjQgLC0NNTQ3eeecdjBgxAqdOnYKXlxfUarXhNf78mteeu5HExEQsX768ky26dXtzy9DQrIOXkzWGejt2+9cnIqKeh0U6EZEZkkol8O/bB/59++DhCC8AQGOLDqdLtb/3uBdX4/zlBhRW1KOwoh5bf70IALCykCK6vwtig5QYH6SChyNXkqfuEx0djejoaMPjESNGICgoCOvWrcPrr79+26+7ePFiJCQkGB5rtVp4e3t3KtaOuDbUfVK4B6eaEBGRUbBIJyLqIRSWMtzh44Q7fJwM56rqmw097deK96qGFqSeKUfqmXIs+fYUgtztDQV7mKcDpJxTSx3k6uoKmUwGjUbT5rxGo2l3zvmfWVpaYujQoTh79iwAGO7TaDRwd/99pXSNRoMhQ4a0+zpyuRxyufwWW9A52sYW7M1rHbUyKYxD3YmIyDhYpBMR9WBOtlYYG6jE2MDWVbYFQcDZsjrsySlDSo4GmUVVyCnVIqdUiw/2nkVfOznGD2ot2EcGuMLaisPiqX1WVlaIiIhASkoKJk+eDADQ6/VISUnB3LlzO/QaOp0O2dnZuPfeewEAfn5+cHNzQ0pKiqEo12q1OHr0KGbPnt0Vzbhtu09p0HxFD/++tghytxM7HCIi6iFYpBMR9SISiQQDVHYYoLLD7LH+qKxvxr7cMqTkavDzmQqU1zZh87FibD5WDLmFFDEBrhgfpMT4QSq4OZje1lckvoSEBMTHxyMyMhLDhg1DUlIS6uvrDau9z5gxA56enkhMTAQAvPbaaxg+fDgCAgJQXV2NVatW4cKFC3jqqacAtP4bnT9/Pt544w0MGDDAsAWbh4eH4YMAU7HjROtQ9wfCPTnUnYiIjIZFOhFRL+Zsa4WHI7zwcIQXmq7ocPRcJVJyNNiTU4aL1b8ZFqF7GScx2NMe4wepEBukwmBPexYlBACYMmUKysvLsXTpUqjVagwZMgS7du0yLPxWVFQEqVRquL6qqgqzZs2CWq2Gk5MTIiIicOjQIQQHBxuuWbBgAerr6/H000+juroaI0eOxK5du0xqj/TK+mYcyK8AANwf7v4XVxMREXWcRBAEQewgupNWq4WDgwNqampgb28vdjhERCZJEATkaWqRklOGPTkaZBVX44/ZQmUvx12DVIgNUiImwBUKSw6L7wzmJuPr6u/pp0cv4OWtJxHiYY+dz40y+usTEVHPcit5iT3pRER0HYlEgkFu9hjkZo854wJQUdeEvbmt89jT8iug0Tbh8/QifJ5eBIWlFCMD+iI2SIm7BimhtDed3k6irvLHVd2JiIiMiUU6ERH9Jdc+cjwa6Y1HI73R2KLDkXOXkXJ18blLNY3Yk6PBnpzWFb7DvRwwPkiF8UFKBLtzWDz1PBptI44WVgIA7g/jUHciIjIuFulERHRLFJYyw4rxrz0YgtOlWkPBfrykxnCs3n0GHg4KxAS4IszbEeFeDgh0s4PcgkPjybztPFEKQQAi+jnBy8lG7HCIiKiHYZFORES3TSKRIMTDASEeDnhu/ACUaRuxN7cMe3LKcOBsOS7VNOLLjBJ8mVECALCSSTHI3Q5hXg4I83JEuJcjApR9IOPe7GRGtl8b6s5edCIi6gIs0omIyGiU9gpMHeaDqcN80Niiw+GCy8gsqsLxkhqcKKlGdUMLTpTU4ERJDYAiAICNlQyDPRxaC/erPe4+zjYcJk8mqbiyAVnF1ZBKgHtZpBMRURcwiSJ9zZo1WLVqFdRqNcLDw/HBBx9g2LBhf3nf5s2b8dhjj+HBBx/Etm3buj5QIiLqMIWlDOMGKTFukBJA64rxxZW/4XhJNU6UVON4SQ1OXqxBQ7MO6ecrkX6+0nCvo40lQj0dEO7liFCv1j+5TzuZgmt7o0f7u0Bpx3+TRERkfKIX6Vu2bEFCQgKSk5MRFRWFpKQkxMXFIS8vD0qlst37zp8/j3/+858YNYrbnhARmQOJRAIfFxv4uNgYVsTW6QUUlNdd7V1vLdxzLmlR3dCCtPwKpF3dhxoAlHbyq0PkW3vcwzwd4GRrJVZzqJfacbwUADApjKu6ExFR1xB9n/SoqCjceeed+Pe//w0A0Ov18Pb2xrPPPotFixbd8B6dTofRo0fjiSeeQFpaGqqrqzvck869aImITFvzFT3y1LWGHvcTJTU4o6mF/gbZysfZBmFXe9rDvBww2NMBtnLRP3++ZcxNxtcV39OzZbWIXf0zLGUSHHs5Fo42/JCIiIg6xmz2SW9ubkZGRgYWL15sOCeVShEbG4vDhw+3e99rr70GpVKJJ598Emlpad0RKhERdRMrCylCvRwQ6uUAoB8AoKH5Ck5f0hrmtp8oqUFhRT2KKhtQVNmA70609m7KpBLc4eOIMQP7YsxAJUI87CHlonRkJNuv9qKPHtCXBToREXUZUYv0iooK6HQ6qFSqNudVKhVyc3NveM+BAwfw4YcfIisrq0Nfo6mpCU1NTYbHWq32tuMlIiJx2FhZINLXGZG+zoZzNQ0tyL5Y06bHvbSmEcfOV+HY+Sq889MZuPaxwugBfTEmsC9GBrjCpY9cxFaQORMEAd9dW9U9nEPdiYio65jVmMDa2lpMnz4dGzZsgKura4fuSUxMxPLly7s4MiIi6m4ONpYYOcAVIwf8ng+KKxvwc345UvPKcfBsBSrqmvHNrxfxza8XIZEAYZ4Orb3sgX0R7uUIC5lUxBaQOTl1SYtzFfWQW0gRG6z66xuIiIhuk6hFuqurK2QyGTQaTZvzGo0Gbm5u111fUFCA8+fPY9KkSYZzer0eAGBhYYG8vDz4+/u3uWfx4sVISEgwPNZqtfD29jZmM4iIyER4O9tgWlQ/TIvqh+YremQWVSH1TGvRfrq0dbj88ZIavL/3LOwVFhg1oC/GDOyL0QP7cvV4uqkdV3vRxwcp0ccM1z0gIiLzIWqWsbKyQkREBFJSUjB58mQArUV3SkoK5s6de931gwYNQnZ2dptzr7zyCmpra/Hee+/dsPiWy+WQyzm8kYiot7GykGJ4fxcM7++ChRMGoUzbiJ/zK5B6phxp+eWobmjBzuxS7MxunWc8yM3u6lz2vojwdYLcQiZyC8hU6PWCYd2DBzjUnYiIupjoHwUnJCQgPj4ekZGRGDZsGJKSklBfX4+ZM2cCAGbMmAFPT08kJiZCoVBg8ODBbe53dHQEgOvOExER/ZHSXoG/RXjhbxFe0OkFHC+pRmpeOVLPlON4STVy1bXIVddi3c/nYGMlwwh/F8MCdD4uNmKHTyL6tbgKF6t/Qx+5BcYGtr89LBERkTGIXqRPmTIF5eXlWLp0KdRqNYYMGYJdu3YZFpMrKiqCVMo5g0REZDytq8A74Q4fJzx/90BU1Tcj7WyFoWivqGvCnpwy7MkpA3AKfq62hl724f1dYG3FXvbeZHtW61D3e4JVUFjyZ09ERF1L9H3Suxv3oiUiopvR6wXkqLWGuewZF6pw5Q+btFtZSBHl52wo2gOUfSCRdG6bN+Ym4zPW9/SKTo/hiSmoqGvGRzPvxDj2pBMR0W0wm33SiYiITI1UKkGIhwNCPBzwj7EBqG1swaGCy4ai/WL1b0jLr0BafgX+ve8sMl65GzJuxd5jHS2sREVdMxxtLDEyoGM7yxAREXUGi3QiIqKbsFNYIi7EDXEhbhAEAQXlddh/dVi8yl4BmZQVek9mKZNiZIArfF1tYMkt+4iIqBuwSCciIuogiUSCAKUdApR2eGpUf/SyGWO90jA/Z/zvU1H8WRMRUbfhR8JERES3qbNz0cl88GdNRETdhUU6ERERERERkYlgkU5ERERERERkIlikExEREREREZkIFulEREREREREJoJFOhEREXXKmjVr4OvrC4VCgaioKKSnp3fovs2bN0MikWDy5Mltzj/++OOQSCRtjgkTJnRB5ERERKaHRToRERHdti1btiAhIQHLli1DZmYmwsPDERcXh7Kyspved/78efzzn//EqFGjbvj8hAkTUFpaajg+//zzrgifiIjI5LBIJyIiotu2evVqzJo1CzNnzkRwcDCSk5NhY2ODjRs3tnuPTqfDtGnTsHz5cvTv3/+G18jlcri5uRkOJyenrmoCERGRSWGRTkRERLelubkZGRkZiI2NNZyTSqWIjY3F4cOH273vtddeg1KpxJNPPtnuNfv374dSqURgYCBmz56Ny5cv3zSWpqYmaLXaNgcREZE5YpFOREREt6WiogI6nQ4qlarNeZVKBbVafcN7Dhw4gA8//BAbNmxo93UnTJiATz75BCkpKVi5ciVSU1MxceJE6HS6du9JTEyEg4OD4fD29r69RhEREYnMQuwAiIiIqHeora3F9OnTsWHDBri6urZ73dSpUw1/Dw0NRVhYGPz9/bF//36MHz/+hvcsXrwYCQkJhsdarZaFOhERmaVeV6QLggAAHAZHREQm41pOupajzIWrqytkMhk0Gk2b8xqNBm5ubtddX1BQgPPnz2PSpEmGc3q9HgBgYWGBvLw8+Pv7X3df//794erqirNnz7ZbpMvlcsjlcsNj5nsiIjIlt5Lre12RXltbCwD8dJ2IiExObW0tHBwcxA6jw6ysrBAREYGUlBTDNmp6vR4pKSmYO3fuddcPGjQI2dnZbc698sorqK2txXvvvddubi4pKcHly5fh7u7e4diY74mIyBR1JNf3uiLdw8MDxcXFsLOzg0Qi6dRrXRtKV1xcDHt7eyNFaBrYNvPEtpknts08GbNtgiCgtrYWHh4eRoqu+yQkJCA+Ph6RkZEYNmwYkpKSUF9fj5kzZwIAZsyYAU9PTyQmJkKhUGDw4MFt7nd0dAQAw/m6ujosX74cDz/8MNzc3FBQUIAFCxYgICAAcXFxHY6L+b5j2Dbz01PbBbBt5opt65hbyfW9rkiXSqXw8vIy6mva29v3uH+Q17Bt5oltM09sm3kyVtvMqQf9j6ZMmYLy8nIsXboUarUaQ4YMwa5duwyLyRUVFUEq7fg6tTKZDCdOnMCmTZtQXV0NDw8P3HPPPXj99dfbDGf/K8z3t4ZtMz89tV0A22au2La/1tFc3+uKdCIiIjKuuXPn3nB4O9C6ldrNfPzxx20eW1tb48cffzRSZEREROaHW7ARERERERERmQgW6Z0gl8uxbNmyWxp+Zy7YNvPEtpknts089eS2UVs9+WfNtpmfntougG0zV2yb8UkEc9vvhYiIiIiIiKiHYk86ERERERERkYlgkU5ERERERERkIlikExEREREREZkIFulEREREREREJoJFeiesWbMGvr6+UCgUiIqKQnp6utghdVpiYiLuvPNO2NnZQalUYvLkycjLyxM7rC7x1ltvQSKRYP78+WKHYhQXL17E3//+d7i4uMDa2hqhoaH45ZdfxA6r03Q6HZYsWQI/Pz9YW1vD398fr7/+Osxxzcuff/4ZkyZNgoeHByQSCbZt29bmeUEQsHTpUri7u8Pa2hqxsbHIz88XJ9hbdLO2tbS0YOHChQgNDYWtrS08PDwwY8YMXLp0SbyAb8Ff/dz+6JlnnoFEIkFSUlK3xUddi7nevDHXmwfmeuZ6sZlarmeRfpu2bNmChIQELFu2DJmZmQgPD0dcXBzKysrEDq1TUlNTMWfOHBw5cgS7d+9GS0sL7rnnHtTX14sdmlEdO3YM69atQ1hYmNihGEVVVRViYmJgaWmJH374AadPn8a7774LJycnsUPrtJUrV2Lt2rX497//jZycHKxcuRJvv/02PvjgA7FDu2X19fUIDw/HmjVrbvj822+/jffffx/Jyck4evQobG1tERcXh8bGxm6O9NbdrG0NDQ3IzMzEkiVLkJmZiW+++QZ5eXl44IEHRIj01v3Vz+2arVu34siRI/Dw8OimyKirMdebN+Z688Fcz1wvNpPL9QLdlmHDhglz5swxPNbpdIKHh4eQmJgoYlTGV1ZWJgAQUlNTxQ7FaGpra4UBAwYIu3fvFsaMGSPMmzdP7JA6beHChcLIkSPFDqNL3HfffcITTzzR5txDDz0kTJs2TaSIjAOAsHXrVsNjvV4vuLm5CatWrTKcq66uFuRyufD555+LEOHt+3PbbiQ9PV0AIFy4cKF7gjKS9tpWUlIieHp6CidPnhT69esn/Otf/+r22Mj4mOvNF3O9eWGuZ643JaaQ69mTfhuam5uRkZGB2NhYwzmpVIrY2FgcPnxYxMiMr6amBgDg7OwsciTGM2fOHNx3331tfn7mbvv27YiMjMQjjzwCpVKJoUOHYsOGDWKHZRQjRoxASkoKzpw5AwA4fvw4Dhw4gIkTJ4ocmXEVFhZCrVa3+Xfp4OCAqKioHve+ArS+t0gkEjg6OoodSqfp9XpMnz4dL774IkJCQsQOh4yEud68MdebF+Z65npT19253qLLv0IPVFFRAZ1OB5VK1ea8SqVCbm6uSFEZn16vx/z58xETE4PBgweLHY5RbN68GZmZmTh27JjYoRjVuXPnsHbtWiQkJOCll17CsWPH8Nxzz8HKygrx8fFih9cpixYtglarxaBBgyCTyaDT6fDmm29i2rRpYodmVGq1GgBu+L5y7bmeorGxEQsXLsRjjz0Ge3t7scPptJUrV8LCwgLPPfec2KGQETHXmy/mevPDXM9cb+q6O9ezSKd2zZkzBydPnsSBAwfEDsUoiouLMW/ePOzevRsKhULscIxKr9cjMjISK1asAAAMHToUJ0+eRHJystkn7i+++AKffvopPvvsM4SEhCArKwvz58+Hh4eH2betN2ppacGjjz4KQRCwdu1ascPptIyMDLz33nvIzMyERCIROxyiW8Zcbz6Y68lcMNd3Hoe73wZXV1fIZDJoNJo25zUaDdzc3ESKyrjmzp2L7777Dvv27YOXl5fY4RhFRkYGysrKcMcdd8DCwgIWFhZITU3F+++/DwsLC+h0OrFDvG3u7u4IDg5ucy4oKAhFRUUiRWQ8L774IhYtWoSpU6ciNDQU06dPx/PPP4/ExESxQzOqa+8dPfl95VrSvnDhAnbv3t0jPllPS0tDWVkZfHx8DO8rFy5cwAsvvABfX1+xw6NOYK43T8z15om5vue8rzDXGweL9NtgZWWFiIgIpKSkGM7p9XqkpKQgOjpaxMg6TxAEzJ07F1u3bsXevXvh5+cndkhGM378eGRnZyMrK8twREZGYtq0acjKyoJMJhM7xNsWExNz3fY5Z86cQb9+/USKyHgaGhoglbZ9q5LJZNDr9SJF1DX8/Pzg5ubW5n1Fq9Xi6NGjZv++AvyetPPz87Fnzx64uLiIHZJRTJ8+HSdOnGjzvuLh4YEXX3wRP/74o9jhUScw15sn5nrzxFzPXG/KxMj1HO5+mxISEhAfH4/IyEgMGzYMSUlJqK+vx8yZM8UOrVPmzJmDzz77DN9++y3s7OwM82McHBxgbW0tcnSdY2dnd918O1tbW7i4uJj9PLznn38eI0aMwIoVK/Doo48iPT0d69evx/r168UOrdMmTZqEN998Ez4+PggJCcGvv/6K1atX44knnhA7tFtWV1eHs2fPGh4XFhYiKysLzs7O8PHxwfz58/HGG29gwIAB8PPzw5IlS+Dh4YHJkyeLF3QH3axt7u7u+Nvf/obMzEx899130Ol0hvcWZ2dnWFlZiRV2h/zVz+3Pv4RYWlrCzc0NgYGB3R0qGRlzvflhrjdPzPXM9WIzuVzfZevG9wIffPCB4OPjI1hZWQnDhg0Tjhw5InZInQbghsdHH30kdmhdoqdsyyIIgrBjxw5h8ODBglwuFwYNGiSsX79e7JCMQqvVCvPmzRN8fHwEhUIh9O/fX3j55ZeFpqYmsUO7Zfv27bvh/6/4+HhBEFq3ZlmyZImgUqkEuVwujB8/XsjLyxM36A66WdsKCwvbfW/Zt2+f2KH/pb/6uf0Zt2DrWZjrzR9zveljrmeuF5up5XqJIAiCMYt+IiIiIiIiIro9nJNOREREREREZCJYpBMRERERERGZCBbpRERERERERCaCRToRERERERGRiWCRTkRERERERGQiWKQTERERERERmQgW6UREREREREQmgkU6US82b948PP3009Dr9WKHQkRERF2AuZ7I/LBIJ+qliouLERgYiHXr1kEq5VsBERFRT8NcT2SeJIIgCGIHQURERERERETsSSfqdR5//HFIJJLrjgkTJogdGhERERkBcz2RebMQOwAi6n4TJkzARx991OacXC4XKRoiIiIyNuZ6IvPFnnSiXkgul8PNza3N4eTkBACQSCRYu3YtJk6cCGtra/Tv3x9fffVVm/uzs7Nx1113wdraGi4uLnj66adRV1fX5pqNGzciJCQEcrkc7u7umDt3ruG51atXIzQ0FLa2tvD29sY//vGP6+4nIiKi28dcT2S+WKQT0XWWLFmChx9+GMePH8e0adMwdepU5OTkAADq6+sRFxcHJycnHDt2DF9++SX27NnTJjGvXbsWc+bMwdNPP43s7Gxs374dAQEBhuelUinef/99nDp1Cps2bcLevXuxYMGCbm8nERFRb8VcT2TCBCLqVeLj4wWZTCbY2tq2Od58801BEAQBgPDMM8+0uScqKkqYPXu2IAiCsH79esHJyUmoq6szPL9z505BKpUKarVaEARB8PDwEF5++eUOx/Tll18KLi4unW0aERERCcz1ROaOc9KJeqFx48Zh7dq1bc45Ozsb/h4dHd3muejoaGRlZQEAcnJyEB4eDltbW8PzMTEx0Ov1yMvLg0QiwaVLlzB+/Ph2v/6ePXuQmJiI3NxcaLVaXLlyBY2NjWhoaICNjY0RWkhERNS7MdcTmS8OdyfqhWxtbREQENDm+GPi7gxra+ubPn/+/Hncf//9CAsLw9dff42MjAysWbMGANDc3GyUGIiIiHo75noi88UinYiuc+TIkeseBwUFAQCCgoJw/Phx1NfXG54/ePAgpFIpAgMDYWdnB19fX6SkpNzwtTMyMqDX6/Huu+9i+PDhGDhwIC5dutR1jSEiIqLrMNcTmS4OdyfqhZqamqBWq9ucs7CwgKurKwDgyy+/RGRkJEaOHIlPP/0U6enp+PDDDwEA06ZNw7JlyxAfH49XX30V5eXlePbZZzF9+nSoVCoAwKuvvopnnnkGSqUSEydORG1tLQ4ePIhnn30WAQEBaGlpwQcffIBJkybh4MGDSE5O7t5vABERUQ/HXE9kxsSeFE9E3Ss+Pl4AcN0RGBgoCELrYjJr1qwR7r77bkEulwu+vr7Cli1b2rzGiRMnhHHjxgkKhUJwdnYWZs2aJdTW1ra5Jjk5WQgMDBQsLS0Fd3d34dlnnzU8t3r1asHd3V2wtrYW4uLihE8++UQAIFRVVXV5+4mIiHo65noi8yYRBEEQ48MBIjJNEokEW7duxeTJk8UOhYiIiLoAcz2RaeOcdCIiIiIiIiITwSKdiIiIiIiIyERwuDsRERERERGRiWBPOhEREREREZGJYJFOREREREREZCJYpBMRERERERGZCBbpRERERERERCaCRToRERERERGRiWCRTkRERERERGQiWKQTERERERERmQgW6UREREREREQmgkU6ERERERERkYn4/zsimVqiMrpYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = historymodelBertCnn.history['loss']\n",
    "val_loss = historymodelBertCnn.history['val_loss']\n",
    "train_accuracy = historymodelBertCnn.history['sparse_categorical_accuracy']\n",
    "val_accuracy = historymodelBertCnn.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Entrenamiento')\n",
    "plt.plot(val_loss, label='Validación')\n",
    "plt.title('Curva de pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Entrenamiento')\n",
    "plt.plot(val_accuracy, label='Validación')\n",
    "plt.title('Curva de precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 71s 914ms/step - loss: 0.9849 - sparse_categorical_accuracy: 0.7098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9848834276199341, 0.7098214030265808]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBertCnn.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bert + NgramCNN + One Layer Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa de atención\n",
    "attention = Attention()([sequence_output, sequence_output])\n",
    "\n",
    "x_1 = layers.Conv1D(filters=50, kernel_size=2, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_1 = layers.GlobalMaxPooling1D()(x_1)\n",
    "x_2 = layers.Conv1D(filters=50, kernel_size=3, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_2 = layers.GlobalMaxPooling1D()(x_2)\n",
    "x_3 = layers.Conv1D(filters=50, kernel_size=4, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_3 = layers.GlobalMaxPooling1D()(x_3)\n",
    "\n",
    "merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(merged)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertCnn2 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertCnn2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertCnn2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bert + CNN + Attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa de atención\n",
    "attention = Attention()([sequence_output, sequence_output])\n",
    "\n",
    "x_1 = layers.Conv1D(filters=50, kernel_size=2, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_1 = Attention()([x_1, x_1])\n",
    "x_1 = layers.GlobalMaxPooling1D()(x_1)\n",
    "x_2 = layers.Conv1D(filters=50, kernel_size=3, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_2 = Attention()([x_2, x_2])\n",
    "x_2 = layers.GlobalMaxPooling1D()(x_2)\n",
    "x_3 = layers.Conv1D(filters=50, kernel_size=4, activation=\"relu\", padding=\"same\")(attention)\n",
    "x_3 = Attention()([x_3, x_3])\n",
    "x_3 = layers.GlobalMaxPooling1D()(x_3)\n",
    "\n",
    "merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(merged)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertCnn3 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertCnn3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertCnn3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa bidireccional\n",
    "x = Bidirectional(LSTM(768, return_sequences=True))(sequence_output)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bert + BiLStm + Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Attention\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "attention1 = Attention()([sequence_output, sequence_output])\n",
    "\n",
    "x = Bidirectional(LSTM(768, return_sequences=True))(attention1)\n",
    "attention2 = Attention()([x, x])\n",
    "x = layers.GlobalMaxPooling1D()(attention2)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTMAttention = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTMAttention.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTMAttention.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BERT + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 3, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda_27 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_28 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_29 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " keras_layer_10 (KerasLayer)    [(None, 768),        108310273   ['lambda_27[0][0]',              \n",
      "                                 (None, 300, 768)]                'lambda_28[0][0]',              \n",
      "                                                                  'lambda_29[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 300, 1536)    9443328     ['keras_layer_10[0][1]']         \n",
      "                                                                                                  \n",
      " global_max_pooling1d_24 (Globa  (None, 1536)        0           ['bidirectional[0][0]']          \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 256)          393472      ['global_max_pooling1d_24[0][0]']\n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 7)            1799        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 118,148,872\n",
      "Trainable params: 9,838,599\n",
      "Non-trainable params: 108,310,273\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa bidireccional\n",
    "x = Bidirectional(LSTM(768, return_sequences=True))(sequence_output)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM3 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BERT + 2 BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 3, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda_36 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_37 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_38 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " keras_layer_12 (KerasLayer)    [(None, 768),        108310273   ['lambda_36[0][0]',              \n",
      "                                 (None, 300, 768)]                'lambda_37[0][0]',              \n",
      "                                                                  'lambda_38[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 300, 128)    426496      ['keras_layer_12[0][1]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d_26 (Globa  (None, 128)         0           ['bidirectional_2[0][0]']        \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          16512       ['global_max_pooling1d_26[0][0]']\n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 7)            903         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,754,184\n",
      "Trainable params: 443,911\n",
      "Non-trainable params: 108,310,273\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa bidireccional\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(sequence_output)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.5)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM3Models2 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM3Models2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM3Models2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#--------------------Checkpoint--------------------\n",
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('model/BERT/BiLstm5/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_path = 'model/BERT/BiLstm5/64batch/BERT_CNN_model_best_{epoch:02d}_val_{val_sparse_categorical_accuracy:.4f}'\n",
    "\n",
    "# Callback de ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_format='tf',\n",
    "    save_weights_only=False,\n",
    ")\n",
    "\n",
    "\n",
    "#----------------Tensorboard-------------------\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "os.makedirs('logs/BERT/BiLstm5/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"logs/BERT/BiLstm5/64batch\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historymodelBertBiLSTM3Models2 =  modelBertBiLSTM3Models2.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data = val_dataset,\n",
    "    callbacks = [model_checkpoint,tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = historymodelBertBiLSTM3Models2.history['loss']\n",
    "val_loss = historymodelBertBiLSTM3Models2.history['val_loss']\n",
    "train_accuracy = historymodelBertBiLSTM3Models2.history['sparse_categorical_accuracy']\n",
    "val_accuracy = historymodelBertBiLSTM3Models2.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Entrenamiento')\n",
    "plt.plot(val_loss, label='Validación')\n",
    "plt.title('Curva de pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Entrenamiento')\n",
    "plt.plot(val_accuracy, label='Validación')\n",
    "plt.title('Curva de precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BERT + 2 BiLSTM - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 3, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda_36 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_37 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_38 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " keras_layer_14 (KerasLayer)    [(None, 768),        108310273   ['lambda_36[0][0]',              \n",
      "                                 (None, 300, 768)]                'lambda_37[0][0]',              \n",
      "                                                                  'lambda_38[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_31 (Bidirectiona  (None, 300, 256)    918528      ['keras_layer_14[0][1]']         \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " global_max_pooling1d_11 (Globa  (None, 256)         0           ['bidirectional_31[0][0]']       \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          32896       ['global_max_pooling1d_11[0][0]']\n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 7)            903         ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,262,600\n",
      "Trainable params: 952,327\n",
      "Non-trainable params: 108,310,273\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa bidireccional\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.25))(sequence_output)\n",
    "x = Attention(use_scale=True)([x, x])\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(sequence_output)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.5)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM3Models3 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM3Models3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM3Models3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Dual Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Conv1D, Dropout\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "\n",
    "Layer1 = Bidirectional(LSTM(32, return_sequences=True))(sequence_output)\n",
    "Layer1 = Conv1D(filters=32, kernel_size=400)(Layer1)\n",
    "Layer1 = Dropout(0.3)(Layer1)\n",
    "#Layer1 = Dropout(0.5)(Layer1)\n",
    "\n",
    "Layer2 = Conv1D(filters=32, kernel_size=400)(sequence_output)\n",
    "Layer2 = Dropout(0.3)(Layer2)\n",
    "#Layer2 = Dropout(0.5)(Layer2)\n",
    "Layer2 = Bidirectional(LSTM(32, return_sequences=True))(Layer2)\n",
    "\n",
    "x= tf.concat([Layer1,Layer2], axis=-1)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "last_dense = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "#last_dropout = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertDualChannel = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertDualChannel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 3, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda_48 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_49 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_50 (Lambda)             (None, 300)          0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " keras_layer_16 (KerasLayer)    [(None, 768),        108310273   ['lambda_48[0][0]',              \n",
      "                                 (None, 300, 768)]                'lambda_49[0][0]',              \n",
      "                                                                  'lambda_50[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_34 (Bidirectiona  (None, 300, 64)     205056      ['keras_layer_16[0][1]']         \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 298, 32)      73760       ['keras_layer_16[0][1]']         \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 298, 32)      6176        ['bidirectional_34[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 298, 32)      0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 298, 32)      0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_35 (Bidirectiona  (None, 298, 64)     16640       ['dropout_22[0][0]']             \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 298, 96)      0           ['dropout_21[0][0]',             \n",
      "                                                                  'bidirectional_35[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 149, 96)     0           ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 149, 96)      0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 14304)        0           ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 512)          7324160     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 7)            3591        ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 115,939,656\n",
      "Trainable params: 7,629,383\n",
      "Non-trainable params: 108,310,273\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBertDualChannel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#--------------------Checkpoint--------------------\n",
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('BERT/Model2/modelBertDualChannel/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_path = 'BERT/Model2/modelBertDualChannel/64batch/BERT_CNN_model_best_{epoch:02d}_val_{val_sparse_categorical_accuracy:.4f}'\n",
    "\n",
    "# Callback de ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_format='tf',\n",
    "    save_weights_only=False,\n",
    ")\n",
    "\n",
    "\n",
    "#----------------Tensorboard-------------------\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "os.makedirs('logs/BERT/Model2/modelBertDualChannel/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"logs/BERT/Model2/modelBertDualChannel/64batch\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import layers\n",
    "#from keras import Model\n",
    "#from keras import regularizers\n",
    "\n",
    "#inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "#input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "#input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "#input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "#bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "#pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "#x_1 = layers.Conv1D(filters=50, kernel_size=2, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "#x_1 = layers.GlobalMaxPooling1D()(x_1)\n",
    "#x_2 = layers.Conv1D(filters=50, kernel_size=3, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "#x_2 = layers.GlobalMaxPooling1D()(x_2)\n",
    "#x_3 = layers.Conv1D(filters=50, kernel_size=4, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "#x_3 = layers.GlobalMaxPooling1D()(x_3)\n",
    "#x_4 = layers.Conv1D(filters=50, kernel_size=5, activation=\"relu\", padding=\"same\")(sequence_output)\n",
    "#x_4 = layers.GlobalMaxPooling1D()(x_4)\n",
    "\n",
    "#merged = tf.concat([x_1, x_2, x_3, x_4], axis=-1)\n",
    "#merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "#dropout = layers.Dropout(0.5)(merged)\n",
    "#last_dense = layers.Dense(units=256, activation=\"relu\",kernel_regularizer=regularizers.L2(0.01))(dropout)\n",
    "#dropout = layers.Dropout(0.5)(last_dense)\n",
    "#output = layers.Dense(units=7, activation=\"softmax\")(dropout)\n",
    "\n",
    "#modelBertCnn = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "#modelBertCnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "#modelBertCnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from keras import layers\\nfrom keras import Model\\nfrom tensorflow.keras.layers import Bidirectional, LSTM\\n#from keras_self_attention import SeqSelfAttention\\nfrom tensorflow.keras.layers import Attention\\nfrom keras import backend as K\\nfrom keras import initializers, regularizers, constraints\\n\\n\\n\\ninputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name=\\'inputs\\')\\ninput_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\ninput_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\ninput_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\n\\nbert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\\n\\npooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\\n\\n# Aplicar capa bidireccional\\nx = Bidirectional(LSTM(768, return_sequences=True, dropout=0.2))(sequence_output)\\nx = Attention(use_scale=True)([x, x])\\nx = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(x)\\nx = Attention(use_scale=True)([x, x])\\n#x = Attention(use_scale=True)([x, x])\\nx = layers.GlobalMaxPooling1D()(x)\\n\\nlast_dense = layers.Dense(units=128, activation=\"relu\")(x)\\ndropout = layers.Dropout(0.5)(last_dense)\\noutput = layers.Dense(units=7, activation=\"softmax\")(last_dense)\\n\\nmodelBertBiLSTM3Models4 = Model(inputs=inputs_full, outputs=output)\\n\\nmodelBertBiLSTM3Models4.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\\n\\nmodelBertBiLSTM3Models4.summary()'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "\n",
    "x = Bidirectional(LSTM(768, return_sequences=True, dropout=0.2))(sequence_output)\n",
    "x = Attention(use_scale=True)([x, x])\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(x)\n",
    "x = Attention(use_scale=True)([x, x])\n",
    "#x = Attention(use_scale=True)([x, x])\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.5)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM3Models4 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM3Models4.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM3Models4.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from keras import layers\\nfrom keras import Model\\nfrom tensorflow.keras.layers import Bidirectional, LSTM\\n\\ninputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name=\\'inputs\\')\\ninput_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\ninput_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\ninput_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\\n\\nbert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\\n\\npooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\\n\\n# Aplicar capa bidireccional\\nx = Bidirectional(LSTM(768, return_sequences=True))(sequence_output)\\nx = layers.GlobalMaxPooling1D()(x)\\n\\nlast_dense = layers.Dense(units=256, activation=\"relu\")(x)\\ndropout = layers.Dropout(0.4)(last_dense)\\noutput = layers.Dense(units=7, activation=\"softmax\")(last_dense)\\n\\nmodelBertBiLSTM3Models6 = Model(inputs=inputs_full, outputs=output)\\n\\nmodelBertBiLSTM3Models6.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\\n\\nmodelBertBiLSTM3Models6.summary()'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from keras import layers\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "inputs_full = layers.Input(shape=(3,SEQUENCE_LENGTH,), dtype=tf.int32, name='inputs')\n",
    "input_word_ids = layers.Lambda(lambda x: x[:, 0 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_mask = layers.Lambda(lambda x: x[:, 1 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "input_type_ids = layers.Lambda(lambda x: x[:, 2 ,:], output_shape=(SEQUENCE_LENGTH,))(inputs_full)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",trainable=False)\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "\n",
    "# Aplicar capa bidireccional\n",
    "x = Bidirectional(LSTM(768, return_sequences=True))(sequence_output)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "last_dense = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "dropout = layers.Dropout(0.4)(last_dense)\n",
    "output = layers.Dense(units=7, activation=\"softmax\")(last_dense)\n",
    "\n",
    "modelBertBiLSTM3Models6 = Model(inputs=inputs_full, outputs=output)\n",
    "\n",
    "modelBertBiLSTM3Models6.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "modelBertBiLSTM3Models6.summary()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Con Embeddings entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[328, 1, 2, 3, 330, 135, 19, 7, 10703, 10704, 51, 3, 10705, 5, 10706, 1187],\n",
       " [8, 3290, 13, 81, 349, 439],\n",
       " [11, 1, 14, 11, 1, 14],\n",
       " [32, 472, 140, 4, 159, 557, 49, 81, 1324],\n",
       " [126, 670, 2, 409, 4, 327, 1796, 32, 670, 13, 4, 218, 9, 1324],\n",
       " [1, 62],\n",
       " [42, 6069, 2, 1436, 106, 536, 8, 32, 8, 90, 1619, 4, 352, 979, 19, 103],\n",
       " [89, 5, 30],\n",
       " [27, 90, 23, 123, 2688],\n",
       " [40,\n",
       "  78,\n",
       "  99,\n",
       "  526,\n",
       "  13,\n",
       "  4,\n",
       "  8446,\n",
       "  491,\n",
       "  17,\n",
       "  8,\n",
       "  19,\n",
       "  2466,\n",
       "  42,\n",
       "  1,\n",
       "  53,\n",
       "  1,\n",
       "  90,\n",
       "  85,\n",
       "  18,\n",
       "  69,\n",
       "  1410,\n",
       "  670,\n",
       "  1013,\n",
       "  10,\n",
       "  59,\n",
       "  100],\n",
       " [1006, 8, 90, 1687],\n",
       " [348],\n",
       " [40, 78, 59],\n",
       " [73, 280],\n",
       " [94, 1970],\n",
       " [94, 94, 94, 8, 365, 93, 146, 102, 11, 1205],\n",
       " [73, 2181, 438, 221, 16, 123, 69, 625, 873, 177],\n",
       " [90, 1, 22, 4, 1188],\n",
       " [94, 14, 8, 353, 4, 665],\n",
       " [2, 16, 3, 1971, 122],\n",
       " [31, 2, 18, 39, 12, 31, 444, 25, 3291],\n",
       " [10707, 7065, 32, 1265, 18, 341, 1380],\n",
       " [126, 11, 298, 886, 8, 8, 329, 1265, 202, 1024],\n",
       " [14],\n",
       " [395, 215, 25, 1079, 2, 19, 7, 725, 757, 32, 1],\n",
       " [36],\n",
       " [355],\n",
       " [355],\n",
       " [3472, 14, 16, 23],\n",
       " [1, 30],\n",
       " [73],\n",
       " [73],\n",
       " [7066, 90],\n",
       " [7066, 10708],\n",
       " [7066, 90, 215, 60, 4],\n",
       " [86, 428, 688],\n",
       " [3, 327, 105, 90, 27, 23],\n",
       " [94, 26, 49, 3, 626, 18, 3, 3714, 14, 14, 8, 45, 11, 428],\n",
       " [88, 17, 43, 1437],\n",
       " [262, 62, 8, 338],\n",
       " [84, 83, 1, 53, 27, 13, 5, 71, 360, 37, 811, 38, 39, 8447],\n",
       " [197, 6, 16, 2, 7, 139, 532, 5, 13, 11, 550],\n",
       " [62,\n",
       "  82,\n",
       "  57,\n",
       "  24,\n",
       "  3473,\n",
       "  18,\n",
       "  11,\n",
       "  550,\n",
       "  99,\n",
       "  7,\n",
       "  1097,\n",
       "  2,\n",
       "  23,\n",
       "  5,\n",
       "  4011,\n",
       "  3,\n",
       "  1111,\n",
       "  160,\n",
       "  17,\n",
       "  40,\n",
       "  10709],\n",
       " [84, 88, 479, 758],\n",
       " [1, 14, 21, 30, 219, 15, 62, 3, 550],\n",
       " [40, 78],\n",
       " [10710, 8, 2, 38, 5],\n",
       " [36, 8, 30, 3, 2966, 6070, 10711, 305, 121, 184, 148],\n",
       " [36, 6, 10, 1047, 8, 2, 793, 384, 2, 7, 632, 19, 3, 225, 1654, 4012, 8448],\n",
       " [1, 30],\n",
       " [57, 96],\n",
       " [32, 2, 27, 114, 93, 22, 332, 132, 26],\n",
       " [275,\n",
       "  1006,\n",
       "  125,\n",
       "  10712,\n",
       "  898,\n",
       "  1139,\n",
       "  14,\n",
       "  8,\n",
       "  30,\n",
       "  125,\n",
       "  1545,\n",
       "  10713,\n",
       "  10,\n",
       "  3,\n",
       "  928,\n",
       "  85,\n",
       "  533,\n",
       "  10714],\n",
       " [153, 262, 62, 8, 99],\n",
       " [195,\n",
       "  361,\n",
       "  8,\n",
       "  14,\n",
       "  14,\n",
       "  4,\n",
       "  89,\n",
       "  1688,\n",
       "  1546,\n",
       "  57,\n",
       "  10715,\n",
       "  37,\n",
       "  62,\n",
       "  8,\n",
       "  10716,\n",
       "  284,\n",
       "  607,\n",
       "  114,\n",
       "  93,\n",
       "  346,\n",
       "  94,\n",
       "  79,\n",
       "  24,\n",
       "  1688],\n",
       " [57,\n",
       "  1080,\n",
       "  11,\n",
       "  12,\n",
       "  1688,\n",
       "  14,\n",
       "  21,\n",
       "  289,\n",
       "  38,\n",
       "  37,\n",
       "  246,\n",
       "  4013,\n",
       "  4014,\n",
       "  10,\n",
       "  3,\n",
       "  390,\n",
       "  1007,\n",
       "  9,\n",
       "  3,\n",
       "  10717,\n",
       "  1014,\n",
       "  20,\n",
       "  3,\n",
       "  336,\n",
       "  830],\n",
       " [29],\n",
       " [25, 2, 7, 578],\n",
       " [424, 670, 670, 279, 16, 19, 1918, 12, 27, 22, 96],\n",
       " [312, 8],\n",
       " [312, 8],\n",
       " [94],\n",
       " [341],\n",
       " [42, 275, 1, 14, 21, 53, 60, 261, 531],\n",
       " [125, 88, 44, 7067, 3292, 2825, 10718, 51, 5346],\n",
       " [32, 148, 186],\n",
       " [59, 59, 5, 2364, 38, 247, 13, 551, 8, 83, 241],\n",
       " [84],\n",
       " [42, 88, 24, 479, 32, 32, 1797, 4, 1469, 5, 7, 980],\n",
       " [77],\n",
       " [8, 14, 21, 53, 25, 2, 184, 801],\n",
       " [211, 90, 1, 140, 5, 8, 17, 4, 464],\n",
       " [197, 322, 32, 315, 23, 19],\n",
       " [94, 8, 348],\n",
       " [66, 2, 8449, 66, 2, 171, 404, 11, 1, 53, 16, 2, 55, 5, 271, 16, 18, 233],\n",
       " [1, 185, 5, 346, 11, 1, 2, 13, 282, 17, 162, 269],\n",
       " [348, 1620, 179, 80, 9, 3, 4803, 8, 30, 26, 164, 5, 3, 10719, 4359],\n",
       " [36, 1860, 3715, 247, 325, 9, 10, 3, 589, 9, 4, 770, 100],\n",
       " [73, 90, 8, 122, 35, 356, 56, 10, 3, 2967, 338],\n",
       " [1, 91, 247, 3293, 78],\n",
       " [36, 73, 1688, 85, 66, 468, 2, 5347, 1300],\n",
       " [73, 656, 11, 132, 31, 13, 4, 77, 243, 627],\n",
       " [82, 8, 85, 243, 10720, 2826, 8450, 38, 54, 37, 333, 3, 1381],\n",
       " [698, 26, 2, 8, 14],\n",
       " [60, 4, 8451, 4360],\n",
       " [94,\n",
       "  8,\n",
       "  365,\n",
       "  93,\n",
       "  22,\n",
       "  102,\n",
       "  5,\n",
       "  277,\n",
       "  132,\n",
       "  125,\n",
       "  14,\n",
       "  8,\n",
       "  365,\n",
       "  93,\n",
       "  62,\n",
       "  87,\n",
       "  182,\n",
       "  27,\n",
       "  90,\n",
       "  356,\n",
       "  25,\n",
       "  887,\n",
       "  96,\n",
       "  6,\n",
       "  1081,\n",
       "  253],\n",
       " [1734, 3, 887, 105],\n",
       " [73],\n",
       " [1734],\n",
       " [26],\n",
       " [94],\n",
       " [94],\n",
       " [87, 14, 16, 23, 18, 10721],\n",
       " [215],\n",
       " [11, 2, 32, 2268, 27, 2, 77, 1206],\n",
       " [14, 21, 8, 267, 332],\n",
       " [73, 11, 77, 1227, 15, 150],\n",
       " [84],\n",
       " [1, 90, 24, 267, 10, 4, 771, 177],\n",
       " [60, 84, 215, 8, 35, 4804, 127, 188],\n",
       " [156],\n",
       " [36, 6, 4805],\n",
       " [32, 438, 2097, 45, 13, 5, 10722, 316, 170, 11, 438, 13, 4, 89, 55],\n",
       " [59, 82, 8, 61, 8, 90, 248, 18, 360, 6, 15, 831],\n",
       " [60, 35, 39, 545, 4806, 1227, 150, 246, 8],\n",
       " [2968, 2968, 2968],\n",
       " [1, 91, 2, 16, 8452],\n",
       " [86, 28, 2, 8452],\n",
       " [251, 243, 1547, 18, 3, 2827, 6071],\n",
       " [29, 29, 29, 88, 7068],\n",
       " [1, 14, 21, 30, 8, 53, 62, 8, 10723, 671],\n",
       " [83,\n",
       "  758,\n",
       "  460,\n",
       "  2,\n",
       "  10,\n",
       "  1251,\n",
       "  84,\n",
       "  1,\n",
       "  45,\n",
       "  13,\n",
       "  4,\n",
       "  34,\n",
       "  11,\n",
       "  1,\n",
       "  90,\n",
       "  888,\n",
       "  25,\n",
       "  484,\n",
       "  18],\n",
       " [8, 122, 54, 189, 61, 5, 23, 5, 4, 411, 18, 15],\n",
       " [73, 94, 1, 1, 13, 832, 1, 195, 353, 103, 33],\n",
       " [1, 91, 17, 17, 40, 8, 30, 1, 63, 2, 4, 1251, 10724],\n",
       " [73],\n",
       " [2182, 8, 365, 93, 759, 3, 10725, 188, 132, 132, 3, 10726],\n",
       " [939, 445, 42, 29, 8, 62, 1, 1, 53, 57, 742, 5, 579, 18, 129],\n",
       " [84],\n",
       " [73],\n",
       " [23, 22, 2183, 2689],\n",
       " [78, 94, 939, 8, 365, 93, 43, 6072, 13, 4, 252],\n",
       " [73, 8, 63, 579, 231, 89, 18, 39, 284, 3, 276, 1585, 50, 15],\n",
       " [29, 57, 89],\n",
       " [59, 1919, 1, 14, 21, 22, 272, 10727, 32],\n",
       " [74, 30],\n",
       " [84,\n",
       "  125,\n",
       "  27,\n",
       "  13,\n",
       "  1798,\n",
       "  16,\n",
       "  150,\n",
       "  5,\n",
       "  951,\n",
       "  1228,\n",
       "  8453,\n",
       "  6,\n",
       "  233,\n",
       "  3,\n",
       "  778,\n",
       "  9,\n",
       "  8,\n",
       "  312,\n",
       "  8,\n",
       "  41,\n",
       "  148],\n",
       " [306, 11, 165, 21, 164],\n",
       " [73, 67, 8, 40, 13, 362, 708, 83, 247, 201, 8, 18, 951, 6, 8453, 18, 1228],\n",
       " [32, 1735, 2, 656, 8, 166, 132, 8, 166],\n",
       " [73, 16, 2],\n",
       " [29, 27, 247, 114, 93, 2, 45, 299, 34, 88, 156, 60, 114, 93, 2, 842],\n",
       " [348,\n",
       "  57,\n",
       "  530,\n",
       "  11,\n",
       "  25,\n",
       "  2,\n",
       "  69,\n",
       "  325,\n",
       "  9,\n",
       "  486,\n",
       "  257,\n",
       "  67,\n",
       "  8,\n",
       "  2,\n",
       "  1972,\n",
       "  18,\n",
       "  874,\n",
       "  772,\n",
       "  10728],\n",
       " [1],\n",
       " [36, 88, 24, 26, 8, 61],\n",
       " [25, 2, 7, 145, 4015, 6073, 564, 25, 2, 211, 1620],\n",
       " [1, 843, 4016, 10729, 213, 5, 1438, 15, 50, 1098, 6073],\n",
       " [9, 373, 9, 373, 1098, 6073],\n",
       " [1],\n",
       " [84],\n",
       " [1, 90, 1, 90, 62, 11],\n",
       " [84],\n",
       " [26],\n",
       " [36, 59, 60, 24, 19, 566, 414],\n",
       " [59, 99, 60, 24, 19, 3, 1439, 414],\n",
       " [84, 424, 1, 246, 367, 8, 4, 2184, 253],\n",
       " [32,\n",
       "  293,\n",
       "  126,\n",
       "  14,\n",
       "  8,\n",
       "  13,\n",
       "  183,\n",
       "  9,\n",
       "  2098,\n",
       "  10730,\n",
       "  832,\n",
       "  100,\n",
       "  308,\n",
       "  35,\n",
       "  28,\n",
       "  11,\n",
       "  13,\n",
       "  21,\n",
       "  2,\n",
       "  651,\n",
       "  414],\n",
       " [36, 73, 57, 280, 6, 40, 9, 4, 929, 64, 349, 2, 21, 3, 371, 709],\n",
       " [36, 285, 7069, 63, 13, 615, 536, 66],\n",
       " [8454, 8455],\n",
       " [445, 698],\n",
       " [36, 73, 8, 13, 5, 71, 39],\n",
       " [8456, 912, 88, 169, 1, 23],\n",
       " [73, 59],\n",
       " [73, 73, 8, 13, 3, 550],\n",
       " [73, 78, 100, 10, 7, 1036, 475],\n",
       " [84,\n",
       "  126,\n",
       "  246,\n",
       "  8,\n",
       "  122,\n",
       "  22,\n",
       "  33,\n",
       "  9,\n",
       "  100,\n",
       "  1,\n",
       "  61,\n",
       "  25,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  1189,\n",
       "  6,\n",
       "  284,\n",
       "  114,\n",
       "  93,\n",
       "  30],\n",
       " [73, 73, 8, 122, 22, 33, 9, 100],\n",
       " [355, 122],\n",
       " [247, 35, 77, 41, 1861, 49, 25, 8457, 543, 11, 27, 13, 5, 23, 5],\n",
       " [84, 293, 211],\n",
       " [57, 57, 77, 1920, 32, 57, 23, 5, 2, 65, 127, 7, 2828],\n",
       " [126, 57, 35, 219, 8, 30, 11, 25, 2],\n",
       " [57, 151, 57, 14, 57, 14],\n",
       " [215, 179, 107, 2, 1655, 17, 8, 184],\n",
       " [29, 24, 77, 1, 91, 417, 62, 15, 689, 720, 9, 55],\n",
       " [125, 253, 42, 16, 2, 4, 117, 17, 3, 778, 9, 7, 1079],\n",
       " [84, 40, 78, 88, 760, 42, 215, 1, 35, 14, 21, 1655, 11, 1229],\n",
       " [29, 1, 14, 21, 211, 1, 53, 57, 35, 4, 186, 2576, 135, 209, 8, 2],\n",
       " [2, 11, 32],\n",
       " [73],\n",
       " [94, 555, 8, 122, 206, 2, 38, 66, 18, 15],\n",
       " [1, 91, 8, 166, 2, 2, 7, 1, 91, 57, 2365, 5, 13, 35, 28, 89],\n",
       " [445, 110],\n",
       " [1, 22, 488, 23, 504, 102, 144, 100],\n",
       " [84, 27, 13, 4, 218, 9, 2969, 100, 4, 72, 9, 10731, 17, 8, 5, 143, 19],\n",
       " [141, 16, 195],\n",
       " [59, 57, 114, 93, 23, 22, 287, 10, 69, 545],\n",
       " [29, 29, 1, 65, 103, 51, 3, 1266, 4807],\n",
       " [1, 13, 4, 465, 49, 25, 626],\n",
       " [197],\n",
       " [2829, 3, 6074, 117, 9, 40, 323, 89, 83],\n",
       " [73],\n",
       " [1, 53, 7, 10732, 114, 93, 192, 4, 159, 557, 186, 9, 404, 209, 11],\n",
       " [36, 94, 87, 49, 25, 28],\n",
       " [215, 74, 13, 4, 153, 1918, 1621],\n",
       " [8458, 6, 10733],\n",
       " [14, 8, 202, 365, 93, 141, 2183, 1, 365, 93, 141, 2183],\n",
       " [472, 141, 2183],\n",
       " [652, 3294, 295, 7070],\n",
       " [100, 8, 23],\n",
       " [39, 10734, 10735, 284, 4, 2577, 10736],\n",
       " [280, 32, 87, 182, 8, 2],\n",
       " [242,\n",
       "  12,\n",
       "  8,\n",
       "  2,\n",
       "  4,\n",
       "  159,\n",
       "  319,\n",
       "  1,\n",
       "  232,\n",
       "  5,\n",
       "  65,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  7071,\n",
       "  2099,\n",
       "  6,\n",
       "  289,\n",
       "  8,\n",
       "  3,\n",
       "  243,\n",
       "  3474],\n",
       " [29, 60, 136, 2, 817, 97],\n",
       " [1,\n",
       "  35,\n",
       "  61,\n",
       "  5,\n",
       "  201,\n",
       "  4,\n",
       "  378,\n",
       "  1799,\n",
       "  10,\n",
       "  81,\n",
       "  409,\n",
       "  32,\n",
       "  864,\n",
       "  30,\n",
       "  11,\n",
       "  1,\n",
       "  2,\n",
       "  21,\n",
       "  278,\n",
       "  362,\n",
       "  4,\n",
       "  672,\n",
       "  122],\n",
       " [673],\n",
       " [10737, 2, 10, 133],\n",
       " [1, 10738],\n",
       " [99, 5348, 21, 79, 1411, 81, 4808],\n",
       " [673,\n",
       "  81,\n",
       "  4361,\n",
       "  10,\n",
       "  133,\n",
       "  243,\n",
       "  55,\n",
       "  6,\n",
       "  3,\n",
       "  196,\n",
       "  428,\n",
       "  9,\n",
       "  16,\n",
       "  2,\n",
       "  60,\n",
       "  18,\n",
       "  166,\n",
       "  708,\n",
       "  230],\n",
       " [3475, 114, 93, 2, 40, 78, 84, 10739],\n",
       " [94, 698, 87, 2, 115],\n",
       " [36, 153, 628, 1, 14, 265, 150, 169, 66, 2, 21, 4, 1382],\n",
       " [47, 3, 121, 211, 561, 47, 4, 952, 9, 81, 484],\n",
       " [36, 59, 1, 415, 1, 13, 11, 28, 43],\n",
       " [57, 35, 114, 93, 356, 16, 33, 60, 607, 35, 4, 1862, 9, 7072, 6],\n",
       " [102, 391],\n",
       " [29, 341],\n",
       " [6, 99, 6, 99, 8, 85, 11, 105, 49, 49, 367, 3, 10740, 8459, 10, 3, 823, 3292],\n",
       " [73],\n",
       " [60, 24, 11, 196],\n",
       " [32, 79, 35, 1048],\n",
       " [40, 78, 562, 472, 353, 188, 353, 188],\n",
       " [84],\n",
       " [156],\n",
       " [8,\n",
       "  30,\n",
       "  1,\n",
       "  14,\n",
       "  21,\n",
       "  53,\n",
       "  27,\n",
       "  367,\n",
       "  479,\n",
       "  484,\n",
       "  14,\n",
       "  8,\n",
       "  450,\n",
       "  5,\n",
       "  1656,\n",
       "  3,\n",
       "  4017,\n",
       "  10741],\n",
       " [60, 114, 93, 2, 1800, 16],\n",
       " [60, 4, 8460, 471, 11, 230, 133, 324, 40, 78],\n",
       " [230, 133, 122, 74, 133, 324],\n",
       " [60, 11, 327, 2467, 105],\n",
       " [1548, 2028, 56, 20, 11, 1656, 10742, 144, 66],\n",
       " [308, 28, 9, 103, 246, 199, 149],\n",
       " [40, 78, 3105, 15, 3, 324],\n",
       " [29, 1, 22, 56],\n",
       " [652],\n",
       " [8, 365, 93, 461, 56],\n",
       " [59, 27, 2, 153, 122],\n",
       " [710],\n",
       " [59, 24, 77],\n",
       " [1, 91, 4018, 60, 60, 24, 441, 3, 1173, 132, 261, 42, 16, 2, 10743, 1352],\n",
       " [59, 211, 16, 329, 505, 1140],\n",
       " [1, 91, 315, 186, 516],\n",
       " [26, 106, 53, 132, 87, 8, 109, 253],\n",
       " [211, 8, 22, 488, 212, 81, 659],\n",
       " [94],\n",
       " [94,\n",
       "  94,\n",
       "  94,\n",
       "  32,\n",
       "  87,\n",
       "  14,\n",
       "  16,\n",
       "  23,\n",
       "  18,\n",
       "  6075,\n",
       "  183,\n",
       "  404,\n",
       "  1,\n",
       "  206,\n",
       "  119,\n",
       "  4,\n",
       "  1082,\n",
       "  9,\n",
       "  55,\n",
       "  390,\n",
       "  85,\n",
       "  6076],\n",
       " [94, 1687, 1, 35, 192, 186, 55, 247, 23, 5, 546, 831],\n",
       " [23, 33, 18, 74],\n",
       " [125, 6075, 7073, 51, 499],\n",
       " [29, 11, 2, 6075, 10744],\n",
       " [40, 78],\n",
       " [293, 40, 78, 7074, 875, 18, 15],\n",
       " [100, 8, 23],\n",
       " [84],\n",
       " [94, 87, 8, 2468],\n",
       " [94],\n",
       " [29, 94, 59, 1, 1, 699, 333, 8, 2, 8, 2, 2690],\n",
       " [1, 30],\n",
       " [26],\n",
       " [42, 1, 165, 21, 71, 8],\n",
       " [84, 42, 54, 21, 16, 2, 940, 82, 8, 13, 5, 71, 15, 102, 11, 8, 63, 71, 15],\n",
       " [59,\n",
       "  280,\n",
       "  10,\n",
       "  4,\n",
       "  1586,\n",
       "  160,\n",
       "  42,\n",
       "  29,\n",
       "  1,\n",
       "  442,\n",
       "  1,\n",
       "  54,\n",
       "  21,\n",
       "  71,\n",
       "  6,\n",
       "  1,\n",
       "  3106,\n",
       "  5,\n",
       "  45,\n",
       "  40,\n",
       "  7,\n",
       "  130],\n",
       " [84, 14, 16, 13, 5, 14, 18, 211, 6, 360],\n",
       " [29],\n",
       " [14, 16, 13, 5, 14, 18, 233],\n",
       " [29],\n",
       " [14, 16, 13, 5, 14, 18, 18, 358, 6, 11, 2100, 11, 31, 294, 47, 64, 412],\n",
       " [29, 42, 472, 43, 96, 5, 11, 338],\n",
       " [306, 57, 24, 100, 5, 8461, 3, 2029],\n",
       " [524, 36, 88, 84, 1, 457, 12, 106, 43, 96, 5, 8461, 3, 2029],\n",
       " [45, 1, 13, 341, 59, 5, 14],\n",
       " [32, 315, 38],\n",
       " [36, 89, 5, 62, 8, 184, 14, 8, 43, 150, 100, 5, 71, 15, 11],\n",
       " [6, 10745, 114, 93, 2, 100, 3, 327, 55],\n",
       " [1, 91, 79, 7, 2269, 122, 10, 3, 327, 160],\n",
       " [57, 24, 195, 473, 5, 71, 716, 6, 564],\n",
       " [84, 4809, 156, 14, 21, 27, 35, 43, 144, 100, 6, 219, 103, 13, 4, 159, 492],\n",
       " [558,\n",
       "  133,\n",
       "  5,\n",
       "  152,\n",
       "  8,\n",
       "  10,\n",
       "  42,\n",
       "  125,\n",
       "  7,\n",
       "  1801,\n",
       "  6077,\n",
       "  6,\n",
       "  1,\n",
       "  53,\n",
       "  284,\n",
       "  1190,\n",
       "  19,\n",
       "  3,\n",
       "  2469],\n",
       " [36, 94, 153, 79, 38, 360, 25, 2, 7, 216, 8462, 8462, 25, 2, 360],\n",
       " [45, 16, 54, 263],\n",
       " [125, 16, 2, 41, 378, 889, 8],\n",
       " [355, 716, 60, 2030],\n",
       " [73, 57, 424, 57, 35, 761, 20, 3, 1049, 10, 44, 5349, 4019],\n",
       " [2030, 85, 4019, 57, 23, 18, 4019],\n",
       " [57, 424, 29, 57, 24, 180, 1, 14, 21, 30, 69, 122],\n",
       " [2, 8, 62, 930, 78, 126],\n",
       " [919,\n",
       "  1412,\n",
       "  26,\n",
       "  2,\n",
       "  11,\n",
       "  45,\n",
       "  169,\n",
       "  8,\n",
       "  175,\n",
       "  249,\n",
       "  18,\n",
       "  10746,\n",
       "  2470,\n",
       "  106,\n",
       "  6,\n",
       "  71,\n",
       "  103,\n",
       "  26,\n",
       "  5,\n",
       "  466],\n",
       " [125, 253],\n",
       " [94],\n",
       " [82, 8, 13, 3, 243, 980, 8, 13, 5, 500, 18, 106, 43, 144, 40, 3, 55],\n",
       " [11, 4362, 13, 22, 5, 2, 1973, 84, 88, 81, 2691, 126],\n",
       " [26, 2, 8, 14],\n",
       " [1, 53, 1, 119, 4, 5350, 38, 100],\n",
       " [32, 10, 3107, 3, 386, 40, 23, 38, 32, 57, 266],\n",
       " [898, 20],\n",
       " [36, 721, 15, 1, 450, 7, 10747, 215, 47, 302],\n",
       " [59, 26, 49, 8],\n",
       " [79, 24, 109, 119, 33, 132, 261, 2, 645],\n",
       " [94, 1688],\n",
       " [82, 1, 62, 56, 262, 152],\n",
       " [36, 99, 8, 30, 316, 170],\n",
       " [247, 19, 4, 3295, 117, 363, 4363],\n",
       " [26, 14, 8, 53, 9, 1301, 56, 5, 104, 726],\n",
       " [42, 25, 2, 1863, 60, 401, 1921, 50, 379, 38, 100],\n",
       " [4, 8463, 2270, 506, 18, 4, 10748, 17, 39, 409],\n",
       " [32],\n",
       " [59, 99, 27, 202, 13, 4, 371],\n",
       " [73],\n",
       " [18, 26],\n",
       " [59,\n",
       "  247,\n",
       "  143,\n",
       "  5,\n",
       "  101,\n",
       "  162,\n",
       "  5,\n",
       "  653,\n",
       "  104,\n",
       "  578,\n",
       "  6,\n",
       "  438,\n",
       "  40,\n",
       "  656,\n",
       "  3296,\n",
       "  132,\n",
       "  1657,\n",
       "  132,\n",
       "  215,\n",
       "  165,\n",
       "  21,\n",
       "  235,\n",
       "  1153,\n",
       "  20,\n",
       "  3,\n",
       "  388],\n",
       " [387, 247, 22],\n",
       " [122, 312, 8, 41, 148, 42, 1141, 9, 8, 2, 297, 176],\n",
       " [27,\n",
       "  2,\n",
       "  23,\n",
       "  5,\n",
       "  13,\n",
       "  4,\n",
       "  8464,\n",
       "  722,\n",
       "  9,\n",
       "  3,\n",
       "  10749,\n",
       "  6,\n",
       "  12,\n",
       "  1,\n",
       "  85,\n",
       "  8464,\n",
       "  1,\n",
       "  91,\n",
       "  1325,\n",
       "  6,\n",
       "  10,\n",
       "  772,\n",
       "  9,\n",
       "  64,\n",
       "  3108],\n",
       " [1, 14],\n",
       " [11, 2, 331, 5, 2, 4, 89, 105, 1, 450, 156],\n",
       " [35,\n",
       "  240,\n",
       "  368,\n",
       "  1,\n",
       "  14,\n",
       "  8,\n",
       "  30,\n",
       "  84,\n",
       "  14,\n",
       "  8,\n",
       "  30,\n",
       "  1,\n",
       "  63,\n",
       "  21,\n",
       "  267,\n",
       "  17,\n",
       "  45,\n",
       "  4,\n",
       "  273,\n",
       "  67,\n",
       "  1,\n",
       "  22,\n",
       "  45,\n",
       "  4,\n",
       "  5351,\n",
       "  9,\n",
       "  7075,\n",
       "  19,\n",
       "  28,\n",
       "  9,\n",
       "  3,\n",
       "  2830,\n",
       "  7076],\n",
       " [59, 8, 8, 7077, 35, 221, 3, 7076, 144],\n",
       " [73, 1, 1622, 1623, 1, 13, 4, 243, 7078, 3716, 19, 3, 170, 527],\n",
       " [84,\n",
       "  25,\n",
       "  2,\n",
       "  26,\n",
       "  57,\n",
       "  140,\n",
       "  49,\n",
       "  25,\n",
       "  1,\n",
       "  1,\n",
       "  192,\n",
       "  5,\n",
       "  128,\n",
       "  10,\n",
       "  4,\n",
       "  1154,\n",
       "  169,\n",
       "  106,\n",
       "  90,\n",
       "  2185],\n",
       " [8, 90, 2185, 10, 3, 1922],\n",
       " [29, 79, 24, 79, 793, 86, 7076, 16, 2],\n",
       " [125, 253],\n",
       " [59, 57, 57, 35, 666, 1, 63, 215, 263, 8, 33],\n",
       " [2970, 1, 125, 1, 14, 21, 30, 59, 40, 78],\n",
       " [29],\n",
       " [29, 1, 633, 21],\n",
       " [42, 1, 206, 71, 8, 25, 25, 2971, 276, 105, 164, 5, 7, 665, 10750],\n",
       " [198, 3, 5352],\n",
       " [59, 57, 114, 93, 22, 171, 10751, 90, 1, 22, 8, 171, 8465],\n",
       " [29, 29, 57, 202, 115, 19, 147],\n",
       " [36, 73, 11, 2271, 83, 505, 5353],\n",
       " [505, 378],\n",
       " [670, 13, 5, 5354, 7, 665, 31, 61, 5, 297, 25],\n",
       " [27, 14, 21, 13, 1549, 42, 54, 8, 2, 2831, 5, 2972, 17, 16, 812, 22, 4, 2578],\n",
       " [215, 1, 1, 77, 14, 21, 53, 27, 192, 4, 2578],\n",
       " [40, 78, 35, 35, 65, 3, 4020, 1230, 6, 99, 12, 8, 22, 95, 356, 3, 2578, 149],\n",
       " [475],\n",
       " [73],\n",
       " [84, 99, 1, 415, 60, 35, 155, 100, 99, 355, 1, 192, 28, 3297, 690, 5, 2579],\n",
       " [36, 29, 29, 29, 29, 29, 29, 29, 1, 35, 1, 35, 192, 4, 1550, 690],\n",
       " [26, 54, 8, 108, 5, 4, 319, 82, 31, 61, 4, 690, 5, 257, 18],\n",
       " [2, 8, 509, 18, 4, 191],\n",
       " [29],\n",
       " [40,\n",
       "  78,\n",
       "  215,\n",
       "  26,\n",
       "  284,\n",
       "  114,\n",
       "  93,\n",
       "  53,\n",
       "  11,\n",
       "  57,\n",
       "  349,\n",
       "  8,\n",
       "  4,\n",
       "  3476,\n",
       "  732,\n",
       "  42,\n",
       "  26,\n",
       "  57,\n",
       "  77,\n",
       "  114,\n",
       "  93,\n",
       "  14,\n",
       "  2,\n",
       "  349,\n",
       "  8,\n",
       "  4,\n",
       "  1470,\n",
       "  732],\n",
       " [84, 42, 25, 2, 3, 179, 55],\n",
       " [94],\n",
       " [94],\n",
       " [1587, 37, 14],\n",
       " [59, 73, 14, 21, 14, 21, 8, 53, 60, 4, 37],\n",
       " [1, 14, 21, 30, 1, 165, 21, 71, 26, 416, 16, 2, 23, 96, 10, 184, 2471],\n",
       " [59, 802, 1, 22, 5, 23, 480, 57, 395, 889, 69, 9, 3, 2101, 17, 405],\n",
       " [26],\n",
       " [73, 42, 10752, 77, 2467],\n",
       " [59, 2467, 2, 516, 353, 56],\n",
       " [73],\n",
       " [355],\n",
       " [32, 125, 2181, 106, 2, 2580, 18, 3, 2186, 514],\n",
       " [73],\n",
       " [240, 49, 11, 3, 327, 125, 74, 43, 19, 5, 74, 105, 77, 14, 21, 435],\n",
       " [1, 91, 1, 53, 16, 1622, 164, 656, 121],\n",
       " [1, 91, 82, 8, 13, 21, 4021, 16, 1, 1, 1, 30, 1, 1622],\n",
       " [14, 27, 13, 4, 363, 414],\n",
       " [29, 24, 414],\n",
       " [88, 424, 17, 126, 526, 35, 141, 39, 324, 129, 1302],\n",
       " [36, 29, 324, 129, 1620, 1302],\n",
       " [156, 2, 211, 14, 11],\n",
       " [29, 88, 40, 78, 14, 21, 803, 49, 16],\n",
       " [73, 83],\n",
       " [1, 30],\n",
       " [40, 78, 14, 21, 1588, 16, 1, 91, 920, 202, 510],\n",
       " [94, 233, 2, 25, 3, 412, 169, 8466, 198, 39, 4022],\n",
       " [328, 32],\n",
       " [36, 10, 7, 409, 323, 14, 69, 505, 24, 1325, 484],\n",
       " [59, 20, 3, 844, 305, 56, 6, 4364, 14, 69, 1551, 1325, 484],\n",
       " [348, 417, 22, 5, 442, 11, 670, 189, 416, 71, 211, 11, 1, 71, 8],\n",
       " [49, 26],\n",
       " [323, 469, 81, 691, 305],\n",
       " [49, 26],\n",
       " [59, 31, 14, 21, 71, 15],\n",
       " [94, 14, 21, 83, 20, 15, 25, 2, 3717, 105],\n",
       " [29, 8, 2, 24, 27, 71, 8, 484],\n",
       " [358, 27, 202, 13, 21, 22, 44, 10753, 51, 81, 564],\n",
       " [36, 78, 293, 308, 88, 67, 1, 14, 21, 542, 56, 44, 2581],\n",
       " [60, 24, 45, 27, 200, 10, 3, 276, 3109],\n",
       " [750, 1, 53, 1, 365, 93, 2972, 3109],\n",
       " [32, 26, 50, 182, 50, 323, 24, 733, 4, 1025, 608, 6, 4, 7079, 1, 14, 21, 239],\n",
       " [84, 1, 53, 1, 192, 5, 14, 69, 1412],\n",
       " [652, 1015, 10, 66],\n",
       " [87, 645, 2468],\n",
       " [1, 415, 8, 54, 21, 268, 15, 82, 1, 85, 1, 2, 10754, 10755, 253],\n",
       " [84, 8, 122, 35, 1687, 1, 10756],\n",
       " [1, 22, 488, 23],\n",
       " [151, 57, 320, 42, 1, 119, 320],\n",
       " [84],\n",
       " [32, 475, 26, 2, 3, 446, 49],\n",
       " [1, 53, 8, 85, 8, 345, 16, 10, 344, 131],\n",
       " [59,\n",
       "  73,\n",
       "  42,\n",
       "  99,\n",
       "  1,\n",
       "  242,\n",
       "  1,\n",
       "  185,\n",
       "  16,\n",
       "  6,\n",
       "  66,\n",
       "  2,\n",
       "  25,\n",
       "  8467,\n",
       "  2272,\n",
       "  6,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  19,\n",
       "  818,\n",
       "  9,\n",
       "  3,\n",
       "  10757,\n",
       "  42,\n",
       "  802,\n",
       "  293,\n",
       "  26,\n",
       "  2,\n",
       "  25,\n",
       "  446,\n",
       "  49],\n",
       " [721, 15, 90, 1, 90, 1, 3110, 28, 9, 384],\n",
       " [215, 26, 306, 84, 84, 84, 315, 32, 671, 144, 100],\n",
       " [36, 1, 53, 8, 122, 2366, 10758, 1689, 215],\n",
       " [215, 26, 1, 91, 45, 10759],\n",
       " [42, 29, 1, 306, 981, 3, 1974, 28, 40, 40, 3, 55],\n",
       " [27, 22, 344],\n",
       " [36, 15, 184],\n",
       " [57, 319],\n",
       " [73],\n",
       " [355],\n",
       " [94, 3472, 16, 23],\n",
       " [8, 30, 26, 8, 2, 78, 1],\n",
       " [348],\n",
       " [84, 82, 8, 122, 13, 7080, 10, 66, 184, 1, 14, 21, 91],\n",
       " [60],\n",
       " [73, 698, 1, 53, 79, 1413, 11, 77, 59],\n",
       " [1413, 16],\n",
       " [126, 308, 1, 54, 13, 4, 371, 18, 25, 82, 16, 2, 21, 17, 15, 6, 2031],\n",
       " [6,\n",
       "  743,\n",
       "  406,\n",
       "  3,\n",
       "  121,\n",
       "  28,\n",
       "  9,\n",
       "  103,\n",
       "  2,\n",
       "  114,\n",
       "  93,\n",
       "  982,\n",
       "  26,\n",
       "  3718,\n",
       "  14,\n",
       "  6,\n",
       "  438,\n",
       "  141,\n",
       "  3,\n",
       "  327,\n",
       "  105,\n",
       "  127],\n",
       " [40, 78, 315, 7, 336, 407],\n",
       " [40,\n",
       "  78,\n",
       "  374,\n",
       "  4,\n",
       "  3719,\n",
       "  6078,\n",
       "  57,\n",
       "  3,\n",
       "  179,\n",
       "  110,\n",
       "  19,\n",
       "  1658,\n",
       "  54,\n",
       "  8,\n",
       "  23,\n",
       "  33,\n",
       "  18,\n",
       "  15],\n",
       " [10760],\n",
       " [298, 22, 10761, 89],\n",
       " [3298, 1690, 673],\n",
       " [7, 2273],\n",
       " [36, 1, 3290, 85, 11, 70, 8, 119],\n",
       " [11, 8, 964, 3, 7081, 405, 8468, 8469],\n",
       " [26, 82, 1, 2274, 4, 734, 17, 8],\n",
       " [262, 46, 8, 44, 1736, 10762, 10, 25, 2691],\n",
       " [558, 192, 44, 4023, 1552],\n",
       " [6, 44, 1736],\n",
       " [438, 609, 1303],\n",
       " [24, 10, 7, 409],\n",
       " [57, 238, 19, 6, 79, 238, 19, 18, 15],\n",
       " [43, 19, 108, 15, 28, 89, 404, 156, 8, 14, 21, 365, 93, 23],\n",
       " [293, 156, 14, 21, 8, 108],\n",
       " [379, 209, 16, 454, 2, 21, 16],\n",
       " [84,\n",
       "  79,\n",
       "  43,\n",
       "  18,\n",
       "  15,\n",
       "  6,\n",
       "  1,\n",
       "  328,\n",
       "  71,\n",
       "  103,\n",
       "  11,\n",
       "  82,\n",
       "  247,\n",
       "  202,\n",
       "  100,\n",
       "  12,\n",
       "  52,\n",
       "  22,\n",
       "  127,\n",
       "  11,\n",
       "  526,\n",
       "  23,\n",
       "  150,\n",
       "  5,\n",
       "  3,\n",
       "  2367,\n",
       "  6,\n",
       "  13,\n",
       "  69],\n",
       " [1864, 374, 278, 172, 17],\n",
       " [233, 87, 14, 8, 46],\n",
       " [36, 60, 940, 73, 1, 1, 90, 14, 16, 18, 261, 279, 125, 7082, 1865, 3720],\n",
       " [652, 25, 2, 368],\n",
       " [73],\n",
       " [36],\n",
       " [84, 197, 526, 2, 78, 526, 2, 78, 150],\n",
       " [312, 8],\n",
       " [84, 472, 367, 16, 10],\n",
       " [155, 29, 758, 758, 356, 16, 5, 15, 356, 16, 5, 15],\n",
       " [100, 8, 23],\n",
       " [59, 82, 3, 8470, 90, 390, 7, 1188, 18, 64, 42, 2187, 99, 40, 78],\n",
       " [215,\n",
       "  1,\n",
       "  2,\n",
       "  53,\n",
       "  82,\n",
       "  27,\n",
       "  13,\n",
       "  4,\n",
       "  4,\n",
       "  243,\n",
       "  449,\n",
       "  6,\n",
       "  125,\n",
       "  27,\n",
       "  199,\n",
       "  38,\n",
       "  17,\n",
       "  4,\n",
       "  258,\n",
       "  223],\n",
       " [4018, 27, 63, 13, 567, 188, 26, 14, 8, 53, 10763, 6, 10764],\n",
       " [84,\n",
       "  42,\n",
       "  155,\n",
       "  27,\n",
       "  165,\n",
       "  21,\n",
       "  7,\n",
       "  773,\n",
       "  7083,\n",
       "  2,\n",
       "  10,\n",
       "  3,\n",
       "  1975,\n",
       "  172,\n",
       "  247,\n",
       "  331,\n",
       "  5,\n",
       "  13,\n",
       "  1155],\n",
       " [59, 22, 1207, 9, 39, 10765, 6, 7084],\n",
       " [1, 53, 1, 537, 1624, 8, 602, 2, 358],\n",
       " [378, 5, 204, 8, 184],\n",
       " [32, 2, 8, 742, 5, 23],\n",
       " [73],\n",
       " [262, 2, 78, 18, 8],\n",
       " [965, 965, 88, 40, 16, 2, 4, 1099, 3477],\n",
       " [35, 81, 200, 9, 3, 4810, 1099, 3477],\n",
       " [8, 90, 65, 16, 127],\n",
       " [65, 81, 1737, 127, 6, 472, 62, 26, 247, 500, 18, 100, 26, 2, 8, 14],\n",
       " [35, 289, 8, 7, 200, 9, 3, 4810, 4365, 16, 78, 127, 1099, 3477],\n",
       " [59, 88, 24, 4, 1099, 3477],\n",
       " [117, 9, 40, 60, 19, 81, 50],\n",
       " [155, 4, 464, 256, 16, 8471, 246, 8, 43, 10, 100, 4, 492],\n",
       " [57, 18, 10766],\n",
       " [323, 89, 18, 1866, 105, 367, 56, 10, 184],\n",
       " [60,\n",
       "  51,\n",
       "  2582,\n",
       "  10,\n",
       "  2186,\n",
       "  8472,\n",
       "  2186,\n",
       "  215,\n",
       "  293,\n",
       "  4,\n",
       "  258,\n",
       "  97,\n",
       "  301,\n",
       "  1,\n",
       "  306,\n",
       "  2,\n",
       "  7085,\n",
       "  735,\n",
       "  8472,\n",
       "  2186],\n",
       " [1, 244, 17, 4, 97, 10, 4811],\n",
       " [802, 293, 32, 1, 2, 275, 1, 2, 2102],\n",
       " [275, 125, 247, 247, 35, 13, 25, 324, 332, 42, 125, 125, 88, 40],\n",
       " [125, 59, 293, 247, 35, 24, 10, 11, 177, 215, 42, 247, 41, 1861, 49, 25],\n",
       " [36, 59, 99, 621, 15, 38],\n",
       " [35, 71, 15, 87],\n",
       " [219, 16, 23, 211],\n",
       " [73, 59, 8, 14, 21, 30, 4024, 4024],\n",
       " [14, 8, 40, 442],\n",
       " [358, 14, 8, 442, 5, 2, 89],\n",
       " [94, 475],\n",
       " [695, 4366, 2973],\n",
       " [312, 8, 17, 141, 1125, 5, 104, 1802],\n",
       " [27, 13, 3476, 81, 1552, 18, 533, 720, 676],\n",
       " [247, 151, 17, 3, 4025, 6, 540, 670, 366, 25],\n",
       " [36, 7, 130, 758, 27, 2, 32, 2366, 5, 2, 332, 27, 555, 13, 4367, 9, 3],\n",
       " [758, 555, 1440],\n",
       " [73, 3, 115, 371],\n",
       " [26, 371, 14, 8, 71, 56, 8, 13],\n",
       " [36, 88, 24, 516, 3, 330, 2, 1, 77, 1, 53, 3475, 114, 93, 2, 84],\n",
       " [84, 298, 22, 69, 28, 8, 365, 93, 201, 103, 10, 39, 4368],\n",
       " [12, 8, 22, 4, 3721, 171, 2275, 9, 10767],\n",
       " [242, 4, 6079, 17, 15, 322],\n",
       " [36, 6, 14, 21, 219, 15, 119, 222, 22, 3, 363, 9, 11, 4369, 122],\n",
       " [939, 43, 19, 215, 26, 215, 26, 1, 53, 57, 35, 114, 93, 23, 95, 6, 141, 1326],\n",
       " [59, 82, 8, 53, 16, 246, 263],\n",
       " [40, 78, 1, 1551, 1208, 8473],\n",
       " [94],\n",
       " [125, 417, 13, 4, 218, 9, 567, 78],\n",
       " [14, 21, 803, 49, 11, 110, 11, 164],\n",
       " [73, 224],\n",
       " [1, 14, 16, 802],\n",
       " [8474, 8474, 1414],\n",
       " [32, 79, 257, 4, 159],\n",
       " [84, 83, 323, 24, 114, 93, 517, 103, 78],\n",
       " [1, 14, 21, 365, 93, 119, 56, 180],\n",
       " [674],\n",
       " [27, 27, 13, 104, 117, 449, 25, 418],\n",
       " [1, 53, 16, 13, 5, 14, 18, 7, 115, 320],\n",
       " [1, 85, 69, 105, 11, 1, 14, 21, 91, 6, 31, 31, 356, 69, 2832],\n",
       " [215, 82, 79, 114, 93, 115, 320, 1, 63, 83, 10, 19, 56, 17, 8],\n",
       " [84,\n",
       "  42,\n",
       "  82,\n",
       "  8,\n",
       "  14,\n",
       "  46,\n",
       "  280,\n",
       "  16,\n",
       "  329,\n",
       "  45,\n",
       "  79,\n",
       "  66,\n",
       "  5,\n",
       "  62,\n",
       "  56,\n",
       "  84,\n",
       "  6,\n",
       "  79,\n",
       "  24,\n",
       "  45,\n",
       "  14,\n",
       "  16,\n",
       "  50,\n",
       "  4,\n",
       "  2276,\n",
       "  5,\n",
       "  15],\n",
       " [84, 42, 82, 31, 152, 57, 24, 23, 5, 393],\n",
       " [504, 25, 33],\n",
       " [60, 401, 50, 89, 50, 2, 66],\n",
       " [125, 654, 1, 263, 8],\n",
       " [73, 1, 140, 5, 8, 19, 3, 334, 57, 3, 388, 11, 22, 761, 18, 3, 10768, 412],\n",
       " [83, 60, 45, 1, 71, 8, 374, 341, 1, 90, 14, 8, 781, 17, 16, 368, 10769, 1620],\n",
       " [40, 78, 10770, 110, 83, 27, 365, 93, 62, 3, 2188],\n",
       " [36, 1174, 2277, 57, 140, 5, 3, 2188],\n",
       " [32, 25, 602, 2, 625, 3111, 17, 645, 253],\n",
       " [1,\n",
       "  91,\n",
       "  81,\n",
       "  564,\n",
       "  71,\n",
       "  15,\n",
       "  11,\n",
       "  8,\n",
       "  22,\n",
       "  4,\n",
       "  667,\n",
       "  9,\n",
       "  80,\n",
       "  127,\n",
       "  131,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  395,\n",
       "  14,\n",
       "  21,\n",
       "  13,\n",
       "  5,\n",
       "  853,\n",
       "  384,\n",
       "  2472,\n",
       "  709],\n",
       " [73],\n",
       " [7,\n",
       "  564,\n",
       "  85,\n",
       "  82,\n",
       "  1,\n",
       "  451,\n",
       "  50,\n",
       "  148,\n",
       "  55,\n",
       "  263,\n",
       "  56,\n",
       "  651,\n",
       "  980,\n",
       "  50,\n",
       "  1,\n",
       "  14,\n",
       "  8475,\n",
       "  49,\n",
       "  33,\n",
       "  1471,\n",
       "  2692,\n",
       "  2,\n",
       "  452,\n",
       "  5,\n",
       "  1867,\n",
       "  4,\n",
       "  547,\n",
       "  5,\n",
       "  3,\n",
       "  10771,\n",
       "  10772],\n",
       " [1, 53, 8, 54, 13, 5, 651, 4, 327, 218, 9, 980, 5, 23, 40, 3, 121, 5, 2103],\n",
       " [36, 83, 35, 34, 1, 633, 21, 10773, 8, 1, 442],\n",
       " [29, 60, 24, 184, 762, 1, 13, 1155, 20, 4, 1863],\n",
       " [1, 7086, 3, 481, 9, 1016, 50, 4, 121, 5, 108, 233, 208],\n",
       " [688],\n",
       " [1, 14, 21, 30],\n",
       " [42, 1, 90, 62, 236, 81, 1327],\n",
       " [73, 73, 88, 39],\n",
       " [42, 215, 26],\n",
       " [156],\n",
       " [29, 29, 29, 37, 128, 19, 3],\n",
       " [29, 384, 117, 166, 638, 88, 3, 4807],\n",
       " [6, 215, 3, 170, 28, 144, 66, 88, 3, 6080],\n",
       " [417, 2, 1383, 391],\n",
       " [29, 2032, 50, 4, 865, 126, 2, 8, 18, 15],\n",
       " [40, 78, 1209, 79, 38, 117],\n",
       " [84],\n",
       " [84],\n",
       " [8,\n",
       "  13,\n",
       "  436,\n",
       "  6,\n",
       "  3,\n",
       "  4370,\n",
       "  2275,\n",
       "  431,\n",
       "  235,\n",
       "  16,\n",
       "  126,\n",
       "  26,\n",
       "  2,\n",
       "  1691,\n",
       "  3112,\n",
       "  12,\n",
       "  37,\n",
       "  2,\n",
       "  4,\n",
       "  794,\n",
       "  4371,\n",
       "  8476],\n",
       " [243, 1267, 8476],\n",
       " [1508, 360, 1252],\n",
       " [1509, 7087],\n",
       " [1508, 39, 3299, 2269, 493, 2],\n",
       " [795, 20, 10774],\n",
       " [59,\n",
       "  83,\n",
       "  156,\n",
       "  14,\n",
       "  21,\n",
       "  8,\n",
       "  35,\n",
       "  156,\n",
       "  14,\n",
       "  21,\n",
       "  8,\n",
       "  14,\n",
       "  81,\n",
       "  4372,\n",
       "  166,\n",
       "  3300,\n",
       "  1803,\n",
       "  105,\n",
       "  18,\n",
       "  176],\n",
       " [84],\n",
       " [59,\n",
       "  11,\n",
       "  206,\n",
       "  21,\n",
       "  2,\n",
       "  4,\n",
       "  371,\n",
       "  1,\n",
       "  91,\n",
       "  1,\n",
       "  115,\n",
       "  10,\n",
       "  1251,\n",
       "  6,\n",
       "  40,\n",
       "  1,\n",
       "  204,\n",
       "  2,\n",
       "  8477,\n",
       "  1112,\n",
       "  593],\n",
       " [3722, 90, 1, 22, 8, 102, 269],\n",
       " [73, 4, 4365, 9, 2368, 6, 6, 4, 506, 82, 79, 10775, 2183, 33],\n",
       " [13, 21, 8, 6, 1, 890, 11, 2833],\n",
       " [931, 43, 19, 8, 35, 85, 5, 39, 11, 8],\n",
       " [43, 19, 8, 53, 37, 206, 23, 33, 18, 15, 14, 21, 8],\n",
       " [59, 1, 91, 2, 8, 280, 8, 61, 5, 23, 33, 18, 39],\n",
       " [1, 91, 77, 53, 49, 16],\n",
       " [1174, 1174, 1, 246],\n",
       " [1, 6081, 2369],\n",
       " [74, 239, 622, 345, 384, 105],\n",
       " [1, 14, 21, 13, 4, 2033],\n",
       " [29, 29, 25, 2, 7, 4812, 9, 10776, 3301],\n",
       " [8],\n",
       " [156],\n",
       " [94, 82, 4026, 90, 13, 4, 744, 1472, 90, 13, 4, 4373],\n",
       " [524, 60, 55, 5, 23],\n",
       " [36, 29, 29, 29, 62, 11, 11, 10777, 4, 159, 801, 125, 27, 13, 464],\n",
       " [253, 26, 90, 27, 14, 10, 464],\n",
       " [1921],\n",
       " [59, 88, 10778],\n",
       " [94, 125, 8, 90, 932, 11],\n",
       " [1],\n",
       " [94, 1, 13, 40, 3, 1471, 1, 192, 35, 14, 26, 1, 14],\n",
       " [215, 26, 1, 2],\n",
       " [84],\n",
       " [62, 25, 2, 4],\n",
       " [40, 78, 1437, 55, 5, 700, 144],\n",
       " [2, 8, 536, 3, 1327],\n",
       " [197],\n",
       " [88, 78, 8, 35, 964],\n",
       " [84],\n",
       " [94, 71, 645, 26],\n",
       " [219, 15, 175, 8, 95],\n",
       " [29, 8],\n",
       " [29, 156],\n",
       " [1734,\n",
       "  59,\n",
       "  298,\n",
       "  22,\n",
       "  44,\n",
       "  1976,\n",
       "  150,\n",
       "  3,\n",
       "  295,\n",
       "  6,\n",
       "  1,\n",
       "  2185,\n",
       "  3302,\n",
       "  40,\n",
       "  144,\n",
       "  3,\n",
       "  377,\n",
       "  9,\n",
       "  7,\n",
       "  1737,\n",
       "  8,\n",
       "  22,\n",
       "  44,\n",
       "  2473,\n",
       "  28],\n",
       " [73, 280, 293, 100],\n",
       " [73, 1, 14, 21, 53, 32, 673],\n",
       " [40, 78, 1, 415, 25, 246, 2, 424],\n",
       " [94, 240, 293, 26, 26, 2, 8, 14, 831],\n",
       " [341, 156],\n",
       " [87, 54, 8, 109, 49, 65, 33, 7, 1736, 1977, 262, 369],\n",
       " [57, 24, 152, 8, 5, 23, 19, 4],\n",
       " [233, 35, 35, 31, 323, 225, 10, 495, 6, 1, 30, 31, 14, 21, 13, 183, 122, 34],\n",
       " [35, 65, 56, 5, 45, 4, 887, 481, 132, 102],\n",
       " [262, 77, 1625, 16],\n",
       " [73, 84],\n",
       " [371, 7088, 10, 3, 4813, 952, 14, 21, 480, 81, 3478, 480, 81, 3478, 4813],\n",
       " [73, 8, 84],\n",
       " [355,\n",
       "  59,\n",
       "  83,\n",
       "  1,\n",
       "  2,\n",
       "  35,\n",
       "  114,\n",
       "  93,\n",
       "  119,\n",
       "  4,\n",
       "  1253,\n",
       "  2,\n",
       "  21,\n",
       "  831,\n",
       "  81,\n",
       "  81,\n",
       "  243,\n",
       "  3113,\n",
       "  546],\n",
       " [8, 365, 93, 140, 1, 91, 1, 90, 43, 144],\n",
       " [40, 78, 40, 78, 57, 43, 144, 6, 57, 367, 1510, 510],\n",
       " [60, 17, 15],\n",
       " [36, 84, 710],\n",
       " [652],\n",
       " [3723, 1589],\n",
       " [197, 652],\n",
       " [57,\n",
       "  14,\n",
       "  1868,\n",
       "  17,\n",
       "  4,\n",
       "  446,\n",
       "  6,\n",
       "  1,\n",
       "  2,\n",
       "  793,\n",
       "  26,\n",
       "  162,\n",
       "  468,\n",
       "  14,\n",
       "  82,\n",
       "  52,\n",
       "  119,\n",
       "  4,\n",
       "  324,\n",
       "  19,\n",
       "  4,\n",
       "  763,\n",
       "  250],\n",
       " [355, 1797, 3, 500],\n",
       " [27, 198, 4, 10779, 19, 4, 250, 616],\n",
       " [60, 1025, 3114, 18, 4, 1413, 6, 16, 1013, 1142, 4, 10780],\n",
       " [36, 6, 66, 2, 4, 324, 10, 16],\n",
       " [31, 61, 5, 140, 5, 8, 188],\n",
       " [652],\n",
       " [57, 151, 57, 4, 159, 320],\n",
       " [219, 15, 185, 47, 125, 47, 1692, 203, 1, 2, 1860, 1620],\n",
       " [32, 5, 2364, 38, 57, 1860, 1620],\n",
       " [89, 568, 476],\n",
       " [7, 363, 2, 211, 1620],\n",
       " [57, 28, 9, 3, 106, 74, 994, 17, 3, 980],\n",
       " [6, 1, 1, 346, 11, 3, 1923, 2, 5355, 42, 57, 151],\n",
       " [110, 1, 532, 1, 2, 689],\n",
       " [11, 2, 87, 130, 610, 16],\n",
       " [1,\n",
       "  5356,\n",
       "  8,\n",
       "  122,\n",
       "  19,\n",
       "  3,\n",
       "  334,\n",
       "  3,\n",
       "  170,\n",
       "  80,\n",
       "  6,\n",
       "  8,\n",
       "  85,\n",
       "  262,\n",
       "  35,\n",
       "  71,\n",
       "  360,\n",
       "  11,\n",
       "  57,\n",
       "  14,\n",
       "  3479,\n",
       "  17,\n",
       "  4,\n",
       "  667,\n",
       "  9,\n",
       "  223],\n",
       " [6, 31, 85, 3479],\n",
       " [2],\n",
       " [59, 82, 8, 13, 294, 240, 8, 8, 54, 13, 146, 15, 141, 56, 1098, 243, 10781],\n",
       " [1098, 10782, 31, 71, 3, 413],\n",
       " [1, 77, 53, 8, 46, 4, 89, 330, 1, 91, 215, 485, 8, 22, 562, 127],\n",
       " [73, 315, 38, 18, 11, 129, 368],\n",
       " [84,\n",
       "  298,\n",
       "  22,\n",
       "  28,\n",
       "  17,\n",
       "  8,\n",
       "  82,\n",
       "  8,\n",
       "  13,\n",
       "  184,\n",
       "  86,\n",
       "  28,\n",
       "  54,\n",
       "  8,\n",
       "  462,\n",
       "  277,\n",
       "  4,\n",
       "  62,\n",
       "  522,\n",
       "  274,\n",
       "  132,\n",
       "  4,\n",
       "  140,\n",
       "  8478],\n",
       " [558,\n",
       "  13,\n",
       "  5,\n",
       "  85,\n",
       "  3,\n",
       "  140,\n",
       "  8478,\n",
       "  67,\n",
       "  20,\n",
       "  701,\n",
       "  1,\n",
       "  90,\n",
       "  1268,\n",
       "  5,\n",
       "  56,\n",
       "  11,\n",
       "  79,\n",
       "  46,\n",
       "  15,\n",
       "  277,\n",
       "  56],\n",
       " [84, 1, 146, 8, 1384, 6, 1140, 1688, 246, 248, 201],\n",
       " [1, 53, 60, 299, 476],\n",
       " [42, 27, 77, 14, 192, 5, 101, 162, 38, 100],\n",
       " [3, 115, 2, 185, 5, 2189, 38],\n",
       " [298, 22, 4, 2278, 9, 3303, 19, 7, 1924, 25, 344],\n",
       " [215,\n",
       "  26,\n",
       "  8,\n",
       "  206,\n",
       "  14,\n",
       "  35,\n",
       "  2104,\n",
       "  2183,\n",
       "  10,\n",
       "  3,\n",
       "  10783,\n",
       "  6,\n",
       "  1252,\n",
       "  8,\n",
       "  189,\n",
       "  22,\n",
       "  2183],\n",
       " [88, 4, 89, 28],\n",
       " [26, 14, 4, 122, 13, 5],\n",
       " [73, 73, 3480, 100, 94, 692, 85, 355, 5, 4814, 10, 225, 7089],\n",
       " [2, 21, 66, 4, 2105, 711, 3724],\n",
       " [197, 197, 66, 2, 52, 257, 19, 2834, 6, 2466, 107],\n",
       " [12, 438, 3725, 479, 1978, 43, 10],\n",
       " [94, 233, 8, 61, 5, 140, 5, 15],\n",
       " [1, 14, 21, 30, 8, 125, 8, 22, 102, 17, 15],\n",
       " [36, 73, 25, 2, 51, 360],\n",
       " [804, 84, 126, 1977, 374, 362, 4, 105, 50, 184, 272, 230],\n",
       " [88],\n",
       " [26, 2, 18, 3, 1553],\n",
       " [73, 4374, 4375, 341, 11, 8479],\n",
       " [215, 52, 85, 4, 10784, 1659, 189, 8480],\n",
       " [387, 156, 14, 21, 8, 35, 141, 39, 8, 1304, 61, 5],\n",
       " [59, 14, 21, 6082, 365, 93],\n",
       " [73],\n",
       " [84, 59, 1, 14, 30, 8],\n",
       " [88, 26, 1, 85],\n",
       " [59, 32],\n",
       " [348, 710, 59, 1691, 24, 43, 60, 35, 114, 93, 2, 15, 6, 360],\n",
       " [36, 59, 256, 19, 10785, 2, 8, 280, 417, 53, 25, 105, 236],\n",
       " [60, 3479, 3, 1210, 236, 2, 10786],\n",
       " [29],\n",
       " [36, 6, 125, 3, 8481, 10787],\n",
       " [88, 3, 1173],\n",
       " [348, 348, 87, 49, 82, 27, 2190, 16],\n",
       " [26, 14, 8, 91, 45, 466, 16, 332],\n",
       " [73],\n",
       " [8, 53, 247, 742, 17, 102, 45, 11],\n",
       " [156, 24],\n",
       " [59, 60, 4, 505, 243, 3304, 1, 91, 26, 82, 28, 9, 176, 61, 5, 238, 33],\n",
       " [57, 24, 238, 33],\n",
       " [73, 73, 60, 35, 11, 18, 7, 179, 665, 2034],\n",
       " [36, 29, 248, 100, 526, 294, 14, 25, 262, 369, 8],\n",
       " [29, 1, 22, 10, 933, 17, 11, 124, 262, 62, 8, 338],\n",
       " [1590, 450, 16, 60, 51],\n",
       " [84, 83, 87, 2, 25, 114, 93, 1804, 8],\n",
       " [60],\n",
       " [79, 78],\n",
       " [215, 26],\n",
       " [57, 152, 8, 5, 14, 15, 4, 2279],\n",
       " [6, 50, 7, 744, 1, 53, 8, 206, 1328, 15, 25, 2279],\n",
       " [7, 2474, 23, 236, 11, 78, 126, 323, 362, 4, 811, 87, 14, 8, 22, 236, 16],\n",
       " [59, 8, 468, 143, 2106, 199, 102, 7090, 9, 2191, 85, 39],\n",
       " [632],\n",
       " [88, 28, 121, 15, 1, 1, 23, 17, 3, 279],\n",
       " [29, 231, 758, 77, 60, 424, 35, 876, 23, 18, 1979],\n",
       " [84, 84, 710],\n",
       " [32, 26, 2, 52, 14],\n",
       " [94, 79, 523],\n",
       " [57, 35, 65, 16, 5, 2, 3481, 1415],\n",
       " [29, 29, 1098, 5357, 29, 28, 2, 46, 183, 717, 38, 100],\n",
       " [355, 698],\n",
       " [211],\n",
       " [73],\n",
       " [57, 89, 1623, 293, 8, 202, 2107, 15, 4, 579],\n",
       " [1, 53, 1, 468, 192, 28, 186, 1016, 9, 873],\n",
       " [280, 125, 219, 15, 22, 16, 17, 645],\n",
       " [84],\n",
       " [1, 268, 25, 1473, 5, 3, 145, 9, 81, 324],\n",
       " [125,\n",
       "  253,\n",
       "  126,\n",
       "  8,\n",
       "  90,\n",
       "  221,\n",
       "  249,\n",
       "  132,\n",
       "  8,\n",
       "  90,\n",
       "  23,\n",
       "  10,\n",
       "  66,\n",
       "  6,\n",
       "  2583,\n",
       "  3,\n",
       "  1175,\n",
       "  1083,\n",
       "  127,\n",
       "  26,\n",
       "  5,\n",
       "  8,\n",
       "  61,\n",
       "  5,\n",
       "  14],\n",
       " [84, 151, 73],\n",
       " [94, 698],\n",
       " [16, 90, 611, 2, 15, 1, 541, 380, 78, 100],\n",
       " [365, 93, 4815],\n",
       " [652, 476, 8, 30, 368],\n",
       " [14, 21, 1738, 16],\n",
       " [355],\n",
       " [652],\n",
       " [355, 211],\n",
       " [73, 253],\n",
       " [1, 90, 22, 4, 1548, 1050, 5, 277, 42, 99, 1, 13, 5, 43, 96, 38, 100],\n",
       " [2475, 31, 467, 119, 17, 4, 89, 317],\n",
       " [84, 99],\n",
       " [84],\n",
       " [32, 62, 645, 19, 1739],\n",
       " [73, 8, 1231],\n",
       " [10788],\n",
       " [240, 90, 8, 14, 15, 4, 2279],\n",
       " [57, 114, 93, 2, 33, 616],\n",
       " [90, 8, 35, 294, 44, 522, 19, 233, 46, 280, 341, 164, 507, 56, 6, 10789],\n",
       " [1, 53, 3, 504, 10, 2, 11, 121],\n",
       " [939],\n",
       " [368, 432, 16, 358, 2, 441, 953, 6, 6, 278, 246, 2],\n",
       " [88, 78],\n",
       " [358],\n",
       " [8, 22],\n",
       " [1, 30],\n",
       " [1, 14],\n",
       " [1305],\n",
       " [308],\n",
       " [59, 1, 35, 53, 3482, 46, 15, 109, 89, 5, 14, 102, 378, 17, 7, 34],\n",
       " [36, 29, 29, 29],\n",
       " [59, 215, 57, 1, 91, 74, 192, 4, 8482, 1552],\n",
       " [8, 91, 18, 4027],\n",
       " [29, 29, 29, 1, 53, 57, 114, 93, 62, 87, 105, 23, 18, 1326, 284, 505, 1037],\n",
       " [132, 4027],\n",
       " [29, 29, 1326],\n",
       " [63, 2, 4027],\n",
       " [29, 29, 1326],\n",
       " [660, 4027],\n",
       " [94,\n",
       "  930,\n",
       "  22,\n",
       "  4,\n",
       "  6083,\n",
       "  9,\n",
       "  2108,\n",
       "  49,\n",
       "  817,\n",
       "  712,\n",
       "  182,\n",
       "  18,\n",
       "  4,\n",
       "  159,\n",
       "  10790,\n",
       "  20,\n",
       "  3,\n",
       "  271],\n",
       " [758, 315, 3, 435],\n",
       " [1, 35, 112, 966],\n",
       " [1, 45, 39],\n",
       " [156, 67, 37, 90, 1156, 6, 257, 4816, 6, 14, 555, 20, 3, 276, 55],\n",
       " [59, 88, 505, 148, 40, 57, 83, 17, 51, 287, 106],\n",
       " [73, 475, 43, 19, 8, 166, 13, 699, 708, 1329, 215, 284, 186, 215, 6, 79, 186],\n",
       " [84, 7, 336, 10791, 141, 387, 2973, 26, 90, 1, 85],\n",
       " [1, 77, 133, 12, 27, 2, 1156, 1269, 6, 1, 206, 21, 13, 119, 8, 11, 121],\n",
       " [36, 29, 28, 9, 384, 83, 17, 3, 4028, 10792],\n",
       " [197, 652],\n",
       " [1, 13, 4, 465],\n",
       " [293, 1, 232, 81, 2693, 5, 845, 19, 7, 796, 432],\n",
       " [4, 6084, 6, 4, 8483],\n",
       " [312, 8],\n",
       " [29],\n",
       " [293, 31, 85, 31, 53, 1, 2, 671],\n",
       " [32,\n",
       "  84,\n",
       "  83,\n",
       "  83,\n",
       "  293,\n",
       "  472,\n",
       "  35,\n",
       "  23,\n",
       "  1416,\n",
       "  526,\n",
       "  13,\n",
       "  69,\n",
       "  551,\n",
       "  6,\n",
       "  8,\n",
       "  246,\n",
       "  450,\n",
       "  40,\n",
       "  49,\n",
       "  16],\n",
       " [36, 43, 19, 698, 60, 60, 24, 11, 196],\n",
       " [83,\n",
       "  35,\n",
       "  67,\n",
       "  69,\n",
       "  2584,\n",
       "  845,\n",
       "  19,\n",
       "  81,\n",
       "  432,\n",
       "  14,\n",
       "  21,\n",
       "  91,\n",
       "  8,\n",
       "  206,\n",
       "  21,\n",
       "  13,\n",
       "  183,\n",
       "  551],\n",
       " [6, 1385, 94, 94, 94, 29, 28, 2, 195, 114, 93],\n",
       " [84, 66, 2],\n",
       " [29, 60, 84, 69, 69, 319, 152, 15, 5, 353, 16, 38, 17, 56, 42, 1, 14, 21],\n",
       " [8, 85, 8, 365, 93, 43, 10, 17, 69, 3305],\n",
       " [36, 78, 78],\n",
       " [59, 24, 35, 3305, 8484, 1693, 580, 2835],\n",
       " [59, 151, 1, 35, 1, 53, 8, 45, 15],\n",
       " [60,\n",
       "  84,\n",
       "  1,\n",
       "  331,\n",
       "  16,\n",
       "  63,\n",
       "  164,\n",
       "  5,\n",
       "  683,\n",
       "  24,\n",
       "  683,\n",
       "  1,\n",
       "  30,\n",
       "  42,\n",
       "  47,\n",
       "  3,\n",
       "  121,\n",
       "  1,\n",
       "  90,\n",
       "  202,\n",
       "  62,\n",
       "  16],\n",
       " [348,\n",
       "  1,\n",
       "  13,\n",
       "  4,\n",
       "  465,\n",
       "  59,\n",
       "  306,\n",
       "  60,\n",
       "  24,\n",
       "  32,\n",
       "  148,\n",
       "  4,\n",
       "  465,\n",
       "  50,\n",
       "  186,\n",
       "  9,\n",
       "  4,\n",
       "  1869,\n",
       "  5358,\n",
       "  10793],\n",
       " [348],\n",
       " [348, 100, 23, 17, 4, 174, 126, 298, 2, 61, 5, 275],\n",
       " [197, 197, 88, 78],\n",
       " [59, 1, 2, 607, 23, 5, 14, 16, 20, 69, 330],\n",
       " [1, 14, 21, 91],\n",
       " [59, 27, 607, 633, 21, 657, 8, 5, 3, 578],\n",
       " [312, 8, 358],\n",
       " [8485],\n",
       " [1270, 57, 1550, 5],\n",
       " [40, 78, 40, 78],\n",
       " [306, 1, 14, 13, 28, 447, 2280],\n",
       " [36, 322, 1, 1, 1271, 2035],\n",
       " [27, 14],\n",
       " [358,\n",
       "  100,\n",
       "  8,\n",
       "  23,\n",
       "  22,\n",
       "  81,\n",
       "  1980,\n",
       "  1554,\n",
       "  6085,\n",
       "  8,\n",
       "  22,\n",
       "  81,\n",
       "  4808,\n",
       "  1386,\n",
       "  81,\n",
       "  10794,\n",
       "  3115,\n",
       "  10795,\n",
       "  6,\n",
       "  81,\n",
       "  229,\n",
       "  1585,\n",
       "  534,\n",
       "  9,\n",
       "  10796],\n",
       " [40, 78, 57, 1441, 97, 190],\n",
       " [27, 35, 552, 25, 10797, 1554, 546],\n",
       " [11, 159, 689, 122, 54, 2, 15],\n",
       " [36, 88, 10798, 78, 66, 10, 3, 589, 10799, 6, 3, 1805, 20, 8486, 10800],\n",
       " [472, 62, 73],\n",
       " [83, 45, 4, 551, 1805],\n",
       " [360,\n",
       "  13,\n",
       "  102,\n",
       "  11,\n",
       "  37,\n",
       "  61,\n",
       "  5,\n",
       "  71,\n",
       "  8,\n",
       "  6,\n",
       "  293,\n",
       "  1,\n",
       "  268,\n",
       "  11,\n",
       "  25,\n",
       "  2,\n",
       "  81,\n",
       "  779,\n",
       "  2828],\n",
       " [29, 25, 2, 7, 779, 2828],\n",
       " [84],\n",
       " [10, 3, 3483, 9, 2269, 787, 609, 1254, 3, 7091, 2, 1068, 8487, 51],\n",
       " [73],\n",
       " [79, 44, 10801, 253],\n",
       " [1, 1231, 79, 4, 10802],\n",
       " [4817],\n",
       " [8488],\n",
       " [4817],\n",
       " [10803],\n",
       " [4817],\n",
       " [10804],\n",
       " [1864],\n",
       " [79, 24, 114, 93, 1353, 709, 78],\n",
       " [1, 633, 21, 1353],\n",
       " [6, 8, 442, 670, 22, 25, 65, 239, 9, 78, 149],\n",
       " [1, 442],\n",
       " [6, 10, 3, 6086, 8, 89, 219, 56, 264, 14, 31, 13, 4, 1417],\n",
       " [73],\n",
       " [90, 31, 1413, 3, 761],\n",
       " [36, 59],\n",
       " [36, 25, 206, 2, 940, 1, 13, 4, 41, 3306, 10805, 8, 242, 358],\n",
       " [60, 8, 25, 2, 1440],\n",
       " [215, 215, 57, 10806, 1, 14, 21, 53, 8489, 95, 100],\n",
       " [1, 85, 27, 35, 199, 3, 638, 1255, 236, 6, 6, 215, 1268, 338],\n",
       " [1, 14, 21, 53, 32, 652, 12, 8, 22, 10, 66],\n",
       " [94, 315, 38],\n",
       " [32, 26, 32, 26, 8, 112, 56, 18, 4, 129],\n",
       " [126,\n",
       "  83,\n",
       "  79,\n",
       "  23,\n",
       "  5,\n",
       "  23,\n",
       "  33,\n",
       "  19,\n",
       "  4,\n",
       "  506,\n",
       "  18,\n",
       "  5359,\n",
       "  6,\n",
       "  79,\n",
       "  23,\n",
       "  5,\n",
       "  2,\n",
       "  32,\n",
       "  2694,\n",
       "  323,\n",
       "  114,\n",
       "  93,\n",
       "  450,\n",
       "  40,\n",
       "  49,\n",
       "  11,\n",
       "  573,\n",
       "  3116,\n",
       "  129],\n",
       " [37, 2, 625, 573],\n",
       " [79, 78],\n",
       " [40, 78, 57, 35, 114, 93, 23, 19, 3, 506],\n",
       " [57, 114, 93, 23, 19, 3, 506],\n",
       " [11, 2, 3, 225, 469],\n",
       " [355],\n",
       " [94],\n",
       " [355],\n",
       " [14, 1, 312, 8, 32, 14, 8],\n",
       " [445],\n",
       " [10807],\n",
       " [1098, 1126, 10808, 122],\n",
       " [1, 1, 242, 12, 8, 2, 35, 45, 2188, 1694, 10, 1098, 5360, 1176, 2, 378],\n",
       " [73, 59, 645, 30, 57, 325, 9, 4029, 11, 121, 10809],\n",
       " [1, 394, 8, 57, 114, 93, 22, 480],\n",
       " [348],\n",
       " [275, 126, 6087],\n",
       " [36, 78, 348, 7092],\n",
       " [26],\n",
       " [240, 1, 450, 81, 1438, 90, 8, 108, 15, 4, 141],\n",
       " [445, 710],\n",
       " [36,\n",
       "  558,\n",
       "  133,\n",
       "  5,\n",
       "  42,\n",
       "  1,\n",
       "  22,\n",
       "  488,\n",
       "  22,\n",
       "  38,\n",
       "  32,\n",
       "  523,\n",
       "  3,\n",
       "  336,\n",
       "  80,\n",
       "  6,\n",
       "  32,\n",
       "  8,\n",
       "  30,\n",
       "  15,\n",
       "  115,\n",
       "  43,\n",
       "  117],\n",
       " [36, 73, 73, 73],\n",
       " [625, 13, 4, 4, 105, 17, 3, 80, 9, 104, 7093, 106],\n",
       " [1, 14, 16, 359, 97],\n",
       " [73],\n",
       " [73],\n",
       " [36, 88, 3717],\n",
       " [242, 26],\n",
       " [43,\n",
       "  19,\n",
       "  211,\n",
       "  242,\n",
       "  96,\n",
       "  10,\n",
       "  499,\n",
       "  12,\n",
       "  31,\n",
       "  489,\n",
       "  10,\n",
       "  133,\n",
       "  18,\n",
       "  2036,\n",
       "  6,\n",
       "  466,\n",
       "  39,\n",
       "  11,\n",
       "  10810,\n",
       "  1740,\n",
       "  10811,\n",
       "  2974],\n",
       " [155, 35, 4, 436],\n",
       " [1, 90, 289, 8, 44, 3117, 82, 8, 61],\n",
       " [36, 73, 59, 1, 35, 185, 733, 4373, 188],\n",
       " [36, 11, 602, 2, 16],\n",
       " [59, 1, 540, 8, 13, 551, 831],\n",
       " [1, 268, 16],\n",
       " [197, 1, 14],\n",
       " [10812, 1017],\n",
       " [308, 27, 206, 504, 3, 2281, 3307],\n",
       " [211, 63, 21, 1013, 150, 3, 2281, 3307],\n",
       " [88, 78, 31, 401, 63, 86, 2, 688, 87, 1, 22, 3308, 66],\n",
       " [94],\n",
       " [35, 215, 33],\n",
       " [26, 2, 8, 14],\n",
       " [1, 125, 23, 5, 4, 1051, 6, 99, 1, 35, 125, 35, 175, 249, 17, 4, 174],\n",
       " [211, 8, 119, 8, 8490, 10, 94, 8, 122],\n",
       " [36, 73, 11, 83, 89],\n",
       " [8, 122, 46, 4],\n",
       " [84],\n",
       " [215, 27, 14, 21, 13, 5, 646],\n",
       " [526, 35, 62],\n",
       " [355, 233],\n",
       " [94, 87, 8, 2468],\n",
       " [558, 133, 5, 289, 645, 42, 1, 35, 8491, 39, 10],\n",
       " [284, 267],\n",
       " [94, 125, 54, 8, 166, 129, 45, 5, 23, 17, 4, 405],\n",
       " [6, 87, 14, 1, 30],\n",
       " [39, 139, 532, 2, 17, 28, 179, 535],\n",
       " [5361,\n",
       "  627,\n",
       "  5361,\n",
       "  627,\n",
       "  26,\n",
       "  2,\n",
       "  52,\n",
       "  2585,\n",
       "  8,\n",
       "  5361,\n",
       "  627,\n",
       "  5361,\n",
       "  627,\n",
       "  60,\n",
       "  24,\n",
       "  81,\n",
       "  764],\n",
       " [215, 8, 63, 559, 853, 25, 3482, 2, 1586, 17, 45, 293, 4, 3478, 4813, 2975],\n",
       " [1, 4, 8492, 29, 29, 29, 29, 29],\n",
       " [84, 59, 82, 1, 2, 10, 25, 17, 3, 208, 558, 2, 4, 10813, 47, 126, 215],\n",
       " [8, 35, 22, 5, 22, 33, 9, 11, 8492, 409, 2282],\n",
       " [1590, 79, 78, 79, 78, 57, 151],\n",
       " [84, 476, 275, 3118, 219, 62, 82, 1, 22, 25, 78],\n",
       " [395,\n",
       "  32,\n",
       "  25,\n",
       "  2,\n",
       "  4,\n",
       "  408,\n",
       "  8493,\n",
       "  1306,\n",
       "  4376,\n",
       "  940,\n",
       "  10814,\n",
       "  1925,\n",
       "  92,\n",
       "  1267,\n",
       "  29,\n",
       "  10815,\n",
       "  18,\n",
       "  3119,\n",
       "  2473,\n",
       "  774,\n",
       "  8465,\n",
       "  78],\n",
       " [275, 873, 5, 23, 322],\n",
       " [3120, 3726],\n",
       " [156, 291, 1695, 864, 23, 17, 16],\n",
       " [73, 308],\n",
       " [26, 8, 14, 21, 53, 558, 23, 38, 5, 39],\n",
       " [211, 16, 65, 8, 804, 97, 5, 528, 648, 8, 45, 15],\n",
       " [8, 30, 26, 758, 8, 23, 1084, 526, 141, 39, 44, 10816],\n",
       " [84, 256, 7, 6088],\n",
       " [84],\n",
       " [84, 88, 88, 479],\n",
       " [633, 21, 8, 579, 249, 18, 15],\n",
       " [36, 1174, 73, 73, 3, 349, 122],\n",
       " [84, 88, 921],\n",
       " [40, 78],\n",
       " [89],\n",
       " [353, 28],\n",
       " [79, 1271],\n",
       " [233, 27, 206, 35, 1211],\n",
       " [32, 26, 2, 16, 17, 802],\n",
       " [1, 365, 93, 85, 4, 1330],\n",
       " [1, 35, 22, 25, 77, 842, 1253, 51, 211, 31, 85, 221, 19],\n",
       " [36, 36, 1860, 1620],\n",
       " [939, 5, 2, 188],\n",
       " [94, 32, 125, 2, 31, 1696, 49, 3, 690],\n",
       " [3309],\n",
       " [73,\n",
       "  16,\n",
       "  625,\n",
       "  10817,\n",
       "  19,\n",
       "  8,\n",
       "  306,\n",
       "  1,\n",
       "  61,\n",
       "  5,\n",
       "  552,\n",
       "  140,\n",
       "  5,\n",
       "  8,\n",
       "  49,\n",
       "  125,\n",
       "  1981,\n",
       "  805],\n",
       " [87, 14, 8, 109],\n",
       " [59,\n",
       "  472,\n",
       "  35,\n",
       "  85,\n",
       "  11,\n",
       "  8494,\n",
       "  246,\n",
       "  2,\n",
       "  4030,\n",
       "  6089,\n",
       "  5,\n",
       "  1511,\n",
       "  3,\n",
       "  3310,\n",
       "  188,\n",
       "  10,\n",
       "  2370,\n",
       "  5,\n",
       "  5362,\n",
       "  223],\n",
       " [84, 32, 1],\n",
       " [6, 2476, 103, 51, 4, 10818],\n",
       " [1, 30, 3, 324, 2, 1190],\n",
       " [2, 24, 50, 516, 50, 3, 471, 11, 387, 65, 239, 9, 3, 324, 40, 47, 866],\n",
       " [79, 78, 79, 78, 1, 206, 21, 1474, 33],\n",
       " [291, 25, 2, 26, 246, 164, 12, 8, 6, 1, 13, 324],\n",
       " [12, 246, 11, 2],\n",
       " [4, 10819, 267],\n",
       " [59, 3, 243, 647, 2, 202, 8, 1619, 1555, 20, 3, 5363],\n",
       " [674, 472, 140, 1418, 17, 4, 436],\n",
       " [84],\n",
       " [12, 2, 8, 43, 95],\n",
       " [2836, 25, 2, 176],\n",
       " [57, 24, 25, 2, 26, 57, 14, 126, 298, 22, 25, 317],\n",
       " [84, 57, 24, 35, 2037],\n",
       " [57],\n",
       " [1, 275],\n",
       " [1, 444, 3, 1157, 19, 3, 1157, 941, 6, 125, 6, 1, 125],\n",
       " [27, 22, 127, 249, 942, 156, 14, 21, 27, 353, 8, 38, 99],\n",
       " [32, 275, 246, 8, 367, 3, 1256],\n",
       " [262, 195, 219, 8, 550, 3, 2371],\n",
       " [438, 378, 122],\n",
       " [81, 501],\n",
       " [59, 6090, 2, 3, 363, 9, 10820, 117, 252, 32, 27, 23, 96, 5, 7094],\n",
       " [1, 22, 16],\n",
       " [1, 22, 16],\n",
       " [29, 8, 14, 21],\n",
       " [73, 240],\n",
       " [59, 8, 35, 152, 82, 1, 61, 5, 23, 5, 412, 18, 8, 831],\n",
       " [490, 490, 490, 490, 355],\n",
       " [275,\n",
       "  63,\n",
       "  8,\n",
       "  322,\n",
       "  71,\n",
       "  6091,\n",
       "  11,\n",
       "  275,\n",
       "  1,\n",
       "  2,\n",
       "  4031,\n",
       "  47,\n",
       "  26,\n",
       "  4818,\n",
       "  4818,\n",
       "  7095,\n",
       "  85,\n",
       "  10,\n",
       "  3,\n",
       "  225,\n",
       "  1307,\n",
       "  55],\n",
       " [8, 14, 21, 85, 4818, 4818, 7095],\n",
       " [4818, 4818, 7095],\n",
       " [31, 85, 31, 2, 184],\n",
       " [1806],\n",
       " [32, 1, 2, 793],\n",
       " [32, 79, 4, 2029],\n",
       " [368, 90, 1, 140, 5, 8, 347, 7, 5364, 322, 26, 2, 8, 14],\n",
       " [59, 1, 2, 13, 4, 770],\n",
       " [11, 54, 2, 153, 312, 8],\n",
       " [36, 215, 3, 276, 105, 164, 5, 15, 28, 55],\n",
       " [14,\n",
       "  21,\n",
       "  8,\n",
       "  242,\n",
       "  12,\n",
       "  27,\n",
       "  2,\n",
       "  3484,\n",
       "  10,\n",
       "  3,\n",
       "  1017,\n",
       "  6,\n",
       "  27,\n",
       "  112,\n",
       "  11,\n",
       "  77,\n",
       "  505,\n",
       "  1272,\n",
       "  6,\n",
       "  61,\n",
       "  5,\n",
       "  65,\n",
       "  4,\n",
       "  364,\n",
       "  1,\n",
       "  14,\n",
       "  21,\n",
       "  13,\n",
       "  7,\n",
       "  1621],\n",
       " [100, 262, 22, 16],\n",
       " [1870, 1871, 65, 287, 1212, 127, 2695, 132, 11, 10821, 114, 93, 402],\n",
       " [1052],\n",
       " [1797, 81, 141, 1327, 17, 898],\n",
       " [1, 30],\n",
       " [36, 73, 1, 206, 607, 141, 103],\n",
       " [36, 1, 14, 21, 53, 1, 416, 146, 11, 514],\n",
       " [26, 4, 1177, 514],\n",
       " [27, 13, 16, 136, 126, 27, 141, 16, 3, 696, 173],\n",
       " [70, 994, 3, 7096, 6, 8495, 3300, 5, 632, 72, 28],\n",
       " [8496,\n",
       "  28,\n",
       "  9,\n",
       "  3,\n",
       "  8495,\n",
       "  3300,\n",
       "  47,\n",
       "  920,\n",
       "  940,\n",
       "  1556,\n",
       "  10822,\n",
       "  867,\n",
       "  16,\n",
       "  127,\n",
       "  10,\n",
       "  28,\n",
       "  1548,\n",
       "  819,\n",
       "  899,\n",
       "  1191],\n",
       " [253,\n",
       "  59,\n",
       "  3,\n",
       "  129,\n",
       "  10,\n",
       "  3,\n",
       "  8497,\n",
       "  10823,\n",
       "  19,\n",
       "  3,\n",
       "  4360,\n",
       "  14,\n",
       "  21,\n",
       "  329,\n",
       "  5,\n",
       "  53,\n",
       "  60,\n",
       "  11,\n",
       "  196],\n",
       " [42, 94, 215, 82, 8, 14, 21, 268, 15, 322, 47, 7, 1975],\n",
       " [126, 293, 242, 57, 202, 398],\n",
       " [28, 166, 313, 396],\n",
       " [32],\n",
       " [1270, 74],\n",
       " [36, 8, 85, 1741, 363, 479, 52, 221, 249],\n",
       " [73, 57, 35, 57, 35, 10, 495, 17, 4, 4803, 293],\n",
       " [73, 59, 1, 1, 22, 45, 3727, 9, 103],\n",
       " [73],\n",
       " [60, 29, 243, 500, 94, 215, 8, 14, 26, 8, 22, 488, 14, 78],\n",
       " [42, 94, 60, 24, 35, 15, 1, 91, 3, 3293, 6, 3, 1742, 2477],\n",
       " [1178],\n",
       " [84, 1970, 96, 15, 38, 100],\n",
       " [169, 8, 115, 3, 125, 4032, 277, 18, 3, 4032, 78],\n",
       " [6, 3, 2029, 277, 18, 3, 170, 2029, 78],\n",
       " [83, 211, 77, 60, 60, 29, 243, 500],\n",
       " [215, 94, 1, 333],\n",
       " [215],\n",
       " [94, 12, 57, 10, 4, 257, 6, 79, 10, 3, 1872, 1, 14, 21, 140, 5, 8, 78],\n",
       " [32, 60, 215, 60, 125, 60, 1037],\n",
       " [262, 62, 8, 898],\n",
       " [73, 12, 247, 10, 3, 1872, 31, 14, 21, 140, 5, 176, 42, 31, 14, 2372],\n",
       " [94, 1, 2, 21, 3, 136, 28, 74, 83, 45, 44, 2584],\n",
       " [40, 78],\n",
       " [73, 88, 3, 276],\n",
       " [36,\n",
       "  155,\n",
       "  11,\n",
       "  165,\n",
       "  21,\n",
       "  2,\n",
       "  3,\n",
       "  28,\n",
       "  3311,\n",
       "  140,\n",
       "  49,\n",
       "  37,\n",
       "  14,\n",
       "  21,\n",
       "  195,\n",
       "  30,\n",
       "  11,\n",
       "  164,\n",
       "  32,\n",
       "  86,\n",
       "  28,\n",
       "  2,\n",
       "  16],\n",
       " [36, 43, 19, 368, 10824, 1232, 819, 6, 22, 1926, 2, 26, 1554, 2, 40, 49],\n",
       " [355, 122],\n",
       " [355, 387],\n",
       " [29, 27],\n",
       " [3312],\n",
       " [3312, 73],\n",
       " [81, 10825],\n",
       " [73, 438, 33, 9, 495],\n",
       " [73, 73, 60, 25],\n",
       " [73, 11, 115],\n",
       " [758, 8, 242, 7, 1591, 6092, 78],\n",
       " [197, 355],\n",
       " [29, 632, 2696, 17, 176, 476],\n",
       " [36, 59, 108, 16, 55],\n",
       " [87, 49, 27, 40, 23, 33, 5, 546, 898, 107],\n",
       " [35, 32, 8, 30, 247, 24, 62, 56, 898],\n",
       " [29],\n",
       " [126,\n",
       "  308,\n",
       "  8,\n",
       "  35,\n",
       "  45,\n",
       "  365,\n",
       "  93,\n",
       "  42,\n",
       "  3,\n",
       "  327,\n",
       "  2974,\n",
       "  10,\n",
       "  66,\n",
       "  74,\n",
       "  239,\n",
       "  215,\n",
       "  126,\n",
       "  1,\n",
       "  22,\n",
       "  3,\n",
       "  632],\n",
       " ...]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizerNormal = Tokenizer()\n",
    "tokenizerNormal.fit_on_texts(texto_clean)\n",
    "sequences = tokenizerNormal.texts_to_sequences(texto_clean)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44914</th>\n",
       "      <td>[When my friend, as common, forget the tickets...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44915</th>\n",
       "      <td>[When I was erroneously accused of being a thi...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44916</th>\n",
       "      <td>[I want something to change by reversal come o...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44917</th>\n",
       "      <td>[A father helping his youngster to contend oth...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44918</th>\n",
       "      <td>[Information technology ' s just that we buy a...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto    label\n",
       "0      also I was the point person on my company's tr...  neutral\n",
       "1                       You must've had your hands full.  neutral\n",
       "2                                That I did. That I did.  neutral\n",
       "3          So let's talk a little bit about your duties.  neutral\n",
       "4      Now you'll be heading a whole division, so you...  neutral\n",
       "...                                                  ...      ...\n",
       "44914  [When my friend, as common, forget the tickets...    angry\n",
       "44915  [When I was erroneously accused of being a thi...    angry\n",
       "44916  [I want something to change by reversal come o...    angry\n",
       "44917  [A father helping his youngster to contend oth...    angry\n",
       "44918  [Information technology ' s just that we buy a...    angry\n",
       "\n",
       "[44919 rows x 2 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"also i be the point person on my company's transition from the kl to gr system.\",\n",
       " \"you must've have your hand full.\",\n",
       " 'that i do. that i do.',\n",
       " \"so let's talk a little bit about your duty.\",\n",
       " \"now you'll be head a whole division so you'll have a lot of duty.\",\n",
       " 'i see.',\n",
       " \"but there'll be perhaps people under you so you can dump a certain amount on them.\",\n",
       " 'good to know.',\n",
       " 'we can go into detail',\n",
       " \"all right then we'll have a definite answer for you on monday but i think i can say with some confidence you'll fit in well here.\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_clean[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[328, 1, 2, 3, 330, 135, 19, 7, 10703, 10704, 51, 3, 10705, 5, 10706, 1187],\n",
       " [8, 3290, 13, 81, 349, 439],\n",
       " [11, 1, 14, 11, 1, 14],\n",
       " [32, 472, 140, 4, 159, 557, 49, 81, 1324],\n",
       " [126, 670, 2, 409, 4, 327, 1796, 32, 670, 13, 4, 218, 9, 1324],\n",
       " [1, 62],\n",
       " [42, 6069, 2, 1436, 106, 536, 8, 32, 8, 90, 1619, 4, 352, 979, 19, 103],\n",
       " [89, 5, 30],\n",
       " [27, 90, 23, 123, 2688],\n",
       " [40,\n",
       "  78,\n",
       "  99,\n",
       "  526,\n",
       "  13,\n",
       "  4,\n",
       "  8446,\n",
       "  491,\n",
       "  17,\n",
       "  8,\n",
       "  19,\n",
       "  2466,\n",
       "  42,\n",
       "  1,\n",
       "  53,\n",
       "  1,\n",
       "  90,\n",
       "  85,\n",
       "  18,\n",
       "  69,\n",
       "  1410,\n",
       "  670,\n",
       "  1013,\n",
       "  10,\n",
       "  59,\n",
       "  100]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Se crea una lista mediante la secuencia, su respectivo label y el largo de la frase.\n",
    "data_with_len_normal = [[sent, data_labels[i], len(sent)]\n",
    "                 for i, sent in enumerate(sequences)]\n",
    "\n",
    "\n",
    "random.shuffle(data_with_len_normal)\n",
    "\n",
    "#Ordena los datos segun el largo de la secuencia obtenida mediante el len(sent) de la segunda posición\n",
    "#data_with_len.sort(key=lambda x: x[2])\n",
    "\n",
    "valor_maximo=-np.inf\n",
    "\n",
    "for sent_lab in data_with_len_normal:\n",
    "    if sent_lab[2]>valor_maximo:\n",
    "        valor_maximo=sent_lab[2]\n",
    "\n",
    "# Función generadora para el dataset\n",
    "def generator():\n",
    "    for sent, label, _ in data_with_len_normal:\n",
    "        yield tf.constant(sent, dtype=tf.int32), tf.constant(label, dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "all_dataset_normal = tf.data.Dataset.from_generator(generator,\n",
    "                                             output_types=(tf.int32, tf.int32))\n",
    "\n",
    "# Batch y padding del dataset\n",
    "BATCH_SIZE_NORMAL = 32\n",
    "all_batched_normal = all_dataset_normal.padded_batch(BATCH_SIZE_NORMAL,\n",
    "                                       padded_shapes=([300], []),\n",
    "                                       padding_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[24, 81, 5847], 5, 3],\n",
       " [[29, 12542], 5, 2],\n",
       " [[303], 6, 1],\n",
       " [[87, 14, 8, 1399], 2, 4],\n",
       " [[1, 14, 21, 30, 476], 4, 5],\n",
       " [[14, 8, 140, 5, 56], 5, 5],\n",
       " [[784, 57, 151], 5, 3],\n",
       " [[94], 4, 1],\n",
       " [[13917, 2813, 4, 1066, 10, 4, 8156, 375, 18, 4, 2846], 1, 11],\n",
       " [[76,\n",
       "   72,\n",
       "   2,\n",
       "   865,\n",
       "   5578,\n",
       "   6,\n",
       "   3202,\n",
       "   75,\n",
       "   84,\n",
       "   456,\n",
       "   40,\n",
       "   9,\n",
       "   4,\n",
       "   929,\n",
       "   50,\n",
       "   1,\n",
       "   2,\n",
       "   23,\n",
       "   144,\n",
       "   3,\n",
       "   2707,\n",
       "   1,\n",
       "   2,\n",
       "   400,\n",
       "   47,\n",
       "   161,\n",
       "   1,\n",
       "   63,\n",
       "   21,\n",
       "   256,\n",
       "   33,\n",
       "   19,\n",
       "   3202,\n",
       "   150,\n",
       "   3,\n",
       "   2707,\n",
       "   6,\n",
       "   13,\n",
       "   5,\n",
       "   2,\n",
       "   306,\n",
       "   4378,\n",
       "   2524,\n",
       "   17,\n",
       "   1092,\n",
       "   16],\n",
       "  2,\n",
       "  46]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_len_normal[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   24,    81,  5847, ...,     0,     0,     0],\n",
      "       [   29, 12542,     0, ...,     0,     0,     0],\n",
      "       [  303,     0,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   79,     4,  1467, ...,     0,     0,     0],\n",
      "       [  162,   978,    19, ...,     0,     0,     0],\n",
      "       [  476,  1654,  1947, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 5, 6, 2, 4, 5, 5, 4, 1, 2, 6, 2, 1, 1, 3, 4, 6, 0, 5, 5, 5, 0,\n",
      "       3, 3, 2, 2, 6, 2, 3, 0, 1, 0])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,  112,    4, ...,    0,    0,    0],\n",
      "       [   1,    2,   41, ...,    0,    0,    0],\n",
      "       [  88, 2532,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 120,    2,  158, ...,    0,    0,    0],\n",
      "       [ 424,  310,   65, ...,    0,    0,    0],\n",
      "       [ 291,  284,  284, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 0, 2, 3, 4, 6, 1, 4, 4, 4, 6, 3, 0, 1, 1, 0, 2, 4, 2, 6,\n",
      "       3, 2, 1, 1, 5, 1, 5, 2, 0, 5])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 120, 2239,  538, ...,    0,    0,    0],\n",
      "       [ 355,    0,    0, ...,    0,    0,    0],\n",
      "       [  12,    1,  431, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  73,    0,    0, ...,    0,    0,    0],\n",
      "       [ 545,  199,   26, ...,    0,    0,    0],\n",
      "       [ 155,   17,    7, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 3, 3, 6, 0, 6, 5, 0, 2, 4, 1, 6, 5, 6, 5, 5, 1, 4, 4, 5, 2, 1,\n",
      "       0, 4, 1, 1, 0, 4, 2, 3, 6, 2])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[1109,  160,  194, ...,    0,    0,    0],\n",
      "       [1691,   46, 2293, ...,    0,    0,    0],\n",
      "       [7228,    0,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  83,   20,   25, ...,    0,    0,    0],\n",
      "       [  84, 1178,    0, ...,    0,    0,    0],\n",
      "       [ 168,  877,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 4, 6, 0, 5, 3, 0, 6, 4, 3, 0, 4, 2, 3, 3, 6, 2, 6, 4, 3, 4, 5,\n",
      "       6, 0, 5, 2, 2, 0, 1, 3, 3, 6])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    7,  129, ...,    0,    0,    0],\n",
      "       [  12,  138,    2, ...,    0,    0,    0],\n",
      "       [  12,    7, 2393, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  36, 3026,  362, ...,    0,    0,    0],\n",
      "       [1414,    8,    2, ...,    0,    0,    0],\n",
      "       [   3,  749,    9, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 1, 5, 4, 4, 5, 0, 3, 1, 0, 4, 1, 1, 3, 0, 5, 3, 3, 4, 1, 3, 0,\n",
      "       6, 3, 4, 4, 4, 4, 0, 3, 1, 1])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  20,    7, 3385, ...,    0,    0,    0],\n",
      "       [ 652,    0,    0, ...,    0,    0,    0],\n",
      "       [ 524,    1,   91, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,  138,    2, ...,    0,    0,    0],\n",
      "       [ 472, 1556,  104, ...,    0,    0,    0],\n",
      "       [ 275,   88,  348, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 3, 4, 0, 0, 4, 0, 3, 2, 5, 4, 6, 5, 5, 1, 2, 0, 0, 3, 0, 6,\n",
      "       3, 3, 4, 1, 6, 3, 4, 1, 4, 3])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    8,    14,     0, ...,     0,     0,     0],\n",
      "       [    1,   292,   389, ...,     0,     0,     0],\n",
      "       [   28,   650,    12, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  137,     2,    19, ...,     0,     0,     0],\n",
      "       [  306,     1,     1, ...,     0,     0,     0],\n",
      "       [    4, 10318,   285, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 1, 2, 6, 5, 3, 6, 4, 0, 1, 5, 3, 0, 5, 0, 1, 6, 2, 0, 5, 2, 1,\n",
      "       6, 1, 3, 0, 6, 0, 0, 2, 6, 1])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  23,   10,   66, ...,    0,    0,    0],\n",
      "       [ 558,  462,   24, ...,    0,    0,    0],\n",
      "       [  20, 1376,  131, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  48,   68,    2, ...,    0,    0,    0],\n",
      "       [  36,  298,    2, ...,    0,    0,    0],\n",
      "       [1537,  568,   10, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 5, 2, 6, 5, 2, 5, 6, 1, 2, 6, 0, 0, 6, 1, 1, 3, 0, 6, 2, 4, 2,\n",
      "       3, 6, 5, 0, 4, 2, 1, 2, 4, 2])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[7286,   24,  679, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0],\n",
      "       [  12,   17,    3, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 174,  345, 5928, ...,    0,    0,    0],\n",
      "       [ 312,    8,    0, ...,    0,    0,    0],\n",
      "       [   1,   30, 3121, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 1, 2, 2, 6, 3, 5, 1, 5, 3, 1, 6, 1, 5, 6, 1, 4, 5, 0, 1, 2, 4,\n",
      "       5, 3, 6, 1, 5, 3, 1, 1, 4, 4])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 387,    0,    0, ...,    0,    0,    0],\n",
      "       [  12,    3, 1958, ...,    0,    0,    0],\n",
      "       [  29, 1095,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  16,   14,   21, ...,    0,    0,    0],\n",
      "       [  20,    3, 5584, ...,    0,    0,    0],\n",
      "       [  36, 1970,  240, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 2, 1, 1, 0, 5, 0, 6, 5, 0, 3, 3, 1, 3, 2, 0, 2, 4, 2, 6, 5, 2,\n",
      "       0, 6, 3, 1, 2, 4, 6, 5, 2, 6])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 12,   1,  43, ...,   0,   0,   0],\n",
      "       [233,   8,  14, ...,   0,   0,   0],\n",
      "       [156,  54,   1, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [156,   0,   0, ...,   0,   0,   0],\n",
      "       [ 29,   1,  30, ...,   0,   0,   0],\n",
      "       [ 36,   7, 130, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 6, 4, 2, 4, 1, 1, 6, 0, 2, 3, 5, 3, 4, 4, 4, 1, 5, 2, 6, 3, 5,\n",
      "       1, 0, 6, 3, 5, 2, 3, 6, 4, 6])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 106,   10, 6179, ...,    0,    0,    0],\n",
      "       [   6,    8,  202, ...,    0,    0,    0],\n",
      "       [  48,   68,   13, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  59,   14,    8, ...,    0,    0,    0],\n",
      "       [  14,    8,   13, ...,    0,    0,    0],\n",
      "       [1756, 1887,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 5, 2, 5, 5, 2, 6, 5, 1, 4, 6, 1, 3, 1, 1, 0, 4, 0, 0, 5, 4, 0,\n",
      "       3, 6, 5, 3, 6, 3, 0, 4, 4, 6])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 197,    8,   90, ...,    0,    0,    0],\n",
      "       [  73,    0,    0, ...,    0,    0,    0],\n",
      "       [  25,   46,   38, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   4, 6032,  135, ...,    0,    0,    0],\n",
      "       [  12,  162, 8340, ...,    0,    0,    0],\n",
      "       [  84,   32,   99, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 5, 2, 3, 5, 2, 1, 4, 6, 5, 5, 2, 5, 0, 2, 0, 3, 3, 1, 1, 6, 6,\n",
      "       1, 3, 4, 1, 0, 0, 1, 1, 0, 4])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 175,   95,   10, ...,    0,    0,    0],\n",
      "       [  76,   72,   14, ...,    0,    0,    0],\n",
      "       [  36, 1028,  125, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  59,   31,   46, ...,    0,    0,    0],\n",
      "       [  12,    1,   13, ...,    0,    0,    0],\n",
      "       [  36,    7,  130, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 5, 3, 2, 1, 4, 2, 1, 1, 5, 1, 3, 5, 2, 0, 5, 3, 3, 3, 6, 5, 3,\n",
      "       4, 3, 6, 2, 6, 1, 0, 0, 3, 3])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    1,     2,   265, ...,     0,     0,     0],\n",
      "       [  621,     3,   446, ...,     0,     0,     0],\n",
      "       [   12,     4,   181, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    1,     1,   242, ...,     0,     0,     0],\n",
      "       [    1,   494,     4, ...,     0,     0,     0],\n",
      "       [  705,     7, 10145, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 3, 3, 0, 2, 0, 1, 4, 5, 1, 3, 5, 3, 2, 0, 3, 5, 3, 3, 4, 3, 4,\n",
      "       5, 2, 3, 5, 4, 6, 5, 4, 2, 1])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  1, 244,   4, ...,   0,   0,   0],\n",
      "       [ 29, 491,   0, ...,   0,   0,   0],\n",
      "       [ 43,  10,   0, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  1, 141,  16, ...,   0,   0,   0],\n",
      "       [ 40,  78,  83, ...,   0,   0,   0],\n",
      "       [ 60,  35,  11, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 4, 3, 3, 1, 5, 6, 0, 2, 5, 0, 2, 1, 0, 2, 3, 1, 0, 2, 0, 5,\n",
      "       2, 3, 6, 0, 0, 5, 2, 3, 4, 0])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  99,   27,   13, ...,    0,    0,    0],\n",
      "       [   8,    2, 1635, ...,    0,    0,    0],\n",
      "       [  89,   36,   36, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,    1,  146, ...,    0,    0,    0],\n",
      "       [3603, 1085, 1111, ...,    0,    0,    0],\n",
      "       [ 348,    0,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 3, 3, 6, 6, 5, 4, 1, 4, 4, 2, 6, 4, 3, 5, 4, 0, 3, 0, 4, 0, 1,\n",
      "       0, 6, 6, 6, 5, 2, 3, 2, 1, 4])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    8,     2,   613, ...,     0,     0,     0],\n",
      "       [    1,    30,    16, ...,     0,     0,     0],\n",
      "       [  914,  9736, 13096, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 7237,     0,     0, ...,     0,     0,     0],\n",
      "       [   36,     7,   130, ...,     0,     0,     0],\n",
      "       [   12,     1,   146, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 3, 3, 0, 4, 6, 3, 6, 4, 4, 1, 6, 1, 6, 6, 3, 2, 6, 1, 1, 1, 2,\n",
      "       5, 6, 1, 2, 2, 3, 1, 6, 1, 1])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   6, 7155, 7155, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0],\n",
      "       [   1,  372,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,  142,    2, ...,    0,    0,    0],\n",
      "       [  91,  417,  292, ...,    0,    0,    0],\n",
      "       [ 564, 1245,   14, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 2, 3, 6, 1, 1, 3, 6, 2, 3, 1, 4, 4, 0, 3, 4, 2, 1, 2, 4, 2, 1,\n",
      "       5, 6, 2, 2, 5, 0, 3, 3, 6, 1])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 168,   42, 7737, ...,    0,    0,    0],\n",
      "       [ 154,    2,   53, ...,    0,    0,    0],\n",
      "       [4308,  154,   14, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [2230, 2133,    0, ...,    0,    0,    0],\n",
      "       [  28,  107,   20, ...,    0,    0,    0],\n",
      "       [  36,    7,  130, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 2, 3, 5, 1, 6, 2, 0, 0, 4, 5, 5, 5, 6, 3, 3, 1, 2, 3, 6, 2, 0,\n",
      "       3, 0, 2, 4, 4, 6, 2, 6, 3, 6])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    7,  117, ...,    0,    0,    0],\n",
      "       [ 167,   58, 1761, ...,    0,    0,    0],\n",
      "       [   4,  388,   34, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  27,  296,    3, ...,    0,    0,    0],\n",
      "       [  54,   37,    0, ...,    0,    0,    0],\n",
      "       [   1,  165,   21, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 6, 1, 3, 3, 3, 0, 1, 1, 4, 5, 6, 5, 3, 2, 1, 3, 4, 4, 0, 1, 0,\n",
      "       3, 5, 6, 3, 5, 5, 3, 3, 4, 6])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[156,  14,  11, ...,   0,   0,   0],\n",
      "       [656,  16,  46, ...,   0,   0,   0],\n",
      "       [ 29, 518,   0, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 84,  27, 494, ...,   0,   0,   0],\n",
      "       [ 73,  59,  82, ...,   0,   0,   0],\n",
      "       [ 14,  21, 886, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 4, 6, 6, 0, 3, 2, 4, 0, 0, 0, 5, 4, 3, 4, 0, 2, 6, 6, 6, 3, 5,\n",
      "       0, 4, 6, 6, 5, 4, 3, 5, 3, 0])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  7, 229,  71, ...,   0,   0,   0],\n",
      "       [ 84,   0,   0, ...,   0,   0,   0],\n",
      "       [ 29, 233,  37, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 48, 220, 379, ...,   0,   0,   0],\n",
      "       [ 42,  45,  35, ...,   0,   0,   0],\n",
      "       [ 40,  78, 110, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 4, 4, 4, 2, 5, 1, 1, 5, 1, 3, 0, 6, 1, 3, 0, 0, 4, 1, 0, 5, 0,\n",
      "       4, 4, 0, 2, 0, 1, 2, 5, 4, 6])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 812,  870,    3, ...,    0,    0,    0],\n",
      "       [   8, 3636, 2672, ...,    0,    0,    0],\n",
      "       [  89,    6,   99, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  70,   23,   14, ...,    0,    0,    0],\n",
      "       [ 135,    1,   30, ...,    0,    0,    0],\n",
      "       [   1,   65,   10, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 2, 6, 4, 0, 6, 2, 1, 2, 6, 1, 2, 2, 5, 4, 5, 1, 3, 0, 3, 1, 1,\n",
      "       6, 4, 2, 2, 1, 6, 3, 2, 1, 3])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 20,   4, 583, ...,   0,   0,   0],\n",
      "       [ 73, 280,  40, ...,   0,   0,   0],\n",
      "       [ 12, 162,  46, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 87,  14,   8, ...,   0,   0,   0],\n",
      "       [  7, 665,   2, ...,   0,   0,   0],\n",
      "       [167,  58,  73, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 3, 2, 0, 6, 2, 3, 5, 0, 3, 2, 5, 2, 2, 3, 4, 3, 2, 6, 0, 2,\n",
      "       3, 6, 0, 6, 1, 3, 5, 0, 0, 6])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,   13, 2098, ...,    0,    0,    0],\n",
      "       [ 758,   79,   24, ...,    0,    0,    0],\n",
      "       [  29,   29,   29, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  29,    8,   46, ...,    0,    0,    0],\n",
      "       [9924,    1,  133, ...,    0,    0,    0],\n",
      "       [  12,    1,  101, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 4, 2, 6, 5, 5, 2, 4, 6, 0, 5, 5, 1, 3, 4, 5, 4, 0, 1, 6, 4,\n",
      "       1, 0, 2, 4, 6, 0, 5, 3, 3, 1])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,  413, 3101, ...,    0,    0,    0],\n",
      "       [ 508,    0,    0, ...,    0,    0,    0],\n",
      "       [  88,   35,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1,   91,   17, ...,    0,    0,    0],\n",
      "       [   7,  145,  431, ...,    0,    0,    0],\n",
      "       [  94,   94,  128, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 3, 5, 4, 5, 3, 0, 2, 1, 5, 2, 4, 5, 1, 6, 6, 5, 6, 0, 2, 1, 1,\n",
      "       2, 6, 4, 1, 4, 1, 5, 4, 0, 0])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    1,   682,    18, ...,     0,     0,     0],\n",
      "       [   79,     4, 14953, ...,     0,     0,     0],\n",
      "       [   29,     0,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   12,     1,   199, ...,     0,     0,     0],\n",
      "       [   23,     5,  1615, ...,     0,     0,     0],\n",
      "       [   73,     0,     0, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 0, 0, 5, 4, 1, 2, 6, 5, 3, 6, 3, 3, 1, 2, 6, 6, 3, 2, 4, 1, 4,\n",
      "       2, 5, 5, 5, 1, 3, 4, 2, 2, 6])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   4,  251,  107, ...,    0,    0,    0],\n",
      "       [ 106,   24, 1653, ...,    0,    0,    0],\n",
      "       [  25,  624,  138, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 197,   19,   25, ...,    0,    0,    0],\n",
      "       [  29, 1502,    0, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 0, 0, 1, 6, 3, 3, 1, 4, 5, 2, 4, 4, 3, 1, 6, 1, 4, 1, 3, 1, 5,\n",
      "       5, 2, 2, 3, 6, 3, 0, 0, 1, 1])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   4,  478,   24, ...,    0,    0,    0],\n",
      "       [  27,    2, 1207, ...,    0,    0,    0],\n",
      "       [ 215,   87,  124, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  14,   21,  803, ...,    0,    0,    0],\n",
      "       [  84,   84,  100, ...,    0,    0,    0],\n",
      "       [  37,    2, 1528, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 2, 6, 0, 0, 6, 3, 1, 2, 2, 0, 6, 2, 0, 2, 4, 0, 3, 4, 0, 0, 3,\n",
      "       5, 6, 3, 0, 1, 4, 6, 4, 4, 5])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(all_batched_normal.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  70    1   13  847    5  283    7  117   97   20  234  137    2  473\n",
      "   50    5   26    1    2   23    5   14   18    7  878  137   14   21\n",
      "  560    4 6405  317    6  414    1   14   21   46  133   82   63  369\n",
      "    7  121  236   44 7419   97   20  234    5 1939  150    6 3246   10\n",
      "    7  244    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0], shape=(300,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "first = next(iter(all_batched_normal.take(1)))\n",
    "\n",
    "print(first[0][24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[312, 8], 4, 2],\n",
       " [[94], 4, 1],\n",
       " [[341], 4, 1],\n",
       " [[42, 275, 1, 14, 21, 53, 60, 261, 531], 4, 9],\n",
       " [[125, 88, 44, 7067, 3292, 2825, 10718, 51, 5346], 4, 9],\n",
       " [[32, 148, 186], 4, 3],\n",
       " [[59, 59, 5, 2364, 38, 247, 13, 551, 8, 83, 241], 4, 11],\n",
       " [[84], 4, 1],\n",
       " [[42, 88, 24, 479, 32, 32, 1797, 4, 1469, 5, 7, 980], 4, 12],\n",
       " [[77], 4, 1],\n",
       " [[8, 14, 21, 53, 25, 2, 184, 801], 4, 8],\n",
       " [[211, 90, 1, 140, 5, 8, 17, 4, 464], 4, 9],\n",
       " [[197, 322, 32, 315, 23, 19], 4, 6],\n",
       " [[94, 8, 348], 4, 3],\n",
       " [[66, 2, 8449, 66, 2, 171, 404, 11, 1, 53, 16, 2, 55, 5, 271, 16, 18, 233],\n",
       "  4,\n",
       "  18],\n",
       " [[1, 185, 5, 346, 11, 1, 2, 13, 282, 17, 162, 269], 4, 12],\n",
       " [[348, 1620, 179, 80, 9, 3, 4803, 8, 30, 26, 164, 5, 3, 10719, 4359], 4, 15],\n",
       " [[36, 1860, 3715, 247, 325, 9, 10, 3, 589, 9, 4, 770, 100], 4, 13],\n",
       " [[73, 90, 8, 122, 35, 356, 56, 10, 3, 2967, 338], 4, 11],\n",
       " [[1, 91, 247, 3293, 78], 4, 5],\n",
       " [[36, 73, 1688, 85, 66, 468, 2, 5347, 1300], 4, 9],\n",
       " [[73, 656, 11, 132, 31, 13, 4, 77, 243, 627], 4, 10],\n",
       " [[82, 8, 85, 243, 10720, 2826, 8450, 38, 54, 37, 333, 3, 1381], 4, 13],\n",
       " [[698, 26, 2, 8, 14], 4, 5],\n",
       " [[60, 4, 8451, 4360], 4, 4],\n",
       " [[94,\n",
       "   8,\n",
       "   365,\n",
       "   93,\n",
       "   22,\n",
       "   102,\n",
       "   5,\n",
       "   277,\n",
       "   132,\n",
       "   125,\n",
       "   14,\n",
       "   8,\n",
       "   365,\n",
       "   93,\n",
       "   62,\n",
       "   87,\n",
       "   182,\n",
       "   27,\n",
       "   90,\n",
       "   356,\n",
       "   25,\n",
       "   887,\n",
       "   96,\n",
       "   6,\n",
       "   1081,\n",
       "   253],\n",
       "  4,\n",
       "  26],\n",
       " [[1734, 3, 887, 105], 4, 4],\n",
       " [[73], 4, 1],\n",
       " [[1734], 4, 1],\n",
       " [[26], 4, 1],\n",
       " [[94], 4, 1],\n",
       " [[94], 4, 1],\n",
       " [[87, 14, 16, 23, 18, 10721], 4, 6],\n",
       " [[215], 4, 1],\n",
       " [[11, 2, 32, 2268, 27, 2, 77, 1206], 4, 8],\n",
       " [[14, 21, 8, 267, 332], 4, 5],\n",
       " [[73, 11, 77, 1227, 15, 150], 4, 6],\n",
       " [[84], 4, 1],\n",
       " [[1, 90, 24, 267, 10, 4, 771, 177], 4, 8],\n",
       " [[60, 84, 215, 8, 35, 4804, 127, 188], 4, 8]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_len_normal[60:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44919"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_with_len_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_BATCHES totales:  1404\n",
      "NB_BATCHES validacion:  280\n",
      "NB_BATCHES testeo:  140\n",
      "NB_BATCHES entrenamiento 984\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Calcular el número total de lotes\n",
    "NB_BATCHES = math.ceil(len(data_with_len_normal) / BATCH_SIZE)\n",
    "print(\"NB_BATCHES totales: \",NB_BATCHES)\n",
    "\n",
    "# Calcular el número de lotes para validación y prueba\n",
    "NB_BATCHES_VAL = (NB_BATCHES * 20) // 100\n",
    "NB_BATCHES_TEST = (NB_BATCHES * 10) // 100\n",
    "print(\"NB_BATCHES validacion: \",NB_BATCHES_VAL)\n",
    "print(\"NB_BATCHES testeo: \",NB_BATCHES_TEST)\n",
    "print(\"NB_BATCHES entrenamiento\", NB_BATCHES - (NB_BATCHES_TEST + NB_BATCHES_VAL))\n",
    "\n",
    "# Se crea los conjuntos de datos para entrenamiento, validación y prueba\n",
    "val_dataset_normal = all_batched_normal.take(NB_BATCHES_VAL)\n",
    "test_dataset_normal = all_batched_normal.skip(NB_BATCHES_VAL).take(NB_BATCHES_TEST)\n",
    "train_dataset_normal = all_batched_normal.skip(NB_BATCHES_VAL + NB_BATCHES_TEST) \n",
    "\n",
    "BUFFER_SIZE = 10000  \n",
    "train_dataset_normal = train_dataset_normal.shuffle(BUFFER_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "140\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "print(len(list(val_dataset_normal)))\n",
    "print(len(list(test_dataset_normal)))\n",
    "print(len(list(train_dataset_normal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   24,    81,  5847, ...,     0,     0,     0],\n",
      "       [   29, 12542,     0, ...,     0,     0,     0],\n",
      "       [  303,     0,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   79,     4,  1467, ...,     0,     0,     0],\n",
      "       [  162,   978,    19, ...,     0,     0,     0],\n",
      "       [  476,  1654,  1947, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 5, 6, 2, 4, 5, 5, 4, 1, 2, 6, 2, 1, 1, 3, 4, 6, 0, 5, 5, 5, 0,\n",
      "       3, 3, 2, 2, 6, 2, 3, 0, 1, 0])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,  112,    4, ...,    0,    0,    0],\n",
      "       [   1,    2,   41, ...,    0,    0,    0],\n",
      "       [  88, 2532,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 120,    2,  158, ...,    0,    0,    0],\n",
      "       [ 424,  310,   65, ...,    0,    0,    0],\n",
      "       [ 291,  284,  284, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 0, 2, 3, 4, 6, 1, 4, 4, 4, 6, 3, 0, 1, 1, 0, 2, 4, 2, 6,\n",
      "       3, 2, 1, 1, 5, 1, 5, 2, 0, 5])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 120, 2239,  538, ...,    0,    0,    0],\n",
      "       [ 355,    0,    0, ...,    0,    0,    0],\n",
      "       [  12,    1,  431, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  73,    0,    0, ...,    0,    0,    0],\n",
      "       [ 545,  199,   26, ...,    0,    0,    0],\n",
      "       [ 155,   17,    7, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 3, 3, 6, 0, 6, 5, 0, 2, 4, 1, 6, 5, 6, 5, 5, 1, 4, 4, 5, 2, 1,\n",
      "       0, 4, 1, 1, 0, 4, 2, 3, 6, 2])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[1109,  160,  194, ...,    0,    0,    0],\n",
      "       [1691,   46, 2293, ...,    0,    0,    0],\n",
      "       [7228,    0,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  83,   20,   25, ...,    0,    0,    0],\n",
      "       [  84, 1178,    0, ...,    0,    0,    0],\n",
      "       [ 168,  877,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 4, 6, 0, 5, 3, 0, 6, 4, 3, 0, 4, 2, 3, 3, 6, 2, 6, 4, 3, 4, 5,\n",
      "       6, 0, 5, 2, 2, 0, 1, 3, 3, 6])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    7,  129, ...,    0,    0,    0],\n",
      "       [  12,  138,    2, ...,    0,    0,    0],\n",
      "       [  12,    7, 2393, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  36, 3026,  362, ...,    0,    0,    0],\n",
      "       [1414,    8,    2, ...,    0,    0,    0],\n",
      "       [   3,  749,    9, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 1, 5, 4, 4, 5, 0, 3, 1, 0, 4, 1, 1, 3, 0, 5, 3, 3, 4, 1, 3, 0,\n",
      "       6, 3, 4, 4, 4, 4, 0, 3, 1, 1])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  20,    7, 3385, ...,    0,    0,    0],\n",
      "       [ 652,    0,    0, ...,    0,    0,    0],\n",
      "       [ 524,    1,   91, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,  138,    2, ...,    0,    0,    0],\n",
      "       [ 472, 1556,  104, ...,    0,    0,    0],\n",
      "       [ 275,   88,  348, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 3, 4, 0, 0, 4, 0, 3, 2, 5, 4, 6, 5, 5, 1, 2, 0, 0, 3, 0, 6,\n",
      "       3, 3, 4, 1, 6, 3, 4, 1, 4, 3])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    8,    14,     0, ...,     0,     0,     0],\n",
      "       [    1,   292,   389, ...,     0,     0,     0],\n",
      "       [   28,   650,    12, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  137,     2,    19, ...,     0,     0,     0],\n",
      "       [  306,     1,     1, ...,     0,     0,     0],\n",
      "       [    4, 10318,   285, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 1, 2, 6, 5, 3, 6, 4, 0, 1, 5, 3, 0, 5, 0, 1, 6, 2, 0, 5, 2, 1,\n",
      "       6, 1, 3, 0, 6, 0, 0, 2, 6, 1])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  23,   10,   66, ...,    0,    0,    0],\n",
      "       [ 558,  462,   24, ...,    0,    0,    0],\n",
      "       [  20, 1376,  131, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  48,   68,    2, ...,    0,    0,    0],\n",
      "       [  36,  298,    2, ...,    0,    0,    0],\n",
      "       [1537,  568,   10, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 5, 2, 6, 5, 2, 5, 6, 1, 2, 6, 0, 0, 6, 1, 1, 3, 0, 6, 2, 4, 2,\n",
      "       3, 6, 5, 0, 4, 2, 1, 2, 4, 2])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[7286,   24,  679, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0],\n",
      "       [  12,   17,    3, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 174,  345, 5928, ...,    0,    0,    0],\n",
      "       [ 312,    8,    0, ...,    0,    0,    0],\n",
      "       [   1,   30, 3121, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 1, 2, 2, 6, 3, 5, 1, 5, 3, 1, 6, 1, 5, 6, 1, 4, 5, 0, 1, 2, 4,\n",
      "       5, 3, 6, 1, 5, 3, 1, 1, 4, 4])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 387,    0,    0, ...,    0,    0,    0],\n",
      "       [  12,    3, 1958, ...,    0,    0,    0],\n",
      "       [  29, 1095,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  16,   14,   21, ...,    0,    0,    0],\n",
      "       [  20,    3, 5584, ...,    0,    0,    0],\n",
      "       [  36, 1970,  240, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 2, 1, 1, 0, 5, 0, 6, 5, 0, 3, 3, 1, 3, 2, 0, 2, 4, 2, 6, 5, 2,\n",
      "       0, 6, 3, 1, 2, 4, 6, 5, 2, 6])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 12,   1,  43, ...,   0,   0,   0],\n",
      "       [233,   8,  14, ...,   0,   0,   0],\n",
      "       [156,  54,   1, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [156,   0,   0, ...,   0,   0,   0],\n",
      "       [ 29,   1,  30, ...,   0,   0,   0],\n",
      "       [ 36,   7, 130, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 6, 4, 2, 4, 1, 1, 6, 0, 2, 3, 5, 3, 4, 4, 4, 1, 5, 2, 6, 3, 5,\n",
      "       1, 0, 6, 3, 5, 2, 3, 6, 4, 6])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 106,   10, 6179, ...,    0,    0,    0],\n",
      "       [   6,    8,  202, ...,    0,    0,    0],\n",
      "       [  48,   68,   13, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  59,   14,    8, ...,    0,    0,    0],\n",
      "       [  14,    8,   13, ...,    0,    0,    0],\n",
      "       [1756, 1887,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 5, 2, 5, 5, 2, 6, 5, 1, 4, 6, 1, 3, 1, 1, 0, 4, 0, 0, 5, 4, 0,\n",
      "       3, 6, 5, 3, 6, 3, 0, 4, 4, 6])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 197,    8,   90, ...,    0,    0,    0],\n",
      "       [  73,    0,    0, ...,    0,    0,    0],\n",
      "       [  25,   46,   38, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   4, 6032,  135, ...,    0,    0,    0],\n",
      "       [  12,  162, 8340, ...,    0,    0,    0],\n",
      "       [  84,   32,   99, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 5, 2, 3, 5, 2, 1, 4, 6, 5, 5, 2, 5, 0, 2, 0, 3, 3, 1, 1, 6, 6,\n",
      "       1, 3, 4, 1, 0, 0, 1, 1, 0, 4])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 175,   95,   10, ...,    0,    0,    0],\n",
      "       [  76,   72,   14, ...,    0,    0,    0],\n",
      "       [  36, 1028,  125, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  59,   31,   46, ...,    0,    0,    0],\n",
      "       [  12,    1,   13, ...,    0,    0,    0],\n",
      "       [  36,    7,  130, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 5, 3, 2, 1, 4, 2, 1, 1, 5, 1, 3, 5, 2, 0, 5, 3, 3, 3, 6, 5, 3,\n",
      "       4, 3, 6, 2, 6, 1, 0, 0, 3, 3])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    1,     2,   265, ...,     0,     0,     0],\n",
      "       [  621,     3,   446, ...,     0,     0,     0],\n",
      "       [   12,     4,   181, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    1,     1,   242, ...,     0,     0,     0],\n",
      "       [    1,   494,     4, ...,     0,     0,     0],\n",
      "       [  705,     7, 10145, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 3, 3, 0, 2, 0, 1, 4, 5, 1, 3, 5, 3, 2, 0, 3, 5, 3, 3, 4, 3, 4,\n",
      "       5, 2, 3, 5, 4, 6, 5, 4, 2, 1])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  1, 244,   4, ...,   0,   0,   0],\n",
      "       [ 29, 491,   0, ...,   0,   0,   0],\n",
      "       [ 43,  10,   0, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  1, 141,  16, ...,   0,   0,   0],\n",
      "       [ 40,  78,  83, ...,   0,   0,   0],\n",
      "       [ 60,  35,  11, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 4, 3, 3, 1, 5, 6, 0, 2, 5, 0, 2, 1, 0, 2, 3, 1, 0, 2, 0, 5,\n",
      "       2, 3, 6, 0, 0, 5, 2, 3, 4, 0])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  99,   27,   13, ...,    0,    0,    0],\n",
      "       [   8,    2, 1635, ...,    0,    0,    0],\n",
      "       [  89,   36,   36, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,    1,  146, ...,    0,    0,    0],\n",
      "       [3603, 1085, 1111, ...,    0,    0,    0],\n",
      "       [ 348,    0,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 3, 3, 6, 6, 5, 4, 1, 4, 4, 2, 6, 4, 3, 5, 4, 0, 3, 0, 4, 0, 1,\n",
      "       0, 6, 6, 6, 5, 2, 3, 2, 1, 4])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    8,     2,   613, ...,     0,     0,     0],\n",
      "       [    1,    30,    16, ...,     0,     0,     0],\n",
      "       [  914,  9736, 13096, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 7237,     0,     0, ...,     0,     0,     0],\n",
      "       [   36,     7,   130, ...,     0,     0,     0],\n",
      "       [   12,     1,   146, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 3, 3, 0, 4, 6, 3, 6, 4, 4, 1, 6, 1, 6, 6, 3, 2, 6, 1, 1, 1, 2,\n",
      "       5, 6, 1, 2, 2, 3, 1, 6, 1, 1])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   6, 7155, 7155, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0],\n",
      "       [   1,  372,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,  142,    2, ...,    0,    0,    0],\n",
      "       [  91,  417,  292, ...,    0,    0,    0],\n",
      "       [ 564, 1245,   14, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 2, 3, 6, 1, 1, 3, 6, 2, 3, 1, 4, 4, 0, 3, 4, 2, 1, 2, 4, 2, 1,\n",
      "       5, 6, 2, 2, 5, 0, 3, 3, 6, 1])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 168,   42, 7737, ...,    0,    0,    0],\n",
      "       [ 154,    2,   53, ...,    0,    0,    0],\n",
      "       [4308,  154,   14, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [2230, 2133,    0, ...,    0,    0,    0],\n",
      "       [  28,  107,   20, ...,    0,    0,    0],\n",
      "       [  36,    7,  130, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 2, 3, 5, 1, 6, 2, 0, 0, 4, 5, 5, 5, 6, 3, 3, 1, 2, 3, 6, 2, 0,\n",
      "       3, 0, 2, 4, 4, 6, 2, 6, 3, 6])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    7,  117, ...,    0,    0,    0],\n",
      "       [ 167,   58, 1761, ...,    0,    0,    0],\n",
      "       [   4,  388,   34, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  27,  296,    3, ...,    0,    0,    0],\n",
      "       [  54,   37,    0, ...,    0,    0,    0],\n",
      "       [   1,  165,   21, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 6, 1, 3, 3, 3, 0, 1, 1, 4, 5, 6, 5, 3, 2, 1, 3, 4, 4, 0, 1, 0,\n",
      "       3, 5, 6, 3, 5, 5, 3, 3, 4, 6])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[156,  14,  11, ...,   0,   0,   0],\n",
      "       [656,  16,  46, ...,   0,   0,   0],\n",
      "       [ 29, 518,   0, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 84,  27, 494, ...,   0,   0,   0],\n",
      "       [ 73,  59,  82, ...,   0,   0,   0],\n",
      "       [ 14,  21, 886, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 4, 6, 6, 0, 3, 2, 4, 0, 0, 0, 5, 4, 3, 4, 0, 2, 6, 6, 6, 3, 5,\n",
      "       0, 4, 6, 6, 5, 4, 3, 5, 3, 0])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  7, 229,  71, ...,   0,   0,   0],\n",
      "       [ 84,   0,   0, ...,   0,   0,   0],\n",
      "       [ 29, 233,  37, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 48, 220, 379, ...,   0,   0,   0],\n",
      "       [ 42,  45,  35, ...,   0,   0,   0],\n",
      "       [ 40,  78, 110, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 4, 4, 4, 2, 5, 1, 1, 5, 1, 3, 0, 6, 1, 3, 0, 0, 4, 1, 0, 5, 0,\n",
      "       4, 4, 0, 2, 0, 1, 2, 5, 4, 6])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 812,  870,    3, ...,    0,    0,    0],\n",
      "       [   8, 3636, 2672, ...,    0,    0,    0],\n",
      "       [  89,    6,   99, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  70,   23,   14, ...,    0,    0,    0],\n",
      "       [ 135,    1,   30, ...,    0,    0,    0],\n",
      "       [   1,   65,   10, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 2, 6, 4, 0, 6, 2, 1, 2, 6, 1, 2, 2, 5, 4, 5, 1, 3, 0, 3, 1, 1,\n",
      "       6, 4, 2, 2, 1, 6, 3, 2, 1, 3])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 20,   4, 583, ...,   0,   0,   0],\n",
      "       [ 73, 280,  40, ...,   0,   0,   0],\n",
      "       [ 12, 162,  46, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 87,  14,   8, ...,   0,   0,   0],\n",
      "       [  7, 665,   2, ...,   0,   0,   0],\n",
      "       [167,  58,  73, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 3, 2, 0, 6, 2, 3, 5, 0, 3, 2, 5, 2, 2, 3, 4, 3, 2, 6, 0, 2,\n",
      "       3, 6, 0, 6, 1, 3, 5, 0, 0, 6])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,   13, 2098, ...,    0,    0,    0],\n",
      "       [ 758,   79,   24, ...,    0,    0,    0],\n",
      "       [  29,   29,   29, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  29,    8,   46, ...,    0,    0,    0],\n",
      "       [9924,    1,  133, ...,    0,    0,    0],\n",
      "       [  12,    1,  101, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 4, 4, 2, 6, 5, 5, 2, 4, 6, 0, 5, 5, 1, 3, 4, 5, 4, 0, 1, 6, 4,\n",
      "       1, 0, 2, 4, 6, 0, 5, 3, 3, 1])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,  413, 3101, ...,    0,    0,    0],\n",
      "       [ 508,    0,    0, ...,    0,    0,    0],\n",
      "       [  88,   35,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1,   91,   17, ...,    0,    0,    0],\n",
      "       [   7,  145,  431, ...,    0,    0,    0],\n",
      "       [  94,   94,  128, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 3, 5, 4, 5, 3, 0, 2, 1, 5, 2, 4, 5, 1, 6, 6, 5, 6, 0, 2, 1, 1,\n",
      "       2, 6, 4, 1, 4, 1, 5, 4, 0, 0])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[    1,   682,    18, ...,     0,     0,     0],\n",
      "       [   79,     4, 14953, ...,     0,     0,     0],\n",
      "       [   29,     0,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   12,     1,   199, ...,     0,     0,     0],\n",
      "       [   23,     5,  1615, ...,     0,     0,     0],\n",
      "       [   73,     0,     0, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 0, 0, 5, 4, 1, 2, 6, 5, 3, 6, 3, 3, 1, 2, 6, 6, 3, 2, 4, 1, 4,\n",
      "       2, 5, 5, 5, 1, 3, 4, 2, 2, 6])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   4,  251,  107, ...,    0,    0,    0],\n",
      "       [ 106,   24, 1653, ...,    0,    0,    0],\n",
      "       [  25,  624,  138, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 197,   19,   25, ...,    0,    0,    0],\n",
      "       [  29, 1502,    0, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 0, 0, 1, 6, 3, 3, 1, 4, 5, 2, 4, 4, 3, 1, 6, 1, 4, 1, 3, 1, 5,\n",
      "       5, 2, 2, 3, 6, 3, 0, 0, 1, 1])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   4,  478,   24, ...,    0,    0,    0],\n",
      "       [  27,    2, 1207, ...,    0,    0,    0],\n",
      "       [ 215,   87,  124, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  14,   21,  803, ...,    0,    0,    0],\n",
      "       [  84,   84,  100, ...,    0,    0,    0],\n",
      "       [  37,    2, 1528, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 2, 6, 0, 0, 6, 3, 1, 2, 2, 0, 6, 2, 0, 2, 4, 0, 3, 4, 0, 0, 3,\n",
      "       5, 6, 3, 0, 1, 4, 6, 4, 4, 5])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(val_dataset_normal.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 1:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  70,   13,    2, ...,    0,    0,    0],\n",
      "       [   8,  192,   21, ...,    0,    0,    0],\n",
      "       [  12,    1,  283, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1,   91,    8, ...,    0,    0,    0],\n",
      "       [   2,   98,   20, ...,    0,    0,    0],\n",
      "       [  12,    1, 1250, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 0, 5, 6, 2, 2, 6, 0, 6, 6, 4, 4, 6, 4, 5, 2, 0, 4, 2, 0, 3, 0,\n",
      "       1, 5, 1, 4, 1, 6, 2, 5, 1, 1])>)\n",
      "Elemento 2:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 852, 3029,  150, ...,    0,    0,    0],\n",
      "       [ 178,    3,  857, ...,    0,    0,    0],\n",
      "       [  78,   32,    3, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   6, 2625, 4245, ...,    0,    0,    0],\n",
      "       [  12,    1,  283, ...,    0,    0,    0],\n",
      "       [   4, 1656,    9, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 5, 4, 4, 6, 5, 6, 3, 5, 1, 0, 6, 4, 5, 5, 3, 4, 6, 6, 5, 2, 5,\n",
      "       1, 1, 6, 6, 2, 1, 0, 1, 5, 2])>)\n",
      "Elemento 3:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 74,  74,   2, ...,   0,   0,   0],\n",
      "       [ 84,   0,   0, ...,   0,   0,   0],\n",
      "       [ 16,   2,  12, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 12,   7, 163, ...,   0,   0,   0],\n",
      "       [812,  22, 488, ...,   0,   0,   0],\n",
      "       [ 29, 828,   0, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 3, 1, 2, 3, 4, 1, 4, 3, 2, 0, 3, 5, 3, 1, 2, 4, 3, 5, 6, 0, 2,\n",
      "       5, 2, 5, 3, 5, 5, 4, 1, 0, 1])>)\n",
      "Elemento 4:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   7,  193,   10, ...,    0,    0,    0],\n",
      "       [ 156,   54,   27, ...,    0,    0,    0],\n",
      "       [  36,  280,  126, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   6, 1240,  287, ...,    0,    0,    0],\n",
      "       [ 284, 2569,   50, ...,    0,    0,    0],\n",
      "       [  26,  206,   76, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 6, 4, 0, 0, 1, 3, 3, 2, 0, 2, 2, 0, 3, 3, 6, 1, 6, 5, 4, 5, 2,\n",
      "       2, 2, 6, 3, 2, 3, 5, 6, 5, 2])>)\n",
      "Elemento 5:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 101,   33,   11, ...,    0,    0,    0],\n",
      "       [7305,  368,    0, ...,    0,    0,    0],\n",
      "       [  14,    8,   85, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1,  146,   11, ...,    0,    0,    0],\n",
      "       [  87,    2,   52, ...,    0,    0,    0],\n",
      "       [  12,    7,  145, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 3, 1, 6, 5, 2, 5, 0, 5, 5, 5, 0, 2, 6, 1, 6, 4, 4, 2, 6, 2,\n",
      "       5, 3, 3, 0, 2, 1, 2, 5, 5, 3])>)\n",
      "Elemento 6:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    1,    2, ...,    0,    0,    0],\n",
      "       [  16,    2,   32, ...,    0,    0,    0],\n",
      "       [9844,    1,    2, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [2277,    0,    0, ...,    0,    0,    0],\n",
      "       [   7, 9418,  193, ...,    0,    0,    0],\n",
      "       [  28,   55,    1, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 6, 3, 2, 4, 1, 6, 4, 3, 5, 0, 2, 6, 3, 4, 4, 6, 4, 2, 2, 1, 2,\n",
      "       2, 1, 1, 1, 0, 6, 1, 4, 5, 2])>)\n",
      "Elemento 7:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   88,     4,   159, ...,     0,     0,     0],\n",
      "       [  403, 14351,    10, ...,     0,     0,     0],\n",
      "       [  110,    25,     2, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  360,    60,    92, ...,     0,     0,     0],\n",
      "       [ 1864,    57,   114, ...,     0,     0,     0],\n",
      "       [    2,    71,     5, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 5, 0, 5, 2, 3, 5, 0, 1, 5, 0, 6, 0, 5, 6, 3, 6, 1, 3, 2, 4,\n",
      "       5, 6, 1, 1, 6, 3, 5, 1, 3, 0])>)\n",
      "Elemento 8:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  59,   25,    2, ...,    0,    0,    0],\n",
      "       [   1,   75,   98, ...,    0,    0,    0],\n",
      "       [   1,  633,   21, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  36,   88,  153, ...,    0,    0,    0],\n",
      "       [ 358,  322,   14, ...,    0,    0,    0],\n",
      "       [  79,  382, 2575, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 0, 0, 6, 6, 5, 2, 0, 1, 3, 1, 3, 5, 5, 3, 5, 0, 4, 1, 2, 4,\n",
      "       3, 0, 1, 6, 5, 4, 1, 3, 0, 0])>)\n",
      "Elemento 9:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   7,  897,    6, ...,    0,    0,    0],\n",
      "       [1809, 1352,  236, ...,    0,    0,    0],\n",
      "       [   1,   53,   60, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  73,   31,  325, ...,    0,    0,    0],\n",
      "       [ 134,   54,  625, ...,    0,    0,    0],\n",
      "       [  28,    9,  287, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 2, 3, 4, 6, 1, 3, 6, 4, 5, 6, 2, 3, 4, 0, 5, 1, 2, 2, 0, 2, 2,\n",
      "       0, 0, 6, 3, 6, 2, 4, 5, 5, 1])>)\n",
      "Elemento 10:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    7,  937, ...,    0,    0,    0],\n",
      "       [   7,  216, 1273, ...,    0,    0,    0],\n",
      "       [  40,   78,   35, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 425,  498,    0, ...,    0,    0,    0],\n",
      "       [  76,   72,   75, ...,    0,    0,    0],\n",
      "       [   1,   75,  266, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 4, 4, 3, 0, 5, 0, 5, 5, 1, 4, 2, 5, 1, 1, 2, 4, 3, 3, 4, 2,\n",
      "       1, 6, 4, 2, 3, 2, 0, 3, 5, 3])>)\n",
      "Elemento 11:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   1,   22, 1223, ...,    0,    0,    0],\n",
      "       [  60,   40,    1, ...,    0,    0,    0],\n",
      "       [   1,   91,  156, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [1375,    4, 2753, ...,    0,    0,    0],\n",
      "       [ 280,   32,   87, ...,    0,    0,    0],\n",
      "       [  29,  293, 1034, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 5, 5, 0, 5, 6, 2, 3, 4, 6, 0, 1, 4, 3, 6, 2, 5, 0, 5, 1, 6, 2,\n",
      "       1, 4, 4, 0, 6, 5, 1, 2, 4, 2])>)\n",
      "Elemento 12:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    3,  110, ...,    0,    0,    0],\n",
      "       [  87,  182,   14, ...,    0,    0,    0],\n",
      "       [  83,  323,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  27,    2,   19, ...,    0,    0,    0],\n",
      "       [   2,   66, 6646, ...,    0,    0,    0],\n",
      "       [ 918,  162,   74, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 4, 3, 3, 2, 6, 6, 2, 5, 3, 2, 2, 1, 6, 0, 0, 4, 6, 6, 1, 3, 5,\n",
      "       5, 3, 6, 4, 3, 3, 1, 0, 0, 1])>)\n",
      "Elemento 13:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  26, 1316,   24, ...,    0,    0,    0],\n",
      "       [ 179,  107,    1, ...,    0,    0,    0],\n",
      "       [  11,    4,   34, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  71,  103,  157, ...,    0,    0,    0],\n",
      "       [  16,    2, 3264, ...,    0,    0,    0],\n",
      "       [  12,    7,  205, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 2, 0, 6, 2, 3, 0, 1, 3, 1, 1, 6, 4, 6, 2, 4, 0, 5, 1, 3, 1, 4,\n",
      "       6, 3, 4, 4, 3, 4, 6, 5, 3, 0])>)\n",
      "Elemento 14:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  42,   48,  220, ...,    0,    0,    0],\n",
      "       [ 486, 4915,    9, ...,    0,    0,    0],\n",
      "       [  12,    1,  458, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  36,    7,    0, ...,    0,    0,    0],\n",
      "       [  70,   22,    4, ...,    0,    0,    0],\n",
      "       [   5,  289,   11, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 1, 1, 5, 6, 5, 1, 0, 1, 4, 4, 5, 6, 1, 0, 5, 6, 3, 3, 1, 0, 0,\n",
      "       2, 2, 6, 3, 3, 0, 6, 6, 2, 5])>)\n",
      "Elemento 15:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[4670,  675, 3020, ...,    0,    0,    0],\n",
      "       [   1, 1775,   25, ...,    0,    0,    0],\n",
      "       [  29, 1970,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  12,    1,    2, ...,    0,    0,    0],\n",
      "       [ 200,   33,   44, ...,    0,    0,    0],\n",
      "       [  12,    1,    2, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 6, 4, 0, 1, 0, 5, 5, 4, 5, 6, 5, 6, 3, 4, 2, 1, 6, 4, 2, 3, 4,\n",
      "       5, 5, 1, 4, 6, 2, 0, 1, 5, 3])>)\n",
      "Elemento 16:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 674,    6,   82, ...,    0,    0,    0],\n",
      "       [  67,   67,   16, ...,    0,    0,    0],\n",
      "       [  10,   11, 7317, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  18,    3,  413, ...,    0,    0,    0],\n",
      "       [  84,   32,    1, ...,    0,    0,    0],\n",
      "       [  12,    7,  193, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 5, 0, 5, 6, 3, 3, 4, 5, 3, 1, 6, 5, 4, 0, 0, 5, 1, 4, 5,\n",
      "       2, 3, 6, 0, 1, 5, 0, 4, 4, 5])>)\n",
      "Elemento 17:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 26,   1,  90, ...,   0,   0,   0],\n",
      "       [ 36, 138, 669, ...,   0,   0,   0],\n",
      "       [ 12, 104, 627, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 12,   1, 941, ...,   0,   0,   0],\n",
      "       [  1,   2, 279, ...,   0,   0,   0],\n",
      "       [120, 552,   7, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 5, 0, 3, 6, 3, 2, 0, 1, 3, 6, 5, 5, 3, 4, 6, 1, 6, 4, 5, 2, 4,\n",
      "       6, 6, 1, 2, 1, 6, 0, 1, 2, 3])>)\n",
      "Elemento 18:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  22,   48,   68, ...,    0,    0,    0],\n",
      "       [  59,   74,   30, ...,    0,    0,    0],\n",
      "       [  27,   13,    5, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   4, 2516, 3967, ...,    0,    0,    0],\n",
      "       [ 362,    4, 1177, ...,    0,    0,    0],\n",
      "       [ 197,    1,   45, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 4, 0, 1, 2, 3, 5, 2, 4, 3, 3, 1, 3, 6, 1, 1, 6, 4, 4, 6, 4, 2,\n",
      "       4, 6, 1, 0, 6, 5, 6, 1, 5, 0])>)\n",
      "Elemento 19:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 537,   69,  862, ...,    0,    0,    0],\n",
      "       [  26,    0,    0, ...,    0,    0,    0],\n",
      "       [   6,   99,   84, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1, 2671,    4, ...,    0,    0,    0],\n",
      "       [  88,  625,  227, ...,    0,    0,    0],\n",
      "       [   8,    8,    8, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 6, 3, 0, 3, 6, 1, 0, 2, 2, 6, 1, 6, 1, 4, 3, 4, 3, 4, 4, 4, 6,\n",
      "       3, 1, 0, 3, 5, 4, 5, 1, 5, 6])>)\n",
      "Elemento 20:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 28,   9,   7, ...,   0,   0,   0],\n",
      "       [  1,  13,   4, ...,   0,   0,   0],\n",
      "       [ 57,  35,  85, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 35, 623,  10, ...,   0,   0,   0],\n",
      "       [  1, 133,  56, ...,   0,   0,   0],\n",
      "       [197,  19,   4, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 4, 2, 3, 2, 2, 6, 0, 0, 2, 6, 5, 1, 3, 0, 5, 0, 3, 3, 5, 1,\n",
      "       0, 0, 6, 6, 2, 6, 6, 2, 5, 1])>)\n",
      "Elemento 21:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[1196,   26,  448, ...,    0,    0,    0],\n",
      "       [  28,  650,  175, ...,    0,    0,    0],\n",
      "       [  50,    4,  191, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 359, 1074,   28, ...,    0,    0,    0],\n",
      "       [   4,  258,  273, ...,    0,    0,    0],\n",
      "       [ 222,  116,  111, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 2, 2, 3, 2, 4, 2, 6, 1, 1, 2, 5, 2, 0, 3, 2, 4, 5, 5, 0, 6, 3,\n",
      "       6, 3, 1, 1, 0, 3, 5, 2, 5, 6])>)\n",
      "Elemento 22:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 112,    4,  626, ...,    0,    0,    0],\n",
      "       [  12,    4, 5755, ...,    0,    0,    0],\n",
      "       [1259,    1,   13, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  28,  909,   20, ...,    0,    0,    0],\n",
      "       [4133,  189,  128, ...,    0,    0,    0],\n",
      "       [   1,  115,   18, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 6, 0, 6, 1, 1, 6, 5, 4, 0, 3, 1, 0, 3, 0, 5, 2, 0, 4, 1, 1,\n",
      "       6, 5, 2, 0, 3, 3, 2, 1, 1, 0])>)\n",
      "Elemento 23:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[   7,  665,   45, ...,    0,    0,    0],\n",
      "       [  11,  105,    2, ...,    0,    0,    0],\n",
      "       [ 275,    8,   30, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   3,  664,   43, ...,    0,    0,    0],\n",
      "       [  26,    2,   27, ...,    0,    0,    0],\n",
      "       [   1,  204, 1577, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 2, 4, 2, 6, 2, 5, 0, 1, 2, 0, 2, 2, 3, 4, 6, 4, 3, 3, 3, 1, 0,\n",
      "       3, 0, 2, 6, 0, 0, 6, 0, 0, 2])>)\n",
      "Elemento 24:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 36,  83,  20, ...,   0,   0,   0],\n",
      "       [ 35, 126, 157, ...,   0,   0,   0],\n",
      "       [  1, 201,  19, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 84,   1, 125, ...,   0,   0,   0],\n",
      "       [ 12,   1,   2, ...,   0,   0,   0],\n",
      "       [  9, 373,   8, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([5, 5, 0, 5, 3, 5, 6, 1, 0, 3, 5, 6, 4, 6, 1, 1, 0, 1, 5, 3, 0, 1,\n",
      "       1, 6, 0, 4, 0, 4, 1, 5, 5, 3])>)\n",
      "Elemento 25:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[13277,     6,  3693, ...,     0,     0,     0],\n",
      "       [   42,   215,    66, ...,     0,     0,     0],\n",
      "       [11263,   691,     2, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  126,    22,    33, ...,     0,     0,     0],\n",
      "       [    3,    55,    12, ...,     0,     0,     0],\n",
      "       [   26,     0,     0, ...,     0,     0,     0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 4, 4, 6, 6, 4, 5, 1, 5, 1, 0, 4, 0, 1, 1, 4, 4, 3, 4, 3, 1, 2,\n",
      "       6, 0, 4, 5, 5, 5, 6, 3, 1, 0])>)\n",
      "Elemento 26:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  12,    1,  431, ...,    0,    0,    0],\n",
      "       [  36,   59,   99, ...,    0,    0,    0],\n",
      "       [  60, 1586,    0, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  20, 1280,  131, ...,    0,    0,    0],\n",
      "       [ 939,    0,    0, ...,    0,    0,    0],\n",
      "       [   3,  811,    9, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([2, 3, 3, 3, 6, 0, 5, 2, 4, 2, 0, 0, 2, 2, 3, 2, 4, 1, 3, 6, 5, 2,\n",
      "       1, 5, 0, 6, 5, 2, 4, 2, 6, 0])>)\n",
      "Elemento 27:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[395,   0,   0, ...,   0,   0,   0],\n",
      "       [  6,   1, 133, ...,   0,   0,   0],\n",
      "       [ 12,   1,   2, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  1,   2, 265, ...,   0,   0,   0],\n",
      "       [  8,  30,   8, ...,   0,   0,   0],\n",
      "       [  1,   2, 383, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 0, 0, 2, 0, 3, 1, 0, 6, 5, 3, 3, 6, 6, 0, 0, 5, 1, 2, 4, 1, 6,\n",
      "       1, 6, 2, 6, 6, 3, 2, 2, 2, 2])>)\n",
      "Elemento 28:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  59,  424,    0, ...,    0,    0,    0],\n",
      "       [  12,  134,  117, ...,    0,    0,    0],\n",
      "       [   1,   14,   21, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [4104,   89, 1115, ...,    0,    0,    0],\n",
      "       [   1,    2,  509, ...,    0,    0,    0],\n",
      "       [ 652,  233,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 5, 5, 1, 2, 1, 0, 2, 4, 5, 5, 4, 5, 0, 5, 3, 2, 3, 2, 0, 3, 2,\n",
      "       1, 4, 3, 4, 1, 5, 6, 6, 3, 4])>)\n",
      "Elemento 29:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[ 42,  25,   2, ...,   0,   0,   0],\n",
      "       [ 11,   2,   4, ...,   0,   0,   0],\n",
      "       [ 27,  90,  22, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 40,  78,  57, ...,   0,   0,   0],\n",
      "       [168, 130,   0, ...,   0,   0,   0],\n",
      "       [  8,  14,  21, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([4, 3, 0, 0, 3, 2, 3, 3, 6, 0, 4, 0, 2, 3, 0, 6, 4, 4, 4, 6, 1, 2,\n",
      "       1, 5, 4, 2, 3, 1, 6, 0, 6, 4])>)\n",
      "Elemento 30:\n",
      "(<tf.Tensor: shape=(32, 300), dtype=int32, numpy=\n",
      "array([[  32,  293, 2632, ...,    0,    0,    0],\n",
      "       [ 215,   28,    9, ...,    0,    0,    0],\n",
      "       [   2,    8,  319, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 253,    2,    8, ...,    0,    0,    0],\n",
      "       [   4, 3681,   92, ...,    0,    0,    0],\n",
      "       [ 215,  298,    2, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([6, 3, 0, 0, 3, 6, 2, 4, 2, 4, 0, 0, 6, 5, 3, 6, 1, 0, 2, 6, 6, 5,\n",
      "       3, 0, 4, 5, 1, 4, 2, 4, 1, 0])>)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(train_dataset_normal.take(30)):\n",
    "    print(f\"Elemento {i+1}:\")\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15114"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximo_largo =300 #Maximo largo de la secuencia\n",
    "vocab_size = len(tokenizerNormal.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'be': 2,\n",
       " 'the': 3,\n",
       " 'a': 4,\n",
       " 'to': 5,\n",
       " 'and': 6,\n",
       " 'my': 7,\n",
       " 'you': 8,\n",
       " 'of': 9,\n",
       " 'in': 10,\n",
       " 'that': 11,\n",
       " 'when': 12,\n",
       " 'have': 13,\n",
       " 'do': 14,\n",
       " 'me': 15,\n",
       " 'it': 16,\n",
       " 'for': 17,\n",
       " 'with': 18,\n",
       " 'on': 19,\n",
       " 'at': 20,\n",
       " \"n't\": 21,\n",
       " 'get': 22,\n",
       " 'go': 23,\n",
       " 'not': 24,\n",
       " 'this': 25,\n",
       " 'what': 26,\n",
       " 'we': 27,\n",
       " 'one': 28,\n",
       " 'no': 29,\n",
       " 'know': 30,\n",
       " 'he': 31,\n",
       " 'so': 32,\n",
       " 'out': 33,\n",
       " 'friend': 34,\n",
       " 'just': 35,\n",
       " 'oh': 36,\n",
       " 'she': 37,\n",
       " 'up': 38,\n",
       " 'her': 39,\n",
       " 'all': 40,\n",
       " 'very': 41,\n",
       " 'but': 42,\n",
       " 'come': 43,\n",
       " 'an': 44,\n",
       " 'like': 45,\n",
       " 'make': 46,\n",
       " 'by': 47,\n",
       " 'information': 48,\n",
       " 'about': 49,\n",
       " 'as': 50,\n",
       " 'from': 51,\n",
       " 'they': 52,\n",
       " 'think': 53,\n",
       " 'would': 54,\n",
       " 'time': 55,\n",
       " 'him': 56,\n",
       " \"i'm\": 57,\n",
       " 'state': 58,\n",
       " 'well': 59,\n",
       " \"it's\": 60,\n",
       " 'want': 61,\n",
       " 'see': 62,\n",
       " 'could': 63,\n",
       " 'his': 64,\n",
       " 'take': 65,\n",
       " 'there': 66,\n",
       " 'because': 67,\n",
       " 'technology': 68,\n",
       " 'some': 69,\n",
       " 'after': 70,\n",
       " 'tell': 71,\n",
       " 'number': 72,\n",
       " 'yeah': 73,\n",
       " 'who': 74,\n",
       " 'felt': 75,\n",
       " 'atomic': 76,\n",
       " 'really': 77,\n",
       " 'right': 78,\n",
       " \"you're\": 79,\n",
       " 'day': 80,\n",
       " 'your': 81,\n",
       " 'if': 82,\n",
       " 'look': 83,\n",
       " 'okay': 84,\n",
       " 'say': 85,\n",
       " 'which': 86,\n",
       " 'how': 87,\n",
       " \"that's\": 88,\n",
       " 'good': 89,\n",
       " 'can': 90,\n",
       " 'mean': 91,\n",
       " 'non': 92,\n",
       " 'na': 93,\n",
       " 'hey': 94,\n",
       " 'home': 95,\n",
       " 'back': 96,\n",
       " 'year': 97,\n",
       " 'disgust': 98,\n",
       " 'then': 99,\n",
       " 'here': 100,\n",
       " 'find': 101,\n",
       " 'something': 102,\n",
       " 'them': 103,\n",
       " 'our': 104,\n",
       " 'thing': 105,\n",
       " 'people': 106,\n",
       " 'night': 107,\n",
       " 'give': 108,\n",
       " 'feel': 109,\n",
       " 'man': 110,\n",
       " 'tree': 111,\n",
       " 'saw': 112,\n",
       " 'maine': 113,\n",
       " 'gon': 114,\n",
       " 'work': 115,\n",
       " 'pine': 116,\n",
       " 'first': 117,\n",
       " 'car': 118,\n",
       " 'leave': 119,\n",
       " 'single': 120,\n",
       " 'way': 121,\n",
       " 'guy': 122,\n",
       " 'into': 123,\n",
       " 'before': 124,\n",
       " 'uh': 125,\n",
       " 'now': 126,\n",
       " 'off': 127,\n",
       " 'live': 128,\n",
       " 'girl': 129,\n",
       " 'god': 130,\n",
       " 'school': 131,\n",
       " 'or': 132,\n",
       " 'love': 133,\n",
       " 'ace': 134,\n",
       " 'person': 135,\n",
       " 'only': 136,\n",
       " 'iodine': 137,\n",
       " 'ane': 138,\n",
       " 'die': 139,\n",
       " 'talk': 140,\n",
       " 'call': 141,\n",
       " 'unity': 142,\n",
       " 'try': 143,\n",
       " 'over': 144,\n",
       " 'father': 145,\n",
       " 'hear': 146,\n",
       " 'mine': 147,\n",
       " 'much': 148,\n",
       " 'away': 149,\n",
       " 'down': 150,\n",
       " 'sorry': 151,\n",
       " 'ask': 152,\n",
       " 'great': 153,\n",
       " 'iodin': 154,\n",
       " 'wait': 155,\n",
       " 'why': 156,\n",
       " 'astir': 157,\n",
       " 'afraid': 158,\n",
       " 'little': 159,\n",
       " 'world': 160,\n",
       " 'fear': 161,\n",
       " 'someone': 162,\n",
       " 'parent': 163,\n",
       " 'happen': 164,\n",
       " 'ca': 165,\n",
       " 'two': 166,\n",
       " 'buckeye': 167,\n",
       " 'ohio': 168,\n",
       " 'where': 169,\n",
       " 'other': 170,\n",
       " 'another': 171,\n",
       " 'room': 172,\n",
       " 'house': 173,\n",
       " 'while': 174,\n",
       " 'walk': 175,\n",
       " 'us': 176,\n",
       " 'place': 177,\n",
       " 'during': 178,\n",
       " 'last': 179,\n",
       " 'alone': 180,\n",
       " 'close': 181,\n",
       " 'long': 182,\n",
       " 'any': 183,\n",
       " 'too': 184,\n",
       " 'start': 185,\n",
       " 'more': 186,\n",
       " 'pass': 187,\n",
       " 'again': 188,\n",
       " 'never': 189,\n",
       " 'old': 190,\n",
       " 'child': 191,\n",
       " 'need': 192,\n",
       " 'mother': 193,\n",
       " 'health': 194,\n",
       " 'even': 195,\n",
       " 'bad': 196,\n",
       " 'yes': 197,\n",
       " 'lose': 198,\n",
       " 'break': 199,\n",
       " 'run': 200,\n",
       " 'put': 201,\n",
       " 'still': 202,\n",
       " 'myself': 203,\n",
       " 'meet': 204,\n",
       " 'brother': 205,\n",
       " 'should': 206,\n",
       " 'organization': 207,\n",
       " 'money': 208,\n",
       " 'than': 209,\n",
       " 'exam': 210,\n",
       " 'ross': 211,\n",
       " 'follow': 212,\n",
       " 'boyfriend': 213,\n",
       " 'class': 214,\n",
       " \"y'know\": 215,\n",
       " 'sister': 216,\n",
       " 'helium': 217,\n",
       " 'lot': 218,\n",
       " 'let': 219,\n",
       " \"technology's\": 220,\n",
       " 'turn': 221,\n",
       " 'without': 222,\n",
       " 'hour': 223,\n",
       " 'once': 224,\n",
       " 'new': 225,\n",
       " 'angry': 226,\n",
       " 'sad': 227,\n",
       " 'life': 228,\n",
       " 'family': 229,\n",
       " 'woman': 230,\n",
       " 'real': 231,\n",
       " 'use': 232,\n",
       " 'joey': 233,\n",
       " 'university': 234,\n",
       " 'stop': 235,\n",
       " 'through': 236,\n",
       " 'their': 237,\n",
       " 'move': 238,\n",
       " 'care': 239,\n",
       " 'listen': 240,\n",
       " 'young': 241,\n",
       " 'remember': 242,\n",
       " 'big': 243,\n",
       " 'study': 244,\n",
       " 'receive': 245,\n",
       " 'will': 246,\n",
       " \"we're\": 247,\n",
       " 'stay': 248,\n",
       " 'around': 249,\n",
       " 'bus': 250,\n",
       " 'dark': 251,\n",
       " 'girlfriend': 252,\n",
       " 'huh': 253,\n",
       " 'week': 254,\n",
       " 'experience': 255,\n",
       " 'hold': 256,\n",
       " 'play': 257,\n",
       " 'few': 258,\n",
       " 'yea': 259,\n",
       " 'examination': 260,\n",
       " 'anything': 261,\n",
       " \"i'll\": 262,\n",
       " 'help': 263,\n",
       " 'drive': 264,\n",
       " 'sit': 265,\n",
       " 'happy': 266,\n",
       " 'sleep': 267,\n",
       " 'believe': 268,\n",
       " 'else': 269,\n",
       " 'whom': 270,\n",
       " 'end': 271,\n",
       " 'many': 272,\n",
       " 'month': 273,\n",
       " 'dog': 274,\n",
       " 'um': 275,\n",
       " 'same': 276,\n",
       " 'eat': 277,\n",
       " 'always': 278,\n",
       " 'watch': 279,\n",
       " 'sure': 280,\n",
       " 'result': 281,\n",
       " 'feeling': 282,\n",
       " 'fail': 283,\n",
       " \"she's\": 284,\n",
       " 'boy': 285,\n",
       " 'student': 286,\n",
       " 'these': 287,\n",
       " 'somebody': 288,\n",
       " 'show': 289,\n",
       " 'whoa': 290,\n",
       " 'cause': 291,\n",
       " 'exist': 292,\n",
       " 'umm': 293,\n",
       " 'keep': 294,\n",
       " 'street': 295,\n",
       " 'cost': 296,\n",
       " 'marry': 297,\n",
       " \"i've\": 298,\n",
       " 'best': 299,\n",
       " 'comprise': 300,\n",
       " 'ago': 301,\n",
       " 'accident': 302,\n",
       " 'wherefore': 303,\n",
       " 'embody': 304,\n",
       " 'party': 305,\n",
       " 'actually': 306,\n",
       " 'drunk': 307,\n",
       " 'maybe': 308,\n",
       " 'everything': 309,\n",
       " 'hither': 310,\n",
       " 'constitute': 311,\n",
       " 'thank': 312,\n",
       " 'three': 313,\n",
       " 'catch': 314,\n",
       " \"what's\": 315,\n",
       " 'each': 316,\n",
       " 'job': 317,\n",
       " 'personify': 318,\n",
       " 'kid': 319,\n",
       " 'late': 320,\n",
       " 'represent': 321,\n",
       " 'please': 322,\n",
       " \"he's\": 323,\n",
       " 'baby': 324,\n",
       " 'kind': 325,\n",
       " 'equal': 326,\n",
       " 'whole': 327,\n",
       " 'also': 328,\n",
       " 'seem': 329,\n",
       " 'point': 330,\n",
       " 'suppose': 331,\n",
       " 'together': 332,\n",
       " 'understand': 333,\n",
       " 'phone': 334,\n",
       " 'death': 335,\n",
       " 'next': 336,\n",
       " 'become': 337,\n",
       " 'later': 338,\n",
       " 'fall': 339,\n",
       " 'film': 340,\n",
       " 'nothing': 341,\n",
       " 'suddenly': 342,\n",
       " 'simply': 343,\n",
       " 'high': 344,\n",
       " 'read': 345,\n",
       " 'realize': 346,\n",
       " 'behind': 347,\n",
       " 'ok': 348,\n",
       " 'hand': 349,\n",
       " 'relationship': 350,\n",
       " 'rattle': 351,\n",
       " 'certain': 352,\n",
       " 'pick': 353,\n",
       " 'road': 354,\n",
       " 'hi': 355,\n",
       " 'throw': 356,\n",
       " 'wow': 357,\n",
       " 'chandler': 358,\n",
       " 'every': 359,\n",
       " 'rachel': 360,\n",
       " 'though': 361,\n",
       " 'such': 362,\n",
       " 'name': 363,\n",
       " 'picture': 364,\n",
       " 'wan': 365,\n",
       " 'accept': 366,\n",
       " 'bring': 367,\n",
       " 'monica': 368,\n",
       " 'pay': 369,\n",
       " 'several': 370,\n",
       " 'problem': 371,\n",
       " 'own': 372,\n",
       " 'course': 373,\n",
       " \"there's\": 374,\n",
       " 'situation': 375,\n",
       " 'form': 376,\n",
       " 'front': 377,\n",
       " 'nice': 378,\n",
       " 'hard': 379,\n",
       " 'stand': 380,\n",
       " 'expect': 381,\n",
       " 'quite': 382,\n",
       " 'test': 383,\n",
       " 'those': 384,\n",
       " 'since': 385,\n",
       " 'line': 386,\n",
       " 'phoebe': 387,\n",
       " 'lady': 388,\n",
       " 'force': 389,\n",
       " 'open': 390,\n",
       " 'wrong': 391,\n",
       " 'female': 392,\n",
       " 'lie': 393,\n",
       " 'miss': 394,\n",
       " 'ah': 395,\n",
       " 'four': 396,\n",
       " 'human': 397,\n",
       " 'learn': 398,\n",
       " 'near': 399,\n",
       " 'hit': 400,\n",
       " 'almost': 401,\n",
       " 'set': 402,\n",
       " 'dead': 403,\n",
       " 'reason': 404,\n",
       " 'drink': 405,\n",
       " 'along': 406,\n",
       " 'present': 407,\n",
       " 'half': 408,\n",
       " 'head': 409,\n",
       " 'fellow': 410,\n",
       " 'lecture': 411,\n",
       " 'bed': 412,\n",
       " 'most': 413,\n",
       " 'yet': 414,\n",
       " 'guess': 415,\n",
       " 'ever': 416,\n",
       " \"you've\": 417,\n",
       " 'morning': 418,\n",
       " 'others': 419,\n",
       " 'kill': 420,\n",
       " 'hospital': 421,\n",
       " 'cry': 422,\n",
       " 'towards': 423,\n",
       " 'fine': 424,\n",
       " 'o': 425,\n",
       " 'act': 426,\n",
       " 'group': 427,\n",
       " 'part': 428,\n",
       " 'teacher': 429,\n",
       " 'holiday': 430,\n",
       " 'begin': 431,\n",
       " 'face': 432,\n",
       " 'ill': 433,\n",
       " 'letter': 434,\n",
       " 'matter': 435,\n",
       " 'second': 436,\n",
       " 'mind': 437,\n",
       " \"they're\": 438,\n",
       " 'full': 439,\n",
       " 'win': 440,\n",
       " 'against': 441,\n",
       " 'promise': 442,\n",
       " 'joy': 443,\n",
       " 'write': 444,\n",
       " 'thanks': 445,\n",
       " 'book': 446,\n",
       " 'small': 447,\n",
       " 'grandmother': 448,\n",
       " 'fight': 449,\n",
       " 'forget': 450,\n",
       " 'spend': 451,\n",
       " 'able': 452,\n",
       " 'door': 453,\n",
       " 'sound': 454,\n",
       " 'grade': 455,\n",
       " 'merely': 456,\n",
       " 'hate': 457,\n",
       " 'beat': 458,\n",
       " 'light': 459,\n",
       " 'mark': 460,\n",
       " 'smell': 461,\n",
       " 'rather': 462,\n",
       " 'english': 463,\n",
       " 'minute': 464,\n",
       " 'question': 465,\n",
       " 'buy': 466,\n",
       " 's': 467,\n",
       " 'might': 468,\n",
       " 'plan': 469,\n",
       " 'body': 470,\n",
       " 'fact': 471,\n",
       " \"let's\": 472,\n",
       " 'scar': 473,\n",
       " 'visit': 474,\n",
       " 'pheebs': 475,\n",
       " 'sir': 476,\n",
       " 'business': 477,\n",
       " 'relative': 478,\n",
       " 'enough': 479,\n",
       " 'change': 480,\n",
       " 'game': 481,\n",
       " 'sick': 482,\n",
       " 'enter': 483,\n",
       " 'stuff': 484,\n",
       " 'until': 485,\n",
       " 'word': 486,\n",
       " 'steal': 487,\n",
       " 'ta': 488,\n",
       " 'fell': 489,\n",
       " 'knock': 490,\n",
       " 'answer': 491,\n",
       " 'moment': 492,\n",
       " 'movie': 493,\n",
       " 'birth': 494,\n",
       " 'town': 495,\n",
       " 'decide': 496,\n",
       " 'upward': 497,\n",
       " 'k': 498,\n",
       " 'college': 499,\n",
       " 'deal': 500,\n",
       " 'son': 501,\n",
       " 'already': 502,\n",
       " 'similar': 503,\n",
       " 'check': 504,\n",
       " 'pretty': 505,\n",
       " 'date': 506,\n",
       " 'between': 507,\n",
       " 'laugh': 508,\n",
       " 'travel': 509,\n",
       " 'food': 510,\n",
       " 'order': 511,\n",
       " 'behave': 512,\n",
       " 'refuse': 513,\n",
       " 'story': 514,\n",
       " 'treat': 515,\n",
       " 'important': 516,\n",
       " 'hurt': 517,\n",
       " 'thought': 518,\n",
       " 'discover': 519,\n",
       " 'speak': 520,\n",
       " 'dream': 521,\n",
       " 'eye': 522,\n",
       " 'early': 523,\n",
       " 'ohh': 524,\n",
       " 'idea': 525,\n",
       " \"we'll\": 526,\n",
       " 'side': 527,\n",
       " 'finally': 528,\n",
       " 'thus': 529,\n",
       " 'sense': 530,\n",
       " 'serious': 531,\n",
       " 'wish': 532,\n",
       " 'five': 533,\n",
       " 'bag': 534,\n",
       " 'kiss': 535,\n",
       " 'under': 536,\n",
       " 'heard': 537,\n",
       " 'require': 538,\n",
       " 'badly': 539,\n",
       " 'hope': 540,\n",
       " 'm': 541,\n",
       " 'send': 542,\n",
       " 'event': 543,\n",
       " 'threaten': 544,\n",
       " 'water': 545,\n",
       " 'dinner': 546,\n",
       " 'trip': 547,\n",
       " 'appear': 548,\n",
       " 'classmate': 549,\n",
       " 'ring': 550,\n",
       " 'fun': 551,\n",
       " 'finish': 552,\n",
       " 'train': 553,\n",
       " 'frighten': 554,\n",
       " 'both': 555,\n",
       " 'suffer': 556,\n",
       " 'bit': 557,\n",
       " \"i'd\": 558,\n",
       " 'totally': 559,\n",
       " 'desire': 560,\n",
       " 'drop': 561,\n",
       " 'cut': 562,\n",
       " 'driver': 563,\n",
       " 'dad': 564,\n",
       " 'separate': 565,\n",
       " 'tv': 566,\n",
       " 'sex': 567,\n",
       " 'evening': 568,\n",
       " 'pas': 569,\n",
       " 'husband': 570,\n",
       " 'former': 571,\n",
       " 'involve': 572,\n",
       " 'stupid': 573,\n",
       " 'report': 574,\n",
       " 'subject': 575,\n",
       " 'piece': 576,\n",
       " 'acquaintance': 577,\n",
       " 'wedding': 578,\n",
       " 'dance': 579,\n",
       " 'sometimes': 580,\n",
       " 'figure': 581,\n",
       " 'age': 582,\n",
       " 'company': 583,\n",
       " 'however': 584,\n",
       " 'nighttime': 585,\n",
       " 'respect': 586,\n",
       " 'everyone': 587,\n",
       " 'final': 588,\n",
       " 'middle': 589,\n",
       " 'short': 590,\n",
       " 'truly': 591,\n",
       " 'anger': 592,\n",
       " 'men': 593,\n",
       " 'e': 594,\n",
       " 'view': 595,\n",
       " 'wake': 596,\n",
       " 'etc': 597,\n",
       " 'serve': 598,\n",
       " 'shout': 599,\n",
       " 'uncle': 600,\n",
       " 'yourself': 601,\n",
       " 'must': 602,\n",
       " 'pregnant': 603,\n",
       " 'chance': 604,\n",
       " 'attack': 605,\n",
       " 'term': 606,\n",
       " 'probably': 607,\n",
       " 'dress': 608,\n",
       " 'male': 609,\n",
       " 'intend': 610,\n",
       " 't': 611,\n",
       " 'strong': 612,\n",
       " 'far': 613,\n",
       " 'affair': 614,\n",
       " 'camp': 615,\n",
       " 'today': 616,\n",
       " 'hell': 617,\n",
       " 'dirty': 618,\n",
       " 'ow': 619,\n",
       " \"ne'er\": 620,\n",
       " 'shut': 621,\n",
       " 'nobody': 622,\n",
       " 'arrive': 623,\n",
       " 'summer': 624,\n",
       " 'kinda': 625,\n",
       " 'scene': 626,\n",
       " 'cat': 627,\n",
       " 'although': 628,\n",
       " 'bear': 629,\n",
       " 'often': 630,\n",
       " 'flat': 631,\n",
       " 'leg': 632,\n",
       " 'wo': 633,\n",
       " 'floor': 634,\n",
       " 'fish': 635,\n",
       " 'upwards': 636,\n",
       " 'concern': 637,\n",
       " 'window': 638,\n",
       " 'blood': 639,\n",
       " 'mass': 640,\n",
       " 'operation': 641,\n",
       " 'trust': 642,\n",
       " 'beautiful': 643,\n",
       " 'low': 644,\n",
       " 'ya': 645,\n",
       " 'imagine': 646,\n",
       " 'news': 647,\n",
       " 'admit': 648,\n",
       " 'sort': 649,\n",
       " 'nox': 650,\n",
       " 'clean': 651,\n",
       " 'hello': 652,\n",
       " 'perform': 653,\n",
       " 'may': 654,\n",
       " 'air': 655,\n",
       " 'either': 656,\n",
       " 'invite': 657,\n",
       " 'outside': 658,\n",
       " 'heart': 659,\n",
       " 'consider': 660,\n",
       " 'hang': 661,\n",
       " 'soul': 662,\n",
       " 'mate': 663,\n",
       " 'emotion': 664,\n",
       " 'roommate': 665,\n",
       " 'glad': 666,\n",
       " 'couple': 667,\n",
       " 'power': 668,\n",
       " 'detest': 669,\n",
       " \"you'll\": 670,\n",
       " 'funny': 671,\n",
       " 'terrible': 672,\n",
       " 'joe': 673,\n",
       " 'alright': 674,\n",
       " 'ton': 675,\n",
       " 'dollar': 676,\n",
       " 'doctor': 677,\n",
       " 'choose': 678,\n",
       " 'crazy': 679,\n",
       " 'midterm': 680,\n",
       " 'individual': 681,\n",
       " 'quarrel': 682,\n",
       " 'anyone': 683,\n",
       " 'married': 684,\n",
       " 'v': 685,\n",
       " 'cancer': 686,\n",
       " 'select': 687,\n",
       " 'exactly': 688,\n",
       " 'naked': 689,\n",
       " 'ticket': 690,\n",
       " 'birthday': 691,\n",
       " 'everybody': 692,\n",
       " 'animal': 693,\n",
       " 'u': 694,\n",
       " 'dear': 695,\n",
       " 'beach': 696,\n",
       " 'nearly': 697,\n",
       " 'rach': 698,\n",
       " 'completely': 699,\n",
       " 'roll': 700,\n",
       " 'least': 701,\n",
       " 'fill': 702,\n",
       " 'kick': 703,\n",
       " 'due': 704,\n",
       " 'notice': 705,\n",
       " 'match': 706,\n",
       " 'colleague': 707,\n",
       " 'different': 708,\n",
       " 'anymore': 709,\n",
       " 'bye': 710,\n",
       " 'football': 711,\n",
       " 'foot': 712,\n",
       " 'fire': 713,\n",
       " 'cross': 714,\n",
       " 'hall': 715,\n",
       " 'mom': 716,\n",
       " 'noise': 717,\n",
       " 'war': 718,\n",
       " 'relation': 719,\n",
       " 'hundred': 720,\n",
       " 'excuse': 721,\n",
       " 'member': 722,\n",
       " 'period': 723,\n",
       " 'leader': 724,\n",
       " 'paper': 725,\n",
       " 'team': 726,\n",
       " 'twenty': 727,\n",
       " 'hardly': 728,\n",
       " 'prepare': 729,\n",
       " 'secondary': 730,\n",
       " 'sadness': 731,\n",
       " 'card': 732,\n",
       " 'wear': 733,\n",
       " 'position': 734,\n",
       " 'across': 735,\n",
       " 'shop': 736,\n",
       " 'b': 737,\n",
       " 'boat': 738,\n",
       " 'mortal': 739,\n",
       " 'grandfather': 740,\n",
       " 'accuse': 741,\n",
       " 'ready': 742,\n",
       " 'somewhere': 743,\n",
       " 'wife': 744,\n",
       " 'glass': 745,\n",
       " 'mad': 746,\n",
       " 'service': 747,\n",
       " 'police': 748,\n",
       " 'behaviour': 749,\n",
       " 'ooh': 750,\n",
       " 'difficult': 751,\n",
       " 'area': 752,\n",
       " 'swim': 753,\n",
       " 'chase': 754,\n",
       " 'ii': 755,\n",
       " 'strange': 756,\n",
       " 'route': 757,\n",
       " 'honey': 758,\n",
       " 'practice': 759,\n",
       " 'true': 760,\n",
       " 'stick': 761,\n",
       " 'soon': 762,\n",
       " 'city': 763,\n",
       " 'fault': 764,\n",
       " 'step': 765,\n",
       " 'seriously': 766,\n",
       " 'sexual': 767,\n",
       " 'daughter': 768,\n",
       " 'occur': 769,\n",
       " 'conversation': 770,\n",
       " 'public': 771,\n",
       " 'control': 772,\n",
       " 'cousin': 773,\n",
       " 'hot': 774,\n",
       " 'carry': 775,\n",
       " 'manner': 776,\n",
       " 'intimate': 777,\n",
       " 'rest': 778,\n",
       " 'red': 779,\n",
       " 'prison': 780,\n",
       " 'sign': 781,\n",
       " 'spot': 782,\n",
       " 'whenever': 783,\n",
       " 'augie': 784,\n",
       " 'yr': 785,\n",
       " 'monophosphate': 786,\n",
       " 'return': 787,\n",
       " 'don': 788,\n",
       " 'truth': 789,\n",
       " 'patient': 790,\n",
       " 'alike': 791,\n",
       " 'recently': 792,\n",
       " 'wonder': 793,\n",
       " 'field': 794,\n",
       " 'weekend': 795,\n",
       " \"friend's\": 796,\n",
       " 'allow': 797,\n",
       " 'attend': 798,\n",
       " 'finger': 799,\n",
       " 'newspaper': 800,\n",
       " 'fast': 801,\n",
       " 'anyway': 802,\n",
       " 'worry': 803,\n",
       " 'ten': 804,\n",
       " 'vacation': 805,\n",
       " 'climb': 806,\n",
       " 'champion': 807,\n",
       " 'country': 808,\n",
       " 'idol': 809,\n",
       " 'elbow': 810,\n",
       " 'mess': 811,\n",
       " \"we've\": 812,\n",
       " 'whose': 813,\n",
       " 'above': 814,\n",
       " 'operate': 815,\n",
       " 'insult': 816,\n",
       " 'six': 817,\n",
       " 'top': 818,\n",
       " 'pain': 819,\n",
       " 'machine': 820,\n",
       " 'seat': 821,\n",
       " 'opinion': 822,\n",
       " 'st': 823,\n",
       " 'save': 824,\n",
       " 'reach': 825,\n",
       " 'fourth': 826,\n",
       " 'snake': 827,\n",
       " 'reaction': 828,\n",
       " 'instructor': 829,\n",
       " 'table': 830,\n",
       " 'tonight': 831,\n",
       " 'clothes': 832,\n",
       " 'c': 833,\n",
       " 'kitchen': 834,\n",
       " 'himself': 835,\n",
       " 'entirely': 836,\n",
       " 'correspond': 837,\n",
       " 'concert': 838,\n",
       " 'succeed': 839,\n",
       " 'horror': 840,\n",
       " 'examn': 841,\n",
       " 'weird': 842,\n",
       " 'usually': 843,\n",
       " 'christmas': 844,\n",
       " 'draw': 845,\n",
       " \"o'clock\": 846,\n",
       " 'manage': 847,\n",
       " 'south': 848,\n",
       " 'sport': 849,\n",
       " 'security': 850,\n",
       " 'arrange': 851,\n",
       " 'ski': 852,\n",
       " 'sell': 853,\n",
       " 'offer': 854,\n",
       " 'shoot': 855,\n",
       " 'mistake': 856,\n",
       " 'funeral': 857,\n",
       " 'immortal': 858,\n",
       " 'divinity': 859,\n",
       " 'ar': 860,\n",
       " 'image': 861,\n",
       " 'ghost': 862,\n",
       " 'admirer': 863,\n",
       " \"you'd\": 864,\n",
       " 'rock': 865,\n",
       " 'herself': 866,\n",
       " 'pull': 867,\n",
       " 'office': 868,\n",
       " 'slip': 869,\n",
       " 'grow': 870,\n",
       " 'metre': 871,\n",
       " 'race': 872,\n",
       " 'coffee': 873,\n",
       " 'barely': 874,\n",
       " 'level': 875,\n",
       " 'g': 876,\n",
       " 'large': 877,\n",
       " 'future': 878,\n",
       " 'program': 879,\n",
       " 'rearward': 880,\n",
       " 'backward': 881,\n",
       " 'blame': 882,\n",
       " 'entrance': 883,\n",
       " 'assault': 884,\n",
       " 'selfish': 885,\n",
       " 'touch': 886,\n",
       " 'ball': 887,\n",
       " 'share': 888,\n",
       " 'meeting': 889,\n",
       " 'cover': 890,\n",
       " 'd': 891,\n",
       " 'joke': 892,\n",
       " 'theatre': 893,\n",
       " 'attitude': 894,\n",
       " 'cable': 895,\n",
       " 'deity': 896,\n",
       " 'ally': 897,\n",
       " 'tomorrow': 898,\n",
       " 'free': 899,\n",
       " 'appointment': 900,\n",
       " 'wh': 901,\n",
       " 'lay': 902,\n",
       " 'lead': 903,\n",
       " 'social': 904,\n",
       " 'condition': 905,\n",
       " 'supporter': 906,\n",
       " 'okey': 907,\n",
       " \"wear't\": 908,\n",
       " 'meter': 909,\n",
       " 'unknown': 910,\n",
       " 'revolt': 911,\n",
       " 'issue': 912,\n",
       " 'law': 913,\n",
       " 'restaurant': 914,\n",
       " 'station': 915,\n",
       " 'location': 916,\n",
       " 'laughter': 917,\n",
       " 'encounter': 918,\n",
       " 'personal': 919,\n",
       " 'its': 920,\n",
       " 'fair': 921,\n",
       " 'approach': 922,\n",
       " 'direction': 923,\n",
       " 'bike': 924,\n",
       " 'chris': 925,\n",
       " 'annie': 926,\n",
       " 'booster': 927,\n",
       " 'village': 928,\n",
       " 'sudden': 929,\n",
       " 'anybody': 930,\n",
       " 'hmm': 931,\n",
       " 'ignore': 932,\n",
       " 'trouble': 933,\n",
       " 'bathroom': 934,\n",
       " 'seven': 935,\n",
       " 'list': 936,\n",
       " 'babe': 937,\n",
       " 'argument': 938,\n",
       " 'ahh': 939,\n",
       " 'easy': 940,\n",
       " 'board': 941,\n",
       " 'midnight': 942,\n",
       " 'post': 943,\n",
       " 'language': 944,\n",
       " 'feature': 945,\n",
       " 'wind': 946,\n",
       " 'genuinely': 947,\n",
       " 'military': 948,\n",
       " 'unwashed': 949,\n",
       " 'till': 950,\n",
       " 'raymond': 951,\n",
       " 'box': 952,\n",
       " 'marriage': 953,\n",
       " 'jump': 954,\n",
       " 'stimulate': 955,\n",
       " 'thousand': 956,\n",
       " 'contact': 957,\n",
       " 'therefore': 958,\n",
       " 'army': 959,\n",
       " 'upwardly': 960,\n",
       " 'nigh': 961,\n",
       " 'lonely': 962,\n",
       " 'spit': 963,\n",
       " 'enjoy': 964,\n",
       " 'th': 965,\n",
       " 'janice': 966,\n",
       " 'dr': 967,\n",
       " 'apart': 968,\n",
       " 'black': 969,\n",
       " 'heavy': 970,\n",
       " 'comparable': 971,\n",
       " 'dimension': 972,\n",
       " 'incident': 973,\n",
       " 'terrify': 974,\n",
       " 'frightened': 975,\n",
       " 'church': 976,\n",
       " 'unza': 977,\n",
       " 'vomit': 978,\n",
       " 'amount': 979,\n",
       " 'apartment': 980,\n",
       " 'smoke': 981,\n",
       " 'realise': 982,\n",
       " 'plate': 983,\n",
       " 'possible': 984,\n",
       " 'shoe': 985,\n",
       " 'quiet': 986,\n",
       " 'particular': 987,\n",
       " 'deuce': 988,\n",
       " 'political': 989,\n",
       " 'induce': 990,\n",
       " 'lift': 991,\n",
       " 'forest': 992,\n",
       " 'beside': 993,\n",
       " 'apply': 994,\n",
       " 'radio': 995,\n",
       " 'fare': 996,\n",
       " 'tight': 997,\n",
       " 'worker': 998,\n",
       " 'include': 999,\n",
       " \"one'm\": 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizerNormal.word_index\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec concatenado con FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['also',\n",
       "  'i',\n",
       "  'be',\n",
       "  'the',\n",
       "  'point',\n",
       "  'person',\n",
       "  'on',\n",
       "  'my',\n",
       "  \"company's\",\n",
       "  'transition',\n",
       "  'from',\n",
       "  'the',\n",
       "  'kl',\n",
       "  'to',\n",
       "  'gr',\n",
       "  'system.'],\n",
       " ['you', \"must've\", 'have', 'your', 'hand', 'full.'],\n",
       " ['that', 'i', 'do.', 'that', 'i', 'do.'],\n",
       " ['so', \"let's\", 'talk', 'a', 'little', 'bit', 'about', 'your', 'duty.'],\n",
       " ['now',\n",
       "  \"you'll\",\n",
       "  'be',\n",
       "  'head',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'division',\n",
       "  'so',\n",
       "  \"you'll\",\n",
       "  'have',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'duty.'],\n",
       " ['i', 'see.'],\n",
       " ['but',\n",
       "  \"there'll\",\n",
       "  'be',\n",
       "  'perhaps',\n",
       "  'people',\n",
       "  'under',\n",
       "  'you',\n",
       "  'so',\n",
       "  'you',\n",
       "  'can',\n",
       "  'dump',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'amount',\n",
       "  'on',\n",
       "  'them.'],\n",
       " ['good', 'to', 'know.'],\n",
       " ['we', 'can', 'go', 'into', 'detail'],\n",
       " ['all',\n",
       "  'right',\n",
       "  'then',\n",
       "  \"we'll\",\n",
       "  'have',\n",
       "  'a',\n",
       "  'definite',\n",
       "  'answer',\n",
       "  'for',\n",
       "  'you',\n",
       "  'on',\n",
       "  'monday',\n",
       "  'but',\n",
       "  'i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'can',\n",
       "  'say',\n",
       "  'with',\n",
       "  'some',\n",
       "  'confidence',\n",
       "  \"you'll\",\n",
       "  'fit',\n",
       "  'in',\n",
       "  'well',\n",
       "  'here.'],\n",
       " ['absolutely.', 'you', 'can', 'relax'],\n",
       " ['ok!'],\n",
       " ['all', 'right', 'well...'],\n",
       " ['yeah', 'sure!'],\n",
       " ['hey', 'mon.'],\n",
       " ['hey',\n",
       "  'hey',\n",
       "  'hey.',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'hear',\n",
       "  'something',\n",
       "  'that',\n",
       "  'suck.'],\n",
       " ['yeah',\n",
       "  'apparently',\n",
       "  \"they're\",\n",
       "  'turn',\n",
       "  'it',\n",
       "  'into',\n",
       "  'some',\n",
       "  'kinda',\n",
       "  'coffee',\n",
       "  'place.'],\n",
       " ['can', 'i', 'get', 'a', 'beer.'],\n",
       " ['hey', 'do', 'you', 'pick', 'a', 'roommate?'],\n",
       " ['be', 'it', 'the', 'italian', 'guy?'],\n",
       " ['he', 'be', 'with', 'her', 'when', 'he', 'write', 'this', 'poem.'],\n",
       " [\"look'my\", 'vessel', 'so', 'empty', 'with', 'nothing', 'inside.'],\n",
       " ['now', 'that', \"i've\", 'touch', 'you', 'you', 'seem', 'empty', \"still.'\"],\n",
       " ['do.'],\n",
       " ['ah',\n",
       "  \"y'know\",\n",
       "  'this',\n",
       "  'building',\n",
       "  'be',\n",
       "  'on',\n",
       "  'my',\n",
       "  'paper',\n",
       "  'route',\n",
       "  'so',\n",
       "  'i...'],\n",
       " ['oh.'],\n",
       " ['hi.'],\n",
       " ['hi.'],\n",
       " [\"how'd\", 'do', 'it', 'go?'],\n",
       " ['i', 'know.'],\n",
       " ['yeah.'],\n",
       " ['yeah.'],\n",
       " ['ameri', 'can.'],\n",
       " ['ameri', 'ccan.'],\n",
       " ['ameri', 'can.', \"y'know\", \"it's\", 'a'],\n",
       " ['which', 'part', 'exactly?'],\n",
       " ['the', 'whole', 'thing!', 'can', 'we', 'go?'],\n",
       " ['hey',\n",
       "  'what',\n",
       "  'about',\n",
       "  'the',\n",
       "  'scene',\n",
       "  'with',\n",
       "  'the',\n",
       "  'kangaroo?',\n",
       "  'do',\n",
       "  'do',\n",
       "  'you',\n",
       "  'like',\n",
       "  'that',\n",
       "  'part?'],\n",
       " [\"that's\", 'for', 'come', 'buddy.'],\n",
       " [\"i'll\", 'see', 'you', 'later.'],\n",
       " ['okay',\n",
       "  'look',\n",
       "  'i',\n",
       "  'think',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'rachel',\n",
       "  'she',\n",
       "  'mess',\n",
       "  'up',\n",
       "  'her',\n",
       "  'dessert.'],\n",
       " ['yes',\n",
       "  'and',\n",
       "  'it',\n",
       "  'be',\n",
       "  'my',\n",
       "  'die',\n",
       "  'wish',\n",
       "  'to',\n",
       "  'have',\n",
       "  'that',\n",
       "  'ring.'],\n",
       " ['see',\n",
       "  'if',\n",
       "  \"i'm\",\n",
       "  'not',\n",
       "  'bury',\n",
       "  'with',\n",
       "  'that',\n",
       "  'ring',\n",
       "  'then',\n",
       "  'my',\n",
       "  'spirit',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'wander',\n",
       "  'the',\n",
       "  'nether',\n",
       "  'world',\n",
       "  'for',\n",
       "  'all',\n",
       "  'eternity'],\n",
       " ['okay', \"that's\", 'enough', 'honey!'],\n",
       " ['i', 'do', \"n't\", 'know.', 'let', 'me', 'see', 'the', 'ring.'],\n",
       " ['all', 'right.'],\n",
       " [\"what've\", 'you', 'be', 'up', 'to?'],\n",
       " ['oh',\n",
       "  'you',\n",
       "  'know',\n",
       "  'the',\n",
       "  'usual',\n",
       "  'teaching',\n",
       "  'aerobics',\n",
       "  'party',\n",
       "  'way',\n",
       "  'too',\n",
       "  'much.'],\n",
       " ['oh',\n",
       "  'and',\n",
       "  'in',\n",
       "  'case',\n",
       "  'you',\n",
       "  'be',\n",
       "  'wonder',\n",
       "  'those',\n",
       "  'be',\n",
       "  'my',\n",
       "  'leg',\n",
       "  'on',\n",
       "  'the',\n",
       "  'new',\n",
       "  'james',\n",
       "  'bond',\n",
       "  'poster.'],\n",
       " ['i', 'know.'],\n",
       " [\"i'm\", 'back.'],\n",
       " ['so', 'be', 'we', 'gon', 'na', 'get', 'together', 'or', 'what?'],\n",
       " ['um',\n",
       "  'absolutely.',\n",
       "  'uh',\n",
       "  \"how'bout\",\n",
       "  'tomorrow',\n",
       "  'afternoon?',\n",
       "  'do',\n",
       "  'you',\n",
       "  'know',\n",
       "  'uh',\n",
       "  'central',\n",
       "  'perk',\n",
       "  'in',\n",
       "  'the',\n",
       "  'village',\n",
       "  'say',\n",
       "  'five',\n",
       "  'ish?'],\n",
       " ['great', \"i'll\", 'see', 'you', 'then.'],\n",
       " ['even',\n",
       "  'though',\n",
       "  'you',\n",
       "  'do',\n",
       "  'do',\n",
       "  'a',\n",
       "  'good',\n",
       "  'bob',\n",
       "  'impression',\n",
       "  \"i'm\",\n",
       "  \"thinkin'when\",\n",
       "  'she',\n",
       "  'see',\n",
       "  'you',\n",
       "  'tomorow',\n",
       "  \"she's\",\n",
       "  'probably',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'realize',\n",
       "  'hey',\n",
       "  \"you're\",\n",
       "  'not',\n",
       "  'bob.'],\n",
       " [\"i'm\",\n",
       "  'hop',\n",
       "  'that',\n",
       "  'when',\n",
       "  'bob',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'show',\n",
       "  'up',\n",
       "  'she',\n",
       "  'will',\n",
       "  'seek',\n",
       "  'comfort',\n",
       "  'in',\n",
       "  'the',\n",
       "  'open',\n",
       "  'arm',\n",
       "  'of',\n",
       "  'the',\n",
       "  'wry',\n",
       "  'stranger',\n",
       "  'at',\n",
       "  'the',\n",
       "  'next',\n",
       "  'table.'],\n",
       " ['no.'],\n",
       " ['this', 'be', 'my', 'wedding.'],\n",
       " ['fine.',\n",
       "  \"you'll\",\n",
       "  \"you'll\",\n",
       "  'watch',\n",
       "  'it',\n",
       "  'on',\n",
       "  'video',\n",
       "  'when',\n",
       "  'we',\n",
       "  'get',\n",
       "  'back.'],\n",
       " ['thank', 'you.'],\n",
       " ['thank', 'you.'],\n",
       " ['hey!'],\n",
       " ['nothing!'],\n",
       " ['but', 'um', 'i', 'do', \"n't\", 'think', \"it's\", 'anything', 'serious.'],\n",
       " ['uh',\n",
       "  \"that's\",\n",
       "  'an',\n",
       "  'eighteenth',\n",
       "  'century',\n",
       "  'indian',\n",
       "  'artifact',\n",
       "  'from',\n",
       "  'calcutta.'],\n",
       " ['so', 'much', 'more.'],\n",
       " ['well',\n",
       "  'well',\n",
       "  'to',\n",
       "  'sum',\n",
       "  'up',\n",
       "  \"we're\",\n",
       "  'have',\n",
       "  'fun',\n",
       "  'you',\n",
       "  'look',\n",
       "  'young.'],\n",
       " ['okay'],\n",
       " ['but',\n",
       "  \"that's\",\n",
       "  'not',\n",
       "  'enough.',\n",
       "  'so',\n",
       "  'so',\n",
       "  \"here's\",\n",
       "  'a',\n",
       "  'key',\n",
       "  'to',\n",
       "  'my',\n",
       "  'apartment.'],\n",
       " ['really.'],\n",
       " ['you', 'do', \"n't\", 'think', 'this', 'be', 'too', 'fast.'],\n",
       " ['ross', 'can', 'i', 'talk', 'to', 'you', 'for', 'a', 'minute?'],\n",
       " ['yes', 'please!', 'so', \"what's\", 'go', 'on?'],\n",
       " ['hey', 'you', 'ok?'],\n",
       " ['there',\n",
       "  'be',\n",
       "  'hum...',\n",
       "  'there',\n",
       "  'be',\n",
       "  'another',\n",
       "  'reason',\n",
       "  'that',\n",
       "  'i',\n",
       "  'think',\n",
       "  'it',\n",
       "  'be',\n",
       "  'time',\n",
       "  'to',\n",
       "  'end',\n",
       "  'it',\n",
       "  'with',\n",
       "  'joey.'],\n",
       " ['i',\n",
       "  'start',\n",
       "  'to',\n",
       "  'realize',\n",
       "  'that',\n",
       "  'i',\n",
       "  'be',\n",
       "  'have',\n",
       "  'feeling',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'else.'],\n",
       " ['ok',\n",
       "  'geller.',\n",
       "  'last',\n",
       "  'day',\n",
       "  'of',\n",
       "  'the',\n",
       "  'conference',\n",
       "  'you',\n",
       "  'know',\n",
       "  'what',\n",
       "  'happen',\n",
       "  'to',\n",
       "  'the',\n",
       "  'keynote',\n",
       "  'speaker.'],\n",
       " ['oh',\n",
       "  'professor',\n",
       "  'clerk',\n",
       "  \"we're\",\n",
       "  'kind',\n",
       "  'of',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'a',\n",
       "  'conversation',\n",
       "  'here.'],\n",
       " ['yeah',\n",
       "  'can',\n",
       "  'you',\n",
       "  'guy',\n",
       "  'just',\n",
       "  'throw',\n",
       "  'him',\n",
       "  'in',\n",
       "  'the',\n",
       "  'pool',\n",
       "  'later?'],\n",
       " ['i', 'mean', \"we're\", 'scientist', 'right?'],\n",
       " ['oh', 'yeah', 'bob', 'say', 'there', 'might', 'be', 'flood', 'damage.'],\n",
       " ['yeah', 'either', 'that', 'or', 'he', 'have', 'a', 'really', 'big', 'cat.'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'say',\n",
       "  'big',\n",
       "  'lima',\n",
       "  'bean',\n",
       "  'bubble',\n",
       "  'up.',\n",
       "  'would',\n",
       "  'she',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'difference?'],\n",
       " ['rach?', 'what', 'be', 'you', 'do?'],\n",
       " [\"it's\", 'a', 'diaper', 'commercial.'],\n",
       " ['hey',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'get',\n",
       "  'something',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'or',\n",
       "  'uh',\n",
       "  'do',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'see',\n",
       "  'how',\n",
       "  'long',\n",
       "  'we',\n",
       "  'can',\n",
       "  'throw',\n",
       "  'this',\n",
       "  'ball',\n",
       "  'back',\n",
       "  'and',\n",
       "  'forth?',\n",
       "  'huh?'],\n",
       " ['uhh', 'the', 'ball', 'thing.'],\n",
       " ['yeah?'],\n",
       " ['uhh'],\n",
       " ['what?'],\n",
       " ['hey.'],\n",
       " ['hey!'],\n",
       " ['how', 'do', 'it', 'go', 'with', 'erin?'],\n",
       " [\"y'know?\"],\n",
       " ['that', 'be', 'so', 'awkward', 'we', 'be', 'really', 'nervous.'],\n",
       " ['do', \"n't\", 'you', 'sleep', 'together?'],\n",
       " ['yeah', 'that', 'really', 'calm', 'me', 'down.'],\n",
       " ['okay.'],\n",
       " ['i', 'can', 'not', 'sleep', 'in', 'a', 'public', 'place.'],\n",
       " [\"it's\", 'okay', \"y'know\", 'you', 'just', 'nod', 'off', 'again.'],\n",
       " ['why?'],\n",
       " ['oh', 'and', 'deaf.'],\n",
       " ['so',\n",
       "  \"they're\",\n",
       "  'constantly',\n",
       "  'like',\n",
       "  'have',\n",
       "  'to',\n",
       "  'reassure',\n",
       "  'each',\n",
       "  'other',\n",
       "  'that',\n",
       "  \"they're\",\n",
       "  'have',\n",
       "  'a',\n",
       "  'good',\n",
       "  'time.'],\n",
       " ['well',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'you',\n",
       "  'can',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'rachel',\n",
       "  'and',\n",
       "  'me',\n",
       "  'tonight.'],\n",
       " [\"it's\", 'just', 'her', 'water', 'breaking.', 'calm', 'down', 'will', 'you?'],\n",
       " ['breathe', 'breathe', 'breathe.'],\n",
       " ['i', 'mean', 'be', 'it', 'gina?'],\n",
       " ['which', 'one', 'be', 'gina?'],\n",
       " ['dark', 'big', 'hair', 'with', 'the', 'airplane', 'earring.'],\n",
       " ['no', 'no', 'no', \"that's\", 'dina.'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'know',\n",
       "  'you',\n",
       "  'think',\n",
       "  'see',\n",
       "  'you',\n",
       "  \"saturday'was\",\n",
       "  'funny.'],\n",
       " ['look',\n",
       "  'honey',\n",
       "  'mark',\n",
       "  'be',\n",
       "  'in',\n",
       "  'fashion',\n",
       "  'okay',\n",
       "  'i',\n",
       "  'like',\n",
       "  'have',\n",
       "  'a',\n",
       "  'friend',\n",
       "  'that',\n",
       "  'i',\n",
       "  'can',\n",
       "  'share',\n",
       "  'this',\n",
       "  'stuff',\n",
       "  'with.'],\n",
       " ['you',\n",
       "  'guy',\n",
       "  'would',\n",
       "  'never',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'a',\n",
       "  'lecture',\n",
       "  'with',\n",
       "  'me.'],\n",
       " ['yeah',\n",
       "  'hey',\n",
       "  'i',\n",
       "  'i',\n",
       "  'have',\n",
       "  'clothes',\n",
       "  'i',\n",
       "  'even',\n",
       "  'pick',\n",
       "  'them',\n",
       "  'out.'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'for',\n",
       "  'all',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'could',\n",
       "  'be',\n",
       "  'a',\n",
       "  'fashion.....',\n",
       "  'monger.'],\n",
       " ['yeah.'],\n",
       " ['unless',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'practice',\n",
       "  'the',\n",
       "  'foxtrot',\n",
       "  'again?',\n",
       "  'or',\n",
       "  'or',\n",
       "  'the',\n",
       "  'tango?'],\n",
       " ['ahh',\n",
       "  'thanks',\n",
       "  'but',\n",
       "  'no.',\n",
       "  'you',\n",
       "  'see',\n",
       "  'i',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"i'm\",\n",
       "  'ready',\n",
       "  'to',\n",
       "  'dance',\n",
       "  'with',\n",
       "  'girl.'],\n",
       " ['okay.'],\n",
       " ['yeah.'],\n",
       " ['go', 'get', 'em', 'treeger.'],\n",
       " ['right.',\n",
       "  'hey',\n",
       "  'ahh',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'come?',\n",
       "  'marge',\n",
       "  'have',\n",
       "  'a',\n",
       "  'girlfriend.'],\n",
       " ['yeah',\n",
       "  'you',\n",
       "  'could',\n",
       "  'dance',\n",
       "  'real',\n",
       "  'good',\n",
       "  'with',\n",
       "  'her',\n",
       "  \"she's\",\n",
       "  'the',\n",
       "  'same',\n",
       "  'size',\n",
       "  'as',\n",
       "  'me.'],\n",
       " ['no', \"i'm\", 'good.'],\n",
       " ['well', 'unfortunately', 'i', 'do', \"n't\", 'get', 'many', 'callback', 'so'],\n",
       " ['who', 'know?'],\n",
       " ['okay',\n",
       "  'uh',\n",
       "  'we',\n",
       "  'have',\n",
       "  'narrow',\n",
       "  'it',\n",
       "  'down',\n",
       "  'to',\n",
       "  'raymond',\n",
       "  'ben',\n",
       "  'kyle',\n",
       "  'and',\n",
       "  'joey.',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'you',\n",
       "  'thank',\n",
       "  'you',\n",
       "  'very',\n",
       "  'much.'],\n",
       " ['actually', 'that', 'ca', \"n't\", 'happen.'],\n",
       " ['yeah',\n",
       "  'because',\n",
       "  'you',\n",
       "  'all',\n",
       "  'have',\n",
       "  'such',\n",
       "  'different',\n",
       "  'look',\n",
       "  \"we're\",\n",
       "  'put',\n",
       "  'you',\n",
       "  'with',\n",
       "  'raymond',\n",
       "  'and',\n",
       "  'kyle',\n",
       "  'with',\n",
       "  'ben.'],\n",
       " ['so', \"it'll\", 'be', 'either', 'you', 'two', 'or', 'you', 'two.'],\n",
       " ['yeah', 'it', 'be.'],\n",
       " ['no',\n",
       "  'we',\n",
       "  \"we're\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'be',\n",
       "  'like',\n",
       "  'best',\n",
       "  'friend',\n",
       "  \"that's\",\n",
       "  'why',\n",
       "  \"it's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'be',\n",
       "  'weird.'],\n",
       " ['ok',\n",
       "  \"i'm\",\n",
       "  'sense',\n",
       "  'that',\n",
       "  'this',\n",
       "  'be',\n",
       "  'some',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'word',\n",
       "  'play',\n",
       "  'because',\n",
       "  'you',\n",
       "  'be',\n",
       "  'pink',\n",
       "  'with',\n",
       "  'barely',\n",
       "  'control',\n",
       "  'glee.'],\n",
       " ['i'],\n",
       " ['oh', \"that's\", 'not', 'what', 'you', 'want...'],\n",
       " ['this',\n",
       "  'be',\n",
       "  'my',\n",
       "  'father',\n",
       "  'paul',\n",
       "  'stevens.',\n",
       "  'dad',\n",
       "  'this',\n",
       "  'be',\n",
       "  'ross',\n",
       "  'geller.'],\n",
       " ['i',\n",
       "  'usually',\n",
       "  'prefer',\n",
       "  \"elizabeth's\",\n",
       "  'boyfriend',\n",
       "  'to',\n",
       "  'address',\n",
       "  'me',\n",
       "  'as',\n",
       "  'mr.',\n",
       "  'stevens.'],\n",
       " ['of', 'course', 'of', 'course', 'mr.', 'stevens.'],\n",
       " ['i'],\n",
       " ['okay.'],\n",
       " ['i', 'can', 'i', 'can', 'see', 'that.'],\n",
       " ['okay.'],\n",
       " ['what?'],\n",
       " ['oh', 'well', \"it's\", 'not', 'on', 'tv', 'yet.'],\n",
       " ['well', 'then', \"it's\", 'not', 'on', 'the', 'wall', 'yet.'],\n",
       " ['okay', 'fine', 'i', 'will', 'bring', 'you', 'a', 'tape', 'huh?'],\n",
       " ['so',\n",
       "  'umm',\n",
       "  'now',\n",
       "  'do',\n",
       "  'you',\n",
       "  'have',\n",
       "  'any',\n",
       "  'of',\n",
       "  'matt',\n",
       "  \"lauer's\",\n",
       "  'clothes',\n",
       "  'here?',\n",
       "  'maybe?',\n",
       "  'just',\n",
       "  'one',\n",
       "  'that',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'clean',\n",
       "  'yet?'],\n",
       " ['oh',\n",
       "  'yeah',\n",
       "  \"i'm\",\n",
       "  'sure.',\n",
       "  'and',\n",
       "  'all',\n",
       "  'of',\n",
       "  'a',\n",
       "  'sudden',\n",
       "  'his',\n",
       "  'hand',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'the',\n",
       "  'problem',\n",
       "  'anymore.'],\n",
       " ['oh', 'boy', 'scout', 'could', 'have', 'camp', 'under', 'there.'],\n",
       " ['uma', 'thurman.'],\n",
       " ['thanks', 'rach.'],\n",
       " ['oh', 'yeah', 'you', 'have', 'to', 'tell', 'her.'],\n",
       " ['feminist', 'issue.', \"that's\", 'where', 'i', 'go!'],\n",
       " ['yeah', 'well...'],\n",
       " ['yeah', 'yeah', 'you', 'have', 'the', 'ring?'],\n",
       " ['yeah', 'right', 'here', 'in', 'my', 'pocket.', 'pheebs?'],\n",
       " ['okay',\n",
       "  'now',\n",
       "  'will',\n",
       "  'you',\n",
       "  'guy',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'here?',\n",
       "  'i',\n",
       "  'want',\n",
       "  'this',\n",
       "  'be',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'surprise',\n",
       "  'and',\n",
       "  \"she's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'know.'],\n",
       " ['yeah', 'yeah', 'you', 'guy.', 'get', 'out', 'of', 'here!'],\n",
       " ['hi', 'guy.'],\n",
       " [\"we're\",\n",
       "  'just',\n",
       "  'really',\n",
       "  'very',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'this',\n",
       "  'charity',\n",
       "  'event',\n",
       "  'that',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to.'],\n",
       " ['okay', 'umm', 'ross?'],\n",
       " [\"i'm\",\n",
       "  \"i'm\",\n",
       "  'really',\n",
       "  'warm',\n",
       "  'so',\n",
       "  \"i'm\",\n",
       "  'go',\n",
       "  'to',\n",
       "  'be',\n",
       "  'take',\n",
       "  'off',\n",
       "  'my',\n",
       "  'sweater.'],\n",
       " ['now', \"i'm\", 'just', 'let', 'you', 'know', 'that', 'this', 'be'],\n",
       " [\"i'm\", 'sorry.', \"i'm\", 'do.', \"i'm\", 'do.'],\n",
       " [\"y'know\", 'last', 'night', 'be', 'embarrass', 'for', 'you', 'too.'],\n",
       " ['no',\n",
       "  'not',\n",
       "  'really.',\n",
       "  'i',\n",
       "  'mean',\n",
       "  \"you've\",\n",
       "  'see',\n",
       "  'me',\n",
       "  'naked',\n",
       "  'hundred',\n",
       "  'of',\n",
       "  'time.'],\n",
       " ['uh',\n",
       "  'huh.',\n",
       "  'but',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'first',\n",
       "  'for',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'my',\n",
       "  'building.'],\n",
       " ['okay.',\n",
       "  'all',\n",
       "  'right',\n",
       "  \"that's\",\n",
       "  'true!',\n",
       "  'but',\n",
       "  \"y'know\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'embarrass',\n",
       "  'that',\n",
       "  'easily.'],\n",
       " ['no',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't!\",\n",
       "  'ross',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  'a',\n",
       "  'more',\n",
       "  'secure',\n",
       "  'person',\n",
       "  'than',\n",
       "  'you',\n",
       "  'be.'],\n",
       " ['be', 'that', 'so?'],\n",
       " ['yeah.'],\n",
       " ['hey', 'both', 'you', 'guy', 'should', 'be', 'up', 'there', 'with', 'me.'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  'you',\n",
       "  'two',\n",
       "  'be',\n",
       "  'be',\n",
       "  'my',\n",
       "  'i',\n",
       "  'mean',\n",
       "  \"i'm\",\n",
       "  'lucky',\n",
       "  'to',\n",
       "  'have',\n",
       "  'just',\n",
       "  'one',\n",
       "  'good'],\n",
       " ['thanks', 'man.'],\n",
       " ['i', 'get', 'ta', 'go', 'check', 'something', 'over', 'here.'],\n",
       " ['okay',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'option',\n",
       "  'here',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'prototype',\n",
       "  'for',\n",
       "  'you',\n",
       "  'to',\n",
       "  'try',\n",
       "  'on.'],\n",
       " ['call', 'it', 'even?!'],\n",
       " ['well', \"i'm\", 'gon', 'na', 'go', 'get', 'these', 'in', 'some', 'water.'],\n",
       " ['no', 'no', 'i', 'take', 'them', 'from', 'the', 'hotel', 'lobby.'],\n",
       " ['i', 'have', 'a', 'question', 'about', 'this', 'scene.'],\n",
       " ['yes?'],\n",
       " ['peel', 'the', 'onion.', 'first', 'of', 'all', \"he's\", 'good', 'look.'],\n",
       " ['yeah.'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'my',\n",
       "  \"character's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'need',\n",
       "  'a',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'more',\n",
       "  'of',\n",
       "  'reason',\n",
       "  'than',\n",
       "  'that.'],\n",
       " ['oh', 'hey', 'how', 'about', 'this', 'one.'],\n",
       " [\"y'know\", 'who', 'have', 'a', 'great', 'video', 'camera?'],\n",
       " ['greg', 'and', 'jenny?'],\n",
       " ['do',\n",
       "  'you',\n",
       "  'still',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'call',\n",
       "  'em?',\n",
       "  'i',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'call',\n",
       "  'em.'],\n",
       " [\"let's\", 'call', 'em.'],\n",
       " ['hello?', 'eighth', 'street', 'deli?'],\n",
       " ['here', 'you', 'go.'],\n",
       " ['her', \"name's\", 'ronni.', \"she's\", 'a', 'pet', 'mortician.'],\n",
       " ['sure.', 'so', 'how', 'long', 'you', 'be...'],\n",
       " ['remember',\n",
       "  'when',\n",
       "  'you',\n",
       "  'be',\n",
       "  'a',\n",
       "  'little',\n",
       "  'kid',\n",
       "  'i',\n",
       "  'use',\n",
       "  'to',\n",
       "  'take',\n",
       "  'you',\n",
       "  'to',\n",
       "  'the',\n",
       "  'navy',\n",
       "  'yard',\n",
       "  'and',\n",
       "  'show',\n",
       "  'you',\n",
       "  'the',\n",
       "  'big',\n",
       "  'ship?'],\n",
       " ['no', \"it's\", 'only', 'be', 'six', 'year.'],\n",
       " ['i',\n",
       "  'just',\n",
       "  'want',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'memory',\n",
       "  'in',\n",
       "  'your',\n",
       "  'head',\n",
       "  'so',\n",
       "  \"you'd\",\n",
       "  'know',\n",
       "  'that',\n",
       "  'i',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'always',\n",
       "  'such',\n",
       "  'a',\n",
       "  'terrible',\n",
       "  'guy.'],\n",
       " ['...', 'joe.'],\n",
       " [\"y'ever\", 'be', 'in', 'love?'],\n",
       " ['...', 'i', \"d'know.\"],\n",
       " ['then', \"y'have\", \"n't.\", \"you're\", 'burn', 'your', 'tomato.'],\n",
       " ['joe',\n",
       "  'your',\n",
       "  \"dad's\",\n",
       "  'in',\n",
       "  'love',\n",
       "  'big',\n",
       "  'time.',\n",
       "  'and',\n",
       "  'the',\n",
       "  'bad',\n",
       "  'part',\n",
       "  'of',\n",
       "  'it',\n",
       "  'be',\n",
       "  \"it's\",\n",
       "  'with',\n",
       "  'two',\n",
       "  'different',\n",
       "  'woman.'],\n",
       " [\"everything's\", 'gon', 'na', 'be', 'all', 'right.', 'okay', 'dick?'],\n",
       " ['hey', 'rach', 'how', 'be', 'work?'],\n",
       " ['oh',\n",
       "  'great.',\n",
       "  'although',\n",
       "  'i',\n",
       "  'do',\n",
       "  'sit',\n",
       "  'down',\n",
       "  'where',\n",
       "  'there',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'a',\n",
       "  'chair.'],\n",
       " ['by',\n",
       "  'the',\n",
       "  'way',\n",
       "  'ross',\n",
       "  'drop',\n",
       "  'by',\n",
       "  'a',\n",
       "  'box',\n",
       "  'of',\n",
       "  'your',\n",
       "  'stuff.'],\n",
       " ['oh', 'well', 'i', 'guess', 'i', 'have', 'that', 'one', 'come.'],\n",
       " [\"i'm\",\n",
       "  'just',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'throw',\n",
       "  'it',\n",
       "  'out',\n",
       "  \"it's\",\n",
       "  'probably',\n",
       "  'just',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'shampoo',\n",
       "  'and...'],\n",
       " ['something', 'wrong?'],\n",
       " ['no.', 'nothing.'],\n",
       " ['and',\n",
       "  'then',\n",
       "  'and',\n",
       "  'then',\n",
       "  'you',\n",
       "  'say',\n",
       "  'that',\n",
       "  'thing',\n",
       "  'about',\n",
       "  'about',\n",
       "  'bring',\n",
       "  'the',\n",
       "  'mesozoic',\n",
       "  'era',\n",
       "  'in',\n",
       "  'the',\n",
       "  'st',\n",
       "  'century.'],\n",
       " ['yeah.'],\n",
       " [\"it's\", 'not', 'that', 'bad.'],\n",
       " ['so', \"you're\", 'just', 'bing?'],\n",
       " ['all', 'right', 'cut', \"let's\", 'pick', 'again', 'pick', 'again.'],\n",
       " ['okay.'],\n",
       " ['why?!'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'we',\n",
       "  'bring',\n",
       "  'enough',\n",
       "  'stuff.',\n",
       "  'do',\n",
       "  'you',\n",
       "  'forget',\n",
       "  'to',\n",
       "  'pack',\n",
       "  'the',\n",
       "  \"baby's\",\n",
       "  'anvil?'],\n",
       " [\"it's\", 'gon', 'na', 'be', 'worth', 'it.'],\n",
       " [\"it's\",\n",
       "  'a',\n",
       "  'known',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'woman',\n",
       "  'love',\n",
       "  'baby',\n",
       "  'all',\n",
       "  'right?'],\n",
       " ['woman', 'love', 'guy', 'who', 'love', 'baby.'],\n",
       " [\"it's\", 'that', 'whole', 'sensitive', 'thing.'],\n",
       " ['quick', 'aim', 'him', 'at', 'that', 'pack', \"o'babes\", 'over', 'there.'],\n",
       " ['maybe', 'one', 'of', 'them', 'will', 'break', 'away.'],\n",
       " ['all', 'right', 'gim', 'me', 'the', 'baby.'],\n",
       " ['no', 'i', 'get', 'him.'],\n",
       " ['hello.'],\n",
       " ['you', 'wan', 'na', 'smell', 'him?'],\n",
       " ['well', 'we', 'be', 'great', 'guy.'],\n",
       " ['bye.'],\n",
       " ['well', 'not', 'really.'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  'technically',\n",
       "  \"it's\",\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'against',\n",
       "  'the',\n",
       "  'rule',\n",
       "  'or',\n",
       "  'anything',\n",
       "  'but',\n",
       "  'it',\n",
       "  'be',\n",
       "  'frown',\n",
       "  'upon.'],\n",
       " ['well', 'ross', 'it', 'seem', 'pretty', 'clear.'],\n",
       " ['i', 'mean', \"what's\", 'more', 'important?'],\n",
       " ['what', 'people', 'think', 'or', 'how', 'you', 'feel', 'huh?'],\n",
       " ['ross', 'you', 'get', 'ta', 'follow', 'your', 'heart.'],\n",
       " ['hey.'],\n",
       " ['hey',\n",
       "  'hey',\n",
       "  'hey!',\n",
       "  'so',\n",
       "  'how',\n",
       "  'do',\n",
       "  'it',\n",
       "  'go',\n",
       "  'with',\n",
       "  'dana?',\n",
       "  'any',\n",
       "  'reason',\n",
       "  'i',\n",
       "  'should',\n",
       "  'leave',\n",
       "  'a',\n",
       "  'block',\n",
       "  'of',\n",
       "  'time',\n",
       "  'open',\n",
       "  'say',\n",
       "  'thursday?'],\n",
       " ['hey',\n",
       "  'relax',\n",
       "  'i',\n",
       "  'just',\n",
       "  'need',\n",
       "  'more',\n",
       "  'time.',\n",
       "  \"we're\",\n",
       "  'go',\n",
       "  'to',\n",
       "  'dinner',\n",
       "  'tonight.'],\n",
       " ['go', 'out', 'with', 'who?'],\n",
       " ['uh', 'dana', 'keystone', 'from', 'college.'],\n",
       " ['no', 'that', 'be', 'dana', 'caplin.'],\n",
       " ['all', 'right.'],\n",
       " ['umm', 'all', 'right', 'wayne', 'level', 'with', 'me.'],\n",
       " ['here', 'you', 'go!'],\n",
       " ['okay?'],\n",
       " ['hey', 'how', 'you', \"doin'?\"],\n",
       " ['hey.'],\n",
       " ['no',\n",
       "  'hey',\n",
       "  'well',\n",
       "  'i',\n",
       "  'i',\n",
       "  'completely',\n",
       "  'understand.',\n",
       "  'you',\n",
       "  'be',\n",
       "  'you',\n",
       "  'be',\n",
       "  'stress.'],\n",
       " ['i', 'know.'],\n",
       " ['what?'],\n",
       " ['but', 'i', 'ca', \"n't\", 'tell', 'you.'],\n",
       " ['okay',\n",
       "  'but',\n",
       "  'would',\n",
       "  \"n't\",\n",
       "  'it',\n",
       "  'be',\n",
       "  'easy',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'something',\n",
       "  'that',\n",
       "  'you',\n",
       "  'could',\n",
       "  'tell',\n",
       "  'me.'],\n",
       " ['well',\n",
       "  'sure',\n",
       "  'in',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'world.',\n",
       "  'but',\n",
       "  'no',\n",
       "  'i',\n",
       "  'promise',\n",
       "  'i',\n",
       "  'would',\n",
       "  \"n't\",\n",
       "  'tell',\n",
       "  'and',\n",
       "  'i',\n",
       "  'swear',\n",
       "  'to',\n",
       "  'like',\n",
       "  'all',\n",
       "  'my',\n",
       "  'god.'],\n",
       " ['okay.', 'do', 'it', 'have', 'to', 'do', 'with', 'ross', 'and', 'rachel?'],\n",
       " ['no.'],\n",
       " ['do', 'it', 'have', 'to', 'do', 'with', 'joey?'],\n",
       " ['no.'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'have',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'with',\n",
       "  'chandler',\n",
       "  'and',\n",
       "  'that',\n",
       "  'sock',\n",
       "  'that',\n",
       "  'he',\n",
       "  'keep',\n",
       "  'by',\n",
       "  'his',\n",
       "  'bed?'],\n",
       " ['no', 'but', \"let's\", 'come', 'back', 'to', 'that', 'later!'],\n",
       " ['actually', \"i'm\", 'not', 'here', 'to', 'complement', 'the', 'chef.'],\n",
       " ['ohh',\n",
       "  'oh',\n",
       "  \"that's\",\n",
       "  'okay',\n",
       "  'i',\n",
       "  'hate',\n",
       "  'when',\n",
       "  'people',\n",
       "  'come',\n",
       "  'back',\n",
       "  'to',\n",
       "  'complement',\n",
       "  'the',\n",
       "  'chef.'],\n",
       " ['like', 'i', 'have', 'nothing', 'well', 'to', 'do!'],\n",
       " ['so', \"what's\", 'up?'],\n",
       " ['oh',\n",
       "  'good',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'too.',\n",
       "  'do',\n",
       "  'you',\n",
       "  'come',\n",
       "  'down',\n",
       "  'here',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'that?'],\n",
       " ['and', \"bobby's\", 'gon', 'na', 'be', 'here', 'the', 'whole', 'time.'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  \"you're\",\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'guy',\n",
       "  'in',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'world.'],\n",
       " [\"i'm\", 'not', 'even', 'scar', 'to', 'tell', 'mom', 'and', 'dad.'],\n",
       " ['okay',\n",
       "  'bobby',\n",
       "  'why',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'we',\n",
       "  'just',\n",
       "  'come',\n",
       "  'over',\n",
       "  'here',\n",
       "  'and',\n",
       "  'let',\n",
       "  'them',\n",
       "  'have',\n",
       "  'a',\n",
       "  'little',\n",
       "  'moment.'],\n",
       " [\"i'd\",\n",
       "  'love',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'you',\n",
       "  'in',\n",
       "  'but',\n",
       "  'uh',\n",
       "  'my',\n",
       "  \"sister's\",\n",
       "  'visiting',\n",
       "  'and',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"she's\",\n",
       "  'asleep',\n",
       "  'on',\n",
       "  'the',\n",
       "  'couch.'],\n",
       " ['oh',\n",
       "  'hey',\n",
       "  'great',\n",
       "  \"you're\",\n",
       "  'up.',\n",
       "  'rachel',\n",
       "  'this',\n",
       "  'be',\n",
       "  'my',\n",
       "  'sister',\n",
       "  'krista.',\n",
       "  'krista',\n",
       "  'this',\n",
       "  'be',\n",
       "  'rachel.'],\n",
       " ['like', 'it', 'would', 'help.'],\n",
       " ['uh', 'it', 'be', 'very', 'nice', 'meeting', 'you.'],\n",
       " ['hi', 'mom', \"it's\", 'jill.'],\n",
       " ['yeah',\n",
       "  \"i'm\",\n",
       "  'fine.',\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  'stick',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bank',\n",
       "  'in',\n",
       "  'an',\n",
       "  'atm',\n",
       "  'vestibule.'],\n",
       " ['jill', 'say', 'vestibule...', \"i'm\", 'go', 'with', 'vestibule.'],\n",
       " [\"i'm\",\n",
       "  'fine.',\n",
       "  'no',\n",
       "  \"i'm\",\n",
       "  'not',\n",
       "  'alone...',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'know',\n",
       "  'some',\n",
       "  'guy.'],\n",
       " ['be', 'you', 'see', 'anybody', 'right', 'now?'],\n",
       " ['personal',\n",
       "  'shopping?',\n",
       "  'what',\n",
       "  'be',\n",
       "  'that?',\n",
       "  'like',\n",
       "  'where',\n",
       "  'you',\n",
       "  'walk',\n",
       "  'around',\n",
       "  'with',\n",
       "  'snooty',\n",
       "  'rich',\n",
       "  'people',\n",
       "  'and',\n",
       "  'tell',\n",
       "  'them',\n",
       "  'what',\n",
       "  'to',\n",
       "  'buy?'],\n",
       " ['uh', 'huh.'],\n",
       " ['hey!'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'the',\n",
       "  'big',\n",
       "  'apartment',\n",
       "  'you',\n",
       "  'have',\n",
       "  'to',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'people',\n",
       "  'come',\n",
       "  'over',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time.'],\n",
       " ['that',\n",
       "  'fridge',\n",
       "  'have',\n",
       "  'get',\n",
       "  'to',\n",
       "  'be',\n",
       "  'stock',\n",
       "  'okay',\n",
       "  \"that's\",\n",
       "  'your',\n",
       "  'department',\n",
       "  'now.'],\n",
       " ['what', 'be', 'you', 'do?'],\n",
       " ['i', 'think', 'i', 'leave', 'a', 'donut', 'up', 'here.'],\n",
       " ['so',\n",
       "  'in',\n",
       "  'conclusion',\n",
       "  'the',\n",
       "  'line',\n",
       "  'all',\n",
       "  'go',\n",
       "  'up',\n",
       "  'so',\n",
       "  \"i'm\",\n",
       "  'happy.'],\n",
       " ['tomorrow', 'at.'],\n",
       " ['oh',\n",
       "  'excuse',\n",
       "  'me.',\n",
       "  'i',\n",
       "  'forget',\n",
       "  'my',\n",
       "  'briefcase',\n",
       "  \"y'know\",\n",
       "  'by',\n",
       "  'accident.'],\n",
       " ['well', 'what', 'about', 'you?'],\n",
       " [\"you're\", 'not', 'feel', 'leave', 'out', 'or', 'anything', 'be', 'ya?'],\n",
       " ['hey', 'bob.'],\n",
       " ['if', 'i', 'see', 'him', \"i'll\", 'ask.'],\n",
       " ['oh', 'then', 'you', 'know', 'each', 'other.'],\n",
       " [\"we're\", 'on', 'a', 'semi', 'first', 'name', 'basis.'],\n",
       " ['what', 'do', 'you', 'think', 'of', 'add', 'him', 'to', 'our', 'team?'],\n",
       " ['but',\n",
       "  'this',\n",
       "  'be',\n",
       "  'eleven.',\n",
       "  \"it's\",\n",
       "  'almost',\n",
       "  'twice',\n",
       "  'as',\n",
       "  'hard',\n",
       "  'up',\n",
       "  'here.'],\n",
       " ['a',\n",
       "  'freakish',\n",
       "  'thin',\n",
       "  'date',\n",
       "  'with',\n",
       "  'a',\n",
       "  'hanger',\n",
       "  'for',\n",
       "  'her',\n",
       "  'head?'],\n",
       " ['so?'],\n",
       " ['well', 'then', 'we', 'still', 'have', 'a', 'problem.'],\n",
       " ['yeah!'],\n",
       " ['with', 'what?'],\n",
       " ['well',\n",
       "  \"we're\",\n",
       "  'try',\n",
       "  'to',\n",
       "  'find',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'our',\n",
       "  'wedding',\n",
       "  'and',\n",
       "  \"they're\",\n",
       "  'all',\n",
       "  'either',\n",
       "  'boring',\n",
       "  'or',\n",
       "  'annoy',\n",
       "  'or',\n",
       "  \"y'know\",\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'stop',\n",
       "  'star',\n",
       "  'at',\n",
       "  'the',\n",
       "  'lady.'],\n",
       " ['phoebe', \"we're\", 'get'],\n",
       " ['guy',\n",
       "  'thank',\n",
       "  'you',\n",
       "  'very',\n",
       "  'much',\n",
       "  'but',\n",
       "  'neither',\n",
       "  'of',\n",
       "  'you',\n",
       "  'be',\n",
       "  'marry',\n",
       "  'us.'],\n",
       " ['we',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'legitimate',\n",
       "  'member',\n",
       "  'of',\n",
       "  'the',\n",
       "  'clergy!',\n",
       "  'and',\n",
       "  'when',\n",
       "  'i',\n",
       "  'say',\n",
       "  'legitimate',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'gay',\n",
       "  'and',\n",
       "  'in',\n",
       "  'control',\n",
       "  'of',\n",
       "  'his',\n",
       "  'saliva!'],\n",
       " ['i', 'do.'],\n",
       " ['that',\n",
       "  'be',\n",
       "  'suppose',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'thing',\n",
       "  'i',\n",
       "  'forget',\n",
       "  'why.'],\n",
       " ['just',\n",
       "  'listen',\n",
       "  'monica',\n",
       "  'i',\n",
       "  'do',\n",
       "  'you',\n",
       "  'know',\n",
       "  'okay',\n",
       "  'do',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'sleep',\n",
       "  'for',\n",
       "  'like',\n",
       "  'a',\n",
       "  'month',\n",
       "  'because',\n",
       "  'i',\n",
       "  'get',\n",
       "  'like',\n",
       "  'a',\n",
       "  'dot',\n",
       "  'of',\n",
       "  'ink',\n",
       "  'on',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sofa',\n",
       "  'cushion.'],\n",
       " ['well', 'you', 'you', 'coulda', 'just', 'turn', 'the', 'cushion', 'over.'],\n",
       " ['yeah',\n",
       "  'i',\n",
       "  \"would've\",\n",
       "  'except',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'big',\n",
       "  'spaghetti',\n",
       "  'stain',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'side.'],\n",
       " ['okay',\n",
       "  'this',\n",
       "  'be',\n",
       "  'what',\n",
       "  \"i'm\",\n",
       "  'talk',\n",
       "  'about',\n",
       "  'this.',\n",
       "  'i',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'live',\n",
       "  'in',\n",
       "  'a',\n",
       "  'land',\n",
       "  'where',\n",
       "  'people',\n",
       "  'can',\n",
       "  'spill.'],\n",
       " ['you', 'can', 'spill.', 'in', 'the', 'sink.'],\n",
       " ['no', \"you're\", 'not', \"you're\", 'wonder', 'which', 'cushion', 'it', 'be.'],\n",
       " ['uh', 'huh.'],\n",
       " ['well',\n",
       "  \"i'm\",\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  'glad',\n",
       "  'i',\n",
       "  'could',\n",
       "  \"y'know\",\n",
       "  'help',\n",
       "  'you',\n",
       "  'out.'],\n",
       " ['hero', 'i', 'uh', 'i', 'do', \"n't\", 'know', 'well', 'all', 'right.'],\n",
       " ['no.'],\n",
       " ['no', 'i', 'wo', \"n't.\"],\n",
       " ['but',\n",
       "  'i',\n",
       "  'should',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'this',\n",
       "  'this',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'happen',\n",
       "  'to',\n",
       "  'my',\n",
       "  'roommate',\n",
       "  'denise.'],\n",
       " ['lose', 'the', 'robe.'],\n",
       " ['well',\n",
       "  \"i'm\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'get',\n",
       "  'another',\n",
       "  'espresso.',\n",
       "  'can',\n",
       "  'i',\n",
       "  'get',\n",
       "  'you',\n",
       "  'another',\n",
       "  'latte?'],\n",
       " ['no', 'no', \"i'm\", 'still', 'work', 'on', 'mine.'],\n",
       " ['oh', 'yeah', 'that', 'hug', 'look', 'pretty', 'brutal.'],\n",
       " ['pretty', 'nice?'],\n",
       " [\"you'll\",\n",
       "  'have',\n",
       "  'to',\n",
       "  'pardon',\n",
       "  'my',\n",
       "  'roommate',\n",
       "  'he',\n",
       "  'want',\n",
       "  'to',\n",
       "  'marry',\n",
       "  'this.'],\n",
       " ['we',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'buck',\n",
       "  'but',\n",
       "  'would',\n",
       "  'you',\n",
       "  'be',\n",
       "  'willing',\n",
       "  'to',\n",
       "  'trade',\n",
       "  'for',\n",
       "  'it?',\n",
       "  \"we've\",\n",
       "  'get',\n",
       "  'a',\n",
       "  'canoe.'],\n",
       " [\"y'know\",\n",
       "  'i',\n",
       "  'i',\n",
       "  'really',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'we',\n",
       "  'need',\n",
       "  'a',\n",
       "  'canoe.'],\n",
       " ['all',\n",
       "  'right',\n",
       "  'just',\n",
       "  'just',\n",
       "  'take',\n",
       "  'the',\n",
       "  'entertainment',\n",
       "  'center',\n",
       "  'and',\n",
       "  'then',\n",
       "  'when',\n",
       "  'you',\n",
       "  'get',\n",
       "  'home',\n",
       "  'throw',\n",
       "  'the',\n",
       "  'canoe',\n",
       "  'away!'],\n",
       " ['pheebs?'],\n",
       " ['yeah?'],\n",
       " ['okay.',\n",
       "  'then',\n",
       "  'i',\n",
       "  'guess',\n",
       "  \"it's\",\n",
       "  'just',\n",
       "  'wait',\n",
       "  'here',\n",
       "  'then.',\n",
       "  'hi.',\n",
       "  'i',\n",
       "  'need',\n",
       "  'one',\n",
       "  'fake',\n",
       "  'ticket',\n",
       "  'to',\n",
       "  'yemen.'],\n",
       " ['oh',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no.',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'i',\n",
       "  'just',\n",
       "  'i',\n",
       "  'just',\n",
       "  'need',\n",
       "  'a',\n",
       "  'pretend',\n",
       "  'ticket.'],\n",
       " ['what',\n",
       "  'would',\n",
       "  'you',\n",
       "  'give',\n",
       "  'to',\n",
       "  'a',\n",
       "  'kid',\n",
       "  'if',\n",
       "  'he',\n",
       "  'want',\n",
       "  'a',\n",
       "  'ticket',\n",
       "  'to',\n",
       "  'play',\n",
       "  'with?'],\n",
       " ['be', 'you', 'travel', 'with', 'a', 'child?'],\n",
       " ['no.'],\n",
       " ['all',\n",
       "  'right',\n",
       "  \"y'know\",\n",
       "  'what',\n",
       "  \"she's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'think',\n",
       "  'that',\n",
       "  \"i'm\",\n",
       "  'hand',\n",
       "  'you',\n",
       "  'a',\n",
       "  'credit',\n",
       "  'card',\n",
       "  'but',\n",
       "  'what',\n",
       "  \"i'm\",\n",
       "  'really',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'do',\n",
       "  'be',\n",
       "  'hand',\n",
       "  'you',\n",
       "  'a',\n",
       "  'library',\n",
       "  'card.'],\n",
       " ['okay', 'but', 'this', 'be', 'the', 'last', 'time.'],\n",
       " ['hey.'],\n",
       " ['hey.'],\n",
       " [\"how's\", 'she', 'do?'],\n",
       " ['well',\n",
       "  'yeah',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'you',\n",
       "  'think',\n",
       "  \"it's\",\n",
       "  'a',\n",
       "  'she?'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'know.',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'tell',\n",
       "  'what',\n",
       "  'ever',\n",
       "  'it',\n",
       "  'be',\n",
       "  'go',\n",
       "  'back',\n",
       "  'in',\n",
       "  'too',\n",
       "  'quickly.'],\n",
       " ['well',\n",
       "  'anyway',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'go',\n",
       "  'change',\n",
       "  \"i'm\",\n",
       "  'ah',\n",
       "  'meeting',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cast',\n",
       "  'for',\n",
       "  'drink.'],\n",
       " ['what?'],\n",
       " ['yeah', 'but', \"jason's\", 'really', 'sensitive.'],\n",
       " ['well', 'sensitive', 'be', 'important', 'pick', 'him.'],\n",
       " ['yeah.'],\n",
       " ['hi.'],\n",
       " ['so',\n",
       "  'uh',\n",
       "  'apparently',\n",
       "  'people',\n",
       "  'be',\n",
       "  'familiar',\n",
       "  'with',\n",
       "  'the',\n",
       "  'europe',\n",
       "  'story?'],\n",
       " ['yeah.'],\n",
       " ['listen',\n",
       "  'about',\n",
       "  'that',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'uh',\n",
       "  'who',\n",
       "  'come',\n",
       "  'on',\n",
       "  'to',\n",
       "  'who',\n",
       "  'thing',\n",
       "  'really',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'matter.'],\n",
       " ['i', 'mean', 'i', 'think', 'it', \"would've\", 'happen', 'either', 'way.'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'initiate',\n",
       "  'it',\n",
       "  'i',\n",
       "  'i',\n",
       "  'i',\n",
       "  'know',\n",
       "  'i',\n",
       "  \"would've.\"],\n",
       " ['do', 'we', 'have', 'a', 'name', 'yet?'],\n",
       " ['no', 'not', 'yet.'],\n",
       " [\"that's\",\n",
       "  'fine',\n",
       "  'for',\n",
       "  'now',\n",
       "  \"we'll\",\n",
       "  'just',\n",
       "  'call',\n",
       "  'her',\n",
       "  'baby',\n",
       "  'girl',\n",
       "  'green.'],\n",
       " ['oh', 'no', 'baby', 'girl', 'geller', 'green.'],\n",
       " ['why', 'be', 'ross', 'do', 'that?'],\n",
       " ['no', \"that's\", 'all', 'right.', 'do', \"n't\", 'worry', 'about', 'it.'],\n",
       " ['yeah!', 'look!'],\n",
       " ['i', 'know.'],\n",
       " ['all',\n",
       "  'right',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'waste',\n",
       "  'it',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'its',\n",
       "  'still',\n",
       "  'food.'],\n",
       " ['hey',\n",
       "  'joey',\n",
       "  'be',\n",
       "  'this',\n",
       "  'the',\n",
       "  'bed',\n",
       "  'where',\n",
       "  'olivia',\n",
       "  'lose',\n",
       "  'her',\n",
       "  'virginity?'],\n",
       " ['also', 'so'],\n",
       " ['oh',\n",
       "  'in',\n",
       "  'my',\n",
       "  'head',\n",
       "  \"he's\",\n",
       "  'do',\n",
       "  'some',\n",
       "  'pretty',\n",
       "  'not',\n",
       "  'gay',\n",
       "  'stuff!'],\n",
       " ['well',\n",
       "  'at',\n",
       "  'the',\n",
       "  'christmas',\n",
       "  'party',\n",
       "  'him',\n",
       "  'and',\n",
       "  'santa',\n",
       "  'do',\n",
       "  'some',\n",
       "  'definitely',\n",
       "  'gay',\n",
       "  'stuff!'],\n",
       " ['ok',\n",
       "  \"you've\",\n",
       "  'get',\n",
       "  'to',\n",
       "  'promise',\n",
       "  'that',\n",
       "  \"you'll\",\n",
       "  'never',\n",
       "  'ever',\n",
       "  'tell',\n",
       "  'ross',\n",
       "  'that',\n",
       "  'i',\n",
       "  'tell',\n",
       "  'you.'],\n",
       " ['about', 'what?'],\n",
       " [\"he's\", 'plan', 'your', 'birthday', 'party.'],\n",
       " ['about', 'what?'],\n",
       " ['well', 'he', 'do', \"n't\", 'tell', 'me.'],\n",
       " ['hey', 'do', \"n't\", 'look', 'at', 'me.', 'this', 'be', \"ross's\", 'thing.'],\n",
       " ['no', 'you', 'be', 'not.', 'we', 'tell', 'you', 'stuff.'],\n",
       " ['chandler',\n",
       "  'we',\n",
       "  'still',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'get',\n",
       "  'an',\n",
       "  'rsvp',\n",
       "  'from',\n",
       "  'your',\n",
       "  'dad.'],\n",
       " ['oh!',\n",
       "  'right.',\n",
       "  'umm',\n",
       "  'maybe',\n",
       "  \"that's\",\n",
       "  'because',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'send',\n",
       "  'him',\n",
       "  'an',\n",
       "  'invitation.'],\n",
       " [\"it's\", 'not', 'like', 'we', 'run', 'in', 'the', 'same', 'circle.'],\n",
       " ['ooh', 'i', 'think', 'i', 'wan', 'na', 'trade', 'circle.'],\n",
       " ['so',\n",
       "  'what!',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  \"he's\",\n",
       "  'not',\n",
       "  'wear',\n",
       "  'a',\n",
       "  'white',\n",
       "  'dress',\n",
       "  'and',\n",
       "  'a',\n",
       "  'veil',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'care.'],\n",
       " ['okay', 'i', 'think', 'i', 'need', 'to', 'do', 'some', 'shopping.'],\n",
       " ['hello!', \"who's\", 'in', 'there?'],\n",
       " ['how', 'ya', \"doin'?\"],\n",
       " ['i',\n",
       "  'guess',\n",
       "  'you',\n",
       "  'would',\n",
       "  \"n't\",\n",
       "  'believe',\n",
       "  'me',\n",
       "  'if',\n",
       "  'i',\n",
       "  'say',\n",
       "  'i',\n",
       "  'be',\n",
       "  'kurt',\n",
       "  'douglas',\n",
       "  'huh?'],\n",
       " ['okay', 'you', 'guy', 'just', 'relax.', 'i', 'doooo.'],\n",
       " ['i', 'get', 'ta', 'go.'],\n",
       " ['sorry', \"i'm\", 'late', 'but', 'i', 'leave', 'late.'],\n",
       " ['okay.'],\n",
       " ['so', 'pheebs', 'what', 'be', 'the', 'book', 'about?'],\n",
       " ['i', 'think', 'you', 'say', 'you', 'read', 'it', 'in', 'high', 'school.'],\n",
       " ['well',\n",
       "  'yeah',\n",
       "  'but',\n",
       "  'then',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'i',\n",
       "  'start',\n",
       "  'it',\n",
       "  'and',\n",
       "  'there',\n",
       "  'be',\n",
       "  'this',\n",
       "  'pep',\n",
       "  'rally',\n",
       "  'and',\n",
       "  'i',\n",
       "  'be',\n",
       "  'i',\n",
       "  'be',\n",
       "  'on',\n",
       "  'top',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pyramid',\n",
       "  'but',\n",
       "  'anyway',\n",
       "  'umm',\n",
       "  'what',\n",
       "  'be',\n",
       "  'this',\n",
       "  'book',\n",
       "  'about?'],\n",
       " ['excuse', 'me', 'can', 'i', 'can', 'i', 'bum', 'one', 'of', 'those?'],\n",
       " [\"y'know\",\n",
       "  'what',\n",
       "  'actually',\n",
       "  'okay',\n",
       "  'okay',\n",
       "  'okay',\n",
       "  \"what's\",\n",
       "  'so',\n",
       "  'funny',\n",
       "  'over',\n",
       "  'here?'],\n",
       " ['oh',\n",
       "  'i',\n",
       "  'think',\n",
       "  'you',\n",
       "  'guy',\n",
       "  'meant',\n",
       "  'marijuana',\n",
       "  'cigarette',\n",
       "  \"y'know?\"],\n",
       " [\"y'know\", 'what', 'i', 'mean', 'like', 'dubbies?'],\n",
       " ['but',\n",
       "  'no',\n",
       "  'i',\n",
       "  'actually',\n",
       "  'smoke',\n",
       "  'the',\n",
       "  'regular',\n",
       "  'one',\n",
       "  'all',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time.'],\n",
       " ['we', 'get', 'high.'],\n",
       " ['oh', 'me', 'too.'],\n",
       " [\"i'm\", 'kid.'],\n",
       " ['yeah.'],\n",
       " ['hi.'],\n",
       " ['hey', \"how'd\", 'it', 'go?'],\n",
       " ['you', 'know', 'what?', 'you', 'be', 'right.', 'i'],\n",
       " ['ok.'],\n",
       " ['okay',\n",
       "  'if',\n",
       "  'you',\n",
       "  'guy',\n",
       "  'have',\n",
       "  'microphone',\n",
       "  'in',\n",
       "  'there',\n",
       "  'too',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'mean'],\n",
       " [\"it's.\"],\n",
       " ['yeah', 'rach', 'i', 'think', \"you're\", 'handle', 'that', 'really', 'well.'],\n",
       " ['handle', 'it?'],\n",
       " ['now',\n",
       "  'maybe',\n",
       "  'i',\n",
       "  'would',\n",
       "  'have',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'this',\n",
       "  'if',\n",
       "  'it',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'for',\n",
       "  'me',\n",
       "  'and',\n",
       "  'joshua.'],\n",
       " ['and',\n",
       "  'somewhere',\n",
       "  'along',\n",
       "  'the',\n",
       "  'way',\n",
       "  'one',\n",
       "  'of',\n",
       "  'them',\n",
       "  'be',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'realise',\n",
       "  'what',\n",
       "  \"they've\",\n",
       "  'do',\n",
       "  'and',\n",
       "  \"they're\",\n",
       "  'call',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'thing',\n",
       "  'off.'],\n",
       " ['all', 'right', \"what's\", 'my', 'next', 'present?'],\n",
       " ['all',\n",
       "  'right',\n",
       "  \"there's\",\n",
       "  'a',\n",
       "  'nuclear',\n",
       "  'holocaust',\n",
       "  \"i'm\",\n",
       "  'the',\n",
       "  'last',\n",
       "  'man',\n",
       "  'on',\n",
       "  'earth.',\n",
       "  'would',\n",
       "  'you',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'me?'],\n",
       " ['enhh'],\n",
       " [\"i've\", 'get', 'canned', 'good.'],\n",
       " ['excellent', 'hole', 'joe.'],\n",
       " ['my', 'drinking?'],\n",
       " ['oh', 'i', \"must've\", 'say', 'that', 'after', 'you', 'leave.'],\n",
       " ['that', 'you', 'enjoy', 'the', 'occasional', 'drink', 'ing', 'binge.'],\n",
       " ['what', 'if', 'i', 'create', 'a', 'position', 'for', 'you?'],\n",
       " [\"i'll\",\n",
       "  'make',\n",
       "  'you',\n",
       "  'an',\n",
       "  'assistant',\n",
       "  'buyer',\n",
       "  'in',\n",
       "  'this',\n",
       "  'department.'],\n",
       " [\"i'd\", 'need', 'an', 'expense', 'account.'],\n",
       " ['and', 'an', 'assistant.'],\n",
       " [\"they're\", 'male', 'nurse.'],\n",
       " ['not', 'in', 'my', 'head.'],\n",
       " [\"i'm\", 'move', 'on', 'and', \"you're\", 'move', 'on', 'with', 'me.'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'give',\n",
       "  'me',\n",
       "  'one',\n",
       "  'good',\n",
       "  'reason',\n",
       "  'why',\n",
       "  'you',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'wan',\n",
       "  'na',\n",
       "  'go.'],\n",
       " ['umm', 'why', 'do', \"n't\", 'you', 'give'],\n",
       " ['hard', 'than', 'it', 'sound.', 'be', \"n't\", 'it?'],\n",
       " ['okay',\n",
       "  \"you're\",\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'and',\n",
       "  'i',\n",
       "  'also',\n",
       "  'tell',\n",
       "  'them',\n",
       "  'that',\n",
       "  'if',\n",
       "  \"we're\",\n",
       "  'still',\n",
       "  'here',\n",
       "  'when',\n",
       "  'they',\n",
       "  'get',\n",
       "  'off',\n",
       "  'that',\n",
       "  \"we'll\",\n",
       "  'go',\n",
       "  'down',\n",
       "  'to',\n",
       "  'the',\n",
       "  'cafeteria',\n",
       "  'and',\n",
       "  'have',\n",
       "  'some'],\n",
       " ['yep!', \"there's\", 'always', 'room', 'for'],\n",
       " ['joey', 'how', 'do', 'you', 'make'],\n",
       " ['oh',\n",
       "  \"it's\",\n",
       "  'easy.',\n",
       "  'yeah',\n",
       "  'i',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do',\n",
       "  'it',\n",
       "  'with',\n",
       "  'anything.',\n",
       "  'watch',\n",
       "  'uh',\n",
       "  \"grandma's\",\n",
       "  'chicken',\n",
       "  'salad'],\n",
       " ['hello', 'this', 'be', 'monica...'],\n",
       " ['yeah???'],\n",
       " ['oh...'],\n",
       " ['okay', 'yes', \"we'll\", 'be', 'right', \"we'll\", 'be', 'right', 'down.'],\n",
       " ['thank', 'you.'],\n",
       " ['okay.', \"let's\", 'bring', 'it', 'in.'],\n",
       " ['wait',\n",
       "  'no',\n",
       "  'honey',\n",
       "  'honey',\n",
       "  'throw',\n",
       "  'it',\n",
       "  'to',\n",
       "  'me',\n",
       "  'throw',\n",
       "  'it',\n",
       "  'to',\n",
       "  'me.'],\n",
       " ['here', 'you', 'go.'],\n",
       " ['well',\n",
       "  'if',\n",
       "  'the',\n",
       "  'magician',\n",
       "  'can',\n",
       "  'open',\n",
       "  'my',\n",
       "  'beer',\n",
       "  'with',\n",
       "  'his',\n",
       "  'but',\n",
       "  'cheek',\n",
       "  'then',\n",
       "  'all',\n",
       "  'right.'],\n",
       " [\"y'know\",\n",
       "  'i',\n",
       "  'be',\n",
       "  'think',\n",
       "  'if',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'a',\n",
       "  'big',\n",
       "  'fight',\n",
       "  'and',\n",
       "  'uh',\n",
       "  'we',\n",
       "  'break',\n",
       "  'up',\n",
       "  'for',\n",
       "  'a',\n",
       "  'few',\n",
       "  'hour'],\n",
       " ['technically',\n",
       "  'we',\n",
       "  'could',\n",
       "  'have',\n",
       "  'sex',\n",
       "  'again.',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'bossy',\n",
       "  'and',\n",
       "  'domineer?!'],\n",
       " ['okay.',\n",
       "  'but',\n",
       "  'wait',\n",
       "  'we',\n",
       "  'ca',\n",
       "  \"n't.\",\n",
       "  'my',\n",
       "  'cousin',\n",
       "  'cassie',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'guest',\n",
       "  'room',\n",
       "  \"we're\",\n",
       "  'suppose',\n",
       "  'to',\n",
       "  'have',\n",
       "  'lunch.'],\n",
       " ['well', 'get', 'rid', 'of', 'her', 'obsessive', 'and', 'shrill.'],\n",
       " ['i', 'think', 'i', 'heard', 'voice.', 'you', 'must', 'be', 'chandler.'],\n",
       " ['nice', 'to', 'meet', 'you', 'too.'],\n",
       " ['so', 'be', 'you', 'ready', 'to', 'go?'],\n",
       " ['yeah.'],\n",
       " [\"i'll\", 'be', 'right', 'with', 'you.'],\n",
       " ['th', 'th', \"that's\", 'all', 'it', 'be', 'a', 'third', 'nipple.'],\n",
       " ['just', 'your', 'run', 'of', 'the', 'mill', 'third', 'nipple.'],\n",
       " ['you', 'can', 'take', 'it', 'off.'],\n",
       " ['take',\n",
       "  'your',\n",
       "  'shirt',\n",
       "  'off',\n",
       "  'and',\n",
       "  \"let's\",\n",
       "  'see',\n",
       "  'what',\n",
       "  \"we're\",\n",
       "  'deal',\n",
       "  'with',\n",
       "  'here.',\n",
       "  'what',\n",
       "  'be',\n",
       "  'you',\n",
       "  'do?'],\n",
       " ['just',\n",
       "  'show',\n",
       "  'you',\n",
       "  'my',\n",
       "  'run',\n",
       "  'of',\n",
       "  'the',\n",
       "  'mill',\n",
       "  'slice',\n",
       "  'it',\n",
       "  'right',\n",
       "  'off',\n",
       "  'third',\n",
       "  'nipple.'],\n",
       " ['well', \"that's\", 'not', 'a', 'third', 'nipple.'],\n",
       " ['first', 'of', 'all', \"it's\", 'on', 'your', 'as.'],\n",
       " ['wait',\n",
       "  'a',\n",
       "  'minute',\n",
       "  'hold',\n",
       "  'it.',\n",
       "  'johnson!',\n",
       "  'will',\n",
       "  'you',\n",
       "  'come',\n",
       "  'in',\n",
       "  'here',\n",
       "  'a',\n",
       "  'moment?'],\n",
       " [\"i'm\", 'with', 'hamilton!'],\n",
       " [\"he's\", 'good', 'with', 'rear', 'thing', 'bring', 'him', 'in', 'too.'],\n",
       " [\"it's\",\n",
       "  'from',\n",
       "  'france',\n",
       "  'in',\n",
       "  'europe',\n",
       "  'western',\n",
       "  'europe.',\n",
       "  \"y'know\",\n",
       "  'umm',\n",
       "  'a',\n",
       "  'few',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'i',\n",
       "  'actually',\n",
       "  'be',\n",
       "  'backpack',\n",
       "  'across',\n",
       "  'western',\n",
       "  'europe.'],\n",
       " ['i', 'study', 'for', 'a', 'year', 'in', 'barcelona.'],\n",
       " ['anyway', 'umm', 'so', 'i', 'be', 'um', 'i', 'be', 'hike'],\n",
       " ['um',\n",
       "  'uh',\n",
       "  \"we're\",\n",
       "  \"we're\",\n",
       "  'just',\n",
       "  'have',\n",
       "  'this',\n",
       "  'baby',\n",
       "  'together',\n",
       "  'but',\n",
       "  'uh',\n",
       "  'uh',\n",
       "  \"that's\",\n",
       "  'all.'],\n",
       " ['uh',\n",
       "  'well',\n",
       "  'umm',\n",
       "  \"we're\",\n",
       "  'just',\n",
       "  'not',\n",
       "  'in',\n",
       "  'that',\n",
       "  'place',\n",
       "  \"y'know?\",\n",
       "  'but',\n",
       "  \"we're\",\n",
       "  'very',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'this.'],\n",
       " ['oh.', 'well', 'then', 'shut', 'me', 'up.'],\n",
       " ['just', 'tell', 'me', 'how.'],\n",
       " ['let', 'it', 'go', 'ross.'],\n",
       " ['yeah', 'well', 'you', 'do', \"n't\", 'know', 'chi', 'chi.'],\n",
       " ['do', 'you', 'all', 'promise?'],\n",
       " ['chandler?', 'do', 'you', 'promise', 'to', 'be', 'good?'],\n",
       " ['hey', 'pheebs.'],\n",
       " ['dear', 'ms.', 'buffay.'],\n",
       " ['thank', 'you', 'for', 'call', 'attention', 'to', 'our', 'error.'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'credit',\n",
       "  'your',\n",
       "  'account',\n",
       "  'with',\n",
       "  'five',\n",
       "  'hundred',\n",
       "  'dollar.'],\n",
       " [\"we're\",\n",
       "  'sorry',\n",
       "  'for',\n",
       "  'the',\n",
       "  'inconvenience',\n",
       "  'and',\n",
       "  'hope',\n",
       "  \"you'll\",\n",
       "  'accept',\n",
       "  'this'],\n",
       " ['oh',\n",
       "  'my',\n",
       "  'god',\n",
       "  'honey',\n",
       "  'we',\n",
       "  'be',\n",
       "  'so',\n",
       "  'meant',\n",
       "  'to',\n",
       "  'be',\n",
       "  'together.',\n",
       "  'we',\n",
       "  'both',\n",
       "  'have',\n",
       "  'copy',\n",
       "  'of',\n",
       "  'the'],\n",
       " ['honey', 'both', 'yours.'],\n",
       " ['yeah?', 'the', 'work', 'problem?'],\n",
       " ['what', 'problem', 'do', 'you', 'tell', 'him', 'you', 'have?'],\n",
       " ['oh',\n",
       "  \"that's\",\n",
       "  'not',\n",
       "  'important.',\n",
       "  'the',\n",
       "  'point',\n",
       "  'be',\n",
       "  'i',\n",
       "  'really',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"everything's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'be',\n",
       "  'okay.'],\n",
       " ['okay',\n",
       "  \"i've\",\n",
       "  'get',\n",
       "  'some',\n",
       "  'one',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'put',\n",
       "  'them',\n",
       "  'in',\n",
       "  'her',\n",
       "  'panty?'],\n",
       " ['when', 'you', 'get', 'a', 'sec', 'another', 'round', 'of', 'daiquiri.'],\n",
       " ['remember', 'a', 'virgin', 'for', 'me', 'please.'],\n",
       " ['oh!',\n",
       "  'and',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'let',\n",
       "  'me',\n",
       "  'leave',\n",
       "  'without',\n",
       "  'get',\n",
       "  'the',\n",
       "  'name',\n",
       "  'of',\n",
       "  'that',\n",
       "  'carpet',\n",
       "  'guy.'],\n",
       " ['ahh',\n",
       "  'come',\n",
       "  'on!',\n",
       "  \"y'know\",\n",
       "  'what',\n",
       "  \"y'know\",\n",
       "  'what',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'go',\n",
       "  'home',\n",
       "  'and',\n",
       "  'call',\n",
       "  'kathy.'],\n",
       " ['well', 'if', 'you', 'think', 'it', 'will', 'help.'],\n",
       " ['all', 'right', 'i', 'definitely', 'taste', 'nutmeg.'],\n",
       " ['hey.'],\n",
       " ['uh', \"you've\", 'have', 'a', 'lot', 'of', 'sex', 'right?'],\n",
       " ['do', \"n't\", 'worry', 'about', 'that', 'man', 'that', 'happen.'],\n",
       " ['yeah!', 'once.'],\n",
       " ['i', 'do', 'it', 'anyway.'],\n",
       " ['sup?', 'sup', 'dude?'],\n",
       " ['so', \"you're\", 'play', 'a', 'little'],\n",
       " ['okay', 'look', \"he's\", 'not', 'gon', 'na', 'hurt', 'them', 'right?'],\n",
       " ['i', 'do', \"n't\", 'wan', 'na', 'leave', 'him', 'alone.'],\n",
       " ['alright?'],\n",
       " ['we', 'we', 'have', 'our', 'first', 'fight', 'this', 'morning.'],\n",
       " ['i', 'think', 'it', 'have', 'to', 'do', 'with', 'my', 'work', 'late.'],\n",
       " ['i',\n",
       "  'say',\n",
       "  'some',\n",
       "  'thing',\n",
       "  'that',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'mean',\n",
       "  'and',\n",
       "  'he',\n",
       "  'he',\n",
       "  'throw',\n",
       "  'some',\n",
       "  'faeces...'],\n",
       " [\"y'know\",\n",
       "  'if',\n",
       "  \"you're\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'work',\n",
       "  'late',\n",
       "  'i',\n",
       "  'could',\n",
       "  'look',\n",
       "  'in',\n",
       "  'on',\n",
       "  'him',\n",
       "  'for',\n",
       "  'you.'],\n",
       " ['okay',\n",
       "  'but',\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'it',\n",
       "  'seem',\n",
       "  'like',\n",
       "  \"you're\",\n",
       "  'there',\n",
       "  'to',\n",
       "  'see',\n",
       "  'him',\n",
       "  'okay',\n",
       "  'and',\n",
       "  \"you're\",\n",
       "  'not',\n",
       "  'like',\n",
       "  'do',\n",
       "  'it',\n",
       "  'as',\n",
       "  'a',\n",
       "  'favour',\n",
       "  'to',\n",
       "  'me.'],\n",
       " ['okay', 'but', 'if', 'he', 'ask', \"i'm\", 'not', 'go', 'to', 'lie.'],\n",
       " ['check', 'this', 'out.'],\n",
       " [\"it's\", 'almost', 'as', 'good', 'as', 'be', 'there.'],\n",
       " ['uh', 'may', 'i', 'help', 'you?'],\n",
       " ['yeah',\n",
       "  'i',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'you',\n",
       "  'on',\n",
       "  'the',\n",
       "  'phone',\n",
       "  \"i'm\",\n",
       "  'the',\n",
       "  'lady',\n",
       "  'that',\n",
       "  'get',\n",
       "  'stick',\n",
       "  'with',\n",
       "  'the',\n",
       "  'racecar',\n",
       "  'bed.'],\n",
       " ['look',\n",
       "  \"it's\",\n",
       "  'like',\n",
       "  'i',\n",
       "  'tell',\n",
       "  'you',\n",
       "  \"there's\",\n",
       "  'nothing',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do.',\n",
       "  'you',\n",
       "  'sign',\n",
       "  'for',\n",
       "  'it',\n",
       "  'monica',\n",
       "  'velula',\n",
       "  'geller.'],\n",
       " ['all',\n",
       "  'right',\n",
       "  'jester',\n",
       "  'man',\n",
       "  'look',\n",
       "  'we',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'see',\n",
       "  'the',\n",
       "  'king.'],\n",
       " ['oh', 'ho', 'kay', \"i'm\", 'talk', 'to', 'the', 'king.'],\n",
       " ['so', 'this', 'must', 'be', 'kinda', 'neat', 'for', 'ya', 'huh?'],\n",
       " ['i',\n",
       "  'mean',\n",
       "  'your',\n",
       "  'dad',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'that',\n",
       "  'you',\n",
       "  'get',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'day',\n",
       "  'off',\n",
       "  'school',\n",
       "  'and',\n",
       "  'you',\n",
       "  'you',\n",
       "  'ah',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'those',\n",
       "  'cooky',\n",
       "  'anymore.'],\n",
       " ['yeah.'],\n",
       " ['my',\n",
       "  'dad',\n",
       "  'say',\n",
       "  'if',\n",
       "  'i',\n",
       "  'spend',\n",
       "  'as',\n",
       "  'much',\n",
       "  'time',\n",
       "  'help',\n",
       "  'him',\n",
       "  'clean',\n",
       "  'apartment',\n",
       "  'as',\n",
       "  'i',\n",
       "  'do',\n",
       "  'daydream',\n",
       "  'about',\n",
       "  'out',\n",
       "  'space',\n",
       "  \"he'd\",\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'afford',\n",
       "  'a',\n",
       "  'trip',\n",
       "  'to',\n",
       "  'the',\n",
       "  'taj',\n",
       "  'mahal.'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'you',\n",
       "  'would',\n",
       "  'have',\n",
       "  'to',\n",
       "  'clean',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'apartment',\n",
       "  'to',\n",
       "  'go',\n",
       "  'all',\n",
       "  'the',\n",
       "  'way',\n",
       "  'to',\n",
       "  'india.'],\n",
       " ['oh.',\n",
       "  'look',\n",
       "  'just',\n",
       "  'friend',\n",
       "  'i',\n",
       "  'wo',\n",
       "  \"n't\",\n",
       "  'grope',\n",
       "  'you.',\n",
       "  'i',\n",
       "  'promise.'],\n",
       " ['no',\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'too',\n",
       "  'soon',\n",
       "  'i',\n",
       "  'have',\n",
       "  'lunch',\n",
       "  'at',\n",
       "  'a',\n",
       "  'eleven.'],\n",
       " ['i',\n",
       "  'invent',\n",
       "  'the',\n",
       "  'game',\n",
       "  'of',\n",
       "  'cup',\n",
       "  'as',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'give',\n",
       "  'joey',\n",
       "  'money.'],\n",
       " ['exactly.'],\n",
       " ['i', 'do', \"n't\", 'know.'],\n",
       " ['but', 'i', 'can', 'see', 'through', 'your', 'sheet.'],\n",
       " ['yeah', 'yeah', \"that's\", 'her.'],\n",
       " ['but', \"y'know\", 'what?'],\n",
       " ['why?'],\n",
       " ['no.', 'no.', 'no.', 'she', 'live', 'on', 'the'],\n",
       " ['no', 'those', 'first', 'two', 'window', \"that's\", 'the', 'lobby.'],\n",
       " ['and',\n",
       "  \"y'know\",\n",
       "  'the',\n",
       "  'other',\n",
       "  'one',\n",
       "  'over',\n",
       "  'there',\n",
       "  \"that's\",\n",
       "  'the',\n",
       "  'stairway.'],\n",
       " [\"you've\", 'be', 'count', 'wrong.'],\n",
       " ['no!', 'steady', 'as', 'a', 'rock!', 'now', 'be', 'you', 'with', 'me.'],\n",
       " ['all', 'right', 'gentleman', \"you're\", 'up', 'first.'],\n",
       " ['okay.'],\n",
       " ['okay.'],\n",
       " ['you',\n",
       "  'have',\n",
       "  'second.',\n",
       "  'and',\n",
       "  'the',\n",
       "  'lightning',\n",
       "  'round',\n",
       "  'begin',\n",
       "  'stop',\n",
       "  'it',\n",
       "  'now.',\n",
       "  'what',\n",
       "  'be',\n",
       "  \"monica's\",\n",
       "  'nickname',\n",
       "  'when',\n",
       "  'she',\n",
       "  'be',\n",
       "  'a',\n",
       "  'field',\n",
       "  'hockey',\n",
       "  'goalie?'],\n",
       " ['big', 'fat', 'goalie.'],\n",
       " ['correct.', 'rachel', 'claim'],\n",
       " ['dangerous', 'liaison'],\n",
       " ['correct.', 'her', 'actual', 'favorite', 'movie', 'be...'],\n",
       " ['weekend', 'at', \"bernie's\"],\n",
       " ['well',\n",
       "  'look',\n",
       "  'why',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'you',\n",
       "  'just',\n",
       "  'why',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'you',\n",
       "  'do',\n",
       "  'your',\n",
       "  'phase',\n",
       "  'two',\n",
       "  'strip',\n",
       "  'club',\n",
       "  'thing',\n",
       "  'with',\n",
       "  'us.'],\n",
       " ['okay.'],\n",
       " ['well',\n",
       "  'that',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'a',\n",
       "  'problem.',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'i',\n",
       "  'work',\n",
       "  'in',\n",
       "  'fashion',\n",
       "  'and',\n",
       "  'all',\n",
       "  'i',\n",
       "  'meet',\n",
       "  'be',\n",
       "  'eligible',\n",
       "  'straight',\n",
       "  'men.'],\n",
       " ['pete', 'can', 'i', 'get', 'you', 'something', 'else?'],\n",
       " ['yeah',\n",
       "  'a',\n",
       "  'slice',\n",
       "  'of',\n",
       "  'cheesecake',\n",
       "  'and',\n",
       "  'and',\n",
       "  'a',\n",
       "  'date',\n",
       "  'if',\n",
       "  \"you're\",\n",
       "  \"give'\",\n",
       "  'em',\n",
       "  'out.'],\n",
       " ['have', \"n't\", 'you', 'and', 'i', 'cover', 'that', 'topic?'],\n",
       " ['hmm', 'come', 'on', 'you', 'just', 'say', 'to', 'her', 'that', 'you.'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'you',\n",
       "  'think',\n",
       "  'she',\n",
       "  'should',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'me',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'you?'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'be',\n",
       "  'you',\n",
       "  'sure',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'her?'],\n",
       " ['i', 'mean', 'really', 'think', 'about', 'it.'],\n",
       " ['ho', 'ho', 'i', 'will.'],\n",
       " ['i', 'respectfully', 'disagree.'],\n",
       " ['who', 'care?', 'nobody', 'read', 'those', 'thing'],\n",
       " ['i', 'do', \"n't\", 'have', 'a', 'page.'],\n",
       " ['no', 'no', 'this', 'be', 'my', 'collection', 'of', 'fossil', 'sample.'],\n",
       " ['you'],\n",
       " ['why?'],\n",
       " ['hey',\n",
       "  'if',\n",
       "  'mommy',\n",
       "  'can',\n",
       "  'have',\n",
       "  'a',\n",
       "  'wife',\n",
       "  'daddy',\n",
       "  'can',\n",
       "  'have',\n",
       "  'a',\n",
       "  'bra.'],\n",
       " ['ohh', \"it's\", 'time', 'to', 'go.'],\n",
       " ['oh',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'see',\n",
       "  'that',\n",
       "  'that',\n",
       "  \"clock's\",\n",
       "  'a',\n",
       "  'little',\n",
       "  'fast',\n",
       "  'uh',\n",
       "  'we',\n",
       "  'have',\n",
       "  'minute.'],\n",
       " ['huh', 'what', 'can', 'we', 'do', 'in', 'minute?'],\n",
       " ['twice?'],\n",
       " ['well', \"that's\", 'ambitious.'],\n",
       " ['hey', 'uh', 'you', 'can', 'ignore', 'that.'],\n",
       " ['i'],\n",
       " ['hey',\n",
       "  'i',\n",
       "  'have',\n",
       "  'all',\n",
       "  'the',\n",
       "  'space',\n",
       "  'i',\n",
       "  'need.',\n",
       "  'just',\n",
       "  'do',\n",
       "  'what',\n",
       "  'i',\n",
       "  'do.'],\n",
       " [\"y'know\", 'what?', 'i', 'be'],\n",
       " ['okay.'],\n",
       " ['see', 'this', 'be', 'a'],\n",
       " ['all', 'right', 'buddy', 'time', 'to', 'roll', 'over.'],\n",
       " ['be', 'you', 'under', 'the', 'sheet?'],\n",
       " ['yes.'],\n",
       " [\"that's\", 'right', 'you', 'just', 'enjoy.'],\n",
       " ['okay.'],\n",
       " ['hey', 'tell', 'ya', 'what.'],\n",
       " ['let', 'me', 'walk', 'you', 'home.'],\n",
       " ['no.', 'you?'],\n",
       " ['no.', 'why?'],\n",
       " ['uhh',\n",
       "  'well',\n",
       "  \"i've\",\n",
       "  'get',\n",
       "  'an',\n",
       "  'audition',\n",
       "  'down',\n",
       "  'the',\n",
       "  'street',\n",
       "  'and',\n",
       "  'i',\n",
       "  'spill',\n",
       "  'sauce',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'front',\n",
       "  'of',\n",
       "  'my',\n",
       "  'shirt.',\n",
       "  'you',\n",
       "  'get',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'one?'],\n",
       " ['yeah', 'sure.', 'umm', 'here.'],\n",
       " ['yeah', 'i', 'do', \"n't\", 'think', 'so', 'joe.'],\n",
       " ['all', 'right', 'i', 'guess', 'this', 'will', 'be', 'fine.'],\n",
       " ['hey', 'listen', 'umm', 'what', 'what', 'be', 'you', 'do', 'tonight?'],\n",
       " ['nothing', 'why?'],\n",
       " ['how',\n",
       "  'would',\n",
       "  'you',\n",
       "  'feel',\n",
       "  'about',\n",
       "  'take',\n",
       "  'out',\n",
       "  'my',\n",
       "  'assistant',\n",
       "  'tag?',\n",
       "  \"i'll\",\n",
       "  'pay.'],\n",
       " [\"i'm\", 'not', 'ask', 'you', 'to', 'go', 'on', 'a'],\n",
       " ['joey',\n",
       "  'just',\n",
       "  'just',\n",
       "  'he',\n",
       "  \"he's\",\n",
       "  'new',\n",
       "  'in',\n",
       "  'town',\n",
       "  'and',\n",
       "  'i',\n",
       "  'know',\n",
       "  'he',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'any',\n",
       "  'guy',\n",
       "  'friend.'],\n",
       " ['just',\n",
       "  'take',\n",
       "  'him',\n",
       "  'to',\n",
       "  'like',\n",
       "  'a',\n",
       "  'ball',\n",
       "  'game',\n",
       "  'or',\n",
       "  'something.'],\n",
       " [\"i'll\", 'really', 'appreciate', 'it.'],\n",
       " ['yeah', 'okay.'],\n",
       " ['problem',\n",
       "  'odour',\n",
       "  'in',\n",
       "  'the',\n",
       "  'litter',\n",
       "  'box?',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'change',\n",
       "  'your',\n",
       "  'kitty',\n",
       "  'change',\n",
       "  'your',\n",
       "  'kitty',\n",
       "  'litter.'],\n",
       " ['yeah.', 'you', 'okay?'],\n",
       " ['hi.',\n",
       "  'well',\n",
       "  'look',\n",
       "  'i',\n",
       "  'be',\n",
       "  'just',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'leave',\n",
       "  'a',\n",
       "  'message',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'tonight',\n",
       "  'your',\n",
       "  'your',\n",
       "  'big',\n",
       "  'anniversary',\n",
       "  'dinner?'],\n",
       " ['you', 'wan', 'na', 'talk', 'i', 'mean', 'i', 'can', 'come', 'over?'],\n",
       " ['all',\n",
       "  'right',\n",
       "  'all',\n",
       "  'right',\n",
       "  \"i'm\",\n",
       "  'come',\n",
       "  'over',\n",
       "  'and',\n",
       "  \"i'm\",\n",
       "  'bring',\n",
       "  'chinese',\n",
       "  'food.'],\n",
       " [\"it's\", 'for', 'me.'],\n",
       " ['oh.', 'okay', 'bye.'],\n",
       " ['hello?'],\n",
       " ['transit', 'authority?'],\n",
       " ['yes', 'hello.'],\n",
       " [\"i'm\",\n",
       "  'do',\n",
       "  'research',\n",
       "  'for',\n",
       "  'a',\n",
       "  'book',\n",
       "  'and',\n",
       "  'i',\n",
       "  'be',\n",
       "  'wonder',\n",
       "  'what',\n",
       "  'someone',\n",
       "  'might',\n",
       "  'do',\n",
       "  'if',\n",
       "  'they',\n",
       "  'leave',\n",
       "  'a',\n",
       "  'baby',\n",
       "  'on',\n",
       "  'a',\n",
       "  'city',\n",
       "  'bus.'],\n",
       " ['hi', \"here's\", 'the', 'deal.'],\n",
       " ['we', 'lose', 'a', 'carseat', 'on', 'a', 'bus', 'today.'],\n",
       " [\"it's\",\n",
       "  'white',\n",
       "  'plastic',\n",
       "  'with',\n",
       "  'a',\n",
       "  'handle',\n",
       "  'and',\n",
       "  'it',\n",
       "  'fit',\n",
       "  'onto',\n",
       "  'a',\n",
       "  'stroller.'],\n",
       " ['oh', 'and', 'there', 'be', 'a', 'baby', 'in', 'it.'],\n",
       " ['he', 'want', 'to', 'talk', 'to', 'you', 'again.'],\n",
       " ['hello.'],\n",
       " [\"i'm\", 'sorry', \"i'm\", 'a', 'little', 'late.'],\n",
       " ['let',\n",
       "  'me',\n",
       "  'start',\n",
       "  'by',\n",
       "  'uh',\n",
       "  'by',\n",
       "  'introduce',\n",
       "  'myself',\n",
       "  'i',\n",
       "  'be',\n",
       "  'professor',\n",
       "  'geller.'],\n",
       " ['so', 'to', 'sum', 'up', \"i'm\", 'professor', 'geller.'],\n",
       " ['good', 'evening', 'sir.'],\n",
       " ['my', 'name', 'be', 'ross', 'geller.'],\n",
       " [\"i'm\",\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  'who',\n",
       "  'apply',\n",
       "  'for',\n",
       "  'the',\n",
       "  'apartment.'],\n",
       " ['and',\n",
       "  'i',\n",
       "  'i',\n",
       "  'realize',\n",
       "  'that',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'be',\n",
       "  'fierce',\n",
       "  'but',\n",
       "  \"i'm\",\n",
       "  'sorry.'],\n",
       " ['man', 'i', 'wish', 'i', 'be', 'naked.'],\n",
       " ['that', 'be', 'how', 'god', 'intend', 'it.'],\n",
       " ['i',\n",
       "  'overhear',\n",
       "  'you',\n",
       "  'guy',\n",
       "  'on',\n",
       "  'the',\n",
       "  'phone',\n",
       "  'the',\n",
       "  'other',\n",
       "  'day',\n",
       "  'and',\n",
       "  'you',\n",
       "  'say',\n",
       "  \"i'll\",\n",
       "  'just',\n",
       "  'tell',\n",
       "  'rachel',\n",
       "  'that',\n",
       "  \"i'm\",\n",
       "  'do',\n",
       "  'laundry',\n",
       "  'for',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'hour.'],\n",
       " ['and', 'he', 'say', 'laundry?'],\n",
       " ['be'],\n",
       " ['well',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'keep',\n",
       "  'listen',\n",
       "  'you',\n",
       "  'you',\n",
       "  'would',\n",
       "  'have',\n",
       "  'hear',\n",
       "  'me',\n",
       "  'call',\n",
       "  'him',\n",
       "  'mr.',\n",
       "  'big',\n",
       "  'ot.'],\n",
       " ['mr.', 'bigot.', 'he', 'tell', 'the', 'most'],\n",
       " ['i',\n",
       "  'really',\n",
       "  'think',\n",
       "  'you',\n",
       "  'make',\n",
       "  'a',\n",
       "  'good',\n",
       "  'point.',\n",
       "  'i',\n",
       "  'mean',\n",
       "  \"y'know\",\n",
       "  'until',\n",
       "  'you',\n",
       "  'get',\n",
       "  'cut',\n",
       "  'off.'],\n",
       " ['yeah', \"what's\", 'up', 'with', 'that', 'girl', 'monica?'],\n",
       " ['okay',\n",
       "  \"i've\",\n",
       "  'get',\n",
       "  'one',\n",
       "  'for',\n",
       "  'you',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'too',\n",
       "  'which',\n",
       "  'one',\n",
       "  'would',\n",
       "  'you',\n",
       "  'rather',\n",
       "  'eat',\n",
       "  'a',\n",
       "  'see',\n",
       "  'eye',\n",
       "  'dog',\n",
       "  'or',\n",
       "  'a',\n",
       "  'talk',\n",
       "  'gorilla?'],\n",
       " [\"i'd\",\n",
       "  'have',\n",
       "  'to',\n",
       "  'say',\n",
       "  'the',\n",
       "  'talk',\n",
       "  'gorilla',\n",
       "  'because',\n",
       "  'at',\n",
       "  'least',\n",
       "  'i',\n",
       "  'can',\n",
       "  'explain',\n",
       "  'to',\n",
       "  'him',\n",
       "  'that',\n",
       "  \"you're\",\n",
       "  'make',\n",
       "  'me',\n",
       "  'eat',\n",
       "  'him.'],\n",
       " ['okay',\n",
       "  'i',\n",
       "  'hear',\n",
       "  'you',\n",
       "  'loud',\n",
       "  'and',\n",
       "  'clear.',\n",
       "  'bob',\n",
       "  'will',\n",
       "  'stay',\n",
       "  'put.'],\n",
       " ['i', 'think', \"it's\", 'best', 'sir.'],\n",
       " ['but', 'we', 'really', 'do', 'need', 'to', 'find', 'someone', 'up', 'here.'],\n",
       " ['the', 'work', 'be', 'start', 'to', 'pile', 'up.'],\n",
       " [\"i've\",\n",
       "  'get',\n",
       "  'a',\n",
       "  'stack',\n",
       "  'of',\n",
       "  'document',\n",
       "  'on',\n",
       "  'my',\n",
       "  'desk',\n",
       "  'this',\n",
       "  'high.'],\n",
       " [\"y'know\",\n",
       "  'what',\n",
       "  'you',\n",
       "  'should',\n",
       "  'do',\n",
       "  'just',\n",
       "  'toss',\n",
       "  'em',\n",
       "  'in',\n",
       "  'the',\n",
       "  'shedder',\n",
       "  'and',\n",
       "  'claim',\n",
       "  'you',\n",
       "  'never',\n",
       "  'get',\n",
       "  'em.'],\n",
       " [\"that's\", 'a', 'good', 'one.'],\n",
       " ['what', 'do', 'a', 'guy', 'have', 'to'],\n",
       " ['yeah',\n",
       "  'yeah',\n",
       "  \"everybody's\",\n",
       "  'here.',\n",
       "  'hey',\n",
       "  'everybody',\n",
       "  'say',\n",
       "  'hi',\n",
       "  'to',\n",
       "  'julie',\n",
       "  'in',\n",
       "  'new',\n",
       "  'mexico.'],\n",
       " ['be', \"n't\", 'there', 'a', 'national', 'football', 'league.'],\n",
       " ['yes.',\n",
       "  'yes',\n",
       "  'there',\n",
       "  'be',\n",
       "  'they',\n",
       "  'play',\n",
       "  'on',\n",
       "  'sunday',\n",
       "  'and',\n",
       "  'monday',\n",
       "  'night.'],\n",
       " ['when', \"they're\", 'hungry', 'enough', \"they'll\", 'come', 'in.'],\n",
       " ['hey', 'joey', 'you', 'want', 'to', 'talk', 'to', 'me?'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'know.',\n",
       "  'you',\n",
       "  'uh',\n",
       "  'you',\n",
       "  'get',\n",
       "  'something',\n",
       "  'for',\n",
       "  'me?'],\n",
       " ['oh', 'yeah', 'this', 'be', 'from', 'rachel.'],\n",
       " ['ten.',\n",
       "  'okay.',\n",
       "  'now',\n",
       "  'tag',\n",
       "  \"there's\",\n",
       "  'such',\n",
       "  'a',\n",
       "  'thing',\n",
       "  'as',\n",
       "  'too',\n",
       "  'many',\n",
       "  'woman.'],\n",
       " [\"that's\"],\n",
       " ['what', 'be', 'with', 'the', 'dish?'],\n",
       " ['yeah', 'toast', 'oatmeal...', 'nothing', 'that', 'spatter.'],\n",
       " [\"y'know\", 'they', 'say', 'a', 'watched', 'pot', 'never', 'beep.'],\n",
       " ['phoebe',\n",
       "  'why',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'you',\n",
       "  'just',\n",
       "  'call',\n",
       "  'her?',\n",
       "  'you',\n",
       "  'obviously',\n",
       "  'want',\n",
       "  'to.'],\n",
       " ['well', 'do', \"n't\", 'cha', 'wan', 'na?'],\n",
       " ['yeah.'],\n",
       " ['okay', 'well', 'i', 'do', 'know', 'you.'],\n",
       " [\"that's\", 'what', 'i', 'say.'],\n",
       " ['well', 'so?'],\n",
       " ['ok',\n",
       "  'bye.',\n",
       "  'well',\n",
       "  \"monica's\",\n",
       "  'not',\n",
       "  'come',\n",
       "  \"it's\",\n",
       "  'just',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'be',\n",
       "  'me',\n",
       "  'and',\n",
       "  'rachel.'],\n",
       " ['oh.',\n",
       "  'well',\n",
       "  'hold',\n",
       "  'on',\n",
       "  'camper',\n",
       "  'be',\n",
       "  'you',\n",
       "  'sure',\n",
       "  \"you've\",\n",
       "  'think',\n",
       "  'this',\n",
       "  'thing',\n",
       "  'through?'],\n",
       " [\"it's\", 'laundry.', 'the', 'thinking', 'through', 'be', 'minimal.'],\n",
       " ['no.'],\n",
       " ['oh', 'and', 'uh', 'the', 'fabric', 'softener?'],\n",
       " [\"that's\", 'the', 'rule.'],\n",
       " ['ok', 'ok', 'how', 'about', 'if', 'we', 'split', 'it?'],\n",
       " ['what', 'do', 'you', 'mean', 'like', 'buy', 'it', 'together?'],\n",
       " ['yeah'],\n",
       " ['you', 'think', \"we're\", 'ready', 'for', 'something', 'like', 'that?'],\n",
       " ['why', 'not?'],\n",
       " ['well',\n",
       "  \"it's\",\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'big',\n",
       "  'commitment',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'what',\n",
       "  'if',\n",
       "  'one',\n",
       "  'of',\n",
       "  'us',\n",
       "  'want',\n",
       "  'to',\n",
       "  'move',\n",
       "  'out?'],\n",
       " [\"i'm\", 'not', 'move', 'out.'],\n",
       " ['yeah',\n",
       "  'yeah',\n",
       "  \"it's\",\n",
       "  'just',\n",
       "  'that',\n",
       "  'with',\n",
       "  'my',\n",
       "  'last',\n",
       "  'roommate',\n",
       "  'kip...'],\n",
       " ['oh',\n",
       "  'no',\n",
       "  'stay',\n",
       "  'here',\n",
       "  \"we'll\",\n",
       "  'keep',\n",
       "  'do',\n",
       "  'this.',\n",
       "  \"i'll\",\n",
       "  'pay',\n",
       "  'you.'],\n",
       " ['no',\n",
       "  'i',\n",
       "  'get',\n",
       "  'in',\n",
       "  'trouble',\n",
       "  'for',\n",
       "  'that',\n",
       "  'before.',\n",
       "  \"i'll\",\n",
       "  'see',\n",
       "  'you',\n",
       "  'later.'],\n",
       " ['aw', 'forget', 'it', \"it's\", 'from'],\n",
       " ['okay', 'look', 'how', 'be', 'this', 'gon', 'na', 'affect', 'you?'],\n",
       " [\"it's\"],\n",
       " [\"you're\", 'right.'],\n",
       " [\"y'know\", 'what?'],\n",
       " [\"i'm\", 'ask', 'you', 'to', 'do', 'me', 'a', 'favor.'],\n",
       " ['and',\n",
       "  'as',\n",
       "  'my',\n",
       "  'wife',\n",
       "  'i',\n",
       "  'think',\n",
       "  'you',\n",
       "  'should',\n",
       "  'grant',\n",
       "  'me',\n",
       "  'this',\n",
       "  'favor.'],\n",
       " ['my',\n",
       "  \"brother's\",\n",
       "  'go',\n",
       "  'through',\n",
       "  'that',\n",
       "  'right',\n",
       "  'now',\n",
       "  \"he's\",\n",
       "  'such',\n",
       "  'a',\n",
       "  'mess.',\n",
       "  'how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'get',\n",
       "  'through',\n",
       "  'it?'],\n",
       " ['well',\n",
       "  'you',\n",
       "  'might',\n",
       "  'try',\n",
       "  'accidentally',\n",
       "  'break',\n",
       "  'something',\n",
       "  'valuable',\n",
       "  'of',\n",
       "  'hers',\n",
       "  'say',\n",
       "  'her'],\n",
       " ['leg?'],\n",
       " [\"that's\", 'one', 'way!', 'me', 'i', 'i', 'go', 'for', 'the', 'watch.'],\n",
       " ['no',\n",
       "  'real',\n",
       "  'honey',\n",
       "  'really',\n",
       "  \"it's\",\n",
       "  'fine',\n",
       "  'just',\n",
       "  'g',\n",
       "  'go',\n",
       "  'with',\n",
       "  'susan.'],\n",
       " ['okay', 'okay', 'bye'],\n",
       " ['so', 'what', 'be', 'they', 'do?'],\n",
       " ['hey', \"you're\", 'early.'],\n",
       " [\"i'm\", 'just', 'take', 'it', 'to', 'be', 're', 'wire.'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'mr.',\n",
       "  'heckle',\n",
       "  'no',\n",
       "  'one',\n",
       "  'be',\n",
       "  'make',\n",
       "  'any',\n",
       "  'noise',\n",
       "  'up',\n",
       "  'here.'],\n",
       " ['hi', 'rach.'],\n",
       " ['ross?'],\n",
       " ['yeah?'],\n",
       " [\"i'm\", 'good', 'except', 'umm', 'you', 'still', 'owe', 'me', 'a', 'dance.'],\n",
       " ['i', 'think', 'i', 'might', 'need', 'one', 'more', 'cup', 'of', 'coffee.'],\n",
       " ['sure!', 'uh', 'let', 'me', 'get', 'it', 'for', 'ya.'],\n",
       " ['okay.'],\n",
       " ['i',\n",
       "  'believe',\n",
       "  'this',\n",
       "  'belong',\n",
       "  'to',\n",
       "  'the',\n",
       "  'father',\n",
       "  'of',\n",
       "  'your',\n",
       "  'baby.'],\n",
       " ['uh',\n",
       "  'huh.',\n",
       "  'now',\n",
       "  'you',\n",
       "  'can',\n",
       "  'turn',\n",
       "  'around',\n",
       "  'or',\n",
       "  'you',\n",
       "  'can',\n",
       "  'go',\n",
       "  'in',\n",
       "  'there',\n",
       "  'and',\n",
       "  'rip',\n",
       "  'the',\n",
       "  'band',\n",
       "  'aid',\n",
       "  'off.',\n",
       "  'what',\n",
       "  'to',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'do?'],\n",
       " ['okay', 'sorry.', 'yeah.'],\n",
       " ['hey', 'rach.'],\n",
       " ['it', 'can', 't', 'be', 'me', 'i', 'm', 'stand', 'right', 'here.'],\n",
       " ['wan', 'na', 'peek?'],\n",
       " ['hello', 'sir', 'you', 'know', 'monica.'],\n",
       " ['do', \"n't\", 'spoil', 'it.'],\n",
       " ['hi.'],\n",
       " ['hello.'],\n",
       " ['hi', 'ross.'],\n",
       " ['yeah', 'huh.'],\n",
       " ['i',\n",
       "  'can',\n",
       "  'get',\n",
       "  'a',\n",
       "  'quick',\n",
       "  'bite',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'but',\n",
       "  'then',\n",
       "  'i',\n",
       "  'have',\n",
       "  'to',\n",
       "  'come',\n",
       "  'back',\n",
       "  'up',\n",
       "  'here.'],\n",
       " ['nooo', 'he?', 's', 'leave', 'for', 'a', 'good', 'job.'],\n",
       " ['okay', 'then.'],\n",
       " ['okay.'],\n",
       " ['so', 'see', 'ya', 'on', 'saturday.'],\n",
       " ['yeah', 'you', 'bet.'],\n",
       " ['whazzup??'],\n",
       " ['listen', 'can', 'you', 'do', 'me', 'a', 'favor?'],\n",
       " [\"i'm\", 'gon', 'na', 'be', 'out', 'today.'],\n",
       " ['can',\n",
       "  'you',\n",
       "  'just',\n",
       "  'keep',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'on',\n",
       "  'joey',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'nothing',\n",
       "  'happen',\n",
       "  'between',\n",
       "  'him',\n",
       "  'and',\n",
       "  'molly?'],\n",
       " ['i', 'think', 'the', 'check', 'in', 'be', 'that', 'way.'],\n",
       " ['ahh.'],\n",
       " ['monica',\n",
       "  'face',\n",
       "  'it',\n",
       "  'chandler',\n",
       "  'be',\n",
       "  'against',\n",
       "  'marriage.',\n",
       "  'and',\n",
       "  'and',\n",
       "  'always',\n",
       "  'will',\n",
       "  'be!'],\n",
       " [\"that's\", 'right.'],\n",
       " ['chandler'],\n",
       " ['you', 'get'],\n",
       " ['i', 'know.'],\n",
       " ['i', 'do.'],\n",
       " ['sometime?'],\n",
       " ['maybe?'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'just',\n",
       "  'think',\n",
       "  \"it'd\",\n",
       "  'make',\n",
       "  'me',\n",
       "  'feel',\n",
       "  'good',\n",
       "  'to',\n",
       "  'do',\n",
       "  'something',\n",
       "  'nice',\n",
       "  'for',\n",
       "  'my',\n",
       "  'friend.'],\n",
       " ['oh', 'no', 'no', 'no.'],\n",
       " ['well',\n",
       "  \"y'know\",\n",
       "  \"i'm.\",\n",
       "  'i',\n",
       "  'mean',\n",
       "  'who',\n",
       "  'need',\n",
       "  'a',\n",
       "  'saving',\n",
       "  'account.'],\n",
       " ['you', 'mean', 'with', 'casey.'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'i',\n",
       "  'think',\n",
       "  \"i'm\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'see',\n",
       "  'how',\n",
       "  'thing',\n",
       "  'go',\n",
       "  'with',\n",
       "  'kathy.',\n",
       "  \"she's\",\n",
       "  'pretty',\n",
       "  'cool.'],\n",
       " ['or', 'casey.'],\n",
       " ['no', 'no', 'kathy.'],\n",
       " ['could', 'be', 'casey.'],\n",
       " ['no.', 'no', 'kathy.'],\n",
       " ['consider', 'casey.'],\n",
       " ['hey',\n",
       "  'anybody',\n",
       "  'get',\n",
       "  'a',\n",
       "  'length',\n",
       "  'of',\n",
       "  'rope',\n",
       "  'about',\n",
       "  'six',\n",
       "  'foot',\n",
       "  'long',\n",
       "  'with',\n",
       "  'a',\n",
       "  'little',\n",
       "  'nouse',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end?'],\n",
       " ['honey', \"what's\", 'the', 'matter?'],\n",
       " ['i', 'just', 'saw', 'janice.'],\n",
       " ['i', 'like', 'her.'],\n",
       " ['why?',\n",
       "  'because',\n",
       "  'she',\n",
       "  'can',\n",
       "  'sing',\n",
       "  'and',\n",
       "  'play',\n",
       "  'guitar',\n",
       "  'and',\n",
       "  'do',\n",
       "  'both',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time?'],\n",
       " ['well',\n",
       "  \"that's\",\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'all',\n",
       "  \"i'm\",\n",
       "  'look',\n",
       "  'for',\n",
       "  'from',\n",
       "  'these',\n",
       "  'people.'],\n",
       " ['yeah',\n",
       "  'pheebs',\n",
       "  'come',\n",
       "  'on',\n",
       "  'you',\n",
       "  'two',\n",
       "  'have',\n",
       "  'completely',\n",
       "  'different',\n",
       "  'style.',\n",
       "  \"y'know\",\n",
       "  \"she's\",\n",
       "  'more..',\n",
       "  \"y'know\",\n",
       "  'and',\n",
       "  \"you're\",\n",
       "  'more'],\n",
       " ['okay',\n",
       "  'my',\n",
       "  'next',\n",
       "  \"song's\",\n",
       "  'call',\n",
       "  'phoebe',\n",
       "  'buffay',\n",
       "  'what',\n",
       "  'can',\n",
       "  'i',\n",
       "  'say.'],\n",
       " ['i',\n",
       "  'really',\n",
       "  'love',\n",
       "  'when',\n",
       "  'we',\n",
       "  'be',\n",
       "  'sing',\n",
       "  'partner',\n",
       "  'and',\n",
       "  'i',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'leave',\n",
       "  'you',\n",
       "  'that',\n",
       "  'way.'],\n",
       " ['oh',\n",
       "  'no',\n",
       "  'one',\n",
       "  'of',\n",
       "  'those',\n",
       "  'look',\n",
       "  'for',\n",
       "  'the',\n",
       "  'hidden',\n",
       "  \"meaning'songs.\"],\n",
       " ['yes', 'hello.'],\n",
       " ['i', 'have', 'a', 'question.'],\n",
       " ['umm',\n",
       "  'i',\n",
       "  'use',\n",
       "  'your',\n",
       "  'pen',\n",
       "  'to',\n",
       "  'draw',\n",
       "  'on',\n",
       "  'my',\n",
       "  \"friend's\",\n",
       "  'face.'],\n",
       " ['a', 'beard', 'and', 'a', 'moustache.'],\n",
       " ['thank', 'you.'],\n",
       " ['no'],\n",
       " ['umm', 'he', 'say', 'he', 'think', 'i', 'be', 'funny.'],\n",
       " ['so',\n",
       "  'okay',\n",
       "  'look',\n",
       "  'look',\n",
       "  'umm',\n",
       "  \"let's\",\n",
       "  'just',\n",
       "  'go',\n",
       "  'downstairs',\n",
       "  \"we'll\",\n",
       "  'have',\n",
       "  'some',\n",
       "  'fun',\n",
       "  'and',\n",
       "  'you',\n",
       "  'will',\n",
       "  'forget',\n",
       "  'all',\n",
       "  'about',\n",
       "  'it.'],\n",
       " ['oh', 'come', 'on!', 'rach', \"it's\", \"it's\", 'not', 'that', 'bad.'],\n",
       " ['look',\n",
       "  'just',\n",
       "  'because',\n",
       "  'some',\n",
       "  'idiot',\n",
       "  'draw',\n",
       "  'on',\n",
       "  'your',\n",
       "  'face',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'mean',\n",
       "  'you',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'any',\n",
       "  'fun!'],\n",
       " ['and',\n",
       "  'besides',\n",
       "  'hey',\n",
       "  'hey',\n",
       "  'hey',\n",
       "  'no',\n",
       "  'one',\n",
       "  'be',\n",
       "  'even',\n",
       "  'gon',\n",
       "  'na'],\n",
       " ['okay', 'there', 'be'],\n",
       " ['no',\n",
       "  \"it's\",\n",
       "  'okay.',\n",
       "  'some',\n",
       "  'some',\n",
       "  'kid',\n",
       "  'ask',\n",
       "  'me',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'it',\n",
       "  'up',\n",
       "  'for',\n",
       "  'him',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\"],\n",
       " ['you', 'say', 'you', 'wan', 'na', 'come', 'in', 'for', 'some', 'lemonade?'],\n",
       " ['oh', 'right', 'right.'],\n",
       " ['well', 'not', 'just', 'lemonade', 'iced', 'tea', 'sometimes', 'juice.'],\n",
       " ['well', 'sorry', 'i', 'just', 'i', 'think', 'you', 'like', 'me.'],\n",
       " [\"it's\",\n",
       "  'okay.',\n",
       "  'i',\n",
       "  'suppose',\n",
       "  'it',\n",
       "  'could',\n",
       "  'happen',\n",
       "  'to',\n",
       "  'anyone',\n",
       "  'not',\n",
       "  'anyone',\n",
       "  'i',\n",
       "  'know',\n",
       "  'but...',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  'i',\n",
       "  'can',\n",
       "  'still',\n",
       "  'see',\n",
       "  'it.'],\n",
       " ['ok',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'question.',\n",
       "  'well',\n",
       "  'actually',\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'so',\n",
       "  'much',\n",
       "  'a',\n",
       "  'question',\n",
       "  'as..',\n",
       "  'more',\n",
       "  'of',\n",
       "  'a',\n",
       "  'general',\n",
       "  'wondering...',\n",
       "  'ment.'],\n",
       " ['ok.'],\n",
       " ['ok.',\n",
       "  'here',\n",
       "  'go.',\n",
       "  'for',\n",
       "  'a',\n",
       "  'while',\n",
       "  'now',\n",
       "  \"i've\",\n",
       "  'be',\n",
       "  'want',\n",
       "  'to',\n",
       "  'um....'],\n",
       " ['yes', 'yes', \"that's\", 'right...'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'be',\n",
       "  'probably',\n",
       "  'go',\n",
       "  'to',\n",
       "  'do',\n",
       "  'it',\n",
       "  'at',\n",
       "  'some',\n",
       "  'point.'],\n",
       " ['i', 'do', \"n't\", 'mean'],\n",
       " ['well',\n",
       "  'we',\n",
       "  'probably',\n",
       "  'wo',\n",
       "  \"n't\",\n",
       "  'invite',\n",
       "  'you',\n",
       "  'to',\n",
       "  'the',\n",
       "  'wedding...'],\n",
       " ['thank', 'you', 'chandler.'],\n",
       " ['sincerely.'],\n",
       " ['david', \"i'm\", 'pretend', 'to'],\n",
       " ['all', 'right.', 'all', 'right.'],\n",
       " ['actually', 'i', 'do', 'have', 'one', 'small', 'complaint.'],\n",
       " ['oh..', 'please!', 'i', 'i', 'welcome', 'criticism.'],\n",
       " ['we', 'do?'],\n",
       " ['chandler',\n",
       "  'here',\n",
       "  'you',\n",
       "  'go',\n",
       "  'get',\n",
       "  'your',\n",
       "  'traditional',\n",
       "  'thanksgiving',\n",
       "  'feast',\n",
       "  'you',\n",
       "  'get',\n",
       "  'your',\n",
       "  'tomato',\n",
       "  'soup',\n",
       "  'your',\n",
       "  'grilled',\n",
       "  'cheese',\n",
       "  \"fixin's\",\n",
       "  'and',\n",
       "  'your',\n",
       "  'family',\n",
       "  'size',\n",
       "  'bag',\n",
       "  'of',\n",
       "  'funyuns.'],\n",
       " ['all', 'right', \"i'm\", 'nine', 'year', 'old.'],\n",
       " ['we', 'just', 'finish', 'this', 'magnificent', 'thanksgiving', 'dinner.'],\n",
       " ['that', 'little', 'naked', 'guy', 'would', 'be', 'me.'],\n",
       " ['oh',\n",
       "  \"that's\",\n",
       "  'nana',\n",
       "  'right',\n",
       "  'there',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"middle.'me\",\n",
       "  'and',\n",
       "  'the',\n",
       "  'gang',\n",
       "  'at',\n",
       "  'java',\n",
       "  \"joe's'.\"],\n",
       " [\"let's\", 'see...', 'yeah?'],\n",
       " ['look', 'like', 'a', 'fun', 'gang.'],\n",
       " ['rachel',\n",
       "  'have',\n",
       "  'something',\n",
       "  'that',\n",
       "  'she',\n",
       "  'want',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'and',\n",
       "  'umm',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'this',\n",
       "  'be',\n",
       "  'your',\n",
       "  'red',\n",
       "  'sweater.'],\n",
       " ['no.', 'this', 'be', 'my', 'red', 'sweater.'],\n",
       " ['okay.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'category',\n",
       "  'of',\n",
       "  'favorite',\n",
       "  'return',\n",
       "  'male',\n",
       "  'character',\n",
       "  'the',\n",
       "  'nominee',\n",
       "  'be',\n",
       "  'john',\n",
       "  'wheeler',\n",
       "  'from'],\n",
       " ['yeah.'],\n",
       " [\"you're\", 'an', 'aquarius', 'huh?'],\n",
       " ['i', 'bet', \"you're\", 'a', 'gemini.'],\n",
       " ['nope.'],\n",
       " ['taurus?'],\n",
       " ['nope.'],\n",
       " ['virgo?'],\n",
       " ['nope.'],\n",
       " ['sagittarius?'],\n",
       " ['yep.'],\n",
       " [\"you're\", 'not', 'gon', 'na', 'speed', 'anymore', 'right?'],\n",
       " ['i', 'wo', \"n't\", 'speed.'],\n",
       " ['and',\n",
       "  'you',\n",
       "  'promise',\n",
       "  \"you'll\",\n",
       "  'get',\n",
       "  'this',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'right',\n",
       "  'away?'],\n",
       " ['i', 'promise.'],\n",
       " ['and',\n",
       "  'in',\n",
       "  'the',\n",
       "  'meantime',\n",
       "  'you',\n",
       "  'good',\n",
       "  'let',\n",
       "  'him',\n",
       "  'drive.',\n",
       "  'do',\n",
       "  'he',\n",
       "  'have',\n",
       "  'a',\n",
       "  'license?'],\n",
       " ['yeah!'],\n",
       " ['can', 'he', 'handle', 'the', 'stick?'],\n",
       " ['oh', 'well'],\n",
       " ['oh',\n",
       "  'this',\n",
       "  'should',\n",
       "  'be',\n",
       "  'easy.',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'very',\n",
       "  'wide',\n",
       "  'pelvis.',\n",
       "  'you',\n",
       "  'remember',\n",
       "  'chandler.'],\n",
       " [\"it's\", 'you.', 'this', 'be', 'yours.'],\n",
       " [\"y'know\",\n",
       "  \"y'know\",\n",
       "  \"i'm\",\n",
       "  \"lookin'and\",\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  \"anyone's\",\n",
       "  'home',\n",
       "  'here.'],\n",
       " ['i',\n",
       "  'say',\n",
       "  'we',\n",
       "  'just',\n",
       "  'break',\n",
       "  'the',\n",
       "  'window',\n",
       "  'crawl',\n",
       "  'through',\n",
       "  'and',\n",
       "  'and',\n",
       "  \"y'know\",\n",
       "  'explain',\n",
       "  'later.'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'so.',\n",
       "  'hello?',\n",
       "  'when',\n",
       "  'you',\n",
       "  'get',\n",
       "  'in',\n",
       "  'there'],\n",
       " ['hey', \"what's\", 'up?'],\n",
       " ['so', 'what', 'so', 'what', 'you', 'saw', 'him', 'with', 'a', 'girl?'],\n",
       " ['now',\n",
       "  'look',\n",
       "  \"you're\",\n",
       "  'go',\n",
       "  'to',\n",
       "  'go',\n",
       "  'out',\n",
       "  'on',\n",
       "  'a',\n",
       "  'date',\n",
       "  'with',\n",
       "  'danny',\n",
       "  'and',\n",
       "  \"you're\",\n",
       "  'go',\n",
       "  'to',\n",
       "  'be',\n",
       "  'so',\n",
       "  'charm',\n",
       "  \"he's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'forget',\n",
       "  'all',\n",
       "  'about',\n",
       "  'that',\n",
       "  'stupid',\n",
       "  'subway',\n",
       "  'girl.'],\n",
       " ['she', 'be', 'kinda', 'stupid.'],\n",
       " [\"you're\", 'right.'],\n",
       " ['all', 'right', \"i'm\", 'just', 'gon', 'na', 'go', 'on', 'the', 'date.'],\n",
       " [\"i'm\", 'gon', 'na', 'go', 'on', 'the', 'date.'],\n",
       " ['that', 'be', 'the', 'new', 'plan.'],\n",
       " ['hi.'],\n",
       " ['hey.'],\n",
       " ['hi.'],\n",
       " ['do', 'i?', 'thank', 'you', 'so', 'do', 'you.'],\n",
       " ['thanks.'],\n",
       " ['sparkly.'],\n",
       " ['mr.', 'major', 'capades', 'guy.'],\n",
       " ['i',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'when',\n",
       "  'you',\n",
       "  'be',\n",
       "  'just',\n",
       "  'like',\n",
       "  'king',\n",
       "  'friday',\n",
       "  'in',\n",
       "  'mr.',\n",
       "  \"roger's\",\n",
       "  'ice',\n",
       "  'be',\n",
       "  'nice.'],\n",
       " ['yeah',\n",
       "  'well',\n",
       "  'ya',\n",
       "  'know',\n",
       "  \"i'm\",\n",
       "  'kind',\n",
       "  'of',\n",
       "  'spooky',\n",
       "  'that',\n",
       "  'way.',\n",
       "  'wooo.'],\n",
       " ['i', 'miss', 'you.', \"i'm\", 'gon', 'na', 'get', 'change.'],\n",
       " ['ok.'],\n",
       " ['um', 'now.', 'phoebs.'],\n",
       " ['oh', 'right', 'ok.', 'ole.'],\n",
       " ['what?'],\n",
       " ['listen',\n",
       "  'i',\n",
       "  'forget',\n",
       "  'your',\n",
       "  'address',\n",
       "  'can',\n",
       "  'you',\n",
       "  'give',\n",
       "  'me',\n",
       "  'a',\n",
       "  'call?'],\n",
       " ['thanks', 'bye.'],\n",
       " ['oh',\n",
       "  \"i'd\",\n",
       "  'love',\n",
       "  'to',\n",
       "  'but',\n",
       "  'i',\n",
       "  'get',\n",
       "  'ta',\n",
       "  'get',\n",
       "  'up',\n",
       "  'so',\n",
       "  'early',\n",
       "  'the',\n",
       "  'next',\n",
       "  'day',\n",
       "  'and',\n",
       "  'so',\n",
       "  'you',\n",
       "  'know',\n",
       "  'me',\n",
       "  'work',\n",
       "  'come',\n",
       "  'first'],\n",
       " ['oh', 'yeah', 'yeah', 'yeah...'],\n",
       " ['kinda',\n",
       "  'have',\n",
       "  'a...',\n",
       "  'a',\n",
       "  'thing',\n",
       "  'for',\n",
       "  'the',\n",
       "  'day',\n",
       "  'of',\n",
       "  'our',\n",
       "  \"life's\",\n",
       "  'people.'],\n",
       " ['i', 'do', 'it', 'every', 'year.'],\n",
       " ['yeah...'],\n",
       " ['yeah...'],\n",
       " ['oh', \"that's\", \"ross's.\"],\n",
       " ['remember', 'what?'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'ross?',\n",
       "  'remember',\n",
       "  'back',\n",
       "  'in',\n",
       "  'college',\n",
       "  'when',\n",
       "  'he',\n",
       "  'fell',\n",
       "  'in',\n",
       "  'love',\n",
       "  'with',\n",
       "  'carol',\n",
       "  'and',\n",
       "  'buy',\n",
       "  'her',\n",
       "  'that',\n",
       "  'ridiculously',\n",
       "  'expensive',\n",
       "  'crystal',\n",
       "  'duck?'],\n",
       " ['wait', 'just', 'a', 'second.'],\n",
       " ['i', 'can', 'show', 'you', 'an', 'id', 'if', 'you', 'want?'],\n",
       " ['oh', 'yeah', 'well', 'i', 'just', 'start', 'wear', 'bra', 'again.'],\n",
       " ['oh', 'that', 'must', 'be', 'it.'],\n",
       " ['well', 'i', 'hope', 'you', 'have', 'fun', 'tonight.'],\n",
       " ['i', 'believe', 'it.'],\n",
       " ['yes', 'i', 'do.'],\n",
       " ['jurassic', 'park'],\n",
       " ['maybe', 'we', 'should', 'check', 'the', 'trash', 'chute.'],\n",
       " ['ross', 'could', \"n't\", 'fit', 'down', 'the', 'trash', 'chute.'],\n",
       " [\"that's\",\n",
       "  'right',\n",
       "  'he',\n",
       "  'almost',\n",
       "  'could.',\n",
       "  'which',\n",
       "  'be',\n",
       "  'exactly',\n",
       "  'how',\n",
       "  'i',\n",
       "  'get',\n",
       "  'stuck',\n",
       "  'there.'],\n",
       " ['hey!'],\n",
       " ['just', \"y'know\", 'out.'],\n",
       " ['what', 'be', 'you', 'do?'],\n",
       " ['i',\n",
       "  'uh',\n",
       "  'go',\n",
       "  'to',\n",
       "  'a',\n",
       "  'bar.',\n",
       "  'and',\n",
       "  'then',\n",
       "  'i',\n",
       "  'just',\n",
       "  'uh',\n",
       "  'just',\n",
       "  'walk',\n",
       "  'around',\n",
       "  'for',\n",
       "  'a',\n",
       "  'while.'],\n",
       " ['ross', 'you', 'leave', 'you', 'scarf', 'in', 'hey', 'you', 'guy.'],\n",
       " ['oh', 'yeah', 'that', 'look', 'good.'],\n",
       " ['you', 'guy', 'make', 'a'],\n",
       " ['okay.'],\n",
       " [\"y'know\", 'we', 'do', \"n't\", 'have', 'to', 'imagine.'],\n",
       " [\"we'll\", 'just', 'see.'],\n",
       " ['hi', 'joey.'],\n",
       " ['hey!', 'how', 'you', \"doin'?\"],\n",
       " [\"i'd\", 'love', 'to', 'show', 'ya', 'but', 'i', 'just', 'tuck', 'her', 'in.'],\n",
       " [\"she's\", 'sleep.'],\n",
       " ['hey',\n",
       "  'uh',\n",
       "  'would',\n",
       "  'you',\n",
       "  'two',\n",
       "  'girl',\n",
       "  'like',\n",
       "  'to',\n",
       "  'go',\n",
       "  'for',\n",
       "  'a',\n",
       "  'drink?'],\n",
       " ['and', 'how', 'do', 'i', 'know?'],\n",
       " ['her', 'die', 'wish', 'be', 'for', 'one', 'last', 'kiss.'],\n",
       " ['smelly',\n",
       "  'cat',\n",
       "  'smelly',\n",
       "  'cat',\n",
       "  'what',\n",
       "  'be',\n",
       "  'they',\n",
       "  'feed',\n",
       "  'you?',\n",
       "  'smelly',\n",
       "  'cat',\n",
       "  'smelly',\n",
       "  'cat',\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'your',\n",
       "  'fault.'],\n",
       " [\"y'know\",\n",
       "  'you',\n",
       "  'could',\n",
       "  'totally',\n",
       "  'sell',\n",
       "  'this.',\n",
       "  \"it'd\",\n",
       "  'be',\n",
       "  'perfect',\n",
       "  'for',\n",
       "  'like',\n",
       "  'umm',\n",
       "  'a',\n",
       "  'kitty',\n",
       "  'litter',\n",
       "  'campaign.'],\n",
       " ['i...', 'a', 'jingle?', 'no', 'no', 'no', 'no', 'no.'],\n",
       " ['okay',\n",
       "  'well',\n",
       "  'if',\n",
       "  'i',\n",
       "  'be',\n",
       "  'in',\n",
       "  'this',\n",
       "  'for',\n",
       "  'the',\n",
       "  'money',\n",
       "  \"i'd\",\n",
       "  'be',\n",
       "  'a',\n",
       "  'millionaire',\n",
       "  'by',\n",
       "  'now',\n",
       "  \"y'know.\"],\n",
       " ['you',\n",
       "  'just',\n",
       "  'get',\n",
       "  'to',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'that',\n",
       "  'jingle',\n",
       "  'head',\n",
       "  'sweetie.'],\n",
       " ['aw', \"you're\", 'right', \"you're\", 'right.', \"i'm\", 'sorry.'],\n",
       " ['okay', 'sir', 'um', 'mm', 'let', 'see', 'if', 'i', 'get', 'this', 'right.'],\n",
       " ['ah',\n",
       "  'so',\n",
       "  'this',\n",
       "  'be',\n",
       "  'a',\n",
       "  'half',\n",
       "  'caf',\n",
       "  'double',\n",
       "  'tall',\n",
       "  'easy',\n",
       "  'hazel',\n",
       "  'nut',\n",
       "  'non',\n",
       "  'fat',\n",
       "  'no',\n",
       "  'foam',\n",
       "  'with',\n",
       "  'whip',\n",
       "  'extra',\n",
       "  'hot',\n",
       "  'latte',\n",
       "  'right?'],\n",
       " ['um', 'coffee', 'to', 'go', 'please.'],\n",
       " ['isabella', 'rosselini.'],\n",
       " ['why?', 'cause', 'otherwise', \"you'd\", 'go', 'for', 'it?'],\n",
       " ['yeah', 'maybe.'],\n",
       " ['what', 'you', 'do', \"n't\", 'think', \"i'd\", 'go', 'up', 'to', 'her?'],\n",
       " ['ross',\n",
       "  'it',\n",
       "  'take',\n",
       "  'you',\n",
       "  'ten',\n",
       "  'year',\n",
       "  'to',\n",
       "  'finally',\n",
       "  'admit',\n",
       "  'you',\n",
       "  'like',\n",
       "  'me.'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'what',\n",
       "  'honey',\n",
       "  'you',\n",
       "  'go',\n",
       "  'ahead',\n",
       "  \"we'll\",\n",
       "  'call',\n",
       "  'her',\n",
       "  'an',\n",
       "  'alternate.'],\n",
       " ['okay', 'hold', 'my', 'crawler.'],\n",
       " ['okay.'],\n",
       " ['okay', \"that's\", \"that's\", 'enough.'],\n",
       " ['wo', \"n't\", 'you', 'dance', 'around', 'with', 'me.'],\n",
       " ['oh', 'ho', 'yeah.', 'yeah', 'the', 'hand', 'guy.'],\n",
       " ['okay', \"that's\", 'fair.'],\n",
       " ['all', 'right.'],\n",
       " ['good!'],\n",
       " ['pick', 'one.'],\n",
       " [\"you're\", 'welcome.'],\n",
       " ['joey!', 'we', 'should', 'just', 'switch.'],\n",
       " ['so', 'what', 'be', 'it', 'for', 'anyway?'],\n",
       " ['i', 'wan', 'na', 'say', 'a', 'disease.'],\n",
       " ['i',\n",
       "  'just',\n",
       "  'get',\n",
       "  'this',\n",
       "  'really',\n",
       "  'weird',\n",
       "  'message',\n",
       "  'from',\n",
       "  'ross.',\n",
       "  'he',\n",
       "  'say',\n",
       "  'turn',\n",
       "  'on'],\n",
       " ['oh', 'oh', 'professor', 'geller.'],\n",
       " ['ahh', 'to', 'be', 'again.'],\n",
       " ['hey!', 'so', 'uh', 'be', 'he', 'excite', 'about', 'the', 'ticket?'],\n",
       " ['doorknob?'],\n",
       " ['yeah',\n",
       "  'it',\n",
       "  'kinda',\n",
       "  'grows',\n",
       "  'on',\n",
       "  'you.',\n",
       "  'actually',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'finish',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'you',\n",
       "  'about',\n",
       "  'uh',\n",
       "  'spring',\n",
       "  'vacation.'],\n",
       " ['how', 'do', 'you', 'feel?'],\n",
       " ['well',\n",
       "  \"let's\",\n",
       "  'just',\n",
       "  'say',\n",
       "  'that',\n",
       "  'krog',\n",
       "  'will',\n",
       "  'be',\n",
       "  'fully',\n",
       "  'equip',\n",
       "  'to',\n",
       "  'destroy',\n",
       "  'the',\n",
       "  'universe',\n",
       "  'again',\n",
       "  'in',\n",
       "  'twelve',\n",
       "  'to',\n",
       "  'fourteen',\n",
       "  'hour.'],\n",
       " ['okay', 'so', 'i'],\n",
       " ['and', 'protect', 'them', 'from', 'a', 'tornado?'],\n",
       " ['i', 'know', 'the', 'baby', 'be', 'asleep.'],\n",
       " ['be',\n",
       "  'not',\n",
       "  'as',\n",
       "  'important',\n",
       "  'as',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'phoebe',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'the',\n",
       "  'baby',\n",
       "  'all',\n",
       "  'by',\n",
       "  'herself.'],\n",
       " [\"you're\", 'right', \"you're\", 'right', 'i', 'should', \"n't\", 'freak', 'out.'],\n",
       " ['cause',\n",
       "  'this',\n",
       "  'be',\n",
       "  'what',\n",
       "  'will',\n",
       "  'happen',\n",
       "  'when',\n",
       "  'you',\n",
       "  'and',\n",
       "  'i',\n",
       "  'have',\n",
       "  'baby!'],\n",
       " ['when', 'will', 'that', 'be?'],\n",
       " ['a', 'dreamless', 'sleep.'],\n",
       " ['well',\n",
       "  'the',\n",
       "  'big',\n",
       "  'news',\n",
       "  'be',\n",
       "  'still',\n",
       "  'you',\n",
       "  'dump',\n",
       "  'barry',\n",
       "  'at',\n",
       "  'the',\n",
       "  'altar!'],\n",
       " ['alright.', \"let's\", 'talk', 'reality', 'for', 'a', 'second.'],\n",
       " ['okay.'],\n",
       " ['when', 'be', 'you', 'come', 'home?'],\n",
       " [\"c'mon\", 'this', 'be', 'us.'],\n",
       " [\"i'm\",\n",
       "  'not!',\n",
       "  'this',\n",
       "  'be',\n",
       "  'what',\n",
       "  \"i'm\",\n",
       "  'do',\n",
       "  'now.',\n",
       "  \"i've\",\n",
       "  'get',\n",
       "  'this',\n",
       "  'job'],\n",
       " ['okay', \"i'm\", 'not', 'just', 'waitress.'],\n",
       " [\"i'm..\"],\n",
       " ['i', 'um...'],\n",
       " ['i',\n",
       "  'write',\n",
       "  'the',\n",
       "  'special',\n",
       "  'on',\n",
       "  'the',\n",
       "  'special',\n",
       "  'board',\n",
       "  'and',\n",
       "  'uh...',\n",
       "  'and',\n",
       "  'i',\n",
       "  'uh...'],\n",
       " ['we',\n",
       "  'get',\n",
       "  'off',\n",
       "  'around',\n",
       "  'midnight',\n",
       "  'why',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'we',\n",
       "  'pick',\n",
       "  'you',\n",
       "  'up',\n",
       "  'then?'],\n",
       " ['so', 'um', 'will', 'you', 'bring', 'the', 'truck?'],\n",
       " [\"i'll\", 'even', 'let', 'you', 'ring', 'the', 'bell.'],\n",
       " [\"they're\", 'nice', 'guy.'],\n",
       " ['your', 'son.'],\n",
       " ['well',\n",
       "  'jamie',\n",
       "  'be',\n",
       "  'the',\n",
       "  'name',\n",
       "  'of',\n",
       "  \"susan's\",\n",
       "  'first',\n",
       "  'girlfriend',\n",
       "  'so',\n",
       "  'we',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'jordie.'],\n",
       " ['i', 'get', 'it.'],\n",
       " ['i', 'get', 'it.'],\n",
       " ['no', 'you', 'do', \"n't.\"],\n",
       " ['yeah', 'listen...'],\n",
       " ['well',\n",
       "  'you',\n",
       "  'just',\n",
       "  'ask',\n",
       "  'if',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'with',\n",
       "  'you',\n",
       "  'tonight.'],\n",
       " ['knock', 'knock', 'knock', 'knock', 'hi.'],\n",
       " ['um',\n",
       "  'could',\n",
       "  'you',\n",
       "  'please',\n",
       "  'tell',\n",
       "  'sergei',\n",
       "  'that',\n",
       "  'um',\n",
       "  'i',\n",
       "  'be',\n",
       "  'fascinate',\n",
       "  'by',\n",
       "  'what',\n",
       "  'boutros',\n",
       "  'boutros',\n",
       "  'gali',\n",
       "  'say',\n",
       "  'in',\n",
       "  'the',\n",
       "  'new',\n",
       "  'york',\n",
       "  'time.'],\n",
       " ['you', 'do', \"n't\", 'say', 'boutros', 'boutros', 'gali.'],\n",
       " ['boutros', 'boutros', 'gali.'],\n",
       " ['he', 'say', 'he', 'be', 'too.'],\n",
       " ['interesting.'],\n",
       " ['so', 'i', 'be', 'wonder....'],\n",
       " ['so', \"you're\", 'a', 'chef?'],\n",
       " ['monica',\n",
       "  'can',\n",
       "  'i',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'you',\n",
       "  'behind',\n",
       "  'my',\n",
       "  'menu',\n",
       "  'please.',\n",
       "  'what',\n",
       "  'be',\n",
       "  'you',\n",
       "  'do?'],\n",
       " ['well', 'i', 'be', 'have', 'a', 'conversation.'],\n",
       " ['that', 'would', 'be', 'great.', 'thank', 'you.'],\n",
       " ['oh',\n",
       "  \"y'know\",\n",
       "  'the',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'happen',\n",
       "  'to',\n",
       "  'me',\n",
       "  'one',\n",
       "  'time.'],\n",
       " ['do',\n",
       "  \"n't\",\n",
       "  'you',\n",
       "  'remember',\n",
       "  'when',\n",
       "  'we',\n",
       "  'be',\n",
       "  'jog',\n",
       "  'in',\n",
       "  'the',\n",
       "  'park',\n",
       "  'and',\n",
       "  'we',\n",
       "  'saw',\n",
       "  'that',\n",
       "  'really',\n",
       "  'pretty',\n",
       "  'bird',\n",
       "  'and',\n",
       "  'want',\n",
       "  'to',\n",
       "  'take',\n",
       "  'a',\n",
       "  'picture',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'my',\n",
       "  'camera!'],\n",
       " ['here', \"i'll\", 'get', 'it.'],\n",
       " [\"we'd\",\n",
       "  'better',\n",
       "  'take',\n",
       "  'these',\n",
       "  'pant',\n",
       "  'off',\n",
       "  'upstairs',\n",
       "  'or',\n",
       "  'that',\n",
       "  \"stain's\",\n",
       "  'gon',\n",
       "  'na',\n",
       "  'set.'],\n",
       " ['action!'],\n",
       " [\"here's\", 'your', 'call', 'sheet', 'for', 'tomorrow.'],\n",
       " ['i', 'know.'],\n",
       " ['oh', 'yeah', 'i', 'should', 'probably', 'call', 'them.'],\n",
       " ['oh', 'i', 'do', \"n't\", 'think', 'i', 'ever', 'hear', 'that', 'story.'],\n",
       " ['what', 'a', 'sweet', 'story.'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'it.',\n",
       "  'only',\n",
       "  'now',\n",
       "  'we',\n",
       "  'call',\n",
       "  'it',\n",
       "  'the',\n",
       "  'beach',\n",
       "  'house.'],\n",
       " ['after',\n",
       "  'apply',\n",
       "  'the',\n",
       "  'waxine',\n",
       "  'and',\n",
       "  'linen',\n",
       "  'strip',\n",
       "  'to',\n",
       "  'leg',\n",
       "  'number',\n",
       "  'one'],\n",
       " ['grasp',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'linen',\n",
       "  'strip',\n",
       "  'by',\n",
       "  'its',\n",
       "  'easy',\n",
       "  'grab',\n",
       "  \"tab'and\",\n",
       "  'pull',\n",
       "  'it',\n",
       "  'off',\n",
       "  'in',\n",
       "  'one',\n",
       "  'quick',\n",
       "  'pain',\n",
       "  'free',\n",
       "  'motion.'],\n",
       " ['huh',\n",
       "  'well',\n",
       "  'the',\n",
       "  'girl',\n",
       "  'in',\n",
       "  'the',\n",
       "  'satin',\n",
       "  'nightie',\n",
       "  'on',\n",
       "  'the',\n",
       "  'commercial',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'seem',\n",
       "  'to',\n",
       "  'think',\n",
       "  \"it's\",\n",
       "  'that',\n",
       "  'bad.'],\n",
       " ['but',\n",
       "  'hey',\n",
       "  \"y'know\",\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'believe',\n",
       "  'me',\n",
       "  'please',\n",
       "  'by',\n",
       "  'my',\n",
       "  'guest.'],\n",
       " ['now', 'umm', 'remember', \"i'm\", 'still', 'learn.'],\n",
       " ['one', 'two', 'three', 'four!'],\n",
       " ['so?'],\n",
       " ['david', 'who?'],\n",
       " ['oh',\n",
       "  'you',\n",
       "  'say',\n",
       "  \"someone's\",\n",
       "  'name',\n",
       "  'enough',\n",
       "  'they',\n",
       "  'turn',\n",
       "  'around.'],\n",
       " ['yeah',\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  \"i'm\",\n",
       "  'just',\n",
       "  'in',\n",
       "  'town',\n",
       "  'for',\n",
       "  'a',\n",
       "  'conference.',\n",
       "  'umm'],\n",
       " ['yeah.', 'well', 'i', 'i', 'get', 'like', 'thirty', 'of', 'them.'],\n",
       " ['yeah.'],\n",
       " [\"it's\",\n",
       "  'no',\n",
       "  'big',\n",
       "  'deal.',\n",
       "  'hey',\n",
       "  \"y'know\",\n",
       "  'you',\n",
       "  'do',\n",
       "  'what',\n",
       "  'you',\n",
       "  'get',\n",
       "  'ta',\n",
       "  'do.',\n",
       "  'right?'],\n",
       " ['but',\n",
       "  'hey',\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'just',\n",
       "  'me',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'the',\n",
       "  'scientist',\n",
       "  'and',\n",
       "  'the',\n",
       "  'tour',\n",
       "  'guide'],\n",
       " ['whatever.'],\n",
       " ['okay', 'mon', 'back', 'me', 'up', 'here.'],\n",
       " ['where',\n",
       "  'you',\n",
       "  'work',\n",
       "  'the',\n",
       "  'uh',\n",
       "  'waiter',\n",
       "  'eat',\n",
       "  'with',\n",
       "  'the',\n",
       "  'waiter',\n",
       "  'right?'],\n",
       " ['and', 'the', 'chef', 'eat', 'with', 'the', 'other', 'chef', 'right?'],\n",
       " ['look', 'ross', 'really', \"it's\", \"it's\", 'no', 'big', 'deal.'],\n",
       " [\"y'know\", 'hey', 'i', 'understand.'],\n",
       " [\"y'know?\"],\n",
       " ['hey',\n",
       "  'when',\n",
       "  \"i'm\",\n",
       "  'in',\n",
       "  'a',\n",
       "  'play',\n",
       "  'and',\n",
       "  \"you're\",\n",
       "  'in',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'talk',\n",
       "  'to',\n",
       "  'you',\n",
       "  'right?'],\n",
       " ['so', \"it's\", \"y'know\", \"it's\", 'uh', \"it's\", 'cool.'],\n",
       " [\"i'll\", 'see', 'you', 'tomorrow.'],\n",
       " ['yeah',\n",
       "  'when',\n",
       "  \"we're\",\n",
       "  'in',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'he',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'talk',\n",
       "  'to',\n",
       "  'us',\n",
       "  'but',\n",
       "  'he',\n",
       "  'do',\n",
       "  'wave.'],\n",
       " ['hey',\n",
       "  'i',\n",
       "  'be',\n",
       "  \"n't\",\n",
       "  'the',\n",
       "  'only',\n",
       "  'one',\n",
       "  'who',\n",
       "  'look',\n",
       "  'like',\n",
       "  'an',\n",
       "  'idiot.'],\n",
       " ['all', 'right?'],\n",
       " ['yeah', \"that's\", 'the', 'same.'],\n",
       " ['oh',\n",
       "  'wait!',\n",
       "  'that',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'the',\n",
       "  'one',\n",
       "  \"rachel's\",\n",
       "  'talk',\n",
       "  'about.',\n",
       "  'she',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'even',\n",
       "  'know',\n",
       "  'that',\n",
       "  'happen.',\n",
       "  'so',\n",
       "  'which',\n",
       "  'one',\n",
       "  'be',\n",
       "  'it?'],\n",
       " ['oh',\n",
       "  'come',\n",
       "  'on',\n",
       "  'monica',\n",
       "  'relive',\n",
       "  'past',\n",
       "  'pain',\n",
       "  'and',\n",
       "  'get',\n",
       "  'depress',\n",
       "  'be',\n",
       "  'what',\n",
       "  'thanksgiving',\n",
       "  'be',\n",
       "  'all',\n",
       "  'about.'],\n",
       " ['hi', 'guy.'],\n",
       " ['hi', 'phoebe.'],\n",
       " ['no', 'we'],\n",
       " ['hormone.'],\n",
       " ['hormone', 'yeah.'],\n",
       " ['your', \"parent'?\"],\n",
       " ['yeah', \"they're\", 'out', 'of', 'town.'],\n",
       " ['yeah', 'yeah', \"it's\", 'this'],\n",
       " ['yeah', 'that', 'work.'],\n",
       " ['honey', 'you', 'remember', 'my', 'bos', 'doug', 'right?'],\n",
       " ['yes', 'hi.'],\n",
       " ['no', 'leg', 'chew', 'for', 'us', 'sir.'],\n",
       " ['oh', 'well', 'give', 'it', 'time.'],\n",
       " ['how',\n",
       "  'about',\n",
       "  'we',\n",
       "  'all',\n",
       "  'go',\n",
       "  'out',\n",
       "  'to',\n",
       "  'dinner',\n",
       "  'tomorrow',\n",
       "  'night?'],\n",
       " ['just', 'so', 'you', 'know', \"we're\", 'not', 'see', 'him', 'tomorrow.'],\n",
       " ['no.'],\n",
       " ['now',\n",
       "  'maybe',\n",
       "  'you',\n",
       "  'just',\n",
       "  'like',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'but',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'duck',\n",
       "  'in',\n",
       "  'there!',\n",
       "  'who',\n",
       "  'care',\n",
       "  \"y'know?\",\n",
       "  'now',\n",
       "  'i',\n",
       "  'get',\n",
       "  'the',\n",
       "  'leg'],\n",
       " ...]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_clean_split = [text.split() for text in texto_clean]\n",
    "texto_clean_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2295d19ed70>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM = 300 #maximo largo de la secuencia\n",
    "maxlen=300\n",
    "w2v_model = gensim.models.Word2Vec(sentences=texto_clean_split, vector_size=DIM, window=5, min_count=1) #Modelo pre-entrenado Word2vec\n",
    "fasttext_model = gensim.models.FastText(sentences=texto_clean_split, vector_size=DIM, window=5, min_count=1) #Modelo pre-entrenado FastText\n",
    "#Tiene que aparecer una vez como minimo en la secuencia para considerarlo\n",
    "\n",
    "w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv['meaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_weights_matrix_embedding_word2vec(model_w2v, fasttext_model):\n",
    "\n",
    "    weights_matrix = np.zeros((vocab_size, DIM)) #el dim es la dimensión del modelo\n",
    "    for word, index in vocab.items():\n",
    "      try:\n",
    "        weights_matrix[index] = model_w2v.wv[word] #obtiene los pesos de la palabra del modelo word2vec\n",
    "      except KeyError:\n",
    "        weights_matrix[index] = fasttext_model.wv[word] #En caso de que no exista en el vocabulario de Word2Vec ocupa FastText\n",
    "\n",
    "\n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del embedding, donde ingresa cada palabra al modelo y retorna los pesos\n",
    "Embeddings_Word2Vec_FastText = get_weights_matrix_embedding_word2vec(w2v_model, fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 300, 300)          4534200   \n",
      "                                                                 \n",
      " bidirectional_26 (Bidirecti  (None, 300, 256)         439296    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 300, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                8224      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,376,191\n",
      "Trainable params: 841,991\n",
      "Non-trainable params: 4,534,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Conv1D, Input, LeakyReLU, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "maximo_largo_secuencias=300\n",
    "\n",
    "input_seq  = Input(shape=(maximo_largo_secuencias,), dtype='int32')\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=maximo_largo_secuencias, weights=[Embeddings_Word2Vec_FastText], input_length=maximo_largo_secuencias, trainable=False)(input_seq)\n",
    "lstm1 = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)\n",
    "dropout = Dropout(0.5)(lstm1)\n",
    "lstm2 = Bidirectional(LSTM(128))(dropout)\n",
    "dense = Dense(32)(lstm2)\n",
    "dense = LeakyReLU(alpha=0.2)(dense)\n",
    "output = Dense(7, activation=\"softmax\")(dense)\n",
    "\n",
    "modelBiLstmWord2Vec = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "modelBiLstmWord2Vec.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "modelBiLstmWord2Vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#--------------------Checkpoint--------------------\n",
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('Embeddings/Word2Vec_FastText/BiLstm/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_path = 'Embeddings/Word2Vec_FastText/BiLstm/64batch/best_model_modelLSTM_{epoch}_{val_sparse_categorical_accuracy:.4f}.h5'\n",
    "\n",
    "# Callback de ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#----------------Tensorboard-------------------\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "os.makedirs('logs/Embeddings/Word2Vec_FastText/BiLstm/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"logs/Embeddings/Word2Vec_FastText/BiLstm/64batch\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "    984/Unknown - 327s 173ms/step - loss: 1.6092 - sparse_categorical_accuracy: 0.3625\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.40714, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_1_0.4071.h5\n",
      "984/984 [==============================] - 384s 231ms/step - loss: 1.6092 - sparse_categorical_accuracy: 0.3625 - val_loss: 1.5070 - val_sparse_categorical_accuracy: 0.4071\n",
      "Epoch 2/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.4643 - sparse_categorical_accuracy: 0.4375\n",
      "Epoch 2: val_sparse_categorical_accuracy improved from 0.40714 to 0.45882, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_2_0.4588.h5\n",
      "984/984 [==============================] - 286s 211ms/step - loss: 1.4643 - sparse_categorical_accuracy: 0.4375 - val_loss: 1.4129 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 3/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.3559 - sparse_categorical_accuracy: 0.4819\n",
      "Epoch 3: val_sparse_categorical_accuracy improved from 0.45882 to 0.49096, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_3_0.4910.h5\n",
      "984/984 [==============================] - 287s 212ms/step - loss: 1.3559 - sparse_categorical_accuracy: 0.4819 - val_loss: 1.3435 - val_sparse_categorical_accuracy: 0.4910\n",
      "Epoch 4/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.2520 - sparse_categorical_accuracy: 0.5284\n",
      "Epoch 4: val_sparse_categorical_accuracy improved from 0.49096 to 0.51730, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_4_0.5173.h5\n",
      "984/984 [==============================] - 291s 216ms/step - loss: 1.2520 - sparse_categorical_accuracy: 0.5284 - val_loss: 1.2790 - val_sparse_categorical_accuracy: 0.5173\n",
      "Epoch 5/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.1541 - sparse_categorical_accuracy: 0.5678\n",
      "Epoch 5: val_sparse_categorical_accuracy improved from 0.51730 to 0.54275, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_5_0.5427.h5\n",
      "984/984 [==============================] - 285s 210ms/step - loss: 1.1541 - sparse_categorical_accuracy: 0.5678 - val_loss: 1.2257 - val_sparse_categorical_accuracy: 0.5427\n",
      "Epoch 6/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.0573 - sparse_categorical_accuracy: 0.6086\n",
      "Epoch 6: val_sparse_categorical_accuracy improved from 0.54275 to 0.57455, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_6_0.5746.h5\n",
      "984/984 [==============================] - 286s 211ms/step - loss: 1.0573 - sparse_categorical_accuracy: 0.6086 - val_loss: 1.1538 - val_sparse_categorical_accuracy: 0.5746\n",
      "Epoch 7/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.9662 - sparse_categorical_accuracy: 0.6404\n",
      "Epoch 7: val_sparse_categorical_accuracy improved from 0.57455 to 0.58839, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_7_0.5884.h5\n",
      "984/984 [==============================] - 286s 211ms/step - loss: 0.9662 - sparse_categorical_accuracy: 0.6404 - val_loss: 1.1337 - val_sparse_categorical_accuracy: 0.5884\n",
      "Epoch 8/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.8884 - sparse_categorical_accuracy: 0.6730\n",
      "Epoch 8: val_sparse_categorical_accuracy improved from 0.58839 to 0.60491, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_8_0.6049.h5\n",
      "984/984 [==============================] - 291s 216ms/step - loss: 0.8884 - sparse_categorical_accuracy: 0.6730 - val_loss: 1.1160 - val_sparse_categorical_accuracy: 0.6049\n",
      "Epoch 9/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.8232 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 9: val_sparse_categorical_accuracy improved from 0.60491 to 0.60971, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_9_0.6097.h5\n",
      "984/984 [==============================] - 288s 214ms/step - loss: 0.8232 - sparse_categorical_accuracy: 0.6924 - val_loss: 1.1234 - val_sparse_categorical_accuracy: 0.6097\n",
      "Epoch 10/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.7608 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 10: val_sparse_categorical_accuracy improved from 0.60971 to 0.63326, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_10_0.6333.h5\n",
      "984/984 [==============================] - 288s 213ms/step - loss: 0.7608 - sparse_categorical_accuracy: 0.7179 - val_loss: 1.0772 - val_sparse_categorical_accuracy: 0.6333\n",
      "Epoch 11/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.7161 - sparse_categorical_accuracy: 0.7373\n",
      "Epoch 11: val_sparse_categorical_accuracy improved from 0.63326 to 0.63873, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_11_0.6387.h5\n",
      "984/984 [==============================] - 292s 217ms/step - loss: 0.7161 - sparse_categorical_accuracy: 0.7373 - val_loss: 1.0664 - val_sparse_categorical_accuracy: 0.6387\n",
      "Epoch 12/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.6659 - sparse_categorical_accuracy: 0.7539\n",
      "Epoch 12: val_sparse_categorical_accuracy improved from 0.63873 to 0.64230, saving model to Embeddings/Word2Vec_FastText/BiLstm/64batch\\best_model_modelLSTM_12_0.6423.h5\n",
      "984/984 [==============================] - 292s 217ms/step - loss: 0.6659 - sparse_categorical_accuracy: 0.7539 - val_loss: 1.0937 - val_sparse_categorical_accuracy: 0.6423\n",
      "Epoch 13/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.9722 - sparse_categorical_accuracy: 0.6429\n",
      "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.64230\n",
      "984/984 [==============================] - 289s 214ms/step - loss: 0.9722 - sparse_categorical_accuracy: 0.6429 - val_loss: 1.1230 - val_sparse_categorical_accuracy: 0.6097\n",
      "Epoch 14/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.8399 - sparse_categorical_accuracy: 0.6873\n",
      "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.64230\n",
      "984/984 [==============================] - 290s 215ms/step - loss: 0.8399 - sparse_categorical_accuracy: 0.6873 - val_loss: 1.1080 - val_sparse_categorical_accuracy: 0.6261\n",
      "Epoch 15/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.7016 - sparse_categorical_accuracy: 0.7410\n",
      "Epoch 15: val_sparse_categorical_accuracy did not improve from 0.64230\n",
      "984/984 [==============================] - 289s 213ms/step - loss: 0.7016 - sparse_categorical_accuracy: 0.7410 - val_loss: 1.1071 - val_sparse_categorical_accuracy: 0.6328\n"
     ]
    }
   ],
   "source": [
    "historyWord2Vec = modelBiLstmWord2Vec.fit(\n",
    "    train_dataset_normal,\n",
    "    validation_data=val_dataset_normal,\n",
    "    epochs=15,\n",
    "    callbacks=[model_checkpoint, tensorboard_callback]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = historyWord2Vec.history['loss']\n",
    "val_loss = historyWord2Vec.history['val_loss']\n",
    "train_accuracy = historyWord2Vec.history['sparse_categorical_accuracy']\n",
    "val_accuracy = historyWord2Vec.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Entrenamiento')\n",
    "plt.plot(val_loss, label='Validación')\n",
    "plt.title('Curva de pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Entrenamiento')\n",
    "plt.plot(val_accuracy, label='Validación')\n",
    "plt.title('Curva de precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + FastText separados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x228b0be7af0>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM = 300 #maximo largo de la secuencia\n",
    "maxlen=300\n",
    "w2v_model = gensim.models.Word2Vec(sentences=texto_clean_split, vector_size=DIM, window=5, min_count=1) #Modelo pre-entrenado Word2vec\n",
    "fasttext_model = gensim.models.FastText(sentences=texto_clean_split, vector_size=DIM, window=5, min_count=1) #Modelo pre-entrenado FastText\n",
    "#Tiene que aparecer una vez como minimo en la secuencia para considerarlo\n",
    "\n",
    "w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_weights_matrix_embedding_word2vecFastText(model_w2v, fasttext_model):\n",
    "\n",
    "    weights_matrix = np.zeros((vocab_size, DIM)) #el dim es la dimensión del modelo\n",
    "    for word, index in vocab.items():\n",
    "      try:\n",
    "        weights_matrix[index] = model_w2v.wv[word] #obtiene los pesos de la palabra del modelo word2vec\n",
    "      except KeyError:\n",
    "        weights_matrix[index] = fasttext_model.wv[word] #en caso de no estar en el vocabulario de word2Vec ocupa FastText\n",
    "\n",
    "\n",
    "    return weights_matrix\n",
    "\n",
    "\n",
    "def get_weights_matrix_embedding(model):\n",
    "    weights_matrix = np.zeros((vocab_size, DIM)) #el dim es la dimensión del modelo\n",
    "\n",
    "    for word, index in vocab.items():\n",
    "        weights_matrix[index] = model.wv[word] #obtiene los pesos de la palabra del modelo wor2vec\n",
    "\n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del embedding, donde ingresa cada palabra al modelo y retorna los pesos\n",
    "EmbeddingsW2Vec = get_weights_matrix_embedding_word2vecFastText(w2v_model, fasttext_model) #Pesos para Word2Vec con complemento de FastText\n",
    "EmbeddingsFastText = get_weights_matrix_embedding(fasttext_model) #Pesos para FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 300, 300)     4534200     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 300, 300)     4534200     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_28 (Bidirectiona  (None, 256)         439296      ['embedding_5[0][0]']            \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_29 (Bidirectiona  (None, 256)         439296      ['embedding_6[0][0]']            \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 256)          0           ['bidirectional_28[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 256)          0           ['bidirectional_29[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512)          0           ['dropout_15[0][0]',             \n",
      "                                                                  'dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 32)           16416       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32)           0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 7)            231         ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,963,639\n",
      "Trainable params: 895,239\n",
      "Non-trainable params: 9,068,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Conv1D, Input, LeakyReLU, concatenate, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "maximo_largo_secuencias=300\n",
    "\n",
    "input_seq  = Input(shape=(maximo_largo_secuencias,), dtype='int32')\n",
    "embedding_word2vec = Embedding(input_dim=vocab_size, output_dim=maximo_largo_secuencias, weights=[EmbeddingsW2Vec], input_length=maximo_largo_secuencias, trainable=False)(input_seq)\n",
    "embedding_fasttext = Embedding(input_dim=vocab_size, output_dim=maximo_largo_secuencias, weights=[EmbeddingsFastText], input_length=maximo_largo_secuencias, trainable=False)(input_seq)\n",
    "\n",
    "lstm_word2vec = Bidirectional(LSTM(128))(embedding_word2vec)\n",
    "dropout_word2vec = Dropout(0.5)(lstm_word2vec)\n",
    "\n",
    "lstm_fasttext = Bidirectional(LSTM(128))(embedding_fasttext)\n",
    "dropout_fastText = Dropout(0.5)(lstm_fasttext)\n",
    "\n",
    "\n",
    "concatenated = concatenate([dropout_word2vec, dropout_fastText])\n",
    "\n",
    "dense = Dense(32)(concatenated)\n",
    "dense = LeakyReLU(alpha=0.2)(dense)\n",
    "output = Dense(7, activation=\"softmax\")(dense)\n",
    "\n",
    "modelBiLstmWord2VecFastText = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "modelBiLstmWord2VecFastText.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "modelBiLstmWord2VecFastText.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#--------------------Checkpoint--------------------\n",
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('Embeddings/Word2VecSeparadoFastText/BiLstm/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "checkpoint_path = 'Embeddings/Word2VecSeparadoFastText/BiLstm/64batch/best_model_modelLSTM_{epoch}_{val_sparse_categorical_accuracy:.4f}.h5'\n",
    "\n",
    "# Callback de ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#----------------Tensorboard-------------------\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "os.makedirs('logs/Embeddings/Word2VecSeparadoFastText/BiLstm/64batch', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"logs/Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "    984/Unknown - 346s 187ms/step - loss: 1.6241 - sparse_categorical_accuracy: 0.3571\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.40156, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_1_0.4016.h5\n",
      "984/984 [==============================] - 399s 241ms/step - loss: 1.6241 - sparse_categorical_accuracy: 0.3571 - val_loss: 1.5286 - val_sparse_categorical_accuracy: 0.4016\n",
      "Epoch 2/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.5136 - sparse_categorical_accuracy: 0.4129\n",
      "Epoch 2: val_sparse_categorical_accuracy improved from 0.40156 to 0.43705, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_2_0.4371.h5\n",
      "984/984 [==============================] - 294s 218ms/step - loss: 1.5136 - sparse_categorical_accuracy: 0.4129 - val_loss: 1.4518 - val_sparse_categorical_accuracy: 0.4371\n",
      "Epoch 3/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.4398 - sparse_categorical_accuracy: 0.4466\n",
      "Epoch 3: val_sparse_categorical_accuracy improved from 0.43705 to 0.45658, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_3_0.4566.h5\n",
      "984/984 [==============================] - 289s 214ms/step - loss: 1.4398 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.4043 - val_sparse_categorical_accuracy: 0.4566\n",
      "Epoch 4/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.3688 - sparse_categorical_accuracy: 0.4743\n",
      "Epoch 4: val_sparse_categorical_accuracy improved from 0.45658 to 0.49263, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_4_0.4926.h5\n",
      "984/984 [==============================] - 296s 221ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.4743 - val_loss: 1.3250 - val_sparse_categorical_accuracy: 0.4926\n",
      "Epoch 5/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.3087 - sparse_categorical_accuracy: 0.5057\n",
      "Epoch 5: val_sparse_categorical_accuracy improved from 0.49263 to 0.51194, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_5_0.5119.h5\n",
      "984/984 [==============================] - 305s 230ms/step - loss: 1.3087 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.2796 - val_sparse_categorical_accuracy: 0.5119\n",
      "Epoch 6/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.2427 - sparse_categorical_accuracy: 0.5291\n",
      "Epoch 6: val_sparse_categorical_accuracy improved from 0.51194 to 0.53482, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_6_0.5348.h5\n",
      "984/984 [==============================] - 302s 227ms/step - loss: 1.2427 - sparse_categorical_accuracy: 0.5291 - val_loss: 1.2352 - val_sparse_categorical_accuracy: 0.5348\n",
      "Epoch 7/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.1916 - sparse_categorical_accuracy: 0.5526\n",
      "Epoch 7: val_sparse_categorical_accuracy improved from 0.53482 to 0.54118, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_7_0.5412.h5\n",
      "984/984 [==============================] - 305s 230ms/step - loss: 1.1916 - sparse_categorical_accuracy: 0.5526 - val_loss: 1.2111 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 8/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.1297 - sparse_categorical_accuracy: 0.5779\n",
      "Epoch 8: val_sparse_categorical_accuracy improved from 0.54118 to 0.54855, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_8_0.5485.h5\n",
      "984/984 [==============================] - 303s 229ms/step - loss: 1.1297 - sparse_categorical_accuracy: 0.5779 - val_loss: 1.2026 - val_sparse_categorical_accuracy: 0.5485\n",
      "Epoch 9/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.0829 - sparse_categorical_accuracy: 0.5963\n",
      "Epoch 9: val_sparse_categorical_accuracy improved from 0.54855 to 0.56283, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_9_0.5628.h5\n",
      "984/984 [==============================] - 304s 229ms/step - loss: 1.0829 - sparse_categorical_accuracy: 0.5963 - val_loss: 1.1661 - val_sparse_categorical_accuracy: 0.5628\n",
      "Epoch 10/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 1.0337 - sparse_categorical_accuracy: 0.6189\n",
      "Epoch 10: val_sparse_categorical_accuracy improved from 0.56283 to 0.57478, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_10_0.5748.h5\n",
      "984/984 [==============================] - 302s 227ms/step - loss: 1.0337 - sparse_categorical_accuracy: 0.6189 - val_loss: 1.1433 - val_sparse_categorical_accuracy: 0.5748\n",
      "Epoch 11/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.9868 - sparse_categorical_accuracy: 0.6333\n",
      "Epoch 11: val_sparse_categorical_accuracy improved from 0.57478 to 0.59342, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_11_0.5934.h5\n",
      "984/984 [==============================] - 301s 226ms/step - loss: 0.9868 - sparse_categorical_accuracy: 0.6333 - val_loss: 1.1118 - val_sparse_categorical_accuracy: 0.5934\n",
      "Epoch 12/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.9459 - sparse_categorical_accuracy: 0.6487\n",
      "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.59342\n",
      "984/984 [==============================] - 302s 229ms/step - loss: 0.9459 - sparse_categorical_accuracy: 0.6487 - val_loss: 1.1108 - val_sparse_categorical_accuracy: 0.5888\n",
      "Epoch 13/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.9097 - sparse_categorical_accuracy: 0.6616\n",
      "Epoch 13: val_sparse_categorical_accuracy improved from 0.59342 to 0.60000, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_13_0.6000.h5\n",
      "984/984 [==============================] - 306s 231ms/step - loss: 0.9097 - sparse_categorical_accuracy: 0.6616 - val_loss: 1.0879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.8767 - sparse_categorical_accuracy: 0.6768\n",
      "Epoch 14: val_sparse_categorical_accuracy improved from 0.60000 to 0.61618, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_14_0.6162.h5\n",
      "984/984 [==============================] - 300s 226ms/step - loss: 0.8767 - sparse_categorical_accuracy: 0.6768 - val_loss: 1.0655 - val_sparse_categorical_accuracy: 0.6162\n",
      "Epoch 15/15\n",
      "984/984 [==============================] - ETA: 0s - loss: 0.8459 - sparse_categorical_accuracy: 0.6887\n",
      "Epoch 15: val_sparse_categorical_accuracy improved from 0.61618 to 0.62321, saving model to Embeddings/Word2VecSeparadoFastText/BiLstm/64batch\\best_model_modelLSTM_15_0.6232.h5\n",
      "984/984 [==============================] - 302s 227ms/step - loss: 0.8459 - sparse_categorical_accuracy: 0.6887 - val_loss: 1.0717 - val_sparse_categorical_accuracy: 0.6232\n"
     ]
    }
   ],
   "source": [
    "historyWord2VecFastText = modelBiLstmWord2VecFastText.fit(\n",
    "    train_dataset_normal,\n",
    "    validation_data=val_dataset_normal,\n",
    "    epochs=15,\n",
    "    callbacks=[model_checkpoint, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAGMCAYAAACmm+O/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADED0lEQVR4nOzdd1gUVxfA4d/SO6hUEQV7R0Wxdw3WRI3d2FvsiTFGUyyJ0RhT1BhbYkRNsbcYe+8Nxd5AFFFALICAtN35/pi4hg8LKLCA532eeeLOztw5u3G8e+Y2jaIoCkIIIYQQQgghhDA4I0MHIIQQQgghhBBCCJUk6UIIIYQQQgghRC4hSboQQgghhBBCCJFLSJIuhBBCCCGEEELkEpKkCyGEEEIIIYQQuYQk6UIIIYQQQgghRC4hSboQQgghhBBCCJFLSJIuhBBCCCGEEELkEpKkCyFytdDQUCZNmsS5c+cMHYoQQggh3iC7d+9mypQpxMfHGzoU8YaRJF0IkY6/vz8ajYYbN24YNI6UlBQ6d+7M2bNnqVChwmuXp9FomDRpkv51Zj6np6cnffr0ee0YhBBCiJyUW+r07PQqdfSkSZPQaDTPfT84OJj27dvj7OyMtbX1a0YoROZIki5EJgQHBzN48GCKFy+OhYUFdnZ21K1bl1mzZvH48WNDh5fvjB07FmNjY/744w+MjOSfKyGEEFlH6nTxPElJSXTq1Inhw4czaNAgQ4cj3kAmhg5AiLzin3/+oVOnTpibm9OrVy8qVqxIcnIyBw8e5OOPP+bChQssXLjQ0GHmG9HR0RQoUICNGzdiaWmZLdfo2bMnXbt2xdzcPFvKF0IIkTtJnZ6/XLlyJdMP8z///HPGjRv3zPfOnTtH3759GTFiRFaEJ0SmSZIuRAaEhITQtWtXihUrxu7du3Fzc9O/N2zYMIKCgvjnn3+y5Frx8fHSrQpwcHBgwoQJmTons9+dsbExxsbGmQ1NCCFEHiZ1uuEoikJiYmKWP3x/lYftJiYmmJg8OxWqXr061atXf92whHhl0n9UiAz49ttviYuLY9GiRWkq8ydKlizJqFGjALhx4wYajQZ/f/90x/3/mOgn46EuXrxI9+7dKVCgAPXq1eO7775Do9Fw8+bNdGWMHz8eMzMzHj58CMCBAwfo1KkTRYsWxdzcHA8PDz788MMMd9W7cOECTZo0wdLSkiJFijBlyhR0Ot0zj92yZQv169fH2toaW1tbWrduzYULF156jSfj4fbv38/gwYMpVKgQdnZ29OrVS/85MnudPn36YGNjQ3BwMK1atcLW1pYePXoAaje1Dz/8ECcnJ2xtbXn77bcJCwt7blz/HaenKApTpkyhSJEiWFlZ0bhx42d+xgcPHjBmzBgqVaqEjY0NdnZ2tGzZkjNnzrz0+xBCCGE4UqercqJO9/T0pE2bNmzbto3q1atjaWnJggULALXH3AcffICHhwfm5uaULFmS6dOnp4tXp9Mxa9YsKlWqhIWFBU5OTrRo0YKTJ0+muc5/x6SnpKQwefJkSpUqhYWFBYUKFaJevXrs2LFDf8yzxqSnpqby1VdfUaJECczNzfH09OTTTz8lKSnpmZ/r4MGD+Pr6YmFhQfHixVm6dOlLvz8hMkJa0oXIgL///pvixYtTp06dbCm/U6dOlCpViqlTp6IoCm3atGHs2LGsXLmSjz/+OM2xK1eu5K233qJAgQIArFq1ioSEBIYMGUKhQoU4fvw4P/30E2FhYaxateqF142IiKBx48akpqYybtw4rK2tWbhw4TOfcC9btozevXvj5+fH9OnTSUhIYN68edSrV4/Tp0/j6en50s85fPhwHBwcmDRpEleuXGHevHncvHmTvXv36ivKzFwnNTUVPz8//Y8gKysrAAYMGMDvv/9O9+7dqVOnDrt376Z169YvjQ9gwoQJTJkyhVatWtGqVStOnTrFW2+9RXJycprjrl+/zvr16+nUqRNeXl5ERkayYMECGjZsyMWLFylcuHCGrieEECJnSZ2ec3U6qF3Ru3XrxuDBgxk4cCBlypQhISGBhg0bcvv2bQYPHkzRokU5fPgw48ePJzw8nJkzZ+rP79+/P/7+/rRs2ZIBAwaQmprKgQMHOHr06HNbuydNmsS0adMYMGAAvr6+xMbGcvLkSU6dOkXz5s2f+5kGDBjAkiVL6NixIx999BHHjh1j2rRpXLp0iXXr1qU5NigoiI4dO9K/f3969+7Nb7/9Rp8+ffDx8cmSyW7FG04RQrxQTEyMAijvvPNOho4PCQlRAGXx4sXp3gOUiRMn6l9PnDhRAZRu3bqlO7Z27dqKj49Pmn3Hjx9XAGXp0qX6fQkJCenOnTZtmqLRaJSbN2++MNYPPvhAAZRjx47p9929e1ext7dXACUkJERRFEV59OiR4uDgoAwcODDN+REREYq9vX26/f9v8eLFCqD4+PgoycnJ+v3ffvutAigbNmzI9HV69+6tAMq4cePSHBsYGKgAytChQ9Ps7969e7rv/0lcTz7n3bt3FTMzM6V169aKTqfTH/fpp58qgNK7d2/9vsTEREWr1aa5RkhIiGJubq58+eWXL/w+hBBCGIbU6TlXpyuKohQrVkwBlK1bt6Yp46uvvlKsra2Vq1evptk/btw4xdjYWAkNDVUURVF2796tAMrIkSPTxfHferpYsWJp6mhvb2+ldevWL/wcT/5/PfHk98OAAQPSHDdmzBgFUHbv3p3uc+3fv1+/7+7du4q5ubny0UcfvfC6QmSEdHcX4iViY2MBsLW1zbZrvP/+++n2denShYCAAIKDg/X7VqxYgbm5Oe+8845+33+fkMfHx3Pv3j3q1KmDoiicPn36hdfdvHkztWrVwtfXV7/PyclJ3238iR07dhAdHU23bt24d++efjM2NqZmzZrs2bMnQ59z0KBBmJqa6l8PGTIEExMTNm/e/MrXGTJkSLrPBDBy5Mg0+z/44IOXxrdz506Sk5MZMWJEmlaAZ51rbm6un6RGq9Vy//59bGxsKFOmDKdOnXrptYQQQuQ8qdNzrk5/wsvLCz8/vzT7Vq1aRf369SlQoECaGJo1a4ZWq2X//v0ArFmzBo1Gw8SJE9Nd/0XLpzk4OHDhwgWuXbuWoc8CT38/jB49Os3+jz76CCDdPAXly5enfv36+tdOTk6UKVOG69evZ/iaQjyPJOlCvISdnR0Ajx49yrZreHl5pdvXqVMnjIyMWLFiBaCOlV61ahUtW7bUxwQQGhpKnz59KFiwIDY2Njg5OdGwYUMAYmJiXnjdmzdvUqpUqXT7y5Qpk+b1k0quSZMmODk5pdm2b9/O3bt3M/Q5//9aNjY2uLm56ceEZ/Y6JiYmFClSJN1nMjIyokSJEi/8TM/yZLzg/8fp5OSk74r4hE6n48cff6RUqVKYm5vj6OiIk5MTZ8+efen3LoQQwjCkTs+5Ov2JZ30f165dY+vWremu36xZMwB9DMHBwRQuXJiCBQtmKKYnvvzyS6KjoyldujSVKlXi448/5uzZsy8858nvh5IlS6bZ7+rqioODQ7o5BYoWLZqujAIFCjxzrh0hMkvGpAvxEnZ2dhQuXJjz589n6PjnPdnVarXPPedZ48UKFy5M/fr1WblyJZ9++ilHjx4lNDSU6dOnpymzefPmPHjwgE8++YSyZctibW3N7du36dOnz3Mni8msJ+UsW7YMV1fXdO8/b3bU7L7Of1uzc9rUqVP54osv6NevH1999RUFCxbEyMiIDz74IMu+dyGEEFlL6vScq9OfeNb3odPpaN68OWPHjn3mOaVLl36tazZo0IDg4GA2bNjA9u3b+fXXX/nxxx+ZP38+AwYMeOG5L2qh/6/nrQ6jKEqm4xXi/0mSLkQGtGnThoULF3LkyBFq1679wmOftLhGR0en2f+sWV1fpkuXLgwdOpQrV66wYsUKrKysaNu2rf79c+fOcfXqVZYsWUKvXr30+/87e+mLFCtW7Jldwa5cuZLm9ZNWaWdnZ/1T7ldx7do1GjdurH8dFxdHeHg4rVq1yrLrFCtWDJ1OR3BwcJrWg///TM8790mcxYsX1++PiopK92R89erVNG7cmEWLFqXZHx0djaOj4yvFLoQQIvtJnZ4zdfqLlChRgri4uJdev0SJEmzbto0HDx5kujW9YMGC9O3bl759+xIXF0eDBg2YNGnSc5P0J78frl27Rrly5fT7IyMjiY6O1v9GECInSHd3ITJg7NixWFtbM2DAACIjI9O9HxwczKxZswD1Kb2jo6N+PNUTc+fOzfR13333XYyNjfnrr79YtWoVbdq0SbPe6pOnuP99aqsoij6Wl2nVqhVHjx7l+PHj+n1RUVH88ccfaY7z8/PDzs6OqVOnkpKSkq6cqKioDF1v4cKFac6fN28eqamptGzZMsuu86Ss2bNnp9n/35lin6dZs2aYmpry008/pflOn3WusbFxuqflq1at4vbt2y+9jhBCCMOROj1n6vQX6dy5M0eOHGHbtm3p3ouOjiY1NRVQvzNFUZg8eXK6417UYn3//v00r21sbChZsmS6pdT+68nDhf+v83/44QeADK8SI0RWkJZ0ITKgRIkS/Pnnn3Tp0oVy5crRq1cvKlasSHJyMocPH2bVqlVp1uccMGAA33zzDQMGDKB69ers37+fq1evZvq6zs7ONG7cmB9++IFHjx7RpUuXNO+XLVuWEiVKMGbMGG7fvo2dnR1r1qzJ8HiosWPHsmzZMlq0aMGoUaP0y7UUK1YszdgtOzs75s2bR8+ePalWrRpdu3bFycmJ0NBQ/vnnH+rWrcucOXNeer3k5GSaNm1K586duXLlCnPnzqVevXq8/fbbWXadKlWq0K1bN+bOnUtMTAx16tRh165dBAUFvTQ+JycnxowZw7Rp02jTpg2tWrXi9OnTbNmyJV3reJs2bfjyyy/p27cvderU4dy5c/zxxx9pWuCFEELkPlKn50yd/iIff/wxGzdupE2bNvply+Lj4zl37hyrV6/mxo0bODo60rhxY3r27Mns2bO5du0aLVq0QKfTceDAARo3bszw4cOfWX758uVp1KgRPj4+FCxYkJMnT7J69ernHg/g7e1N7969WbhwIdHR0TRs2JDjx4+zZMkS2rVrl6bXgBDZziBzyguRR129elUZOHCg4unpqZiZmSm2trZK3bp1lZ9++klJTEzUH5eQkKD0799fsbe3V2xtbZXOnTsrd+/efe5yLVFRUc+95i+//KIAiq2trfL48eN071+8eFFp1qyZYmNjozg6OioDBw5Uzpw589wlY/7f2bNnlYYNGyoWFhaKu7u78tVXXymLFi1Ks1zLE3v27FH8/PwUe3t7xcLCQilRooTSp08f5eTJky+8xpPlWvbt26cMGjRIKVCggGJjY6P06NFDuX//frrjM3Kd3r17K9bW1s+83uPHj5WRI0cqhQoVUqytrZW2bdsqt27deukSbIqiKFqtVpk8ebLi5uamWFpaKo0aNVLOnz+fbnmXxMRE5aOPPtIfV7duXeXIkSNKw4YNlYYNG77w+xBCCGF4Uqdnf51erFix5y6F9ujRI2X8+PFKyZIlFTMzM8XR0VGpU6eO8t1336VZ2i01NVWZMWOGUrZsWcXMzExxcnJSWrZsqQQEBKS5zn/r6ClTpii+vr6Kg4ODYmlpqZQtW1b5+uuv05T7/0uwKYqipKSkKJMnT1a8vLwUU1NTxcPDQxk/fnyavw8v+lzyG0BkFY2iyOwGQojs5e/vT9++fTlx4gTVq1c3dDhCCCGEeEVSpwuR/WRMuhBCCCGEEEIIkUtIki6EEEIIIYQQQuQSkqQLIYQQQgghhBC5hIxJF0IIIYQQQgghcglpSRdCCCGEEEIIIXIJSdKFEEIIIYQQQohcQpJ0IYQQQgghhBAilzAxdAA5TafTcefOHWxtbdFoNIYORwghhEBRFB49ekThwoUxMpLn51lB6nshhBC5SabqeuUNc+vWLQWQTTbZZJNNtly33bp1y9DV5CuZM2eOUqxYMcXc3Fzx9fVVjh079txjGzZs+MzP3qpVK/0xOp1O+eKLLxRXV1fFwsJCadq0qXL16tVMxST1vWyyySabbLlxy0hd/8a1pNva2gJw69Yt7OzsDByNEEIIAbGxsXh4eOjrqLxkxYoVjB49mvnz51OzZk1mzpyJn58fV65cwdnZOd3xa9euJTk5Wf/6/v37eHt706lTJ/2+b7/9ltmzZ7NkyRK8vLz44osv8PPz4+LFi1hYWGQoLqnvhRBC5CaZqevfuCXYYmNjsbe3JyYmRiptIYQQuUJerptq1qxJjRo1mDNnDqB2M/fw8GDEiBGMGzfupefPnDmTCRMmEB4ejrW1NYqiULhwYT766CPGjBkDQExMDC4uLvj7+9O1a9cMxZWXv1MhhBD5T2bqJRn4JoQQQohXkpycTEBAAM2aNdPvMzIyolmzZhw5ciRDZSxatIiuXbtibW0NQEhICBEREWnKtLe3p2bNmi8sMykpidjY2DSbEEIIkRdJki6EEEKIV3Lv3j20Wi0uLi5p9ru4uBAREfHS848fP8758+cZMGCAft+T8zJb5rRp07C3t9dvHh4emfkoQgghRK4hSboQQgghDGLRokVUqlQJX1/f1y5r/PjxxMTE6Ldbt25lQYRCCCFEznvjJo4TQogXURSF1NRUtFqtoUMR+YixsTEmJib5bikwR0dHjI2NiYyMTLM/MjISV1fXF54bHx/P8uXL+fLLL9Psf3JeZGQkbm5uacqsUqXKc8szNzfH3Nw8U/FrtVpSUlIydY4QL5Nf73chRM6RJF0IIf6VnJxMeHg4CQkJhg5F5ENWVla4ublhZmZm6FCyjJmZGT4+PuzatYt27doB6sRxu3btYvjw4S88d9WqVSQlJfHee++l2e/l5YWrqyu7du3SJ+WxsbEcO3aMIUOGZFnscXFxhIWF8YbNnytySH6834UQOUeSdCGEQE0sQkJCMDY2pnDhwpiZmUkriMgSiqKQnJxMVFQUISEhlCpVCiOj/DPabPTo0fTu3Zvq1avj6+vLzJkziY+Pp2/fvgD06tULd3d3pk2blua8RYsW0a5dOwoVKpRmv0aj4YMPPmDKlCmUKlVKvwRb4cKF9Q8CXpdWqyUsLAwrKyucnJzkXhdZJr/f70KInCFJuhBCoLaiP1k6ysrKytDhiHzG0tISU1NTbt68SXJycobX+s4LunTpQlRUFBMmTCAiIoIqVaqwdetW/cRvoaGh6ZKUK1eucPDgQbZv3/7MMseOHUt8fDyDBg0iOjqaevXqsXXr1iz73lJSUlAUBScnJywtLbOkTCGeyM/3uxAiZ8g66UIIASQmJhISEoKXl5f8oBLZ4kV/x6Ruynov+k7lfhfZTf6OCSH+n6yTLoQQQgghhBBC5EGSpL8GrU5h4f5gwmMeGzoUIYQQgKenJzNnzjR0GEKIbCb3uhAiJ9y4F8+vB67n+CSjkqS/hkkbLzB182XGrj6LTvdGjRoQQuQiffr0QaPRpNtatGiRofP37t2LRqMhOjo6ewPNASdOnGDQoEFZWmajRo344IMPsrRMIV6F3OtPyb0uhMguMQkp/HHsJu/OO0yj7/Yy5Z9LnAmLydEYZOK419CnricrT97iwLV7LDt6k951PA0dkhDiDdWiRQsWL16cZl9m14x+meTk5Fy/nJCTk5OhQxAiW8m9rpJ7XQiRlVK0OvZdiWLt6TB2XrxLslYHgJEG6pdyIqfXAJGW9NdQwsmG8S3LAjBtyyWCo+IMHJEQ4k1lbm6Oq6trmq1AgQKAuqTVr7/+Svv27bGysqJUqVJs3LgRgBs3btC4cWMAChQogEajoU+fPoDaqjR8+HA++OADHB0d8fPzA+D8+fO0bNkSGxsbXFxc6NmzJ/fu3dPH0qhRI0aOHMnYsWMpWLAgrq6uTJo0KU28P/zwA5UqVcLa2hoPDw+GDh1KXNzTf0P9/f1xcHBg06ZNlClTBisrKzp27EhCQgJLlizB09OTAgUKMHLkSLRarf68/+8CGx0dzYABA3BycsLOzo4mTZpw5swZ/fuTJk2iSpUqLFu2DE9PT+zt7enatSuPHj0C1JbLffv2MWvWLH2r5Y0bNwDYt28fvr6+mJub4+bmxrhx40hNTX2N/4tCvJzc6yq514UQr0tRFM6FxTBp4wVqTd3FgKUn2XwugmStjrKutnzWqhxHxzdlST9fvD0ccjQ2SdJfU6/antQr6Uhiio7RKwJJ+fepixAi71MUhYTkVINsWT32afLkyXTu3JmzZ8/SqlUrevTowYMHD/Dw8GDNmjWAuixWeHg4s2bN0p+3ZMkSzMzMOHToEPPnzyc6OpomTZpQtWpVTp48ydatW4mMjKRz585prrdkyRKsra05duwY3377LV9++SU7duzQv29kZMTs2bO5cOECS5YsYffu3YwdOzZNGQkJCcyePZvly5ezdetW9u7dS/v27dm8eTObN29m2bJlLFiwgNWrVz/3c3fq1Im7d++yZcsWAgICqFatGk2bNuXBgwf6Y4KDg1m/fj2bNm1i06ZN7Nu3j2+++QaAWbNmUbt2bQYOHEh4eDjh4eF4eHhw+/ZtWrVqRY0aNThz5gzz5s1j0aJFTJky5dX/JwmDkXtd7nW514V4c4THPGbe3mDe+nE/beccxP/wDe7HJ+NoY86Ael5sHlmfrR80YGCD4jjbGWZ1Bunu/pqMjDTM6FQZvx/3cyYshrl7ghnVrJShwxJCZIHHKVrKT9hmkGtf/NIPK7OM/xO9adMmbGxs0uz79NNP+fTTTwG1lahbt24ATJ06ldmzZ3P8+HFatGhBwYIFAXB2dsbBwSFNGaVKleLbb7/Vv54yZQpVq1Zl6tSp+n2//fYbHh4eXL16ldKlSwNQuXJlJk6cqC9jzpw57Nq1i+bNmwOkGffp6enJlClTeP/995k7d65+f0pKCvPmzaNEiRIAdOzYkWXLlhEZGYmNjQ3ly5encePG7Nmzhy5duqT7Tg4ePMjx48e5e/euvjvwd999x/r161m9erV+PKtOp8Pf3x9bW1sAevbsya5du/j666+xt7fHzMwMKysrXF1d9WXPnTsXDw8P5syZg0ajoWzZsty5c4dPPvmECRMmpFsXXORucq/LvS73uhD5W3xSKtsuRLD21G0OBd/jyfNRcxMj3qrgSodq7tQv6YiJce64pw2apO/fv58ZM2YQEBBAeHg469ato127di88JykpiS+//JLff/+diIgI3NzcmDBhAv369cuZoJ/Bzd6Sr9pVZNTyQGbvvkbjsk5ULuJgsHiEEG+exo0bM2/evDT7nvwgB/WH9BPW1tbY2dlx9+7dl5br4+OT5vWZM2fYs2dPuiQB1Faq//5w/y83N7c019u5cyfTpk3j8uXLxMbGkpqaSmJiIgkJCVhZWQFgZWWl/9EO4OLigqenZ5pru7i4PPdznDlzhri4OAoVKpRm/+PHjwkODta/9vT01P9of1asz3Lp0iVq166NRvN0lFrdunWJi4sjLCyMokWLvvB8IV6V3Ovpyb0uhHgWrU7h6PX7rDkVxtbzESQkPx0y4+tVkHerudOykht2FqYGjPLZDJqkx8fH4+3tTb9+/ejQoUOGzuncuTORkZEsWrSIkiVLEh4ejk5n+C7mb3sXZvvFSP45G86HKwL5Z2R9LEyNDR2WEOI1WJoac/FLP4NdOzOsra0pWbLkc983NU1bAWk0mgz922ltbZ3mdVxcHG3btmX69OnpjnVzc8vQ9W7cuEGbNm0YMmQIX3/9NQULFuTgwYP079+f5ORk/Q/3Z5WRmc8RFxeHm5sbe/fuTffef1sRX/W7EfmH3Otyrwsh8o+gu49Yc+o260/fJjwmUb/fs5AVHaoVoX1VdzwKWhkwwpczaJLesmVLWrZsmeHjt27dyr59+7h+/br+qbGnp2c2RZc5Go2Gr9tV5ETIA4Kj4vlmy2UmvV3B0GEJIV6DRqPJVDfUvOrJLM7/nZTpeapVq8aaNWvw9PTExOTVvpuAgAB0Oh3ff/+9vqvoypUrX6msF6lWrRoRERGYmJi8Vl1hZmaW7rspV64ca9asQVEUfQvboUOHsLW1pUiRIq8TtjAAudfTk3tdJfe6EHnDg/hk/j5zhzWnwjj7n+XS7CxMaONdmHeruVOtaIE0vWJys9zR6T6DNm7cSPXq1fn2229xd3endOnSjBkzhsePHz/3nKSkJGJjY9Ns2cXByoxvO6rdvvwP3+DgtXsvOUMIIbJGUlISERERabb/zsL8IsWKFUOj0bBp0yaioqLSzLz8/4YNG8aDBw/o1q0bJ06cIDg4mG3bttG3b98M/fAHKFmyJCkpKfz0009cv36dZcuWMX/+/AydmxnNmjWjdu3atGvXju3bt3Pjxg0OHz7MZ599xsmTJzNcjqenJ8eOHePGjRvcu3cPnU7H0KFDuXXrFiNGjODy5cts2LCBiRMnMnr0aBmjKrKV3Ovpyb0uxJspKVXL1vPhDFx6Et+vdzJx4wXOhsVgYqShWTln5vaoxvHPmjG1fSV8ihXMMwk65LEk/fr16xw8eJDz58+zbt06Zs6cyerVqxk6dOhzz5k2bRr29vb6zcPDI1tjbFTGmfdqqeOTPl59hpjHKdl6PSGEALWnkZubW5qtXr16GTrX3d2dyZMnM27cOFxcXBg+fPhzjy1cuDCHDh1Cq9Xy1ltvUalSJT744AMcHBwy/IPV29ubH374genTp1OxYkX++OMPpk2blqFzM0Oj0bB582YaNGhA3759KV26NF27duXmzZu4uLhkuJwxY8ZgbGxM+fLlcXJyIjQ0FHd3dzZv3szx48fx9vbm/fffp3///nz++edZ/jmE+C+519OTe12IN8vp0Id8vv4cvl/v4v3fT7HjYiSpOoVK7vZMbFueo5825dfeNWhVyS3PDj/WKFm99scr0mg0L5047q233uLAgQNERERgb28PwNq1a+nYsSPx8fFYWlqmOycpKYmkpCT969jYWDw8PIiJicHOzi7LPwdAQnIqrWYd4Mb9BNpVKczMrlWz5TpCiKyTmJhISEgIXl5eWFgYZrkNkb+96O9YbGws9vb22Vo3vWle9J3K/S6ym/wdEyJr6XQKuy/fZd6+YAJuPtTvd7Ezp33VInSo5k5pF9sXlGB4manr89QALDc3N9zd3fUJOqhjhRRFISwsjFKl0i99Zm5url+OI6dYmZnwQ5cqdJx3mPWBd2he3pXWld1efqIQQgghhBBCCABStDo2BN5hwb5grt1Vh+iYGRvRqpIr7/oUoU4JR4yN8k439ozKU0l63bp1WbVqFXFxcfplOa5evYqRkVGum7yjWtECDG1Ukjl7gvhs/TlqeBbA2U6epAohhBBCCCHEiyQkp7L8+C1+PXCdO//O0G5jbkKPWkXpX9cr3+dVBh2THhcXR2BgIIGBgQCEhIQQGBhIaGgoAOPHj6dXr17647t3706hQoXo27cvFy9eZP/+/Xz88cf069fvmV3dDW1k01JUKGxHdEIKY9ecJZeMLBBCCCGEEEKIXOdBfDI/7rhKnW928+Wmi9yJScTRxpyxLcpwaFwTxrcsl+8TdDBwS/rJkydp3Lix/vXo0aMB6N27N/7+/oSHh+sTdgAbGxt27NjBiBEjqF69OoUKFaJz585MmTIlx2PPCDMTI2Z2qULrnw6y90oUfx4PpUfNYoYOSwghhBBCCCFyjbCHCfx6IIQVJ27xOEVdQaJYISsGNSjOu9WK5NkJ4F6VQZP0Ro0avbB12d/fP92+smXLsmPHjmyMKmuVcrFlrF8ZpvxziSmbLlG3hCOejtaGDksIIYQQQgghDOpKxCMW7Atm45k7pOrUvLCiux3vNyxBy4pu+XK8eUbkqTHpeVW/ul7sunSXI9fvM3plICsH18bEOE+tfieEEEIIIYQQWeLkjQfM2xvMrst39fvqlizE+w1LUK+kY55a0zw7SJKeA4yMNHzX2ZsWP+7nVGg0C/ZfZ1jjkoYOSwghhBBCCCFyhE6nsOfKXebtDebkv8uoaTTQsqIrgxuUwNvDwbAB5iKSpOcQdwdLJr1dgY9WneHHHVdpWNqJiu72Lz9RCCGEEEIIIfKoFK2Ov8/cYf6+YK5GPl1G7V0fdwbWL05xJxsDR5j7SJ/rHNShmjt+FVxI1Sl8uCKQxH8nRRBCCPF8QUFBTJ06lcePHxs6FCFENpJ7XYj8JSE5lcWHQmg0Yy+jV57hamQcNuYmDG5QnAOfNGZah8qSoD+HJOk5SKPRMLV9JRxtzLl2N47vtl0xdEhCCEGjRo344IMP9K89PT2ZOXPmC8/RaDSsX78+y2J43jUTExPp2LEjhQsXzpVLbQqRl8i9LoTICQ/jk5m58yp1v9nN5L8vcjv6MY42Znzs9+8yaq3K4fIGLKP2OqS7ew4rZGPO9Hcr0X/JSRYdCqFpORdqlyhk6LCEEHlU27ZtSUlJYevWreneO3DgAA0aNODMmTNUrlw5w2WeOHECa+ucXYXiedccMWIE7dq1o0+fPjkajxC5jdzrQojc7nb0Y349cJ3lx58uo1a0oLqMWkefN28ZtdchSboBNC3nQtcaHiw/cYsxq86w9YP62FqYGjosIUQe1L9/f959913CwsIoUqRImvcWL15M9erVM/WjHcDJySkrQ3yta/7yyy85HIkQuZPc60KI3OrCnRh+O3iDDYG39cuoVSj8ZBk1V1nV6hXIN2Ygn7cpj0dBS25HP2by3xcNHY4QIo9q06YNTk5O+Pv7p9kfFxfHqlWraNeuHd26dcPd3R0rKysqVarEX3/99cIy/7876rVr12jQoAEWFhaUL1+eHTt2pDvnk08+oXTp0lhZWVG8eHG++OILUlJS0hzz999/U6NGDSwsLHB0dKR9+/bPvWZoaCjvvPMONjY22NnZ0blzZyIjI/XvT5o0iSpVqrBs2TI8PT2xt7ena9euPHr0KAPfmhB5j9zrcq8LkZvEJaXy57FQ3p5zkNazD7LmVBipOoU6JQqxtJ8vm0bUo613YUnQX5F8awZiY27CD52roNHA6oAwtl2IMHRIQoj/pyiQHG+YTVEyFKKJiQm9evXC398f5T/nrFq1Cq1Wy3vvvYePjw///PMP58+fZ9CgQfTs2ZPjx49nqHydTkeHDh0wMzPj2LFjzJ8/n08++STdcba2tvj7+3Px4kVmzZrFL7/8wo8//qh//59//qF9+/a0atWK06dPs2vXLnx9fZ97zXfeeYcHDx6wb98+duzYwfXr1+nSpUua44KDg1m/fj2bNm1i06ZN7Nu3j2+++SZDn0uINORel3tdCPFSiqJwOvQhn6w+i+/XO/l03TnOhsVgaqyhdWU31g+ry58Da9GgtNMbv87565Lu7gZUw7MggxuUYP6+YMavPUe1ogVwsjU3dFhCiCdSEmBqYcNc+9M7YJaxsaL9+vVjxowZ7Nu3j0aNGgFq99d3332XYsWKMWbMGP2xI0aMYNu2baxcufK5P5z/a+fOnVy+fJlt27ZRuLD6XUydOpWWLVumOe7zzz/X/9nT05MxY8awfPlyxo4dC8DXX39N165dmTx5sv44b2/vZ15z165dnDt3jpCQEDw8PABYunQpFSpU4MSJE9SoUQNQf+D7+/tja2sLQM+ePdm1axdff/31Sz+XEGnIvS73uhDiuWISUlh3OozlJ25xOeJpL5biTtZ0q1GUDtXcKWQjOUxWkiTdwD5sXoq9V+5yOeIR49ee5Zde1eXJkxAiU8qWLUudOnX47bffaNSoEUFBQRw4cIAvv/wSrVbL1KlTWblyJbdv3yY5OZmkpCSsrKwyVPalS5fw8PDQ/2gHqF27drrjVqxYwezZswkODiYuLo7U1FTs7Oz07wcGBjJw4MBMXfPJj3aA8uXL4+DgwKVLl/Q/3D09PfU/2gHc3Ny4e/duhq4hRF4k97pK7nUhsp+iKBwPecDyE7fYfC6cpFQdAOYmRrSu5EZX36LU8CwgeUs2kSTdwMxNjPmxSxXemXOInZfusvLkLbrUKGrosIQQAKZWaiuXoa6dCf3792fEiBH8/PPPLF68mBIlStCwYUOmT5/OrFmzmDlzJpUqVcLa2poPPviA5OTkLAv1yJEj9OjRg8mTJ+Pn54e9vT3Lly/n+++/1x+THUsqmZqmnXBTo9Gg0+my/DriDSD3eobIvS5E/nc/Lok1p9RW8+tR8fr9ZV1t6eZblHZV3LG3kgmvs5sk6blAOTc7Rr9Vmm+2XObLvy9Su7gjRQtlrtIWQmQDjSbD3VANrXPnzowaNYo///yTpUuXMmTIEDQaDYcOHeKdd97hvffeA9Ruo1evXqV8+fIZKrdcuXLcunWL8PBw3NzcADh69GiaYw4fPkyxYsX47LPP9Ptu3ryZ5pjKlSuza9cu+vbtm+Fr3rp1S9/CdvHiRaKjozMctxCZIve63OtCvMF0OoXDwff563go2y9GkKJV572wMjOmbeXCdKtZFO8i9tJqnoNk4rhcYmD94vh6FiQ+WctHqwLR6jI2kYwQQgDY2NjQpUsXxo8fT3h4uH6t4VKlSrFjxw4OHz7MpUuXGDx4cJqZk1+mWbNmlC5dmt69e3PmzBkOHDiQ5gf6k2uEhoayfPlygoODmT17NuvWrUtzzMSJE/nrr7+YOHEily5d4ty5c0yfPv2516xUqRI9evTg1KlTHD9+nF69etGwYUOqV6+euS9G5Iiff/4ZT09PLCwsqFmz5ksnK4uOjmbYsGG4ublhbm5O6dKl2bx5s/79SZMmodFo0mxly5bN7o+RJ8i9LoTIKpGxify8J4iG3+3hvUXH+OdcOClahcpF7JnavhLHP2vG9I6VqeLhIAl6DpMkPZcwNtLwfWdvrM2MOXHjIb8cuG7okIQQeUz//v15+PAhfn5++nGln3/+OdWqVcPPz49GjRrh6upKu3btMlymkZER69at4/Hjx/j6+jJgwIB0kzW9/fbbfPjhhwwfPpwqVapw+PBhvvjiizTHNGrUiFWrVrFx40aqVKlCkyZNnpvIaTQaNmzYQIECBWjQoAHNmjWjePHirFixInNfiMgRK1asYPTo0UycOJFTp07h7e2Nn5/fc8cMJycn07x5c27cuMHq1au5cuUKv/zyC+7u7mmOq1ChAuHh4frt4MGDOfFx8gS514UQr0qrU9h1KZIBS05S55vdzNh2hVsPHmNrbkLPWsX4Z2Q9Ng6vR/eaRbExl07XhqJRlAyu/ZFPxMbGYm9vT0xMTJqJTnKLFSdC+WTNOcyMjdgwvC7l3HJfjELkR4mJiYSEhODl5YWFhYWhwxH50Iv+juX2uulFatasSY0aNZgzZw6gdrP28PBgxIgRjBs3Lt3x8+fPZ8aMGVy+fDndWOMnJk2axPr16wkMDHzluF70ncr9LrKb/B0TuU3YwwRWngxj1clbhMck6vdXL1aArr5FaV3JDUszYwNGmP9lpq6XlvRcpnN1D5qVcyZZq+PDFYEkpWoNHZIQQgjxTMnJyQQEBNCsWTP9PiMjI5o1a8aRI0eeec7GjRupXbs2w4YNw8XFhYoVKzJ16lS02rT13bVr1yhcuDDFixenR48ehIaGvjCWpKQkYmNj02xCCPEmS9Hq2Ho+nN6/Haf+t3uYvesa4TGJFLAypX89L3Z82IDVQ+rQ0aeIJOi5jPRheF2RF8C5vDrpTBbQaDRM61CZ0zP3czniET/uuMa4ljIOTwghRO5z7949tFotLi4uafa7uLhw+fLlZ55z/fp1du/eTY8ePdi8eTNBQUEMHTqUlJQUJk6cCKit8/7+/pQpU4bw8HAmT55M/fr1OX/+fJqluP5r2rRpadbmFkKIN9XdR4n4H7rBypNh3ItL0u+vXbwQ3WoWxa+CC+YmkpTnZpKkv44L62F1P6gzHJpNzrJE3cnWnKkdKjF4WQAL9gfTtJwzNTwLZknZQgghhCHpdDqcnZ1ZuHAhxsbG+Pj4cPv2bWbMmKFP0lu2bKk/vnLlytSsWZNixYqxcuVK+vfv/8xyx48fz+jRo/WvY2Nj06y/LYQQ+d2tBwks2B/MypNhJP+7rrmjjTkdfYrQtYYHno55YxULIUn660m4B4oWDs0CjRE0nZhlibpfBVc6+hRhdUAYo1cGsmVUA5m8QQghRK7i6OiIsbFxulnEIyMjcXV1feY5bm5umJqaYmz8tBWnXLlyREREkJycjJmZWbpzHBwcKF26NEFBQc+NxdzcHHNz81f8JEIIkXddjXzEvL3BbDxzR79CVNWiDgyqX5xm5V0wNZYRznmN/B97HTUGQKvv1D8f/BF2fwVZOA/fhLblcXew5NaDx0zZdDHLyhVCCCGygpmZGT4+PuzatUu/T6fTsWvXLmrXrv3Mc+rWrUtQUBA6nU6/7+rVq7i5uT0zQQeIi4sjODhYv363EEIIOB36kIFLT/LWj/tZd/o2Wp1C/VKO/DWwFmuH1KFlJTdJ0PMo+b/2unwHQstv1T8f+B52T8myRN3OwpTvOnmj0cDyE7fYeTHj650KIV7NG7bghchB+fXv1ujRo/nll19YsmQJly5dYsiQIcTHx9O3b18AevXqxfjx4/XHDxkyhAcPHjBq1CiuXr3KP//8w9SpUxk2bJj+mDFjxrBv3z5u3LjB4cOHad++PcbGxnTr1i1LY8+v/0+E4cnfLZFdFEXhUNA9uv9ylPZzD7PjYiQaDbSs6Mrfw+uxrH9NapcoJOua53HSfzor1BysJuZbP4ED34GRMTT+NEuKrl2iEP3revHrwRDGrT3LtqINKGQj3fmEyGpPloJKSEjA0tLSwNGI/CghIQHgucuO5VVdunQhKiqKCRMmEBERQZUqVdi6dat+MrnQ0FCMjJ62CXh4eLBt2zY+/PBDKleujLu7O6NGjeKTTz7RHxMWFka3bt24f/8+Tk5O1KtXj6NHj+Lk5JQlMT/pap+cnCz3u8gW+fV+F4aj0ynsuBTJ3D1BnAmLAcDESEO7qu6837AEJZ1tDByhyEqyTnpWOjIXtv3bWtBwHDQe/+LjMygxRcvbcw5yNTKOt8q7MP89H4yM5OmYEFktPDyc6OhonJ2dsbKykqfQIksoikJCQgJ3797FwcHhmV228/I66bnVi75TRVEIDQ0lJSWFwoULp3mIIMTryMj9LkRmpGh1/H3mDvP2BnPtbhwA5iZGdPMtyoD6XhQpYGXgCEVGZaaul5b0rFR7KKDAtk9h3zfqJHKNxr12sRamxvzQuQrt5x5i+8VIxq89x9QOlTCWRF2ILPVkoqu7d+8aOBKRHzk4ODx3MjWRszQaDW5uboSEhHDz5k1DhyPyIbnfxetKTNGy6uQtFuy/TtjDxwDYmpvQs3Yx+tXzwlF61uZrBk3S9+/fz4wZMwgICCA8PJx169bRrl275x6/d+9eGjdunG5/eHh47vmHsPYwUHSw/XPYO02d9b3h2NcutqK7Pd92rMxHK8+w4uQtkrU6ZnSsjIlMBiFElnnyw93Z2ZmUlBRDhyPykf+fzVwYnpmZGaVKlSI5OdnQoYh8Ru538ToeJabwx7FQfj0Qol/jvJC1Gf3qedGzdjHsLGQIxZvAoEl6fHw83t7e9OvXjw4dOmT4vCtXrqTpIuDs7Jwd4b26OiPURH3HBNjzNaCBhh+/drHtqxbB1NiID5YHsu70bZJTdczsWkVmbRQiixkbG8sPLCHeAEZGRlhYWBg6DCGE4H5cEv6Hb7Dk8A1iE1MBcHewZFCD4nSu7oGlmfwueZMYNElv2bIlLVu2zPR5zs7OODg4ZH1AWanuKHUyuZ0TYc8Utet7gzGvXWybyoUxMzZi2J+n+OdcOEmpOn7uURVzE7lxhRBCCCGEyEvuRD/mlwPX+et4KIkp6tKUJZysGdKoJO9UKSyNcW+oPDkmvUqVKiQlJVGxYkUmTZpE3bp1n3tsUlISSUlJ+texsbE5EaKq3gdqi/quyeoa6hojqD/6tYt9q4IrC3tV5/1lAey8FMmgpQEs6OmDhakk6kIIIYQQQuR216PimL8vmHWnb5OiVefxruRuz7DGJXirvKtMEv2Gy1OPZtzc3Jg/fz5r1qxhzZo1eHh40KhRI06dOvXcc6ZNm4a9vb1+8/DwyMGIUZPyJl+of941GQ7+mCXFNi7jzG99amBpasy+q1H08z9BQnJqlpQthBBCCCGEyHrnb8cw7I9TNP1hHytPhpGiVahVvCDL+vuycXhdWlR0kwRd5J4l2DQazUsnjnuWhg0bUrRoUZYtW/bM95/Vku7h4ZHzy9zsnwG7p6h/bv6l2h0+CxwPeUDfxceJT9ZSw7MAv/Wpga1MKCGEEHmKLMGW9eQ7FULkFoqicOT6fRbuv87eK1H6/c3KOTOkUUl8ihUwYHQip7xRS7D5+vpy8ODB575vbm6OuXkuWKKgwcfqGPU9X6sTymmM1AnmXpOvV0GWDahJ79+Oc+LGQ95bdJylfX2xt5JEXQghhBBCCENJTtWx6ewdfj0QwsVwdcitkQbaehdmSKMSlHWVB4ji2fJ8kh4YGIibm5uhw8iYhmPVMep7p6lLtKGBOsNfu9hqRQvw18BavLfoGGduRdP916Ms61+TgtZmrx+zEEIIIYQQIsMexifz5/FQlhy+wd1Hao9eC1MjOvoUYWD94hQrZG3gCEVuZ9AkPS4ujqCgIP3rkJAQAgMDKViwIEWLFmX8+PHcvn2bpUuXAjBz5ky8vLyoUKECiYmJ/Prrr+zevZvt27cb6iNkXqNxaqK+bzps/0xtUa899LWLrehuz/JBtXjv12NcuBNLt4VH+X1ATZxsc0EvAiGEEEIIIfK54Kg4fjsYwppTYfqZ2l3szOldx5PuvkVxsJIGNJExBk3ST548SePGjfWvR49WZz7v3bs3/v7+hIeHExoaqn8/OTmZjz76iNu3b2NlZUXlypXZuXNnmjLyhEbj1a7v+7+FbePV5dlqDXntYsu62rF8UG26/3KUK5GP6LLwCH8OqIWrvawBK4QQQgghRFZTFIXDwfdZdDCE3Zfv6vdXdLejfz0vWlcqjJlJnpqrW+QCuWbiuJySayaSURR1IrkD36mvW34LNQdnSdE37sXT49dj3I5+TNGCVvw5sCZFClhlSdlCCCGyXq6pm/IR+U6FENkpKVXLxsA7LDoYwuWIR4Da7tasnAv963lR06sgGo3M0i6eeqMmjsuzNBpo8rna9f3gD7BlrNr13Xfgaxft6WjNisG16P7LMUIfJNBlwVH+HFhTxr8IIYQQQgjxGh7EJ/PH0ZssOXKTe3HqeHNLU2M6Vy9Cn7peeDnK723x+iRJNySNBppOUBP1QzNh8xh1fxYk6kUKWLFicC16/HKM6/fi6bzgCH8OrEUJJ5vXLlsIIYQQQog3ybXIR/x2KIS1p26TlKqON3e1s9CPN5eVlURWkiTd0DQaaDYJUODQLDVR12igxoDXLtrN3pLlg9XJ5K5GxtFlwVH+GFCTMq62r122EEIIIYQQ+ZmiKBwMusevB0LYd/Xp+uaV3O0ZUN+LVpXcMDWW8eb5mqJATBjYF1FztBwiSXpuoNFAs8lqi/rhn+Cfj9Su79X7vXbRzrYWLB9Um/d+PcbF8Fi6LjzCsv41qehunwWBCyGEEEIIkb8kpjwdb34l8ul48+blXBhQvzg1PAvIePP8KukR3DkNYSfhdgCEnYC4SBhxCgqVyLEwJEnPLTQaaP6V+rTmyBzY9CGggep9X7vogtZm/DWwFr1+O8aZsBi6/3KUpf1rUsXD4bXLFkIIIYQQIj+4F5fE70dv8vvRm9yLSwbAysyYztU96FvXU+Z3ym90Woi6ArdPqsl4WABEXVIbTv9LYwz3rkmS/sbSaOCtKWqifvRn2PSB2qLu0/u1i7a3MuX3ATXpu/gEJ28+5L1fj7G4bw1qeBZ8/biFEEIIIYTIo65GPmLRgRDWBd4m+d/x5m72FvSp40lX36LYW8p483wh7q7aQh52Qk3Mb5+G5Efpj7MrAkV8wL06FKkBbt5glrMrZUmSnttoNOD3tfoE59g8+HukmqhX6/naRdtamLKkny8DlpzkyPX79Fp0nEW9q1OnpGMWBC6EEEIIIUTecTj4HvP2BnPg2j39vspF7BlQvzgtK7rKePO8LCURIs7+20J+Ut1iQtMfZ2oNhatCkerq5l4d7NxyPt7/I0l6bqTRQItpaqJ+fAFsHKHuq/reaxdtbW7C4r41GLQsgP1Xo+jrf4IFPX1oVMY5CwIXQgghhBAid4tPSmXKPxf56/gt4N82svKu9K/vRfViMt48z1EUeHD933Hk/7aUR5wHXcr/HagBpzJPk/Ei1cGpHBjnvpQ490UkVBoNtJwOKHB8IWwYDmigao/XLtrC1JiFPX0Y/ucpdl66y6ClAfzcoxrNy7u8dtlCCCGEEELkVgE3H/DhijOEPkgAoEfNogxuUIKihXK2O7N4DY+j/03GTz6d4O3xg/THWTmq3dWfdF13rwYWeWPybEnSczONBlp+q7aon/gVNgxT92dRoj63hw+jlp9my/kIhvwewKyuVWld2fDdO4QQQgghhMhKyak6Zu26yry9wegUKGxvwXedvalTQoZ95hnRoXDgBzj9e/pWcmMzdez4kxbyItXBoViOLpuWlSRJz+00Gmj1ndqN4+Qi2DAUgneD31Swfb2WbzMTI37qVpWPVp1hQ+AdRvx1imStN+2rFsmi4IUQQgghhDCsq5GP+HBFIBfuxALQoao7E9+uIBPC5RUPb8KB7yHwz6fJeQFPKOL7tOu6a0UwMTdomFlJkvS84Emibm4Lh2fD+dVwbQc0nwTV+oDRq09qYWJsxA+dq2BuYsTKk2GMXnmGlFSFzjU8six8IYQQQgghcppOp7D48A2mb71McqoOBytTpravRKtK0nM0T3h44z/Jeaq6z6sBNBwHnnUNGlp2kyQ9rzAyguaTofw76tJs4WfUtdQD/4K2M8GlwisXbWyk4ZsOlTEzMeL3o6GMXXOWpFQtPWt7ZlX0QgghhBBC5Jjb0Y/5eNUZDgffB6BRGSe+fbcyznYWBo5MvNSDEDU5P/PXf5LzhtBoHBSrY9jYcogk6XmNezUYsBtO/AK7p0DYcVjQAGoPg4afgJn1KxVrZKThq3cqYmZszG+HQvhiwwWSUnUMqF88iz+AEEIIIYQQ2UNRFNYH3mbChgs8SkzF0tSYz1qXo0fNojJre273IAQOfKc2QipadV/xxmpyXrSWYWPLYZKk50XGJlBrCJR7G7aMhcub4NAsuLAOWv8ApZq/UrEajYYv2pTDwtSIuXuDmfLPJRKStYxoUlL+URNCCCGEELnaw/hkPl9/nn/OhQNQxcOBH7tUwcvx1RqxRA55cB32/9ty/iQ5L9FE7dZetKZhYzMQSdLzMnt36PoHXN4Mmz9WZzz8oyOUbwctvgG7zI+30Wg0fOxXBnMTY37ceZUfdlwl5nEKn7Uqh5GRJOpCCCGEECL32XvlLmNXn+XuoyRMjDSMbFqKoY1KYGL86nM3iWx2P/jfbu3L/5OcN1Vbzj18DRubgUmSnh+UbaVOorB3GhydCxfXqzPAN50A1fuBkXGmitNoNIxqVgpbCxO+3HSRRQdDiHmcwjcdKsk/dEIIIYQQItdISE5l2ubLLDt6E4ASTtb82KUKlYs4GDYw8Xz3g2H/d3B2xdPkvGQzteXco4ZhY8slJEnPL8xtwO9rqNwZ/v4A7pyCzWPUbiNtZoJb5UwX2a+eF3aWpnyy5iyrA8J4lJjCrK5VsTDNXNIvhBBCCCFEVjsd+pDRK88Qci8egD51PBnXsqz8Vs2t7gXB/hlwbiUoOnVfqbfUebWKVDdsbLmMRlEUxdBB5KTY2Fjs7e2JiYnBzs7O0OFkD50WTiyCXV9C8iPQGKtj2BuNV5P5TNp2IYIRf54mWaujbslCLOhZHRtzeb4jhBBZ5Y2om3KYfKdC5F8pWh1zdgcxZ08QWp2Cq50FMzpVpn4pJ0OHJp7l3rV/k/NV/0nO/f5Nzn0MG1sOyky9JH2X8yMjY6g5CIafUJdsU7RwZA7MrQVXtma6OL8Krvj3rYG1mTGHgu7T49djPIxPzobAhRBC5EU///wznp6eWFhYULNmTY4fP/7C46Ojoxk2bBhubm6Ym5tTunRpNm/e/FplCiHeDMFRcbw77zCzdl1Dq1N427sw2z5oIAl6bnTvGqwZCD/7/tu1XQelW8DA3dBj5RuVoGeWJOn5mZ0bdF4K3VeCfVGIuQV/dYEV70HsnUwVVaekI38OrEUBK1PO3Iqm84IjRMQkZlPgQggh8ooVK1YwevRoJk6cyKlTp/D29sbPz4+7d+8+8/jk5GSaN2/OjRs3WL16NVeuXOGXX37B3d39lcsUQuR/iqKw5PANWs8+wNmwGOwsTJjdrSqzu1XF3srU0OGJ/4q6CmsGqMn5k67tpVvCwD3QfQW4S3L+MtLd/U2RHA/7psPhOWrLupktNPkcfAdmamK5a5GP6LnoOBGxiRQpYMnv/WviKctaCCHEa8nLdVPNmjWpUaMGc+bMAUCn0+Hh4cGIESMYN25cuuPnz5/PjBkzuHz5Mqamz/5hndkynyUvf6dCiLQiYhL5ePUZDly7B0D9Uo5827EybvaWBo5MpBF1BfZ9C+fXAP+mmGVaQcOxULiqQUPLDaS7u0jPzBqafwmD90ORGupY9a2fwK9N4U5ghosp5WLLqvdr41nIirCHj+k4/wiXwmOzL24hhBC5VnJyMgEBATRr1ky/z8jIiGbNmnHkyJFnnrNx40Zq167NsGHDcHFxoWLFikydOhWtVvvKZQoh8q+/z9zBb+Z+Dly7h7mJEZPfrsCSvr6SoOcWigJhJ2F1P/i5JpxfDShQto2ad3T7SxL0VyCzf71pXCtCv+0QsBh2ToY7p+GXxlDzfWj8KZjbvrQIj4JWrHq/Dr1+O86l8Fi6LDjC4r418ClWMAc+gBBCiNzi3r17aLVaXFxc0ux3cXHh8uXLzzzn+vXr7N69mx49erB582aCgoIYOnQoKSkpTJw48ZXKBEhKSiIpKUn/OjZWHiALkZfFJKQwYeN5NgSqQzQrF7Hnh85VKOmc+UmQRRZTFIg8r7aYn18D0aFP3yvbRp0Q7hVWlhJPSZL+JjIyghr91Zto23j15jo6Fy5ugJbfQrk2Ly3Cydac5YNq0d//BCdvPqTHr8dY0LM6DUvLpB1CCCGeT6fT4ezszMKFCzE2NsbHx4fbt28zY8YMJk6c+MrlTps2jcmTJ2dhpEIIQzl47R5jVp0hIjYRYyMNwxqXZESTkpgaSydgg4q6ChfWqrnDvatP95taQ9nWUHckuFYyXHz5iEH/pu/fv5+2bdtSuHBhNBoN69evz/C5hw4dwsTEhCpVqmRbfPmerQt0/A3eWwMOxSD2NqzoAX91h5iwl55ub2nKsv41aVjaicQUHQOWnGDT2cxNSCeEECLvcnR0xNjYmMjIyDT7IyMjcXV1feY5bm5ulC5dGmPjp/OhlCtXjoiICJKTk1+pTIDx48cTExOj327duvUan0wIYQiPk7VM/vsC7y06RkRsIl6O1qx+vzajm5eWBN1QHt6AAz/AvHrwcw3YO01N0I3NoVxb6OQPHwfBu79Igp6FDPq3PT4+Hm9vb37++edMnRcdHU2vXr1o2rRpNkX2hinZDIYehXqjwcgErvwDc3zhyM/qmusvYGlmzC+9qtOmshspWoURf53mr+OhLzxHCCFE/mBmZoaPjw+7du3S79PpdOzatYvatWs/85y6desSFBSETqfT77t69Spubm6YmZm9UpkA5ubm2NnZpdmEEHmDTqew7nQYTb7fy+JDNwB4r1ZR/hlZj6pFCxg2uDdR7B04Mhd+aQqzvGHXZIg8p+YJpd6C9gvUxLzL71ChPZhZGTrifMeg3d1btmxJy5YtM33e+++/T/fu3TE2Ns5U67t4ATMraDYRKneGvz+AW0dh26dw6zi8uwiMn/9XxczEiFldq2Jnacqfx0IZv/YcMY9TeL9hiZyLXwghhEGMHj2a3r17U716dXx9fZk5cybx8fH07dsXgF69euHu7s60adMAGDJkCHPmzGHUqFGMGDGCa9euMXXqVEaOHJnhMoUQ+UfAzQd8uekSZ25FA+DuYMmU9hVpXMbZsIG9aeLvqUNfz6+Fm4fQz86uMQLP+lDxXbXl3ErmoMoJeW5M+uLFi7l+/Tq///47U6ZMeenxMpFMJjmXg75b4NQS2PwxXFwPJhbQbp46lv05jI00fN2uIg6WpszdG8w3Wy4TnZDCJy3KoNFoci5+IYQQOapLly5ERUUxYcIEIiIiqFKlClu3btVP/BYaGorRf+oPDw8Ptm3bxocffkjlypVxd3dn1KhRfPLJJxkuUwiR94U9TOCbLZfZdDYcAGszY4Y2Lkn/el5YmGZ8eeA8ISkODv4IV7eBjTMULJ52K1AMTMxzPq7H0XB5kzrG/Po+dZnmJzxqqYl5+XfUIbIiR+WaddI1Gg3r1q2jXbt2zz3m2rVr1KtXjwMHDlC6dGkmTZrE+vXrCQwMfO45kyZNeuZEMrJuagZc2gQre6k3rE8faDMTMpBwL9gXzLQt6gy83Xw9mNKuEsZGkqgLIcTzyJreWU++UyFyp7ikVObtDeKXAyEkp+rQaKCzjwcf+ZXG2dbC0OFlLZ0Ozi5XV1SKi3jBgRqw94CCXmrSXqjEfxJ4TzDNwuXmkuLg6lY1MQ/aCdrkp+8VrgoVOqhd2B08su6aAshcvZRnWtK1Wi3du3dn8uTJlC5dOsPnjR8/ntGjR+tfx8bG4uEhf+kypFwb6LAQ1gyAAH8wsYQW016aqA9uWAJ7S1M+XXeOv47fIvZxKj92qYKZiUz4IYQQQgjxJtLqFNYEhDFj+xWiHqm9XGsXL8TnbcpRobC9gaPLBqFHYes4dbljUJPtBmPVxq8H1/+zhUByHMSEqlvIvvRl2bn/m7R7/V8LvBeYZ2BJupRECNqhJuZXtkLq46fvOZeHih3U5LyQDFXNLfJMkv7o0SNOnjzJ6dOnGT58OKBOJKMoCiYmJmzfvp0mTZqkO8/c3BxzcwN0H8kvKnWE1CTYMBSOzQNTC2g68aWJelffothZmjJq+Wn+ORfOo6RU5r9XDSuzPPNXTgghhBBCZIEjwff5atNFLoarw049C1nxaatyNC/vkv+GRUbfgp0T1YQYwMwWGoyBWkOe3aVdUSA+6v8S93+3+9chKUZdgSn2Ntw4kP58G5f/JO7/SeLti8LtAHXJtEubIPnR03MKFle7slfoAC7ls+d7EK8lz2RMdnZ2nDt3Ls2+uXPnsnv3blavXo2Xl5eBInsDVO2hPnH75yN1PI2pNTT8+KWntarkhq2FCYOWBrD/ahQ9Fx3nt941sLcyzYGghRBCCCGEId24F8/UzZfYflFdUtHWwoRRTUvRq7Zn/uthmRwPh2bBodn/tlRroOp70OSLF4/p1mjUceo2zlC0Vtr3FAUeP3xG8h6s/vfxA4iLVLfQIy+Oz64IVGyvJuduVTI0hFUYjkGT9Li4OIKCgvSvQ0JCCAwMpGDBghQtWpTx48dz+/Ztli5dipGRERUrVkxzvrOzMxYWFun2i2xQY4DaVWb7Z7BnitqiXmfES0+rX8qJ3wfUpO/i4wTcfEiXhUdY2t83/405EkIIIYQQAMQ8TmHO7mv4H75BilbB2EhDd9+ifNi8NAWtzQwdXtbS6eDcKtg5CR7dUfcVq6sOEXXzfr2yNRp1NnWrglCkevr3Hz9Uu8s/6Tb/30Q+/i5YO6vjyyu+C0VqvHASaJG7GDRJP3nyJI0bN9a/fjJ2vHfv3vj7+xMeHk5oqKy5nWvUGQ4pj9Ukffvn6qzvvgNfeppPsQKsfL82PRcd53LEIzrNP8Lv/WviUVDWVBRCCCGEyC9StTr+OnGLH3dc5UG8OiFZw9JOfN66HKVcbA0cXTYIOwlbPoHbJ9XXDkWh+VfqjOg50VJtWQDcC4B7tfTvJSeov9UlMc+Tcs3s7jlFZnvNAru+hAPfq39+52e1K08G3Lwfz3uLjnHrwWNc7MxZ1r8mpfPjP9hCCJFJUjdlPflOhchZ+65G8fU/F7kaGQdASWcbPmtdLn+udx57R205P7tCfW1qDQ0+glrD1N6mQjxDvpzdXeQiTb5QW9SPzoUNw9WndJU6vvS0YoWsWf1+HXotOs6VyEd0XnAE/76+VPFwyP6YhRBCCCFElgu6+4iv/7nEnitRABSwMuXD5qXp5lsUU+N81oqbnACHf4JDMyElQd1XpQc0nQC2rgYNTeQvkqSLzNNowG+qmqgHLIa1g9TZKsu1fempLnYWrBhciz6LTxB4K5ruvxzll17VqVvSMQcCF0IIIYQQWeFhfDIzd17l92OhaHUKJkYaetfxZGSTUvlvkmBFUWdr3zERYsPUfR611HHnz+pqLsRrymePt0SO0Wig9Q/g3U1d73FVX7i2I0OnOliZ8ceAmtQr6UhCspa+i0+w9XxENgcshBBCCCFeV3KqjkUHQ2g4Yw9LjtxEq1NoXt6FHaMb8kWb8vkvQb8dAL/5wZr+aoJu7wEdf4N+WyVBF9lGknTx6oyM4O056qyRuhRY8R5c35ehU63NTVjUpzotKriSrNUx9I8AVp64lc0BCyGEEEKIV6EoCjsvRuI3cz9fbbpIbGIqZV1t+XNATX7pVR0vR2tDh5i1YsNh3RD4pQncOgamVtD4Mxh+Qp0tXZYwE9lIuruL12NsAh1+gdQkuLIZ/uoKPdelX+fxGcxNjJnTvSqfrjvHypNhjF1zlksRsXzaqlz+G8MkhBBCCJFHXQqPZco/FzkUdB8ARxszxrxVhk7VPTA2ymfJaspjOPIzHPgBUuLVfZW7QrOJYFfYsLGJN4Yk6eL1GZtCJ381QQ/eDb93hN4bwN3npaeaGBsx/d3KuNhZ8NPuIBYfusGFO7HM6V5V1lIXQgghhDCgxBQtUzdf4vejN9EpYGZiRP96XgxtVAJbi3zWrV1R4OJ62D4BYv5dArqIL7T4Boq8/DetEFlJmitF1jAxhy5/QLF6kPwIlnWAiPMZOlWj0fDRW2VY2NMHG3MTjoc8oO1PBwm4+TCbgxZCCCGEEM9y60ECHecfZukRNUFvXcmNXaMb8kmLsvkvQQ8/A/6tYVUfNUG3c4cOv0L/7ZKgC4OQJF1kHTMr6L5cfeqYGA1L34GoKxk+/a0KrmwYXpdSzjZExibRdeERlh29iaIo2RezEEIIIYRIY8/lu7T56SDnb8dS0NqMpf18+blHNTwKWhk6tKz1KBI2DIMFDeHmITCxhIbj1HHnlTvJuHNhMJKki6xlbgs9VoGbNyTcgyVvw/3gDJ9ewsmGdcPq0qqSKylahS/Wn+fj1WdJTNFmY9BCCCGEEEKrU/hhx1X6LTlBzOMUvD0c2DSiHg1KOxk6tKyjTYErW2BlL5hZEU7/DihQqROMOAmNx4NZPpsET+Q5GuUNa6aMjY3F3t6emJgY7OzsDB1O/pXwQO02dPeiulRF3y3g4JHh0xVFYeH+60zfehmdAhXd7Zj/ng9FCuSzJ7hCCIHUTdlBvlMhMudhfDKjVgSy/2oUAO/VKsoXbcpjbmJs4MiygKJAeCCcWQ7nVqsNSU8UqQF+U8HD12DhiTdDZuolSdJF9om7C4tbwv0gKOClJup2bpkq4lDQPUb8dZoH8ckUsDJldreq1C+Vj57mCiEEUjdlB/lOhci4s2HRDPn9FLejH2NhasTU9pXoUK2IocN6fTG34dxKNTmPuvx0v7UzVO4M3l3BtZLh4hNvFEnSX0Aq7RwWc1tN1KNvgmNp6LMZbDKXZN+OfsyQ3wM4GxaDkQbG+JVhSMMSaGSckBAin5C6KevJdyrEyymKwvITt5i44QLJWh2ehayY954P5dzy8D2TFAeXN8GZv+D6PuDfVMfEAsq2Bu9uULyxuoywEDlIkvQXkErbAB7egMWtIPY2uFSC3hvBqmCmikhM0TJxwwVWnLwFQIsKrszoVDn/zS4qhHgjSd2U9eQ7FeLFElO0fLH+PKsCwgBoXt6F7zp5Y2+ZB39b6bRw44DaYn5x49P1zQGK1VVbzMu/Axb2hotRvPEyUy/JIySR/Qp4Qq+N4N8KIs/B7+9Cr/WZ+ofSwtSY6R0rU6WoAxM3XGDrhQiu3X3Egp7VKelsk22hCyGEEELkN6H3E3j/9wAuhsfqeym+36AERkZ5rJdi1BW1xfzsSrUx6ImCxdUW88qd1d+hQuQx0pIucs7dS2qL+uMH4FELeq59pdkzT4c+ZMjvp4iITcTazJjvO3vTomLmxroLIURuInVT1pPvVIhn23Upkg9XBBKbmEohazNmd6tK3ZKOhg4r4+Lvwfk1anJ+5/TT/Rb2UPFdNTkvUkOWTxO5jnR3fwGptA0s/Az4t4WkGPBqAN1XgqllpouJepTE8D9PcSzkAQBDGpVgzFtlMM5rT4CFEAKpm7KDfKdCpKXVKczceZWfdgcBULWoA3N7VMPNPvO/w3JcahJc3ap2Z7+2HXSp6n4jEyj1ltqdvZQfmFoYNk4hXkCS9BeQSjsXuHUClrWD5Dj1H9Yuf4CJWaaLSdXq+GbLZX49GAJA/VKOzOpalYLWmS9LCCEMSeqmrCffqRBPPYhPZtTy0xy4pi491rt2MT5rXR4zEyMDR/YCigJhJ9QW8/NrITH66XuFq6ot5hXfBes81AtAvNEkSX8BqbRziRuH1LHpqY+hbBvotOSVZ9n8+8wdxq4+y+MULe4Olizo6UNFd5kYRAiRd0jdlPXkOxVCFXgrmqG/B3AnJhFLU2OmdahEu6ruhg7r+R7ehLMr1OT8wfWn+20Lg3cXqNwVnMsaLj4hXpEk6S8glXYuErwb/uwC2mSo1AnaLwAj41cq6krEIwYvO8mN+wmYmRjxdbuKdKrukcUBCyFE9pC6KevJdyredIqi8MexUL78+yLJWh1ejtbMe68aZV1z4f2gKHB9DxyZC0E7nu43tYJyb6vd2b0avPLvRCFyA5ndXeQNJZpA56Ww4j04t0rd1+o7sHTIdFFlXG3ZMLweo1cEsuvyXT5efZYzYdFMaFMhd3flEkIIIYTIYo+TtXy2/hxrT6kznvtVcGFGJ2/sctvStSmP1ZnZj86DqEv/7tSoCbl3NyjXFsxlFR/x5pGWdGF4F9bD6r6g6MDKEZpPBu/uYJT55FqnU/hpdxAzd11FUdRJUeb18MHVXiYSEULkXlI3ZT35TsWb6ub9eAYvC+ByxCOMNDC2RVkGNyiOJjfNdv4oAk78Cid/g4T76j4zG6j6HvgOgkIlDBufENlAuru/gFTauVTIfvjnI7h3VX1dpAa0mqFODPIK9ly+y6jlp4lNTMXRxpyfu1elZvFCWRiwEEJkHambsp58p+JNtPNiJB+uDORRYiqONuryanVK5KKJ1e4Eqq3m59eALkXdZ18Uag6Cqj1fqTelEHmFJOkvIJV2LpaaDMfmw77p6szvaMCnDzSdAFYFM13cf58kGxtp+KxVOfrW9cxdT5KFEAKpm7KDfKfiTaLVKfyw4wo/7wkGoFpRB+bmlp6EOi1c2awm5zcPPd3vUQtqDVEnEH7FyYOFyEskSX8BqbTzgNhw2PHF03HqlgXURL1a70xPGJKQnMr4tefYEHgHgHeqFGZah0pYmUllIITIPaRuynrynYo3xf24JEYtD+RgkLq8Wp86nnzaqpzh5+RJjIXTv6sNMNE31X1GJlChvZqcu/sYNj4hcpgk6S8glXYecuMQbP4Y7l5QX7t5qxPLefhmqhhFUVh86AZfb76EVqdQ1tWWBT19KFbIOhuCFkKIzJO6KevJdyreBKdDHzL0j1OE/7u82jfvVuKdKgZeXu1BCBxfCKeWQfIjdZ9lAfDpC74Dwa6wYeMTwkAyUy8Z9BHb/v37adu2LYULF0aj0bB+/foXHn/w4EHq1q1LoUKFsLS0pGzZsvz44485E6zIeZ51YfB+aDEdzO0g/Awsag7rh0FcVIaL0Wg09KvnxZ8DauJoY87liEe0/ekgB65lvAwhhBDP9/PPP+Pp6YmFhQU1a9bk+PHjzz3W398fjUaTZrOwSNslt0+fPumOadGiRXZ/DCHyDEVRWHbkBp0XHCE8JpHijtZsGF7XcAm6oqiNK8t7wE/V4OhcNUF3LA1tfoQPL0KziZKgC5FBBu3zGx8fj7e3N/369aNDhw4vPd7a2prhw4dTuXJlrK2tOXjwIIMHD8ba2ppBgwblQMQixxmbQK33oWIH2DkJAv+AwN/h0t/Q+FOoMSDD45hqFi/EphH1GPpHAKdCo+m7+ARft69IlxpFs/czCCFELqTVavH392fXrl3cvXsXnU6X5v3du3dnqJwVK1YwevRo5s+fT82aNZk5cyZ+fn5cuXIFZ2fnZ55jZ2fHlStX9K+fNVdIixYtWLx4sf61ubl5huIRIr9LSE7ls3XnWXdaXV6tRQVXZnSqjK0hlldLTYYLa9WkPPzM0/0lmkKtoepyu6+wWo8Qb7pc091do9Gwbt062rVrl6nzOnTogLW1NcuWLcvQ8dL9LY+7dRw2j3laEThXUGeB96yb4SKSUrV8svos6/8dpz6scQk+al4GIyOZUE4IYRiGqJuGDx+Ov78/rVu3xs3NLV2inNGeajVr1qRGjRrMmTMHAJ1Oh4eHByNGjGDcuHHpjvf39+eDDz4gOjr6uWX26dOH6Ojol/awexGp70V+dPFOLCP+OkVwVDzGRho+aVGGgfUNsLxa/D04uRhO/AJxkeo+Ewvw7go1h4Bz2ZyNR4g8IDP1Up6ePev06dMcPnyYKVOmPPeYpKQkkpKS9K9jY2NzIjSRXTx8YeAeOLUEdn2pjlf3bwWVOkPzL8HO7aVFmJsY82OXKhQtaMXs3UH8vCeY0AePmdGxMhammZuYTggh8qrly5ezcuVKWrVq9cplJCcnExAQwPjx4/X7jIyMaNasGUeOHHnueXFxcRQrVgydTke1atWYOnUqFSpUSHPM3r17cXZ2pkCBAjRp0oQpU6ZQqJAspSneTE/m1/lmy2WStTpc7MyZ1bUqtXJ6ednIi3BsHpxdCamJ6j4bV3WsuU9fsJZ7VIiskCeT9CJFihAVFUVqaiqTJk1iwIABzz122rRpTJ48OQejE9nOyBiq94Py7dREPcAfzq1Ul/do+Ik6Y6jxi7t8aTQaRr9VBo+CVoxfe46/z9whIuYxC3tWp4C1WY58DCGEMCQzMzNKliz5WmXcu3cPrVaLi4tLmv0uLi5cvnz5meeUKVOG3377jcqVKxMTE8N3331HnTp1uHDhAkWKFAHUru4dOnTAy8uL4OBgPv30U1q2bMmRI0cwNn72w1R5KC/yq/txSXy8+iy7L98FoFk5F77tWJmCOfV7RaeDoJ1ql/bre57ud6sCtYepv8dM5LeTEFkpT3Z3DwkJIS4ujqNHjzJu3DjmzJlDt27dnnnssyptDw8P6f6Wn9w+pc4Cf/uk+tqxDLScDiUaZ+j0Q0H3eP/3AB4lpuLlaM3iPjXwdJSZ34UQOccQXbO///57rl+/zpw5c165q+ydO3dwd3fn8OHD1K5dW79/7Nix7Nu3j2PHjr20jJSUFMqVK0e3bt346quvnnnM9evXKVGiBDt37qRp06bPPGbSpEnPfCgv9b3Iyw5eu8eHKwOJepSEmYkRn7cuR89axbK3e3tqMkScg1vHnm6PwtX3NEbquua1hkLRWpDT3eyFyMNypLv76tWrWblyJaGhoSQnJ6d579SpU69abIZ4eXkBUKlSJSIjI5k0adJzk3Rzc3OZbCa/c68G/XfAmT9hx0S4dwWWtYPy78BbX4ODxwtPr1vSkTVD6tB38QlC7sXTfu4hfu1dHZ9iBXMmfiGEMICDBw+yZ88etmzZQoUKFTA1TdsDae3atS8tw9HREWNjYyIjI9Psj4yMxNXVNUNxmJqaUrVqVYKCgp57TPHixXF0dCQoKOi5Sfr48eMZPXq0/vWTh/JC5EUpWh3fb7/Kgv3BKAqUcrZhdreqlHPLhgdO8ffUOX9uHVP/e+fU067sT5jbQbVearf2Ap5ZH4MQIo1XStJnz57NZ599Rp8+fdiwYQN9+/YlODiYEydOMGzYsKyO8YV0Ol2alnLxhjIygqrvQdnWsGeaOpHJxQ1wbQfU/wjqjACT5z+sKe1iy7phdRiw5CRnw2Lo9ssxfujsTZvKslSIECJ/cnBwoH379q9VhpmZGT4+PuzatUvfE06n07Fr1y6GDx+eoTK0Wi3nzp174dj4sLAw7t+/j5vb8+cdkYfyIr+4eT+ekX+d5kxYDADdaxbli9blsTTLgnlzdDqIuvw0Ib91DB4Epz/OsgB41FTnAvKoCYWrgZnV619fCJEhr5Skz507l4ULF9KtWzf8/f0ZO3YsxYsXZ8KECTx48CDD5cTFxaV5ch4SEkJgYCAFCxakaNGijB8/ntu3b7N06VJAXYe1aNGilC2rzhi5f/9+vvvuO0aOHPkqH0PkR5YFoNW3UK2n2gU+9Ajs/kpduq3lt1Cq+XNPdba1YPmgWoz8K5CdlyIZ/udpbj14zPsNDTBrqhBCZLP/Lm/2OkaPHk3v3r2pXr06vr6+zJw5k/j4ePr27QtAr169cHd3Z9q0aQB8+eWX1KpVi5IlSxIdHc2MGTO4efOmfn6ZuLg4Jk+ezLvvvourqyvBwcGMHTuWkiVL4ufnlyUxC5FbrT99m8/XnycuKRU7CxO+7ViZFhVfPinucyU9grCTTxPysJOQFJP+OKeyTxNyj5pQqKR0ZRfCgF4pSQ8NDaVOnToAWFpa8ujRIwB69uxJrVq19MuwvMzJkydp3PjpuOEn3dR69+6Nv78/4eHhhIaG6t/X6XSMHz+ekJAQTExMKFGiBNOnT2fw4MGv8jFEfuZaCfpugXOrYPvn8OA6/NERyrQCv6lQ0OuZp1mZmbCgpw9T/rnI4kM3mL71MqEP4vnynYqYGss6n0KI/CcqKkq/ZnmZMmVwcnLK1PldunQhKiqKCRMmEBERQZUqVdi6dat+MrnQ0FCM/rNO8sOHDxk4cCAREREUKFAAHx8fDh8+TPny5QEwNjbm7NmzLFmyhOjoaAoXLsxbb73FV199JS3lIt+KS0plwvrzrP137XNfz4L82LUK7g6WGS9EUeDhjbRd1+9eAEWX9jhTayji8zQhL1JdbeQQQuQarzRxXPHixVmzZg1Vq1alevXqDBw4kMGDB7N9+3a6du2aqdb0nCbrpr6BEmNh33Q4Nh90qWBsDvU+hLqjXth1a/GhEL7cdBFFgQalnfi5e1VsLV48a7wQQrwKQ9RN8fHxjBgxgqVLl6LTqT/ijY2N6dWrFz/99BNWVnm7a6vU9yKvOBsWzci/TnPjfgJGGhjVtDTDGpfA5GWNAymJEH7mPxO8HYf4u+mPcyj6NCH38AXnCmCcJxd4EiJPy/aJ45o0acLGjRupWrUqffv25cMPP2T16tWcPHmSDh06vFLQQmQbCzvw+xqq9oQtH0PIftj3jdoF/q2v1KVDntGlq29dL4oUsGLkX6fZfzWKTvOP8FufGhTOzFNtIYTIJWbOnEmlSpX0E6+NHj2affv28ffff1O3bl1AnUxu5MiRfPTRR8ybN8+Q4QqR7+l0Cr8cuM6MbVdI1Sm4O1gys2sVang+Y+JabYo6ljz8jLrdOa3+V5t28maMTKFwlacJeRFfsHuN7vJCCIN4pZZ0nU6HTqfDxETN8ZcvX87hw4cpVaoUgwcPxsws966VKE/W33CKAhfXw7bPITZM3edZH1p8A64Vn3nK2bBo+vmf5F5cEi525izqXYOK7vY5F7MQIt/LibopICCATp06MXnyZHr27ImjoyOrV6+mUaNGaY7bs2cPnTt3JioqKlviyClS34vc7O6jRD5aeYYD1+4B0KqSK9PaV8beylRtIb978WlCHh4IkRdB+4yJkq2d0k7w5lYFTC1y9LMIITImM/VSrlknPadIpS0ASE6AQzPh0Cx1mRGNEfj0hSafg1X6J9hhDxPo53+Cq5FxWJkZ83P3ajQu65zzcQsh8qWcqpuioqLo1asXW7ZswcrKioCAAMqVK5fmmAsXLuDr60t8fHy2xZETpL4XudWeK3cZs/IM9+OTKWCazLf1jGnmEI4m/KyalEddUofn/T9zO3DzfroVqQ4FvGSCNyHyiGxJ0s+ePZvhACpXrpzhY3OaVNoijehQ2P6F2roOYOEAjT+D6v3SjdeKeZzC0D8COBR0HyMNTH67Aj1re+Z0xEKIfCgn6yZFUdBoNDRt2pRChQqxdOlSLCzUlrfHjx/Tu3dvHjx4wM6dO7M1juwm9b3IbZLiHrL8738IPX+EikYhVDMNpahyG83/T+wGYFlQ7bb+36TcwVNdclYIkSdlS5JuZGSERqPRV+4votVqMx5tDpNKWzxTyAHY8ok6CyqAc3m1C3zxhmkOS07V8dm6c6wKULvKD2pQnHEtymJkJE+xhRCvzhB10/nz5/Hz8yMpKQlvb28Azpw5g4WFBdu2baNChQo5Ekd2kfpeGFT8fYg4o++ynhx2GrOYG88+1sY1bTLu5g32RaSFXIh8JluS9Js3b+r/fPr0acaMGcPHH39M7dq1AThy5Ajff/893377Le3atXv16LOZVNriubSpELAY9nwNjx+q+8q1hbe+hgLF9IcpisLPe4L4bvtVAFpWdOXHLlWwMDU2RNRCiHzAUHVTQkICf/zxB5cvXwagXLly9OjRA0vLvD9BptT3IkdFXoTLm56OI4+59czD7uCEiXsVnEvX/Dchrwy2rjkcrBDCELJ9TLqvry+TJk2iVatWafZv3ryZL774goCAgMwWmWOk0hYvlfAA9kyFk4vUtUWNzaHuSHXZNjNr/WEbAm/z8aqzJGt1VC3qwC+9quNoI2v4CiEyT+qmrCffqcgROq06x82eqenGkWsLeBGYUowdD105r3hhXawqX3ZriIudTOwmxJso25N0S0tLTp06lW6ymUuXLlGtWjUeP36c2SJzjFTaIsMiL6hd4G8cUF/buUPzL6Hiu/ouaMeu32fQsgBiHqfgUdCSxX18KelsY8CghRB5UU7VTRs3bqRly5aYmpqycePGFx779ttvZ1scOUHqe5HtHt6EdYMh9Ij6ukRTKNkU3Lw5nVKE4Wuuczv6MSZGGj56qwyDGxSX4XFCvMGyPUmvVq0aFStW5Ndff9Uvt5acnMyAAQM4f/48p06derXIc4BU2iJTFAUubVSXbIsJVfcVrQ0tp6vd1IDgqDj6Lj5B6IME7C1NWdDTh1rFCxkwaCFEXpNTdZORkRERERE4Oztj9IIJqDQaTa6eXyYjpL4X2UZR4OwK+GcMJD8CMxtoNQO8u6FVYN7eIH7ceQ2tTsGjoCWzu1alatECho5aCGFg2Z6kHz9+nLZt26Ioin4m97Nnz6LRaPj777/x9fV9tchzgFTa4pWkPIbDc+DgD5CSAGjApzc0+QKsHbkfl8SApSc5HRqNqbGGbztWpn3VIoaOWgiRR0jdlPXkOxXZIuEB/DMaLqxTX3vUhPYLoKAX4TGP+XBFIEevPwDgnSqFmdKuIrYWpgYMWAiRW+TIOunx8fHpJpvp3r071tbWLznTsKTSFq8lJgx2TITzq9XX5vbQaBz4DiRRZ8TolYFsPhcBwOjmpRnRpORLV0MQQojcUjdFR0fj4OBgsOtnpdzynYp85PpeWDcEHt0BIxO1/q/7IRibsP1CBGPXnCU6IQUrM2O+eqciHaq5y28AIYRejiTpeZVU2iJL3DwMW8ZCxDn1tWMZaDENXfEmTN92mQX7rgPQ0acIU9tXwsxE1jUVQjyfIeqm6dOn4+npSZcuXQDo1KkTa9aswc3Njc2bN+uXZcurpL4XWSY1CXZ9CUfmqK8LlYQOC8Hdh8fJWr7efJHfj6pD4iq52zO7W1W8HHN3o5UQIudlS5KeXyabkUpbZBmdFk4thd1fQcJ9dV+Z1uA3hT+uGTNhwwW0OoU6JQox7z0f7C2lu5sQ4tkMUTd5eXnxxx9/UKdOHXbs2EHnzp1ZsWIFK1euJDQ0lO3bt+dIHNlF6nuRJSIvwJqBcPeC+rp6P3hrCphZcyk8lpF/neba3TgABjUozpi3ysiDeSHEM2VLkp5fJpuRSltkuccPYe90OL4QFC0Ym0Ht4ex37cWQlVeIT9ZSrJAV33XypoZnQUNHK4TIhQxRN1laWnL16lU8PDwYNWoUiYmJLFiwgKtXr1KzZk0ePnyYI3FkF6nvxWvR6eDYfNg5CbRJYOUI78yBMi1RFAX/wzeYtuUyyak6nGzN+aGzN/VLORk6aiFELpaZeinDj/p0Oh3Ozs76Pz9vy80JuhDZwrIAtPwGhhyG4o1BmwwHf6DBtpZsbxpBYTtzbt5PoPOCI3z590UeJ8s9IoQwvAIFCnDr1i0Atm7dSrNmzQBQFEXqcvFmi70Dv7eHbePVBL2UHww9AmVaci8uiX7+J5j890WSU3U0LevM1lH1JUEXQmQpE0MHIES+4VwWeq6DK5th26fw8Abue0ax370GvxXuxvTLTvx2KIQ9V+7yXafK+BSTVnUhhOF06NCB7t27U6pUKe7fv0/Lli0BOH36NCVLljRwdEIYyIX18PcoSIwGE0vw+1rt4q7RsO9qFB+tPMO9uCTMTIz4vHU5etYqJpPDCSGyXIaT9NmzZ2e40JEjR75SMELkeRoNlG0NJZvBkZ9h/3eY3D7BIE7Qx64A21OrsP5BNXrMf0jPemX46K0yWJgaGzpqIcQb6Mcff8TT05Nbt27x7bffYmNjA0B4eDhDhw41cHRC5LDEWNg6DgL/UF+7VYF3fwXHUiSlapmx9Qq/HgwBoIyLLbO7VaWMq63h4hVC5GsZHpPu5eWV5nVUVBQJCQn6pVqio6OxsrLC2dmZ69evZ3mgWUXGqIkcFRsO+6bDxQ3w+IF+d7xizj6dN6et69K6Qx+qlPY0XIxCCIOTuinryXcqMiz0KKwdBNE3QWME9UZDw0/AxIygu3GM/Os0F8NjAehduxjjW5WTB+xCiEzL9iXY/vzzT+bOncuiRYsoU6YMAFeuXGHgwIEMHjyYHj16vFrkOUAqbWEQ2lQIPQKXN8GlTRAbpn8rRTHmln11POp0xrRCG7B1NWCgQghDyKm6Kb+s1JIRUt+Ll9KmqA/SD3wPig7si0KHBVCsDoqisPzELSb/fYHEFB0Frc2Y0bEyTcu5GDpqIUQele1JeokSJVi9ejVVq1ZNsz8gIICOHTsSEhKS2SJzjFTawuAUBcIDSTy3kehTa3FNuvH0LTRoitRQu8yXawuFShguTiFEjsmpuim/rNSSEVLfixe6FwRrB8KdU+pr727QcjpY2BOdkMy4NefYeiECgPqlHPm+kzfOdhYGDFgIkddlpl56pYnjwsPDSU1NTbdfq9USGRn5KkUK8ebQaKBwVSwKV8XVbyKHjx0lYNsy6qUepapREIQdV7edE8GpHJRrA2XbgJu3eq4QQrwinU73zD8L8cZQFAjwVyd4TUkACwdo8yNU7ADAkeD7fLgikIjYREyNNYz1K0v/el4YGUn9K4TIOa/Ukt62bVtu377Nr7/+SrVq1QC1FX3QoEG4u7u/tAudIcmTdZEbRSckM2njBY4Enqe5cQDtLU5TTXcejfKfh2H2Rf9tYW8DRWuDkYyHEyK/kLop68l3KtKJi4KNI+DqFvW1V0NoNw/s3UnR6pi58ypz9wajKFDc0ZrZ3apS0d3esDELIfKNbO/uHhUVRe/evdm6dSumpqYApKam4ufnh7+/v3499dxIKm2Rm227EMFn685xLy6ZAkbxTCl/mxYmJzEO3q0+8X/CqhCUaQll20LxRmAqXfCEyMsMUTeNHDmSkiVLpluRZc6cOQQFBTFz5swciSO7SH0v0ri6DTYMg/goMDaDZpOg5hAwMuLm/XhGLg/kzK1oALpU92BC2/JYm8tKxUKIrJOtSbqiKNy6dQsnJyfCwsK4dOkSAGXLlqV06dKvHnUOkUpb5HYP45OZuPECG8/cAdSlXr5vX5qKiQHqpHNXt8Djh09PMLNRl3wr1xZKNQcLeeovRF5jiLrpSc83Hx+fNPtPnTrF22+/TVhY2HPOzBukvhcAJCfA9s/h5CL1tXN56PALuFYEYO2pML5Yf574ZC12FiZM61CZ1pXdDBiwECK/ytYkXafTYWFhwYULFyhVqtRrBWoIUmmLvGLr+XA+W3ee+/HJGBtpGNqoBCOalMJMo4Obh9SZ4i//A7G3n55kZArFakPB4mDn/u9WGOyLqP81szbcBxJCPJch6iYLCwvOnz9PyZIl0+wPCgqiYsWKJCYm5kgc2UXqe8Gd07BmINy/pr6uNQyaTgBTC2ITU5iw/jzrA9UH4r6eBfmxaxXcHSwNGLAQIj/L1onjjIyMKFWqFPfv33/tJH3//v3MmDGDgIAAwsPDWbduHe3atXvu8WvXrmXevHkEBgaSlJREhQoVmDRpEn5+fq8VhxC5UYuKbtTwLMiEjRf452w4P+0OYsfFSL7r5E3F4g2heENo+a06M+2lTWrSfu8qhOxXt2excFATd3v3p0m8/b+JvN2TRN4qRz+nEMIwSpYsydatWxk+fHia/Vu2bKF48eIGikqILJD0SF1a7eg80KWCrZs69rxEYwACbj7kgxWnufXgMcZGGj5oWoqhjUtiLJPDCSFyiVcabPPNN9/w8ccfM2/ePCpWrPjKF4+Pj8fb25t+/frRoUOHlx6/f/9+mjdvztSpU3FwcGDx4sW0bduWY8eOpVsOToj8oJCNOT93r0ariuF8seE8lyMe0e7nQwxtXJLhjUtiZmIE7j7q1mwiRF2FW0ch5rbawh57G2LvqK+TH0FitLrdvfD8i1oW+L9W+P8k9E/2SSIvRJ43evRohg8fTlRUFE2aNAFg165dfP/993l+PLp4QykKnFsF27+AOHX5NMq/A21mglVBtDqFuXuCmLnrGlqdgkdBS2Z2qYpPsQIGDVsIIf7fK00cV6BAARISEkhNTcXMzAxLy7Rdgx48eJD5QDSal7akP0uFChXo0qULEyZMyNDx0v1N5FX34pKYsOE8m8+pPzzKudnxXafKVCicwTHoibFq0p4mgX/y+o765+S4jJVlWeBpy3vJplC1pyTuQrwGQ9VN8+bN4+uvv+bOHbXLr6enJ5MmTaJXr145FkN2kfr+DRNxDjaPhdDD6uuCxaHFdCj9FgC3ox/z4fJAjt9Qf6O2q1KYr9pVxNbC1FARCyHeMNm+TnpuecKu0+l49OgRBQsWfO4xSUlJJCUl6V/HxsbmRGhCZDlHG3Pm9vBh09k7fLH+PJfCY3lnziGGNynJsMYlMTU2enEBFnbq5lzu2e8rCiTF/idpD3vaCv/fhD4lXp247vFDiDwH17bBvm+h9jCo0V8mrhMiDxkyZAhDhgwhKioKS0tLbGxsDB2SEJnz+CHsmQonfgVFB6ZW0GAM1B4OJuYAbD4Xzrg1Z4lNTMXG3ISv2lWgfdUiBg5cCCGe75WS9N69e2d1HK/ku+++Iy4ujs6dOz/3mGnTpjF58uQcjEqI7NWmcmFqehXi8/Xn2HYhkpk7r+nHqpdze43WIo1GTbAt7MGl/LOPURRIjHna8h51GY4vhOhQ2DUZDs6EmoPUZW2sC716LEKIHJGamsrevXsJDg6me/fuANy5cwc7OztJ2EXuptNB4O+wcxIk3Ff3VWgPb01RJ0sFEpJTmbzxIitO3gKgiocDs7pWoVghmURVCJG7vVJ3d4Dg4GAWL15McHAws2bNwtnZmS1btlC0aFEqVKiQ+UAy2d39zz//ZODAgWzYsIFmzZo997hntaR7eHhI9zeR5ymKwsYzd5i48QLRCSmYGmsY0aQUQxqVeHmrelbSpsD5NXDgB7h3Rd1nagU+faHOcLVLvBDihQzRNfvmzZu0aNGC0NBQkpKSuHr1KsWLF2fUqFEkJSUxf/78HIkju0h393zsdgBs/lj9L4BTWXUi1eIN9YeE3Iunv/8Jrt+LR6OBYY1KMqpZqZytH4UQ4j8yUy9l6F+qK1eupHm9b98+KlWqxLFjx1i7di1xceo41jNnzjBx4sRXDDvjli9fzoABA1i5cuULE3QAc3Nz7Ozs0mxC5AcajYZ3qriz/cMGNC/vQopW4YcdV2k/9xA378fnXCDGpuDdFYYehc7LwM0bUhLg6M8wyxv+HgUPQnIuHiFEhowaNYrq1avz8OHDNHPLtG/fnl27dhkwMiGeI/4ebBwBvzRVE3QzW/CbCu8fTJOgX4t8ROcFR7h+Lx43ewv+GliLMX5lJEEXQuQZGfrXau3atfTo0QOtVgvAuHHjmDJlCjt27MDMzEx/XJMmTTh69Gj2RPqvv/76i759+/LXX3/RunXrbL2WEHmBs60FC3v6MLNLFewtTTl/O5a35xziwLWonA3EyAjKvw2D9sF7a6BoHdAmQ4A//FRNXav27qWcjUkI8VwHDhzg888/T1OPgzp53O3btzNV1s8//4ynpycWFhbUrFmT48ePP/dYf39/NBpNms3CwiLNMYqiMGHCBNzc3LC0tKRZs2Zcu3YtUzGJfESbCsd/UeuSU0sBBby7wYgAdT4U46eTv124E0OXhUeJepREWVdb/h5Rj1rFZfiVECJvyVCSPmbMGAoWLKhfj/zcuXO0b98+3XHOzs7cu3cvwxePi4sjMDCQwMBAAEJCQggMDCQ0NBSA8ePHp5lh9s8//6RXr158//331KxZk4iICCIiIoiJicnwNYXIjzQaDe2qurPtgwZU8XAg5nEKvX87zq8HrvOKI1peJxgo2Qz6bYG+W9Q/Kzo4txLm1oLlPeD2qZyNSQiRjk6n0z98/6+wsDBsbW0zXM6KFSsYPXo0EydO5NSpU3h7e+Pn58fdu3efe46dnR3h4eH67ebNm2ne//bbb5k9ezbz58/n2LFjWFtb4+fnR2JiYsY/oMgfbh6BhY1g8xh1ThTXStBvG7SfD7YuaQ4NvBVNt4VHeRCfTCV3e5YPqoWjjblh4hZCiNeQoSTd1NSUn376icGDBwPg4OBAeHh4uuNOnz6Nu7t7hi9+8uRJqlatql/jfPTo0VStWlW/nFp4eLg+YQdYuHAhqampDBs2DDc3N/02atSoDF9TiPzM1d6C5YNq8W61IugUmPLPJT5adYbElPQ/xHNEsTpqq/qgvVDubUADlzfBL41hWXu4cVCdjE4IkePeeuutNKu1aDQa4uLimDhxIq1atcpwOT/88AMDBw6kb9++lC9fnvnz52NlZcVvv/323HM0Gg2urq76zcXlabKlKAozZ87k888/55133qFy5cosXbqUO3fusH79+lf5qCIvehQBawfB4hbqSiIWDtD6e7W3VtFa6Q4/ceMB7/16jNjEVHyKFeCPgTVxsDJLX64QQuQBrzRx3JgxYzh27BirVq2idOnSnDp1isjISHr16kWvXr1yZFz6q5KJZMSbQFEUFh+6wdebL6HVKXgXsWdBz+q42lu8/OTsdPcyHJoJZ1eC8u+DA49aUP8jKNVcbYUX4g1kiLrp1q1btGjRAkVRuHbtGtWrV+fatWs4Ojqyf/9+nJ2dX1pGcnIyVlZWrF69Os3Er7179yY6OpoNGzakO8ff358BAwbg7u6OTqejWrVqTJ06VT/p7PXr1ylRogSnT5+mSpUq+vMaNmxIlSpVmDVr1jNjkYli8wltChybD3unQ/IjQAM+vaHJhOeuGnI46B79l5zkcYqWWsULsqh3DazNX2kBIyGEyDZZPnHc/5s6dSrlypWjaNGixMXFUb58eRo0aECdOnX4/PPPXyloIUTW0Wg09KvnxZK+vthbmnImLIa2cw4ScPOhYQNzLqt2URx5Cqr3B2NzuHUU/uwECxrAhfWgM1CrvxBvGA8PD86cOcNnn33Ghx9+SNWqVfnmm284ffp0hhJ0gHv37qHVatO0hAO4uLgQERHxzHPKlCnDb7/9xoYNG/j999/R6XTUqVOHsLAwAP15mSkT1CVX7e3t9ZuHh0eGPoPIRa7vhXl1YfvnaoLuXh0G7oa2s56boO+9cpe+/id4nKKlfilHFvfxlQRdCJHnZaolXavV8t1337Fx40aSk5OpXLky7777LnFxcVStWpVSpUplZ6xZQlrSxZvm5v14Bi0N4ErkI8yMjZjSviKdq+eSH6+PIuDwT3ByMaT8OyN9oVJQfzRU6pRmMiAh8rOcrptSUlIoW7YsmzZtoly5cq9czp07d3B3d+fw4cPUrl1bv3/s2LHs27ePY8eOZSiWcuXK0a1bN7766isOHz5M3bp1uXPnDm5ubvrjOnfujEajYcWKFc8sR1rS87DoW2pifnG9+trKEZpPBu/u6qSkz7H9QgTD/jxFilahWTlnfu5RDXMT45yJWQghMinbWtKnTp3Kp59+io2NDe7u7vz555+sXr2azp0754kEXYg3UbFC1qwdWge/Ci4ka3WMXX2WSRsvkKLVGTo0sHUFv6/hw/PQ8BOwsIf712D9EJhdTZ3NN+WxoaMUIt8xNTXNkknYHB0dMTY2JjIyMs3+yMhIXF1dMxxL1apVCQoKAtCfl9kyZcnVPCg1CfZ/Bz/7qgm6xghqvq/O2l71vRcm6JvO3mHoH2qC3qqSK3N7+EiCLoTINzKVpC9dupS5c+eybds21q9fz99//80ff/yBTpcLfuwLIZ7L2tyEeT18+LBZaQD8D9+g16LjPIhPNnBk/7IqCI0/hQ/OQ7PJYO0MMaHqbL4zK8OhWZD0yNBRCpGvDBs2jOnTp5OamvrKZZiZmeHj45NmXXWdTseuXbvStKy/iFar5dy5c/pWcy8vL1xdXdOUGRsby7FjxzJcpsgDrm5XV/zY/RWkJECxujD4ALScDpYOLzx1TUAYI/86TapOoX1Vd2Z3rYqZiayBLoTIPzLV3d3c3JygoKA047wsLCwICgqiSJEi2RJgVpPu7uJNt+1CBKNXBBKfrKVIAUt+6VWdcm657F5IeQynf1eT85hb6j4LB6gxACq0A5eKMsmcyFcMUTe1b9+eXbt2YWNjQ6VKlbC2tk7z/tq1azNUzooVK+jduzcLFizA19eXmTNnsnLlSi5fvoyLiwu9evXC3d2dadOmAfDll19Sq1YtSpYsSXR0NDNmzGD9+vUEBARQvnx5AKZPn84333zDkiVL8PLy4osvvuDs2bNcvHgx3ZrqzyP1fS714Dps/RSublFf27rBW1Og4rsZ+nf9z2OhfLruHABda3jwdftKGBtJfSCEyP0yUy9lamaN1NTUdJWjqakpKSkpmY9SCGEQfhVcWTu0LgOXniT0QQId5h7m+87etKrk9vKTc4qpJfgOhGq94dwqOPgD3A+CA9+pm507lPaD0i3Aq4F6vBAiUxwcHHj33Xdfu5wuXboQFRXFhAkTiIiIoEqVKmzdulU/8VtoaChG/+m2/PDhQwYOHEhERAQFChTAx8eHw4cP6xN0UMe0x8fHM2jQIKKjo6lXrx5bt27NcIIucqljC2D7F6BNAiNTqD0UGnwM5rYZOn3xoRAm/30RgN61izGxbQWMJEEXQuRDmWpJNzIyomXLlpibm+v3/f333zRp0iTNE/iMPn03BHmyLoQqOiGZ4X+e5mDQPQBGNCnJh81K584fPDotXNqoLt0WvAdS/zNO3cQSijf6N2n3A7vCBgtTiFeVk3WTTqdjxowZ+klgmzRpwqRJk7C0zF8Pu6S+z2VOLYONw9U/F28MLb8Fp9IZPn3e3mCmb70MwOAGxRnXsiwa6VElhMhDMlMvZSpJ79u3b4aOW7x4cUaLzHFSaQvxVKpWx7Qtl1l0MASAZuVc+LGLN7YWuXhW9ZTHEHIArm6Fq9sgNizt+27eagt7aT9wq/rCiYeEyC1ysm766quvmDRpEs2aNcPS0pJt27bRrVs3fvvtt2y9bk6T+j4XubIVlncHRQv1PoSmEzM8ZElRFGbtusbMndcAGNm0FB82KyUJuhAiz8m2JD0/kEpbiPTWBIQxft05klN1lHK24Zde1fF0tH75iYamKBB5QR3beHUbhJ0E/vNPmo0LlHpLTdqLNwJzG0NFKsQL5WTdVKpUKcaMGcPgwYMB2LlzJ61bt+bx48dpuqXndVLf5xK3jsOSt9UeUFV6wDs/ZypBn771CvP3BQPwsV8ZhjUumZ3RCiFEtpEk/QWk0hbi2QJvRTN42UkiY5OwszDhp+7VaFjaydBhZU5cFATtgCtbIHg3JMc9fc/YDDzrQ5mWauJeoJjh4hTi/+Rk3ZQfJoHNCKnvc4GoK/CbHzx+qP672/VPMM5YTy1FUZj890X8D98A4Is25elfzysbgxVCiOyVbRPHCSHyryoeDvw9vB6Dfw/gdGg0fRcfZ3zLcgyo75V3uhXaOEGV7uqWmgw3D6kt7Fe3wMMbELxL3QCcy/87jr0lFKkORrK+rngzyCSwIkfE3IZlHdQE3b06dPLPcIKu0yl8tv48fx0PBWBKu4q8V0serAoh3hzSki6ESCMpVcsX68+z8qQ61rt9VXemdaiEhWkeTmIVBe5dfTqOPfQIKLqn71sW/LdbvB+UbAoW9oaLVbyRcrJuyg+TwGaE1PcG9Pgh/NYSoi5BoVLQbxtYF8rQqalaHWPXnGXtqdsYaWD6u5XpVN3j5ScKIUQuJ93dX0AqbSFeTlEUlh65yZebLqLVKVQuYs+Cnj642eeT2Z8THkDQLjVpD9oBiTFP3zMygWJ11HHsFdrLbPEiR+Rk3ZQfJoHNCKnvDSTlMSxrrz4MtXWD/tvBoWjGTtXq+GBFIP+cDcfYSMOPXarwtrf8GyyEyB8kSX8BqbSFyLjDQfcY9ucpHiak4Ghjzvz3qlHds6Chw8pa2lS4dfRpK/u9q0/f0xhD2dZQoz94NczwZEdCZJbUTVlPvlMD0KbCqt5weROY20O/LeBSIUOnJqVqGf7naXZcjMTUWMNP3arRoqJrNgcshBA5R5L0F5BKW4jMufUggYFLT3I54tH/2rvv8Ciqto/j391NsgmBBEJIg9B7RwIBQboERAQ7ijTbq6KCQVFUUGyxPCIWBAsiIk0eAQuKD0QBQTqEIr2E0BKKkAapO+8fq9FID5tMNvl9rmsuNrMzk/tMdO/cOWfOwdNm4eU+jenX+vJ6RdzSyb2w+3+w7RtnT9BfKtZxFuvN7gKf8qaFJyWTcpPr6Z4WMcOA74fD+s/BZocBc6F6+8s6NSM7l/+btp6lu47j5WHlo3ta0rl+UKGGKyJS1FSkX4SStsiVS8/M4ck5m/hxayIAA9tWY/SNDfG0lZzlms4raRusmwybZkNWqnOfhw80vR0i7oOw5qaGJyWHcpPr6Z4WsSWvw5IYwAJ3TIWGfS7rtPTMHO6fuo6V+07i42nj00ERtKsdWLixioiY4EryUgn/DVtEXMHX7sGH/a9hxPV1Afhi5QHu+XQ1J9MyTY6skAU3hF5vw4jt0GscBDVyrvW74Qv4uCN80hXiZkJ2htmRioiYZ91nfxboQK//XHaBnpKRzaDP1rBy30nK2j2Yem9rFegiIqhIF5HLZLFYeKxrHT4ZGEFZuwer9//BTR+sYMuh5Euf7O7s5ZxD3R9eAUMWQuPbwOoJh9fB/IdgXAP43/Pwxz6zIxURKVrbv4cFI5yvO4yEVvdf1mmnz2Qx4NPVrDtwCj9vD6bd15rWNUrYnCciIgWk4e4icsV2J6XywBfriD95BpvVwuBrq/PE9XUpa/cwO7Sik3YMNk6DdVMg+eDf+2t3c/6SWqe71l6Xy6bc5Hq6p0XgwG/wRV/IzYRrBkHvdy9rgs2TaZncM3kN24+mUKGMJ9Pui6RxZS19KSIlm55JvwglbRHXSD6TzbPzt7Bg81EAQvy8GdO7IT0bh2ApTbOgO3Jh9yJY+ynsWQz8+ZHqHw4tB8M1A6GsJkCSi1Nucj3d00KWtA2m9HAuYVnvBrhjGtgu/YfaYykZ9P90NbuPpRFY1s70+yOpF1KuCAIWETGXivSLUNIWca0lO4/xwre/c+DkGQA61q3ES30aUa2ir8mRmeCPfc6e9Y3T4Owp5z6rp/P5zFb3QdW2WsZNzku5yfV0TwvR6YMwuTukHoHwNjBwPnj6XPK0I6fP0v/T1ew/kU6InzfTH4ikVqWyhR+viEgxoCL9IpS0RVwvIzuXD5fsZdKSvWTlOrB7WHm0c20e7FgTu0cpHPKdnQHb5jt71w+t/Xt/UENnsd70Tudz7iJ/Um5yPd3TQnLmD/gsCk7sgkr1YciPUObSz5JvO5LCfVPXcjQ5gyoVfJhxfxuqVixTBAGLiBQPKtIvQklbpPDsO57G6G+2smLPSQBqVvLllT6NubY0z9Z7JM65jNvmOc6Z4QG8ykKzfs5l3IIbmhqeFA/KTa6ne1oIss7AF33g0Brwqwz3/Q/8q1zytNjtSTw2cyNnsnKpVcmXL+6LpHL5S/e8i4iUJCrSL0JJW6RwGYbBt5uO8PL32znx5xJtfZuH8VyvhlQqZzc5OhOdPQ2bZjl710/u/nt/1WudvesNbgIPL9PCE3MpN7me7qmL5ebA7P6wayF4+8O9P0FQg4ueYhgGn62I59UF23AY0K52RT7s3xJ/H88iClpEpPhQkX4RStoiRSP5bDZv/28n01YdwDCgnLcHI6PqcXdkNWzWUvxctmHA/mXO3vXt34OR+/d7FitYbGD1cM4Mb7E5/8177QHWixxj9TjPOf/cb3W+ttmhSgTU7QHlw827F5JHucn1dE9dyDDg20dh45fg4Q0Dv4GqbS56Sk6ugxe/+50vVyUAcFfrcF7q0xhPm1b/FZHSyW2K9GXLlvHWW2+xfv16jh49yrx58+jbt+8Fjz969CgjRoxg3bp17Nmzh8cff5zx48df0fdU0hYpWpsPnea5eVvZcti5nnqzKv680rcJTapouR1SjsCGL2D955B61JwYgptAvR7Ogj3sGmchL0VOucn1dE9dKPZl+PU/zj8k3jkd6t9w0cNTMrIZOn0Dv+4+gcUCz/ZswP3X1ShdK3+IiPzLleQlUxc1Tk9Pp1mzZtx7773ccsstlzw+MzOTSpUq8fzzz/POO+8UQYQicrWaVinP/KHtmL76AG8t3MmmQ8n0mbCcgW2rE929Ln7epXjYo18YdHoGOoyEs384l3Nz5Dh71x1/bnmv/9rv+NcxF9vvOP81M5JhbywcXA1JW5zbsrfANwjqdoe6PaFmJ7Br1mWRUm/1x84CHeDG8Zcs0A/+cYZ7P1/L7mNp+HjaGN+vOVGNQgo/ThGREqTYDHe3WCyX7En/p06dOtG8eXP1pIu4kWMpGbyyYDvfbjoCQKVydkbf2JDeTUPVw2KG9JOwZxHs/BH2xEJW6t/v2exQ4zpnD7uGxRc65SbX0z11gd/nwZwhgAGdn4OOIy96+IaEUzz4xTpOpGUR7Gdn8qBWNK6sUVMiIuBGPelFITMzk8zMzLyvU1JSTIxGpHQL8vPmvbtacEdEOGO+2cq+E+k8PnMjX609yMt9G1MjsBSurW4m34rOWeab9YOcLEj4DXYuhF0/wql42LPYuf3wpIbFi5Q2+5fB3AcBA1rdDx2euujh3206wog5m8jKcdAozI/Jg1oR4u9dNLGKiJQwJf63rJiYGPz9/fO28HD1BomYrX2dQH4cfh3R19fFy8PK8j0niHpnGeMW7SIjO/fSFxDX8/ByDnHv+To8HgePrIZuL0J4G+dzqH8Nif+0K7xdD74Z6pz4LjPN5MBFxOUSt8Cs/pCbBQ16Q8834QKjnQzD4P3Y3Tw2cyNZOQ66NQjmq/9rqwJdROQqlPjh7ufrSQ8PD9fwN5FiIv5EOmO+/Z1lu44DUL1iGV7q05gOdSuZHJnk0bD4Qqeh2a6ne1pApw7A5OshLQmqtYN75oLn+QvuzJxcRn29hbkbDwNwf/sajLqhQelewUNE5AI03P0f7HY7dnspXptZpJirHujL1CGt+GFLIi99/zvxJ88w8LM19GoaypgbGxLsp94Y0/17WPyBFc61knf+CKcPaFi8SEmRfgK+vMVZoAc1gn4zLlig/5GexUPT1rMm/g9sVgsv9WlE/8hqRRywiEjJVOKLdBEp/iwWC72ahtKhbiDjFu1i6m/xLNh8lKU7jxN9fV0Gtq2Gh9bWLR48vKBWZ+fW43U4vuPPgn0hHFqj2eJF3FVWOsy4A07uAf9wuOdr8Cl/3kP3HEvjvqlrOXDyDOXsHnx4zzVcV0ejn0REXMXUIj0tLY09e/bkfb1//37i4uIICAigatWqjBo1isOHD/PFF1/kHRMXF5d37vHjx4mLi8PLy4uGDRsWdfgi4mLlvD15oXcjbr2mCs/P30rcwdO89P02vt5wiFdvbkLz8PJmhyj/ZLFAUAPn1v4J57D43f9zTjy352dIPwYbv3RuNi/n0Nm6PZyFe0BNs6MXkb/kZsNXg+DwevAJcA5x9ws976G/7TnBQ1+uJyUjhyoVfJgyuBV1gssVccAiIiWbqc+kL1myhM6dO5+zf9CgQXz++ecMHjyY+Ph4lixZkvfe+ZZpqlatGvHx8Zf1PfWMmoh7cDgMZq5N4I0fd5CSkYPFAne3rsrTPeuX7rXV3cU/h8XvWuicLf6fAutCne7Oor1qG7CV7p+pcpPr6Z5eJsOA+Q/Dppng4QODvoPwVuc9dPbaBJ6bt5Uch8E1Vcvz8cAIAsvqkUIRkctxJXmp2EwcV1SUtEXcy/HUTGJ+2J43MVGwn52X+zSme6MQkyOTy2YYcGK3s1jf/T9IWAmOnL/ft/tD7S5QJwrqXA++gebFahLlJtfTPb0MhgGLX4AV74LFBnfNhLpR5xzmcBi88dMOPlq6D4CbmoXx5m1N8fa0FXXEIiJuS0X6RShpi7in3/ae4Nm5W4g/eQaAG5qE8OJNjQgqp4nl3M7Z07D3Z2fBvvt/cObkP960QJUIZ8FeNwpCmlxw6aeSRLnJ9XRPL+HYDudkj/G/Or/u8yG06H/OYWezcnlidhwLf08EYFjXOgzvVue8IxtFROTCVKRfhJK2iPvKyM5l/OLdfPLrPnIdBv4+njzXqwG3t6yiXxjdlSMXDm+A3T85e9oTt+R/v1yY8xn2OlFQsyN4+ZoTZyFTbnI93dMLyEyFpW/AqonOES0e3tD9FWj9wDmHHkvJ4P4v1rH5UDJeNitv3taUvi0qmxC0iIj7u5K8pOmSRcRteHvaeKZnfb4Z2o5GYX4kn81m5H83M2DyGhL+7GEXN2O1OZ9/7fI8PLQcntgGN46HejeAZxlIPQLrP4dZd8EbNeDLW2HNJ861nItK1hk4fRCObITdi2HTLPjtA1g8FhaNKbo4irEJEyZQvXp1vL29iYyMZM2aNZd13qxZs7BYLPTt2zff/sGDB2OxWPJtPXr0KITISxHDgK1fwwet4Lf3nQV6vV4wdPV5C/RtR1LoM2EFmw8lE+DrxfQHIlWgi4gUEfWki4hbysl18Ony/byzaBeZOQ58PG2M6F6XIe1qYLOqV71EyM6A+OV/97KfTsj/fqX6ziHxdaIgPBJsl7FgiWFARrJziP2Zk851oc+c+PPfk3//e+aEc7b6Mycg+yJ/APLwgecTr66duHdumj17NgMHDmTSpElERkYyfvx45syZw86dOwkKCrrgefHx8bRv356aNWsSEBDA/Pnz894bPHgwSUlJTJkyJW+f3W6nQoUKlx2XO99Tlzu+0zm0ff8y59cVqkPPN8/7/DlA7PYkHp+5kfSsXGpV8uWzwa2oVrFkjmIRESkqGu5+EUraIiXL/hPpjJq7mVX7/gCgWRV/Xr+1KQ1C9f93iWIYzkIjb/K5VWDk/v2+d3mo3RVqdARH9t8Fdl7R/Y8C3JF95d/f5gVlAsG3IpSp+OfrQOe/10U7RwRcBXfOTZGRkbRq1YoPPvgAAIfDQXh4OI899hjPPPPMec/Jzc2lQ4cO3Hvvvfz666+cPn36nCL93/uulDvfU5fJTPtzaPuHfw9tbx8N7YaB57nzeRiGwZQV8byyYBsOA66tVZGJ/VviX6Z0r74gIuIKV5KXTF0nXUTkatUI9GXmA22YtfYgr/2wnU2Hkun9/nIe7lSLoZ1ra/bhksJigaD6zq39cDh7CvbE/jn53CI4+4dzKO/Wry/vel5lncX2X4W2byCUCchffP9zn71cqZjA7kplZWWxfv16Ro0albfParXSrVs3Vq5cecHzXnrpJYKCgrjvvvv49ddfz3vMkiVLCAoKokKFCnTp0oVXXnmFihUrXvCamZmZZGZm5n2dkpJSgBaVEIYBv8+Dn55zPjICzkdIesQ4e9HPIyfXwdjvtjFtlfNRkrtah/NSn8Z42vRkpIhIUVORLiJuz2KxcFfrqnSpH8SYb7by0+9JvP/zHn7YcpTXb21Kq+oBZocoruZTAZrc5twcuXBonXNY/KF1zoL6r0I7rxCvmH/feXoR5cqdOHGC3NxcgoOD8+0PDg5mx44d5z1n+fLlTJ48mbi4uAtet0ePHtxyyy3UqFGDvXv38uyzz9KzZ09WrlyJzXb+P7zFxMQwduzYArelxDjf0PYeb0C9Cz/Tn5KRzaMzNrJs13EsFni2ZwPuv66GJuQUETGJinQRKTGC/bz5aEAEP245yuhvfmfv8XRun7SSAW2qMbJHPcp5a8hmiWS1QdVI5ybFWmpqKgMGDOCTTz4hMDDwgsf169cv73WTJk1o2rQptWrVYsmSJXTt2vW854waNYro6Oi8r1NSUggPD3dd8MVdZhosexNWTrisoe1/OfjHGe6bupZdSWn4eNoY3685UY1CijBwERH5NxXpIlLi9GwSyrW1Ann1h218te4Q01YdYPH2JF69uTFd6gdf+gIiclkCAwOx2WwkJSXl25+UlERIyLmF3t69e4mPj6d37955+xwOBwAeHh7s3LmTWrVqnXNezZo1CQwMZM+ePRcs0u12O3a7/Wqa454MA7bNh4XP/j20vW5P59D2gBoXPXVnYir9P13FibQsgv3sTB7UisaV/Qs/ZhERuSg9aCQiJZJ/GU/evK0Z0++PpGpAGY4mZ3Dv5+t4fOZGTqZlXvoCInJJXl5etGzZktjY2Lx9DoeD2NhY2rZte87x9evXZ8uWLcTFxeVtN910E507dyYuLu6CPd+HDh3i5MmThIaGFlpb3NLxXTCtL8wZ7CzQy1eDu2bB3bMuWaDvPZ6WV6A3CPVj/tB2KtBFRIoJ9aSLSInWrnYgPw3vwDuLd/Hpr/v4dtMRft19nNE3NuTmFpX1zKXIVYqOjmbQoEFERETQunVrxo8fT3p6OkOGDAFg4MCBVK5cmZiYGLy9vWncuHG+88uXLw+Qtz8tLY2xY8dy6623EhISwt69exk5ciS1a9cmKur8S4aVOplpsOytP4e2Z4PNDu2fcE6q6OlzydMTTp6h/yer8wr0mQ9EUr6MV+HHLSIil0VFuoiUeD5eNp69oQE3Ng1l5H83syMxleivNvFN3BFevbkxVSqUMTtEEbd15513cvz4ccaMGUNiYiLNmzdn4cKFeZPJJSQkYLVe/sA9m83G5s2bmTp1KqdPnyYsLIzu3bvz8ssvl87h7P9kGLDtG/jpWUg57NxXt8efQ9trXtYlDp8+y12frCIxJYM6QWX58r7WKtBFRIoZrZMuIqVKdq6Dj5ft493Y3WTlOCjjZeOpqHoMbFsdm1W96mIO5SbXK3H39Pgu+PEp2LfE+XX5atDzDajX87IvcSwlgzs+Wkn8yTNUr1iGr/6vLUF+WulARKQoXEle0jPpIlKqeNqsDO1cmx+HXUfr6gGcycpl7HfbuG3Sb+xKSjU7PBGR/LLSYfGLMPFaZ4Fus0PHZ2Do6isq0E+mZdL/09XEnzxDlQo+zHigjQp0EZFiSkW6iJRKtSqVZdaDbXilb2PK2j3YmHCaXu/9yvjFu8jKcZgdnoiUdoYBv8+HD1rD8necz57X6Q5DV0HnUZf17PlfTp/J4p7Ja9h9LI0QP29mPtCGsPKXf76IiBQtFekiUmpZrRbuaVONRdEd6NYgiOxcg/GLd3Pj+7+yIeGU2eGJSGl1YjdMuxnmDIKUQ1C+KvSbCXd/ddnPnv8lJSObQZ+tYfvRFALL2pnxQCThAZqHQ0SkOFORLiKlXqi/D58MjOD9u1pQ0deLXUlp3DrxN174ZispGdlmhycipcmaT+DDtrDvlz+Htj8NQ9dA/RvgClejSM/M4d4pa9l0KJkKZTyZfn8kNSuVLaTARUTEVVSki4gAFouF3s3CWBzdkVuuqYxhwNSVB+j69lK+3XSEUjbHpoiYIW4m/PDkv4a2P3tFQ9v/kpGdy/1T17HuwCn8vD2Ydl8k9ULKFULQIiLiairSRUT+oYKvF+PuaO7scQr05XhqJo/P3MiAyWvYfyLd7PBEpKTauRC+Gep83WZogYa2/yUzJ5f/m7aelftOUtbuwdR7W9O4sr8LgxURkcKkIl1E5Dza1Q7kx+HXEX19Xbw8rCzfc4Ko8csYv3gXGdm5ZocnIiXJgZXO58+NXGjaD7q/csVD2/+Snevg0RkbWbrrOD6eNj4b3IoWVSu4OGARESlMKtJFRC7A7mHj8a51+N/wDlxXJ5CsHAfjF++mx/hl/Lr7uNnhiUhJkLgVZtwJORlQJwr6fADWgv16lusweGJ2HIu2JeHlYeXTQRG0rhHg4oBFRKSwqUgXEbmE6oG+fHFvaz64uwVB5ezEnzzDgMlreGzmRo6lZJgdnoi4q1Px8OWtkJkM4W3g9s/B5lmgSzkcBk/9dxPfbz6Kp83CR/e0pF3tQJeGKyIiRUNFuojIZbBYLNzYNIzYER0ZfG11rBb4btMRur69lKm/xZPr0MRyInIF0o45l1lLS4SghnD3LPAq2NJohmHw/DdbmbvhMDarhffvuobO9YNcHLCIiBQVFekiIlegnLcnL97UiG8fbU+zKv6kZubwwre/03fCCjYfOm12eCLiDjKSnT3of+xzroF+z1zwKdhz44Zh8NL325ixOgGLBcbd0YwejUNcHLCIiBQlFekiIgXQuLI/cx9px8t9G1PO24Mth5PpM2EFY77ZSvJZra0uIheQnQGz+kPiZigTCAPmg19ogS5lGAZv/rSTKSviAXjz1qb0aV7ZdbGKiIgpTC3Sly1bRu/evQkLC8NisTB//vxLnrNkyRKuueYa7HY7tWvX5vPPPy/0OEVEzsdmtTCgTTViR3Skb/MwDAO++HNt9W/iDmttdRHJLzcHvr4P4n8Fr3Jwz9dQsVaBL/de7B4mLtkLwMt9G3N7RLirIhUREROZWqSnp6fTrFkzJkyYcFnH79+/n169etG5c2fi4uIYPnw4999/Pz/99FMhRyoicmFB5bwZ369F3trqJ9IyGTYrjnsmr2bf8TSzwxOR4sAwYMETsON7sHnBXTMgrHmBL/fR0r28s3gXAM/3asCANtVcFKiIiJjNYhSTrh6LxcK8efPo27fvBY95+umnWbBgAVu3bs3b169fP06fPs3ChQsv6/ukpKTg7+9PcnIyfn5+Vxu2iEg+mTm5fLR0Hx/8soesHAdeNisPdarFI51q4e1pMzs8KaaUm1yv2N3TxWNh+TiwWOH2qdDwpgJf6vMV+3nxu20APBVVj6Gda7sqShERKSRXkpfc6pn0lStX0q1bt3z7oqKiWLly5QXPyczMJCUlJd8mIlJY/lpbfdETHehYtxJZuQ7ei3Wurb5sl9ZWFymVVk5wFugAN75zVQX6rDUJeQX6o51rq0AXESmB3KpIT0xMJDg4ON++4OBgUlJSOHv27HnPiYmJwd/fP28LD9fzWiJS+KpV9OXzIa2YcPc1BPs511Yf+Nkahs7YQJLWVhcpPTbNgp+edb7uOgZaDi7wpeZtPMSoeVsAuL99DUZ0r+uCAEVEpLhxqyK9IEaNGkVycnLedvDgQbNDEpFSwmKx0KtpKIujOzKknXNt9QWbj9L17aVMWbFfa6uLlHS7foL5jzhft3kE2kcX+FI/bDnKiK82YRgwoE01nuvVAIvF4qJARUSkOHGrIj0kJISkpKR8+5KSkvDz88PHx+e859jtdvz8/PJtIiJFqZy3Jy/0/nNt9fDypGXmMPa7bfSZsJxNB0+bHZ6IFIaEVfDVIDByoemd0P1VKGBRvXhbEo/P3IjDgDsiqjD2pkYq0EVESjC3KtLbtm1LbGxsvn2LFi2ibdu2JkUkInL5Glf2Z+7D1/JK38b4eXuw9XAKfT9cwej5WltdpERJ2gYz7oCcs1CnO/SZANaC/cq1bNdxHpm+gRyHQZ/mYcTc0hSrVQW6iEhJZmqRnpaWRlxcHHFxcYBzibW4uDgSEhIA51D1gQMH5h3/0EMPsW/fPkaOHMmOHTv48MMP+eqrr3jiiSfMCF9E5IrZrBbuaVON2BGduLlFZQwDpq06QJf/LGHqb/Fk5TjMDlFErsapA/DlLZCRDOGRzpncbZ4FutSqfSd5cNo6snId9GgUwtu3N8OmAl1EpMQztUhft24dLVq0oEWLFgBER0fTokULxowZA8DRo0fzCnaAGjVqsGDBAhYtWkSzZs14++23+fTTT4mKijIlfhGRgqpUzs47dzZnxv2R1Kzky8n0LF749ne6jVvKN3GHceh5dRH3k3Ycpt0MqUehUgO4axZ4lSnQpdYfOMW9n68lI9tBl/pBvHdXCzxsbjUAUkRECqjYrJNeVIrduqkiUupl5zqYtfYg7y7ezYm0TAAahfkxskd9OtQJ1LOnpYByk+sV+T3NSIGpN8LRTeBfFe77CfzCCnSpLYeSufuTVaRm5tC+diCfDorA29Pm4oBFRKQoldh10kVESiJPm5UBbaqx9KlOjLi+LmXtHvx+JIVBn62h/6erNbmcSHGXnQGz7nYW6GUCYcC8AhfoOxJTGPDZalIzc2hdPYCPB7ZUgS4iUsqoSBcRKSZ87R481rUOy0Z25r72NfCyWflt70n6TFjB0Okb2Hc8zewQReTfHLkw936I/xW8ysI9/4XA2gW6VE6ug2Ez4zh9Jpvm4eX5bEgrynh5uDhgEREp7lSki4gUMwG+Xoy+sSE/P9mRW66pjMUCC7Yc5fp3lvHsvC0cS8kwO0QRATAMWBAN278Dmxf0mwFhLQp8uemrE9iZlEqFMp5MGdyKsnYV6CIipZGKdBGRYqpKhTKMu6M5Pw67ji71g8h1GMxYnUCHt37hrZ92kJKhZdtETPXzK7D+c7BY4dZPoWbHAl/qVHoW4xbtAmBE93pU8PVyUZAiIuJuVKSLiBRz9UP8+GxwK776v7ZcU7U8GdkOJvyylw5v/sIny/aRkZ1rdogipc+qifDrf5yve42Dhn2u6nJvL9pJ8tlsGoT6cVfrqi4IUERE3JWKdBERN9G6RgBfP3wtHw9oSe2gspw+k82rP2yny3+WMGfdQXK1bJtI0dj8FSx8xvm6y/MQMeSqLrftSAozVjuXnH2xd0OthS4iUsqpSBcRcSMWi4XujUJYOOw63ry1KaH+3hxJzuCp/26m57vLWLwtiVK2sqZI0dq9COY/7Hwd+TBc9+RVXc4wDMZ+9zsOA3o1DSWyZkUXBCkiIu5MRbqIiBvysFm5o1U4vzzZiVE96+Pv48mupDTu/2Idt09aybr4P8wOUaTkObgGZg8ARw40uQOiXgPL1fV6/7AlkdX7/8Db08qzNzRwUaAiIuLOVKSLiLgxb08b/9exFstGdubhTrXw9rSy7sApbpu0kvunrmNXUqrZIUopMGHCBKpXr463tzeRkZGsWbPmss6bNWsWFouFvn375ttvGAZjxowhNDQUHx8funXrxu7duwsh8itwbDtMvx1yzkLt66Hvh2C9ul+jzmbl8toP2wF4qGMtKpf3cUWkIiLi5lSki4iUAP4+njzdoz5LnuzMXa3DsVktLN6eRI/xy3hyziYOnz5rdohSQs2ePZvo6GheeOEFNmzYQLNmzYiKiuLYsWMXPS8+Pp4nn3yS66677pz33nzzTd577z0mTZrE6tWr8fX1JSoqiowMk5YfPJ0A026BjNNQpTXcMRVsnld92Y+W7eXw6bOE+Xvzfx1qXX2cIiJSIqhIFxEpQUL8vYm5pSk/De9Aj0YhOAz47/pDdP7PEl5dsI1T6VlmhyglzLhx43jggQcYMmQIDRs2ZNKkSZQpU4bPPvvsgufk5ubSv39/xo4dS82aNfO9ZxgG48eP5/nnn6dPnz40bdqUL774giNHjjB//vxCbs15pJ+AaTdD6hGoVB/ung1evld92cOnzzJp6V4Anu3VAB8v21VfU0RESgYV6SIiJVDtoLJMGtCSeY9cS5uaAWTlOPjk1/10eOsXJvyyhzNZOWaHKCVAVlYW69evp1u3bnn7rFYr3bp1Y+XKlRc876WXXiIoKIj77rvvnPf2799PYmJivmv6+/sTGRl50WtmZmaSkpKSb3OJpK1w+iD4h8M9c6FMgEsu+9oP28nIdhBZI4BeTUJdck0RESkZVKSLiJRgLapWYOYDbfh8SCsahPqRmpHDWz/tpN3rP/Pu4t2cPqOedSm4EydOkJubS3BwcL79wcHBJCYmnvec5cuXM3nyZD755JPzvv/XeVdyTYCYmBj8/f3ztvDw8CtpyoXV7AQD5jk3/8ouueSqfSdZsPkoVgu80LsRlqucfE5EREoWFekiIiWcxWKhU70gFjzWnvF3NqdaxTKcOpPNO4t30e71n3nth+0cSzHpWV8pVVJTUxkwYACffPIJgYGBLr32qFGjSE5OztsOHjzouotXbweBdVxyqVyHwdjvtgFwV+uqNAzzc8l1RUSk5PAwOwARESkaVquFvi0qc2PTUH7YmsiHv+xhR2IqHy/bx+cr4rktogoPdahF1YplzA5V3ERgYCA2m42kpKR8+5OSkggJCTnn+L179xIfH0/v3r3z9jkcDgA8PDzYuXNn3nlJSUmEhv49DDwpKYnmzZtfMBa73Y7dbr+a5hSJmWsS2H40BT9vD0Z0r2d2OCIiUgypJ11EpJTxsFm5qVkYPw67jimDWxFRrQJZuQ5mrE6g039+YdisjexIdNHzvFKieXl50bJlS2JjY/P2ORwOYmNjadu27TnH169fny1bthAXF5e33XTTTXTu3Jm4uDjCw8OpUaMGISEh+a6ZkpLC6tWrz3tNd5J8Jpu3/7cTgOjr6xLg62VyRCIiUhypJ11EpJSyWCx0rh9E5/pBrNn/Bx8u2cOSncf5Ju4I38QdoVuDIB7uVJuW1SqYHaoUY9HR0QwaNIiIiAhat27N+PHjSU9PZ8iQIQAMHDiQypUrExMTg7e3N40bN853fvny5QHy7R8+fDivvPIKderUoUaNGowePZqwsLBz1lN3N+8s3sWpM9nUDS7LPW2qmR2OiIgUUyrSRUSE1jUCaF2jNVsPJzNx6V5+2HKUxduPsXj7MdrUDOCRTrW5rk6gJriSc9x5550cP36cMWPGkJiYSPPmzVm4cGHexG8JCQlYrVc2cG/kyJGkp6fz4IMPcvr0adq3b8/ChQvx9vYujCYUiZ2JqUxbdQBwThbnYdNgRhEROT+LYRiG2UEUpZSUFPz9/UlOTsbPT5O1iIicz77jaXy0dB9zNx4iO9eZJppU9ueRTrWIahSC1api3ZWUm1yvON1TwzC4Z/JqVuw5SVSjYD4aEGFqPCIiUvSuJC/pz7giInKOmpXK8sZtTVk2sjP3tquBj6eNLYeTeXj6Brq9s5Sv1h0kK8dhdpgibuGn35NYseckXh5Wnu/V0OxwRESkmFORLiIiFxTq78OY3g1Z8UwXHu9SGz9vD/YdT2fkfzfT6a1fmLJiP2ezcs0OU6TYysjO5dUfnEuuPXhdTcIDtHqCiIhcnIp0ERG5pABfL6K712PFM10Y1bM+lcrZOZKcwdjvttHujZ/54OfdJJ/NNjtMkWLn01/3cfCPs4T4efNI51pmhyMiIm5ARbqIiFy2ct6e/F/HWvw6sjOv9G1MeIAPf6Rn8Z//7aLd6z/z+o87OJ6aaXaYIsXC0eSzTPhlLwCjbqhPGS/N1ysiIpemIl1ERK6Yt6eNe9pU45cRnXi3X3PqBZcjLTOHSUv30u6Nnxk9fysH/zhjdpgipnr9xx2czc4loloFbmoWZnY4IiLiJlSki4hIgXnYrPRpXpkfh13HJwMjaFG1PFk5DqatOkCn/yzhidlx7ExMNTtMkSK3Lv4Pvok7gsUCL97USMsXiojIZSsWRfqECROoXr063t7eREZGsmbNmgsem52dzUsvvUStWrXw9vamWbNmLFy4sAijFRGRf7NaLVzfMJi5D1/LzAfacF2dQHIdBvM2HiZq/DLu+XQ1sduTcDhK1aqfUko5HAZjv3NOFndnRDiNK/ubHJGIiLgT04v02bNnEx0dzQsvvMCGDRto1qwZUVFRHDt27LzHP//883z00Ue8//77bNu2jYceeoibb76ZjRs3FnHkIiLybxaLhba1KjLtvki+fbQdPRuHYLXA8j0nuG/qOrq8vYQpK/aTmqFJ5qTkmrP+IFsOJ1PO24Mno+qZHY6IiLgZi2EYpnZrREZG0qpVKz744AMAHA4H4eHhPPbYYzzzzDPnHB8WFsZzzz3H0KFD8/bdeuut+Pj48OWXX17y+13JIvIiInL1Dv5xhmmrDjBrTQIpGTkAlLV7cHtEFQZfW51qFX1NjtB8yk2uZ9Y9TcnIpst/lnAiLYvnezXg/utqFtn3FhGR4utK8pKpPelZWVmsX7+ebt265e2zWq1069aNlStXnveczMxMvL298+3z8fFh+fLlFzw+JSUl3yYiIkUnPKAMz97QgJWjuvJy38bUquRLWmYOU1bE0+k/S7jv87Us330Ck/9mLOIS7y3ezYm0LGpV8mXQtdXNDkdERNyQqUX6iRMnyM3NJTg4ON/+4OBgEhMTz3tOVFQU48aNY/fu3TgcDhYtWsTcuXM5evToeY+PiYnB398/bwsPD3d5O0RE5NJ87R4MaFONRU90ZOq9relUrxKGAbE7jnHP5NVEjV/GjNUJnM3KNTtUkQLZcyyNz3+LB2BM70Z42kx/qlBERNyQ22WPd999lzp16lC/fn28vLx49NFHGTJkCFbr+ZsyatQokpOT87aDBw8WccQiIvJPVquFjnUr8fmQ1sSO6MjAttUo42VjV1Iaz87bQtvXY3n9xx0cOX3W7FBFLpthGLz8/TZyHAbdGgTRsW4ls0MSERE3ZWqRHhgYiM1mIykpKd/+pKQkQkJCzntOpUqVmD9/Punp6Rw4cIAdO3ZQtmxZatY8/zNfdrsdPz+/fJuIiBQPtSqV5aU+jVk5qivP92pAeIAPp89kM2npXq578xeGTt/Auvg/NBReir2fdxxj6a7jeNmsPN+rodnhiIiIGzO1SPfy8qJly5bExsbm7XM4HMTGxtK2bduLnuvt7U3lypXJycnh66+/pk+fPoUdroiIFBJ/H0/uv64mS57szMcDWtK2ZkVyHQYLthzltkkruemDFXy9/hCZORoKL8VPZk4uL3/vXHLt3vY1qB6oyRBFRKTgPMwOIDo6mkGDBhEREUHr1q0ZP3486enpDBkyBICBAwdSuXJlYmJiAFi9ejWHDx+mefPmHD58mBdffBGHw8HIkSPNbIaIiLiAzWqhe6MQujcKYfvRFD5fEc/8uMNsOZzMiDmbiPlxB/0jq9K/TVWCynlf+oIiRWDKinjiT54hqJydR7vUNjscERFxc6YX6XfeeSfHjx9nzJgxJCYm0rx5cxYuXJg3mVxCQkK+580zMjJ4/vnn2bdvH2XLluWGG25g2rRplC9f3qQWiIhIYWgQ6scbtzXl6Z71mbkmgWkrD5CYksG7sbv5cMkeejcNY0i7GjSp4m92qFKKHUvJ4P3Y3QA83aM+Ze2m/2olIiJuzvR10oua1qIVEXFP2bkOFm5NZMqK/WxIOJ23P6JaBYa0q0FUo2A83HQ2beUm1yuqezriq018veEQzcPLM/fha7FaLYX2vURExH1dSV7Sn3tFRMQteNqs9G4WRu9mYWw6eJopK/azYMtR1h04xboDpwj192ZA22rcGRFOxbJ2s8OVUmBjwim+3nAIgBd6N1SBLiIiLuGeXQ4iIlKqNQsvz/h+LVjxdBce71Kbir5eHE3O4M2FO2kb8zOPz9zIqn0nNSu8FBqHw+DF75yTxd16TRVaVK1gckQiIlJSqCddRETcVpCfN9Hd6/FI59p8t+kI01YdYPOhZL7ddIRvNx2hViVf7mpdldtaVqF8GS+zw5USZO7Gw2w6eBpfLxtP96hndjgiIlKCqEgXERG35+1p4/aIcG6PCGfr4WSmr07gm7jD7D2ezisLtvPmTzu5sUkod0dWpWW1ClgsGpYsBZeWmcMbC3cA8FjXOgT5aaUBERFxHRXpIiJSojSu7E/MLU149ob6fBN3hBmrE9h2NIW5Gw8zd+Nh6gWX467W4dx8TRX8fTzNDlfc0Ps/7+Z4aibVK5ZhSLvqZocjIiIljGZ3FxGREs0wDDYdSmb6qgN8t/kIGdkOALw9rfRuGsbdkVVpHl7e1N515SbXK6x7uv9EOt3fWUp2rsHkQRF0bRDssmuLiEjJpdndRURE/mSxWGgeXp7m4eV5/saGzN94mBmrE9iZlMqc9YeYs/4QDUL9uDuyKn2bh1HOW73rcmGvfL+N7FyDjnUr0aV+kNnhiIhICaSedBERKXUMw2BDwimmr0rg+y1Hycpx9q6X8bLRp3kYd7euRpMq/kUWj3KT6xXGPV2y8xiDp6zFw2ph4fAO1A4q65LriohIyaeedBERkYuwWCy0rBZAy2oBjOndkK83HGbG6gPsPZ7OzDUHmbnmIE0q+3N3ZFVuahaGr13psrTLynHw0vfOJdcGX1tdBbqIiBQarZMuIiKlWvkyXtzXvgaLozsy+8E23NQsDC+blS2Hkxk1dwuRr8Xy/PwtbDuSYnaoYqIvVsaz73g6gWW9eLxbHbPDERGREkxdAyIiIjh71yNrViSyZkX+SM/iv+udPer7T6Tz5aoEvlyVQPPw8twdWZXeTcPw8bKZHbIUkeOpmby7eDcAT0XVw0/zFoiISCFSkS4iIvIvAb5ePNihFve3r8mqfSeZvjqBn35PJO7gaeIOnubl77dx6zVVuDuyKnWDy5kdrhSy//y0k9TMHJpU9uf2luFmhyMiIiWcinQREZELsFotXFs7kGtrB3I8NZM56w8yc00CB/84y+e/xTN1ZTwrn+lKiL+32aFKIdlyKJmv1h8E4MWbGmK1mrdUn4iIlA4q0kVERC5DpXJ2HulUm4c61GL5nhNMX32ArByHCvQSzt/Hky71gijn7UHLagFmhyMiIqWAJo4TERG5AlarhQ51K/HRgAg+HdTK7HCKhQkTJlC9enW8vb2JjIxkzZo1Fzx27ty5REREUL58eXx9fWnevDnTpk3Ld8zgwYOxWCz5th49ehR2M86rasUyTB7cijdua2rK9xcRkdJHPekiIiIFZNPQZ2bPnk10dDSTJk0iMjKS8ePHExUVxc6dOwkKCjrn+ICAAJ577jnq16+Pl5cX33//PUOGDCEoKIioqKi843r06MGUKVPyvrbb7UXSnguxe2iiQBERKRrqSRcREZECGzduHA888ABDhgyhYcOGTJo0iTJlyvDZZ5+d9/hOnTpx880306BBA2rVqsWwYcNo2rQpy5cvz3ec3W4nJCQkb6tQoUJRNEdERMR0KtJFRESkQLKysli/fj3dunXL22e1WunWrRsrV6685PmGYRAbG8vOnTvp0KFDvveWLFlCUFAQ9erV4+GHH+bkyZMuj19ERKQ40nB3ERERKZATJ06Qm5tLcHBwvv3BwcHs2LHjguclJydTuXJlMjMzsdlsfPjhh1x//fV57/fo0YNbbrmFGjVqsHfvXp599ll69uzJypUrsdnOP+w8MzOTzMzMvK9TUlKusnUiIiLmUJEuIiIiRapcuXLExcWRlpZGbGws0dHR1KxZk06dOgHQr1+/vGObNGlC06ZNqVWrFkuWLKFr167nvWZMTAxjx44tivBFREQKlYa7i4iISIEEBgZis9lISkrKtz8pKYmQkJALnme1WqlduzbNmzdnxIgR3HbbbcTExFzw+Jo1axIYGMiePXsueMyoUaNITk7O2w4ePHjlDRIRESkGVKSLiIhIgXh5edGyZUtiY2Pz9jkcDmJjY2nbtu1lX8fhcOQbqv5vhw4d4uTJk4SGhl7wGLvdjp+fX75NRETEHWm4u4iIiBRYdHQ0gwYNIiIigtatWzN+/HjS09MZMmQIAAMHDqRy5cp5PeUxMTFERERQq1YtMjMz+eGHH5g2bRoTJ04EIC0tjbFjx3LrrbcSEhLC3r17GTlyJLVr1863RJuIiEhJpSJdRERECuzOO+/k+PHjjBkzhsTERJo3b87ChQvzJpNLSEjAav174F56ejqPPPIIhw4dwsfHh/r16/Pll19y5513AmCz2di8eTNTp07l9OnThIWF0b17d15++WXT10oXEREpChbDMAyzgyhKKSkp+Pv7k5ycrKFwIiJSLCg3uZ7uqYiIFCdXkpf0TLqIiIiIiIhIMVHqhrv/NXBA66eKiEhx8VdOKmWD2wqV8r2IiBQnV5LrS12RnpqaCkB4eLjJkYiIiOSXmpqKv7+/2WGUCMr3IiJSHF1Ori91z6Q7HA6OHDlCuXLlsFgsV329lJQUwsPDOXjwYIl75q2ktq2ktgvUNneltrknV7bNMAxSU1MJCwvLN8maFJwr873+O3ZPapv7KantArXNXZmV60tdT7rVaqVKlSouv25JXpO1pLatpLYL1DZ3pba5J1e1TT3orlUY+V7/Hbsntc39lNR2gdrmroo61+vP9SIiIiIiIiLFhIp0ERERERERkWJCRfpVstvtvPDCC9jtdrNDcbmS2raS2i5Q29yV2uaeSnLbJL+S/LNW29xTSW1bSW0XqG3uyqy2lbqJ40RERERERESKK/Wki4iIiIiIiBQTKtJFREREREREigkV6SIiIiIiIiLFhIp0ERERERERkWJCRfpVmDBhAtWrV8fb25vIyEjWrFljdkhXLSYmhlatWlGuXDmCgoLo27cvO3fuNDusQvH6669jsVgYPny42aG4xOHDh7nnnnuoWLEiPj4+NGnShHXr1pkd1lXLzc1l9OjR1KhRAx8fH2rVqsXLL7+MO855uWzZMnr37k1YWBgWi4X58+fne98wDMaMGUNoaCg+Pj5069aN3bt3mxPsFbpY27Kzs3n66adp0qQJvr6+hIWFMXDgQI4cOWJewFfgUj+3f3rooYewWCyMHz++yOKTwqVc796U692Dcr1yvdmKW65XkV5As2fPJjo6mhdeeIENGzbQrFkzoqKiOHbsmNmhXZWlS5cydOhQVq1axaJFi8jOzqZ79+6kp6ebHZpLrV27lo8++oimTZuaHYpLnDp1inbt2uHp6cmPP/7Itm3bePvtt6lQoYLZoV21N954g4kTJ/LBBx+wfft23njjDd58803ef/99s0O7Yunp6TRr1owJEyac9/0333yT9957j0mTJrF69Wp8fX2JiooiIyOjiCO9chdr25kzZ9iwYQOjR49mw4YNzJ07l507d3LTTTeZEOmVu9TP7S/z5s1j1apVhIWFFVFkUtiU692bcr37UK5Xrjdbscv1hhRI69atjaFDh+Z9nZuba4SFhRkxMTEmRuV6x44dMwBj6dKlZofiMqmpqUadOnWMRYsWGR07djSGDRtmdkhX7emnnzbat29vdhiFolevXsa9996bb98tt9xi9O/f36SIXAMw5s2bl/e1w+EwQkJCjLfeeitv3+nTpw273W7MnDnThAgL7t9tO581a9YYgHHgwIGiCcpFLtS2Q4cOGZUrVza2bt1qVKtWzXjnnXeKPDZxPeV696Vc716U65Xri5PikOvVk14AWVlZrF+/nm7duuXts1qtdOvWjZUrV5oYmeslJycDEBAQYHIkrjN06FB69eqV7+fn7r799lsiIiK4/fbbCQoKokWLFnzyySdmh+US1157LbGxsezatQuATZs2sXz5cnr27GlyZK61f/9+EhMT8/136e/vT2RkZIn7XAHnZ4vFYqF8+fJmh3LVHA4HAwYM4KmnnqJRo0ZmhyMuolzv3pTr3YtyvXJ9cVfUud6j0L9DCXTixAlyc3MJDg7Otz84OJgdO3aYFJXrORwOhg8fTrt27WjcuLHZ4bjErFmz2LBhA2vXrjU7FJfat28fEydOJDo6mmeffZa1a9fy+OOP4+XlxaBBg8wO76o888wzpKSkUL9+fWw2G7m5ubz66qv079/f7NBcKjExEeC8nyt/vVdSZGRk8PTTT3PXXXfh5+dndjhX7Y033sDDw4PHH3/c7FDEhZTr3ZdyvftRrleuL+6KOterSJcLGjp0KFu3bmX58uVmh+ISBw8eZNiwYSxatAhvb2+zw3Eph8NBREQEr732GgAtWrRg69atTJo0ye0T91dffcX06dOZMWMGjRo1Ii4ujuHDhxMWFub2bSuNsrOzueOOOzAMg4kTJ5odzlVbv3497777Lhs2bMBisZgdjsgVU653H8r14i6U66+ehrsXQGBgIDabjaSkpHz7k5KSCAkJMSkq13r00Uf5/vvv+eWXX6hSpYrZ4bjE+vXrOXbsGNdccw0eHh54eHiwdOlS3nvvPTw8PMjNzTU7xAILDQ2lYcOG+fY1aNCAhIQEkyJynaeeeopnnnmGfv360aRJEwYMGMATTzxBTEyM2aG51F+fHSX5c+WvpH3gwAEWLVpUIv6y/uuvv3Ls2DGqVq2a97ly4MABRowYQfXq1c0OT66Ccr17Uq53T8r1JedzRbneNVSkF4CXlxctW7YkNjY2b5/D4SA2Npa2bduaGNnVMwyDRx99lHnz5vHzzz9To0YNs0Nyma5du7Jlyxbi4uLytoiICPr3709cXBw2m83sEAusXbt25yyfs2vXLqpVq2ZSRK5z5swZrNb8H1U2mw2Hw2FSRIWjRo0ahISE5PtcSUlJYfXq1W7/uQJ/J+3du3ezePFiKlasaHZILjFgwAA2b96c73MlLCyMp556ip9++sns8OQqKNe7J+V696Rcr1xfnJmR6zXcvYCio6MZNGgQERERtG7dmvHjx5Oens6QIUPMDu2qDB06lBkzZvDNN99Qrly5vOdj/P398fHxMTm6q1OuXLlznrfz9fWlYsWKbv8c3hNPPMG1117La6+9xh133MGaNWv4+OOP+fjjj80O7ar17t2bV199lapVq9KoUSM2btzIuHHjuPfee80O7YqlpaWxZ8+evK/3799PXFwcAQEBVK1aleHDh/PKK69Qp04datSowejRowkLC6Nv377mBX2ZLta20NBQbrvtNjZs2MD3339Pbm5u3mdLQEAAXl5eZoV9WS71c/v3LyGenp6EhIRQr169og5VXEy53v0o17sn5XrlerMVu1xfaPPGlwLvv/++UbVqVcPLy8to3bq1sWrVKrNDumrAebcpU6aYHVqhKCnLshiGYXz33XdG48aNDbvdbtSvX9/4+OOPzQ7JJVJSUoxhw4YZVatWNby9vY2aNWsazz33nJGZmWl2aFfsl19+Oe//X4MGDTIMw7k0y+jRo43g4GDDbrcbXbt2NXbu3Glu0JfpYm3bv3//BT9bfvnlF7NDv6RL/dz+TUuwlSzK9e5Pub74U65Xrjdbccv1FsMwDFcW/SIiIiIiIiJSMHomXURERERERKSYUJEuIiIiIiIiUkyoSBcREREREREpJlSki4iIiIiIiBQTKtJFREREREREigkV6SIiIiIiIiLFhIp0ERERERERkWJCRbpIKTZs2DAefPBBHA6H2aGIiIhIIVCuF3E/KtJFSqmDBw9Sr149PvroI6xWfRSIiIiUNMr1Iu7JYhiGYXYQIiIiIiIiIqKedJFSZ/DgwVgslnO2Hj16mB2aiIiIuIByvYh78zA7ABEpej169GDKlCn59tntdpOiEREREVdTrhdxX+pJFymF7HY7ISEh+bYKFSoAYLFYmDhxIj179sTHx4eaNWvy3//+N9/5W7ZsoUuXLvj4+FCxYkUefPBB0tLS8h3z2Wef0ahRI+x2O6GhoTz66KN5740bN44mTZrg6+tLeHg4jzzyyDnni4iISMEp14u4LxXpInKO0aNHc+utt7Jp0yb69+9Pv3792L59OwDp6elERUVRoUIF1q5dy5w5c1i8eHG+xDxx4kSGDh3Kgw8+yJYtW/j222+pXbt23vtWq5X33nuP33//nalTp/Lzzz8zcuTIIm+niIhIaaVcL1KMGSJSqgwaNMiw2WyGr69vvu3VV181DMMwAOOhhx7Kd05kZKTx8MMPG4ZhGB9//LFRoUIFIy0tLe/9BQsWGFar1UhMTDQMwzDCwsKM55577rJjmjNnjlGxYsWrbZqIiIgYyvUi7k7PpIuUQp07d2bixIn59gUEBOS9btu2bb732rZtS1xcHADbt2+nWbNm+Pr65r3frl07HA4HO3fuxGKxcOTIEbp27XrB77948WJiYmLYsWMHKSkp5OTkkJGRwZkzZyhTpowLWigiIlK6KdeLuC8NdxcphXx9faldu3a+7Z+J+2r4+Phc9P34+HhuvPFGmjZtytdff8369euZMGECAFlZWS6JQUREpLRTrhdxXyrSReQcq1atOufrBg0aANCgQQM2bdpEenp63vsrVqzAarVSr149ypUrR/Xq1YmNjT3vtdevX4/D4eDtt9+mTZs21K1blyNHjhReY0REROQcyvUixZeGu4uUQpmZmSQmJubb5+HhQWBgIABz5swhIiKC9u3bM336dNasWcPkyZMB6N+/Py+88AKDBg3ixRdf5Pjx4zz22GMMGDCA4OBgAF588UUeeughgoKC6NmzJ6mpqaxYsYLHHnuM2rVrk52dzfvvv0/v3r1ZsWIFkyZNKtobICIiUsIp14u4MbMfiheRojVo0CADOGerV6+eYRjOyWQmTJhgXH/99YbdbjeqV69uzJ49O981Nm/ebHTu3Nnw9vY2AgICjAceeMBITU3Nd8ykSZOMevXqGZ6enkZoaKjx2GOP5b03btw4IzQ01PDx8TGioqKML774wgCMU6dOFXr7RURESjrlehH3ZjEMwzDjjwMiUjxZLBbmzZtH3759zQ5FRERECoFyvUjxpmfSRURERERERIoJFekiIiIiIiIixYSGu4uIiIiIiIgUE+pJFxERERERESkmVKSLiIiIiIiIFBMq0kVERERERESKCRXpIiIiIiIiIsWEinQRERERERGRYkJFuoiIiIiIiEgxoSJdREREREREpJhQkS4iIiIiIiJSTKhIFxERERERESkm/h9khjDxIbU3xwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = historyWord2VecFastText.history['loss']\n",
    "val_loss = historyWord2VecFastText.history['val_loss']\n",
    "train_accuracy = historyWord2VecFastText.history['sparse_categorical_accuracy']\n",
    "val_accuracy = historyWord2VecFastText.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Entrenamiento')\n",
    "plt.plot(val_loss, label='Validación')\n",
    "plt.title('Curva de pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Entrenamiento')\n",
    "plt.plot(val_accuracy, label='Validación')\n",
    "plt.title('Curva de precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dictionary = dict()\n",
    "\n",
    "glove_file = open('glove.6B.300d.txt', encoding='utf-8')\n",
    "for linea in glove_file:\n",
    "    values = linea.split()\n",
    "    word = values[0]\n",
    "    vector_dimensiones = np.asarray(values[1:], dtype=\"float32\") #se obtiene el vector de pesos\n",
    "    embedding_dictionary[word] = vector_dimensiones #a cada palabra se define el vector de pesos\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_pesos_matrix_para_cada_palabra(call_model):\n",
    "    weights_matrix = np.zeros((vocab_size, maximo_largo))\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        embedding_vector = call_model.get(word) #se transforma y se obtiene la matriz de pesos\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            weights_matrix[index] = embedding_vector\n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embeddings_Glove = obtener_pesos_matrix_para_cada_palabra(embedding_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 300, 300)          4534200   \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirecti  (None, 300, 512)         1140736   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_24 (Bidirecti  (None, 256)              656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,365,119\n",
      "Trainable params: 1,830,919\n",
      "Non-trainable params: 4,534,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Conv1D, Input, LeakyReLU, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "\n",
    "input_seq  = Input(shape=(maximo_largo,), dtype='int32')\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=maximo_largo, weights=[Embeddings_Glove], input_length=maximo_largo, trainable=False)(input_seq)\n",
    "lstm1 = Bidirectional(LSTM(256, return_sequences=True, dropout=0.25))(embedding_layer)\n",
    "lstm2 = Bidirectional(LSTM(128, dropout=0.25))(lstm1)\n",
    "dense = Dense(128)(lstm2)\n",
    "dense = LeakyReLU(alpha=0.2)(dense)\n",
    "output = Dense(7, activation=\"softmax\")(dense)\n",
    "\n",
    "modelBiLstmGlove = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "modelBiLstmGlove.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "modelBiLstmGlove.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_IEMOCAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
