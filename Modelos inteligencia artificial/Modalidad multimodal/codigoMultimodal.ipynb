{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) física(s), 1 GPU(s) lógica(s)\n",
      "Funciona\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"GPU(s) física(s),\", len(logical_gpus), \"GPU(s) lógica(s)\")\n",
    "        print(\"Funciona\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cv2 import CascadeClassifier\n",
    "import os\n",
    "import re\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import bert\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import TFRobertaModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "\n",
    "def set_seed(seed=42):\n",
    "  np.random.seed(seed) \n",
    "  tf.random.set_seed(seed) \n",
    "  random.seed(seed)\n",
    "  os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "  os.environ['TF_CUDNN_DETERMINISM'] = \"1\"\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Modelo cargado text\n",
      "Modelo cargado facial\n"
     ]
    }
   ],
   "source": [
    "def custom_objects_fn():\n",
    "    return {'TFRobertaModel': TFRobertaModel}\n",
    "\n",
    "modeltext = load_model('BERT_CNN_model_best_13_val_0.7836.h5', custom_objects=custom_objects_fn())\n",
    "print(\"Modelo cargado text\")\n",
    "modelfacial = load_model('best_model_ModelPaper1_200_7020Test.h5')\n",
    "print(\"Modelo cargado facial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " model_42 (Functional)          (None, 7)            43426146    ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 7)            125731463   ['input_ids[0][0]',              \n",
      "                                                                  'attention_mask[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 14)           0           ['model_42[2][0]',               \n",
      "                                                                  'model[2][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 169,157,609\n",
      "Trainable params: 125,731,519\n",
      "Non-trainable params: 43,426,090\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_input = tf.keras.layers.Input(shape=(48,48,3), name='image_input')\n",
    "text_input_ids = tf.keras.layers.Input(shape=(300,), dtype=tf.int32, name='input_ids')\n",
    "text_attention_mask = tf.keras.layers.Input(shape=(300,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "features_facial = modelfacial(image_input)\n",
    "features_text = modeltext([text_input_ids,text_attention_mask])\n",
    "merged = tf.keras.layers.Concatenate()([features_facial, features_text])\n",
    "\n",
    "multimodal_model = tf.keras.models.Model(inputs=[image_input,text_input_ids,text_attention_mask], outputs=merged)\n",
    "multimodal_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "multimodal_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "def prepare_text_data(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='tf', padding='max_length', truncation=True, max_length=300)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_masks = inputs['attention_mask']\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def prepare_image_data(image_filepath):\n",
    "    image_data = []\n",
    "    image = Image.open(image_filepath).convert('L')\n",
    "    image = image.resize((48, 48))\n",
    "    image = np.array(image) / 255.0  \n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    image_data.append(image)\n",
    "    return np.array(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_multimodal(text, image_filepaths):\n",
    "    text_data = text\n",
    "    text_input_ids, text_attention_masks = prepare_text_data(text_data)\n",
    "\n",
    "    image_data = image_filepaths\n",
    "    image_inputs = prepare_image_data(image_data)\n",
    "\n",
    "    predictions = multimodal_model.predict([image_inputs, text_input_ids, text_attention_masks])\n",
    "    return predictions\n",
    "\n",
    "texts = \"I think is lineal model\"\n",
    "image_filepaths = \"test.png\"\n",
    "\n",
    "predictions = predict_multimodal(texts, image_filepaths)\n",
    "clases = [\"enojado\", \"disgusto\", \"asustado\", \"feliz\", \"neutral\", \"triste\", \"sorprendido\"]\n",
    "predictions_indice = np.argmax(predictions)\n",
    "emotion_final = clases[predictions_indice]\n",
    "print(emotion_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_IEMOCAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
